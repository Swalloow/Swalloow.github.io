<?xml version="1.0" encoding="UTF-8" ?>

<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
   
      <title>swalloow.github.io/</title>
   
   <link>http://swalloow.github.io/</link>
   <description>About Data Science, Data Engineering</description>
   <language>ko-KO</language>
   <managingEditor> Swalloow</managingEditor>
   <atom:link href="rss" rel="self" type="application/rss+xml" />
   
	<item>
	  <title>빅데이터 처리에 Scala가 필요한 이유</title>
	  <link>//scala-for-bigdata</link>
	  <author>Swalloow</author>
	  <pubDate>2017-03-17T19:18:00+09:00</pubDate>
	  <guid>//scala-for-bigdata</guid>
	  <description><![CDATA[
	     <p>​   ​</p>

<p>StackOverFlow나 Quora를 보면 <strong>Scala has taken over the Big Data world.</strong> 라는 글을 많이 볼 수 있습니다.
게다가 Spark의 엔진은 Scala로 구현되어 있습니다. 이 포스팅에서는 데이터를 다루는데에 스칼라가 가지는 강점이 무엇인지 알아보고자 합니다.</p>

<p>​   ​</p>

<h2 id="scala--">Scala가 가지는 강점</h2>

<p>​   ​</p>

<h4 id="static-typing-type-inference">Static Typing, Type Inference</h4>

<p>스칼라의 <code class="highlighter-rouge">val</code> 변수는 한번 지정된 값을 바꾸지 않습니다.
이러한 변수를 <code class="highlighter-rouge">Immutable variable</code> 이라고 부릅니다. 예를 들면 아래와 같습니다.</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="n">msg</span> <span class="k">=</span> <span class="s">"Hello Scala"</span>
<span class="nc">String</span> <span class="k">=</span> <span class="nc">Hello</span> <span class="nc">Scala</span>

<span class="k">val</span> <span class="n">msg</span> <span class="k">=</span> <span class="s">"Reassign to val"</span>
<span class="n">error</span><span class="k">:</span> <span class="kt">reassignment</span> <span class="kt">to</span> <span class="kt">val</span></code></pre></figure>

<p>위의 예제를 보면, msg 변수에 문자열을 할당했지만 어디에도 String 이라는 단어는 없습니다.
스칼라는 알아서 타입을 추론하여 지정해주기 때문입니다.
따라서, <code class="highlighter-rouge">val</code> 변수에 재할당을 시도하면 <code class="highlighter-rouge">reassignment to val</code> 이라는 오류가 발생하게 됩니다.</p>

<p>이처럼 스칼라는 input 타입을 보고 함수나 출력 값의 타입을 추론해주며 이를 통해 코드를 깔끔하게 유지할 수 있습니다.
또한, 다양하고 많은 데이터가 사용되는 경우 정적변수가 문제를 단순화 해주는 효과가 있습니다.</p>

<p>​   ​</p>

<h4 id="scalable-language">Scalable Language</h4>

<p>기존의 Hadoop 기반의 데이터 인프라는 자바 언어를 통해 MapReduce 연산 그리고 알고리즘을 구현해야했습니다.
하지만 자바는 코드가 너무 길어 생산성 그리고 가독성이 매우 떨어집니다.</p>

<p>스칼라는 모든 것들이 일관성있게 그리고 간결하게 구현되도록 설계되었습니다.
이를 통해 얻을 수 있는 장점은 <strong>“적은 양의 코드로 방대한 규모의 시스템을 작성할 수 있다”</strong> 는 것입니다.</p>

<p>연산자를 예로 들어보겠습니다.
자바에서는 ‘==’ 와 같은 비교연산자를 제공합니다.
하지만 비교연산자는 주소값을 비교하기 때문에
String과 같은 객체를 비교할 때는 <code class="highlighter-rouge">equal()</code> 메서드를 사용해서 비교해야 했습니다.
이 또한 스칼라의 Scalable과 거리가 멉니다.
스칼라에서는 모든 것이 Object이기 때문에 <code class="highlighter-rouge">==</code> 로 모든 비교가 가능합니다.</p>

<p>​   ​</p>

<h4 id="object-oriented-functional-language">Object Oriented, Functional Language</h4>

<figure class="highlight"><pre><code class="language-markdown" data-lang="markdown">y1 = 2x + 5
y2 = 4(y1) = 4(2x + 5)</code></pre></figure>

<p>함수형 언어를 이해하기 전에 어렸을 때 배웠던 함수식을 떠올려보겠습니다.
위의 식에서 x는 input, y는 output이 됩니다.
우리는 어떤 함수에 input을 넣으면 output이 나온다고 이해하고 있습니다.
그리고 아래의 식처럼 함수를 인자로 넣을 수도 있습니다 (합성함수).
함수형 언어도 이와 비슷합니다.</p>

<p>스칼라는 객체지향 프로그래밍과 함수형 프로그래밍을 모두 완벽하게 지원하는 언어입니다.
스칼라에서는 모든 것이 객체이며 함수가 <code class="highlighter-rouge">first object</code> 입니다.
함수를 마치 하나의 값으로 취급하며 이를 변수 또는 파라미터로 넘길 수 있습니다.</p>

<p>모든 것을 함수로 해결하면 의도하지 않은 동작(Side Effect)이 발생할 일이 없고,
한번 검증된 함수는 신뢰할 수 있기 때문에 버그가 줄어드는 효과가 있습니다.
또한, Immutable 변수는 문제를 단순화시켜주기 때문에 데이터 공유, 병렬처리에 강합니다.</p>

<p>​   ​</p>

<h2 id="java-scala-">Java와 Scala를 비교해보자</h2>

<p>Scala는 Interactive한 Shell을 제공합니다.
이렇게 바로 확인할 수 있는 Shell을 통해 데이터의 탐색적 분석이 가능합니다.
IntelliJ IDEA에서도 <code class="highlighter-rouge">Worksheet</code>이라는 기능을 통해 사용할 수 있습니다.
스칼라 개발환경은 <strong>Scala 2.12.1</strong> 이며, IDE는 <strong>IntelliJ IDEA</strong> 를 사용하였습니다.</p>

<p><img src="/assets/images/intellij.png" alt="IntelliJ" /></p>

<p>간단한 WordCount 예제를 통해 코드를 비교해보곘습니다.</p>

<h4 id="java-hadoop-word-count">JAVA Hadoop Word Count</h4>
<script src="https://gist.github.com/Swalloow/25a96ff50fdb60a9859972fa0e4bb92b.js"></script>

<p>​   ​</p>

<h4 id="scala-spark-word-count">Scala Spark Word Count</h4>
<script src="https://gist.github.com/Swalloow/ddc125f58b2b2ca4815444557d769bdb.js"></script>

<p>​   ​</p>

<h2 id="section">정리하자면,</h2>

<ul>
  <li>파이썬과 같이 아주 간결한 문법</li>
  <li>객체지향과 함수형 프로그래밍 모두 가능</li>
  <li>자바와 호환되며 JVM 위에서 실행되기 때문에 좋은 성능</li>
  <li>정적 타입을 지향</li>
  <li>REPL Shell을 활용하여 Scripting</li>
</ul>

<p>​   ​</p>

	  ]]></description>
	</item>

	<item>
	  <title>GFS, HDFS 그리고 MapReduce</title>
	  <link>//map-reduce</link>
	  <author>Swalloow</author>
	  <pubDate>2017-03-14T19:18:00+09:00</pubDate>
	  <guid>//map-reduce</guid>
	  <description><![CDATA[
	     <p>​   ​</p>

<p>데이터가 급속히 늘어나면서 기존의 방법으로 처리가 힘들어지자,
빅데이터를 위한 대용량 분산 파일 시스템이 나타나기 시작했습니다.
여기에서는 GFS, HDFS 그리고 Map Reduce 개념에 대해 정리해보려고 합니다.</p>

<p>​   ​</p>

<h2 id="gfs-google-file-system">GFS (Google File System)</h2>

<p>Google File System은 2003년 논문을 통해 소개되었습니다.
이전에 구글에서 사용하던 파일 시스템은 Big File 이었는데,
구글의 데이터가 급격히 늘어남에 따라 핵심 데이터 스토리지와 구글 검색 엔진을 위해
최적화 된 파일 시스템이 필요하게 된 것 입니다.</p>

<p><img src="/assets/images/GFS.png" alt="Google File System" /></p>

<p>GFS는 크게 하나의 master node와 여러 개의 slave node로 구성되어 있습니다.
기능으로 보면 Master, Chunk Server, Client로 이루어져 있습니다.</p>

<ul>
  <li><strong>Master</strong>: GFS 전체를 관리하고 통제하는 중앙 서버의 역할</li>
  <li><strong>Chunk Server</strong>: 물리적인 서버, 실제 입출력을 처리</li>
  <li><strong>Client</strong>: 파일 입출력을 요청하는 클라이언트 어플리케이션</li>
</ul>

<p>수행과정은 다음과 같습니다.
먼저 Client가 Master에게 파일의 읽기, 쓰기를 요청하게 되면,
Master는 Client와 가까운 Chunk Server의 정보를 Client에게 전달합니다.
Client는 전달받은 Chunk Server와 직접 통신하며 IO 작업을 수행하게 됩니다.</p>

<p>GFS의 엄청난 강점은 <strong>Failuer Tolerance</strong> 입니다.
다시 말해서, 물리적으로 서버 중 하나가 고장이 나도 정지하지 않고 잘 돌아가도록 설계되었습니다.
예를 들어, Chunk Server 중 하나가 고장이 나면 Master는 고장나지 않은 Chunk Server의 정보를 전달하고
Master Server가 고장이 나면 다른 서버가 Master를 대체하게 됩니다.
이러한 이유로 Chunk Server는 가격이 저렴한 범용 컴퓨터들로 구성할 수 있게 되었고, 클러스터 환경에서 잘 동작할 수 있게 되었습니다.</p>

<p>​   ​</p>

<h2 id="mapreduce">MapReduce</h2>

<p>Map Reduce는 마찬가지로 2004년 구글의 논문(저자: 구글의 전설 제프 딘)을 통해 소개되었습니다.
논문의 제목은 <strong>MapReduce: Simplified Data Processing on Large Clusters</strong> 입니다.
즉, MapReduce는 말 그대로 대용량 분산 클러스터에서 데이터를 간단히 처리하는 방법입니다.</p>

<p>그는 논문을 통해 2가지 Function을 제시하는데 바로 Map과 Reduce 입니다.
논문에서 제시한 MapReduce의 예시 수도코드는 다음과 같습니다.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="nb">map</span><span class="p">(</span><span class="n">String</span> <span class="n">key</span><span class="p">,</span> <span class="n">String</span> <span class="n">value</span><span class="p">):</span>
    <span class="o">//</span> <span class="n">key</span><span class="p">:</span> <span class="n">document</span> <span class="n">name</span>
    <span class="o">//</span> <span class="n">value</span><span class="p">:</span> <span class="n">document</span> <span class="n">contents</span>
    <span class="k">for</span> <span class="n">each</span> <span class="n">word</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">value</span><span class="p">:</span>
        <span class="n">EmitIntermediate</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="s">"1"</span><span class="p">)</span>

<span class="nb">reduce</span><span class="p">(</span><span class="n">String</span> <span class="n">key</span><span class="p">,</span> <span class="n">Iterator</span> <span class="n">values</span><span class="p">):</span>
    <span class="o">//</span> <span class="n">key</span><span class="p">:</span> <span class="n">a</span> <span class="n">word</span>
    <span class="o">//</span> <span class="n">values</span><span class="p">:</span> <span class="n">a</span> <span class="nb">list</span> <span class="n">of</span> <span class="n">counts</span>
    <span class="nb">int</span> <span class="n">result</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="k">for</span> <span class="n">each</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">values</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">+=</span> <span class="n">ParseInt</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
    <span class="n">Emit</span><span class="p">(</span><span class="n">AsString</span><span class="p">(</span><span class="n">result</span><span class="p">))</span></code></pre></figure>

<p>먼저 <strong>Map</strong> 함수는 어떤 key-value를 input으로 받아서 각 단어와 관련 발생 횟수를 출력합니다.
그리고 <strong>Reduce</strong> 함수는 특정 단어에 대해 생성된 모든 카운트를 합산합니다.</p>

<figure class="highlight"><pre><code class="language-markdown" data-lang="markdown">map(k1, v1) -&gt; list(k2, v2)
reduce(k2, list(v2)) -&gt; list(v2)</code></pre></figure>

<p><strong>Map</strong> 함수는 key-vale를 읽어서 필터링하거나 다른 값으로 변환시켜주며,
<strong>Reduce</strong> 함수는 Map을 통해 출력된 리스트에
새로운 key를 기준으로 Groupping하고 이를 Aggregation한 결과를 출력합니다.</p>

<p><img src="/assets/images/mapreduce.png" alt="MapReduce" /></p>

<p>MapReduce는 여러 대의 컴퓨터에서 데이터를 처리하는 경우, 병렬처리를 하기 때문에 확장이 쉽습니다.
스케줄러가 데이터를 분산 배치하면 worker에서 작업을 수행하고 각 중간 결과는 로컬 디스크에 저장되며,
나중에 Reduce 연산을 할당받으면 중간 결과를 읽어와서 작업을 수행하고 마찬가지로 파일 시스템에 저장합니다.
위의 그림과 같이 Master 노드에 모든 데이터를 받아서 처리하던 옛날 방식과 통신 처리면에서 확실히 줄어든 것을 알 수 있습니다.</p>

<p>구글은 MapReduce를 URL 접근빈도, Web-Link Graph를 계산하는데 사용하였고,
이를 통해 인덱싱, 정렬 등에서 엄청난 성능향상을 보여주었습니다.</p>

<p>​   ​</p>

<h2 id="hdfs-hadoop-distributed-file-system">HDFS (Hadoop Distributed File System)</h2>

<p>Hadoop은 2006년 Doug Cutting과 Mike Cafarella가 개발한 분산처리 프레임워크입니다.
이들은 구글의 GFS를 대체하기 위해 <strong>HDFS</strong> 와 <strong>MapReduce</strong> 를 구현하였습니다.</p>

<p>GFS가 C++로 구현되었다면, Hadoop은 자바로 개발된 데다가 아파치 재단의 오픈소스로 넘어가면서 인기가 많아졌습니다.
GFS를 구현한 결과물이기 때문에 크게 달라진 것은 없으나
<strong>YARN, Hadoop Ecosystem</strong> 등 다른 장점으로 인해 많이 사용됩니다.</p>

<p>​   ​</p>

<h2 id="reference">Reference</h2>

<ul>
  <li><a href="http://xpgc.vicp.net/course/svt/TechDoc/storagepaper/gfs-sosp2003.pdf">논문: The Google File System</a></li>
  <li><a href="https://static.googleusercontent.com/media/research.google.com/ko//archive/mapreduce-osdi04.pdf">논문: MapReduce - Simplified Data Processing on Large Clusters</a></li>
</ul>

<p>​   ​</p>

	  ]]></description>
	</item>

	<item>
	  <title>OS X에서 Homebrew로 Spark, Zeppelin 설치하기</title>
	  <link>//spark-zeppelin-install</link>
	  <author>Swalloow</author>
	  <pubDate>2017-03-13T19:18:00+09:00</pubDate>
	  <guid>//spark-zeppelin-install</guid>
	  <description><![CDATA[
	     <p>​   ​</p>

<blockquote>
  <p><strong>Apache Spark</strong> is a fast and general engine for large-scale data processing.
<strong>Zeppelin</strong>, a web-based notebook that enables interactive data analytics.
You can make beautiful data-driven, interactive and collaborative documents with SQL, Scala and more.</p>
</blockquote>

<p>공식 문서에 나와있는 소개 글처럼 Spark는 대용량 데이터 처리를 위한 범용 엔진입니다.
얼마 전까지는 <strong>범용적 목적의 분산 고성능 클러스터링 플랫폼</strong> 이라고 설명했는데 최근에 쉽게 다가가기 위해 바꾼듯 합니다.</p>

<p>그리고 Zeppelin은 데이터 분석을 위한 웹 기반의 노트북입니다.
Zeppelin은 작년 말부터 Apache-Top Level project로 승격하면서 인기가 높아지고 있습니다.
Zeppelin이 Jupyter Notebook과 다른 점은 빅데이터 처리를 위해 Spark 등 다양한 아파치 프로젝트를 지원하고,
Javascript 기반의 데이터 시각화가 내장되어 있어 편리합니다.</p>

<p>​   ​</p>

<h2 id="spark-install">Spark Install</h2>

<p>Spark는 Scala로 구현되어 있지만 SDK를 통해 Java, Python API 또한 지원합니다.
그리고 빅데이터 플랫폼으로 Hadoop, AWS S3, Cassandra 등 다양한 저장소를 지원합니다.
만약 Hadoop이 필요없다면 홈페이지에서 Hadoop이 제외된 바이너리 파일로 설치하시면 됩니다.
여기에서는 간단하게 OS X의 Homebrew를 통해 설치하도록 하겠습니다.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="gp">$ </span>brew install scala
<span class="gp">$ </span><span class="nb">export </span><span class="nv">SCALA_HOME</span><span class="o">=</span>/usr/local/bin/scala
<span class="gp">$ </span><span class="nb">export </span><span class="nv">PATH</span><span class="o">=</span><span class="nv">$PATH</span>:<span class="nv">$SCALA_HOME</span>/bin</code></pre></figure>

<p>먼저 스칼라를 설치하고 환경변수를 저장합니다.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="gp">$ </span>brew install apache-spark
<span class="gp">$ </span>spark-shell</code></pre></figure>

<p>그리고 Spark을 설치한 다음, <code class="highlighter-rouge">spark-shell</code> 명령을 통해 실행시키면 됩니다.</p>

<p><img src="/assets/images/spark-shell.png" alt="spark-shell" /></p>

<p><a href="http://172.30.105.117:4040">http://172.30.105.117:4040</a> 주소로 접속하면 Spark UI를 확인할 수 있습니다.</p>

<p><img src="/assets/images/spark-ui.png" alt="spark-ui" /></p>

<p>​   ​</p>

<h2 id="zeppelin-install">Zeppelin Install</h2>

<p>Zeppelin은 GitHub 저장소를 clone하여 설치하는 방법과 홈페이지에서 다운받는 방법이 있습니다.
여기에서는 위와 마찬가지로 Homebrew를 통해 설치해보려 합니다.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="gp">$ </span>brew install apache-zeppelin
<span class="gp">$ </span>/usr/local/Cellar/apache-zeppelin/0.7.0/bin/zeppelin-daemon.sh start
<span class="gp">$ </span>/usr/local/Cellar/apache-zeppelin/0.7.0/bin/zeppelin-daemon.sh stop</code></pre></figure>

<p>brew 명령어로 apache-zeppelin을 설치하고
스크립트를 실행하면 <a href="localhost:8080">localhost:8080</a> 포트에서 Zeppelin을 사용할 수 있게 됩니다.
명령어가 너무 길다보니 <code class="highlighter-rouge">~/.zshrc</code>에 등록해서 사용하면 좀 편리합니다.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="gp">$ </span>vi ~/.zshrc
<span class="gp">$ </span><span class="nb">alias </span>zeppelin-start <span class="o">=</span> <span class="s2">"/usr/.../bin/zeppelin-daemon.sh start"</span>
<span class="gp">$ </span><span class="nb">alias </span>zeppelin-stop <span class="o">=</span> <span class="s2">"/usr/.../bin/zeppelin-daemon.sh stop"</span>
<span class="gp">$ </span><span class="nb">source</span> ~/.zshrc</code></pre></figure>

<p>위와 같이 alias로 등록해주면 앞으로 <code class="highlighter-rouge">zeppelin-start</code> 명령어를 통해 실행할 수 있게 됩니다.
자세한 환경설정은 <a href="https://zeppelin.apache.org/">Zeppelin 홈페이지</a>에서 확인하실 수 있습니다.</p>

<p>​   ​</p>

	  ]]></description>
	</item>

	<item>
	  <title>Pandas DataFrame을 병렬처리 하는 방법</title>
	  <link>//pandas-parallel</link>
	  <author>Swalloow</author>
	  <pubDate>2017-02-27T19:18:00+09:00</pubDate>
	  <guid>//pandas-parallel</guid>
	  <description><![CDATA[
	     <p>​   ​</p>

<p>Scikit-learn의 모델들은 cython과 joblib으로 최적화 및 자동 병렬처리 되도록 설계되어 있지만,
Pandas는 여전히 내부적으로 병렬처리 기능을 지원하지 않습니다.</p>

<p>하지만, 큰 규모의 DataFrame을 돌리다보면 전처리에도 시간이 많이 걸리게 됩니다.
그런 경우에 병렬처리를 통해 속도를 개선할 수 있습니다.</p>

<p>이 포스팅에서는 가장 간단한 CPU 프로세스 병렬처리를 다루도록 하겠습니다. 방법은 간단합니다.
거대한 DataFrame을 CPU 코어 수 만큼 분할하고, 전처리 기능을 수행한 다음 다시 합치면 됩니다.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="kn">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">multiprocessing</span> <span class="kn">import</span> <span class="n">Pool</span>

<span class="n">num_cores</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">iris</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">sns</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span><span class="s">'iris'</span><span class="p">))</span></code></pre></figure>

<p>예시로 iris 데이터를 사용하겠습니다.
cpu 코어의 수는 <code class="highlighter-rouge">multiprocessing.cpu_count()</code> 함수를 통해서 얻으실 수 있습니다.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">parallelize_dataframe</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">func</span><span class="p">):</span>
    <span class="n">df_split</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array_split</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">num_cores</span><span class="p">)</span>
    <span class="n">pool</span> <span class="o">=</span> <span class="n">Pool</span><span class="p">(</span><span class="n">num_cores</span><span class="p">)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">pool</span><span class="o">.</span><span class="nb">map</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">df_split</span><span class="p">))</span>
    <span class="n">pool</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="n">pool</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">df</span></code></pre></figure>

<p>parallelize_dataframe은 어떤 전처리 함수가 들어왔을 때 CPU 병렬처리를 도와주는 함수입니다.
multiprocessing.Pool을 이용하여 분할된 DataFrame에 함수를 적용시키고,
pd.concat()으로 다시 합치는 과정입니다.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">multiply_columns</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="n">data</span><span class="p">[</span><span class="s">'length_of_word'</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s">'species'</span><span class="p">]</span><span class="o">.</span><span class="nb">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">data</span></code></pre></figure>

<p>각 종 이름의 글자 수를 세는 전처리 함수를 예로 들어 속도차이를 확인해보겠습니다.
결과는 아래와 같습니다.</p>

<p>​   ​</p>

<p><img src="/assets/images/pandas-parallel.png" alt="pandas-parrallel" /></p>

<p>다른 방법으로 Pandas의 engine에 Dask를 사용하는 방법도 있습니다.
<a href="http://dask.readthedocs.io/en/latest/">http://dask.readthedocs.io/en/latest/</a></p>

<p>​   ​</p>

	  ]]></description>
	</item>

	<item>
	  <title>DataFrame을 MySQL에 저장하는 방법</title>
	  <link>//dataframe-to-mysql</link>
	  <author>Swalloow</author>
	  <pubDate>2017-02-26T19:18:00+09:00</pubDate>
	  <guid>//dataframe-to-mysql</guid>
	  <description><![CDATA[
	     <p>​</p>

<p>DataFrame을 MySQL에 저장하기 위해 먼저 커넥터가 필요합니다.
파이썬3에서는 <code class="highlighter-rouge">MySQLdb</code>를 지원하지 않기 때문에, <code class="highlighter-rouge">pymysql</code>로 불러와야 합니다.
꼭 pymysql이 아니어도 상관없지만, 사용해보면 <code class="highlighter-rouge">mysql-connector</code> 보다 빠르다는걸 체감할 수 있습니다.
먼저, 필요한 패키지를 설치해줍니다.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c"># python3</span>
<span class="err">$</span> <span class="n">pip</span> <span class="n">install</span> <span class="n">pymysql</span>
<span class="err">$</span> <span class="n">pip</span> <span class="n">install</span> <span class="n">sqlalchemy</span></code></pre></figure>

<p>​</p>

<h2 id="sqlalchemy-pymysql-mysqldb">SQLAlchemy, pymysql, MySQLdb</h2>

<p><code class="highlighter-rouge">install_as_MySQLdb()</code> 함수를 통해 MySQLdb와 호환 가능합니다.
이제 sqlalchemy를 통해 DB에 연결할 수 있습니다.
주소에서 root, password, table은 DB에 맞게 변경해야 합니다.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sqlalchemy</span> <span class="kn">import</span> <span class="n">create_engine</span>

<span class="c"># MySQL Connector using pymysql</span>
<span class="n">pymysql</span><span class="o">.</span><span class="n">install_as_MySQLdb</span><span class="p">()</span>
<span class="kn">import</span> <span class="nn">MySQLdb</span>

<span class="n">engine</span> <span class="o">=</span> <span class="n">create_engine</span><span class="p">(</span><span class="s">"mysql+mysqldb://root:"</span><span class="o">+</span><span class="s">"password"</span><span class="o">+</span><span class="s">"@localhost/table_name"</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s">'utf-8'</span><span class="p">)</span>
<span class="n">conn</span> <span class="o">=</span> <span class="n">engine</span><span class="o">.</span><span class="n">connect</span><span class="p">()</span></code></pre></figure>

<p>​</p>

<h2 id="mysql-">MySQL에 저장하기</h2>

<p>이제 DataFrame을 MySQL에 테이블 형태로 저장할 차례입니다.
아래와 같이 pandas의 <code class="highlighter-rouge">to_sql()</code> 함수를 사용하여 저장하면 됩니다.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">df</span><span class="o">.</span><span class="n">to_sql</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">table</span><span class="p">,</span> <span class="n">con</span><span class="o">=</span><span class="n">engine</span><span class="p">,</span> <span class="n">if_exists</span><span class="o">=</span><span class="s">'append'</span><span class="p">)</span></code></pre></figure>

<p>자주 사용할 수 있으니 함수로 따로 설정해주면 편합니다.</p>

<script src="https://gist.github.com/Swalloow/9dbbba9579b87548c71af68337f95299.js"></script>

<p>​</p>

	  ]]></description>
	</item>

	<item>
	  <title>Jupyter Notebook 외부접속 설정하기</title>
	  <link>//jupyter-config</link>
	  <author>Swalloow</author>
	  <pubDate>2017-02-12T19:18:00+09:00</pubDate>
	  <guid>//jupyter-config</guid>
	  <description><![CDATA[
	     <p>​</p>

<p>이번 포스팅에서는 Jupyter Notebook을 환경구축하고 난 이후에 외부접속을 설정하는 과정에 대해 알아보겠습니다. 환경구축하는 방법에 대해서는 이전의 포스팅 <a href="https://swalloow.github.io/jupyter-notebook-kernel">https://swalloow.github.io/jupyter-notebook-kernel</a> 을 참고해주시기 바랍니다.</p>

<p>​</p>

<h2 id="section">외부접속 허용하기</h2>

<p>우선 <code class="highlighter-rouge">~/.jupyter/jupyter_notebook_config.py</code> 에 있는 Jupyter Notebook의 설정파일을 열어줍니다. 아마 모두 주석이 걸려있을텐데 필요한 부분만 수정해주시면 됩니다.</p>

<ul>
  <li>실행경로 변경 : <code class="highlighter-rouge">c.NotebookApp.default_url = '/tree'</code></li>
  <li>외부접속 허용 : <code class="highlighter-rouge">c.NotebookApp.ip = '0.0.0.0'</code></li>
  <li>
    <p>포트변경: <code class="highlighter-rouge">c.NotebookApp.port = 8888</code></p>

    <p>​</p>
  </li>
</ul>

<h2 id="section-1">비밀번호 설정하기</h2>

<p>비밀번호를 설정하면 url에 접속했을 때, 암호를 입력하는 화면이 나타나게 됩니다. Jupyter Notebook에서는 HASH 값을 통해 암호화된 비밀번호를 적용할 수 있습니다.</p>

<p>먼저, 새로운 노트를 생성하고 다음의 스크립트를 작성합니다. 암호를 설정하는 칸이 나오고 결과 값이 주어지면 그대로 복사해서 <code class="highlighter-rouge">c.NotebookApp.password = u''</code> 여기에 붙여넣기 하시면 됩니다.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">notebook.auth</span> <span class="kn">import</span> <span class="n">passwd</span><span class="p">;</span>
<span class="n">passwd</span><span class="p">()</span></code></pre></figure>

<p>​</p>

	  ]]></description>
	</item>

	<item>
	  <title>Jupyter Notebook 다중커널 설정하기</title>
	  <link>//jupyter-notebook-kernel</link>
	  <author>Swalloow</author>
	  <pubDate>2017-01-28T19:18:00+09:00</pubDate>
	  <guid>//jupyter-notebook-kernel</guid>
	  <description><![CDATA[
	     <p>​</p>

<p>Jupyer Notebook은 웹 기반의 대화형 노트북 지원으로 수식, 표, 그림 등을 표현하기 쉬운 개발 환경입니다.
코딩과 문서화(Markdown)까지 한 화면에서 가능하며 커널 확장을 통해 다양한 파이썬 버전 뿐만 아니라 여러 언어를 지원합니다.</p>

<p>이제 파이썬을 처음 설치한다고 가정하고 맥 OS에서 간단하게 jupyter 환경설정하는 방법을 소개해드리고자 합니다.</p>

<p>​</p>

<h3 id="pyenv-">pyenv 설치하기</h3>

<h5 id="homebrew--pyenv-">1. Homebrew를 통해 pyenv를 설치</h5>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="err">$</span> <span class="n">brew</span> <span class="n">install</span> <span class="n">pyenv</span></code></pre></figure>

<p>​</p>

<h5 id="pyenv-init-bashrc--zsh---zshrc">2. pyenv init을 ~/.bashrc에 추가 (zsh를 사용하는 경우 ~/.zshrc)</h5>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="err">$</span> <span class="n">echo</span> <span class="s">'eval "$(pyenv init -)"'</span> <span class="o">&gt;&gt;</span> <span class="o">~/.</span><span class="n">bashrc</span></code></pre></figure>

<p>​</p>

<h5 id="pyenv--1">3. pyenv 사용해보기</h5>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="err">$</span> <span class="n">pyenv</span> <span class="n">versions</span>
<span class="n">system</span> <span class="p">(</span><span class="nb">set</span> <span class="n">by</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">USERNAME</span><span class="o">/.</span><span class="n">pyenv</span><span class="o">/</span><span class="n">version</span><span class="p">)</span></code></pre></figure>

<p>​</p>

<h5 id="pyenv--">4. pyenv 명령어 정리</h5>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="err">$</span> <span class="n">pyenv</span> <span class="n">install</span> <span class="o">&lt;</span><span class="n">version</span><span class="o">&gt;</span>
<span class="err">$</span> <span class="n">pyenv</span> <span class="n">uninstall</span> <span class="o">&lt;</span><span class="n">version</span><span class="o">&gt;</span>
<span class="err">$</span> <span class="n">pyenv</span> <span class="n">install</span> <span class="o">-</span><span class="nb">list</span>
<span class="err">$</span> <span class="n">pyenv</span> <span class="n">shell</span> <span class="o">&lt;</span><span class="n">version</span><span class="o">&gt;</span>
<span class="err">$</span> <span class="n">pyenv</span> <span class="n">activate</span> <span class="o">&lt;</span><span class="n">environment</span><span class="o">&gt;</span>
<span class="err">$</span> <span class="n">pyenv</span> <span class="n">deactivate</span> <span class="o">&lt;</span><span class="n">environment</span><span class="o">&gt;</span></code></pre></figure>

<p>​</p>

<h3 id="pyenv-virtualenv-">pyenv-virtualenv 설치하기</h3>

<h5 id="homebrew--pyenv-virtualenv-">1. Homebrew를 통해 pyenv-virtualenv를 설치</h5>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="err">$</span> <span class="n">brew</span> <span class="n">install</span> <span class="n">pyenv</span><span class="o">-</span><span class="n">virtualenv</span></code></pre></figure>

<p>​</p>

<h5 id="virtualenv-init-bashrc--zsh---zshrc">2. virtualenv init을 ~/.bashrc에 추가 (zsh를 사용하는 경우 ~/.zshrc)</h5>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="err">$</span> <span class="n">echo</span> <span class="s">'eval "$(pyenv virtualenv-init -)"'</span> <span class="o">&gt;&gt;</span> <span class="o">~/.</span><span class="n">bashrc</span></code></pre></figure>

<p>​</p>

<h5 id="pyenv-virtualenv--1">2. pyenv-virtualenv 사용해보기</h5>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c"># pyenv virtualenv [python version] [myname]</span>
<span class="err">$</span> <span class="n">pyenv</span> <span class="n">virtualenv</span> <span class="mf">2.7</span><span class="o">.</span><span class="mi">11</span> <span class="n">python2</span>
<span class="err">$</span> <span class="n">pyenv</span> <span class="n">virtualenv</span> <span class="mf">3.5</span><span class="o">.</span><span class="mi">1</span> <span class="n">python3</span></code></pre></figure>

<p>​</p>

<h5 id="virtualenv--">2. virtualenv 명령어 정리</h5>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="err">$</span> <span class="n">pyenv</span> <span class="n">virtualenv</span> <span class="n">versions</span>
<span class="err">$</span> <span class="n">pyenv</span> <span class="n">virtualenv</span> <span class="p">[</span><span class="n">python</span> <span class="n">version</span><span class="p">]</span> <span class="p">[</span><span class="n">myname</span><span class="p">]</span>
<span class="err">$</span> <span class="n">pyenv</span> <span class="n">shell</span> <span class="p">[</span><span class="n">myname</span><span class="p">]</span></code></pre></figure>

<p>​</p>

<h3 id="jupyter-notebook-">Jupyter Notebook 설치</h3>

<p>이제 방금 설치했던 파이썬 2와 3 버전의 환경에 python, notebook, jupyter를 설치할 차례입니다.
따라서 방금 설치한 환경을 각각 activate한 다음에 아래와 같은 명령어를 실행시켜야 합니다.</p>

<p>​</p>

<h5 id="pip-install-python2-python3--">1. pip install (python2, python3 각각 실행)</h5>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="err">$</span> <span class="n">pip</span> <span class="n">install</span> <span class="n">ipython</span>
<span class="err">$</span> <span class="n">pip</span> <span class="n">install</span> <span class="n">notebook</span>
<span class="err">$</span> <span class="n">pip</span> <span class="n">install</span> <span class="n">jupyter</span></code></pre></figure>

<p>​</p>

<h5 id="jupyter-configuration-----">2. 초기 Jupyter configuration 파일 생성 (마찬가지로 각각 실행)</h5>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="err">$</span> <span class="n">jupyter</span> <span class="n">notebook</span> <span class="o">--</span><span class="n">generate</span><span class="o">-</span><span class="n">config</span>
<span class="n">Installed</span> <span class="n">kernelspec</span> <span class="n">python3</span> <span class="ow">in</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">username</span><span class="o">/</span><span class="n">Library</span><span class="o">/</span><span class="n">Jupyter</span><span class="o">/</span><span class="n">kernels</span><span class="o">/</span><span class="n">python3</span></code></pre></figure>

<p>​</p>

<h5 id="jupyternotebookconfigpy-----">3. 생성된 jupyter_notebook_config.py 설정 (원하는 경우에만 커스텀 설정)</h5>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="err">$</span> <span class="n">vi</span> <span class="o">/</span><span class="n">Users</span><span class="o">/</span><span class="n">username</span><span class="o">/</span><span class="n">Library</span><span class="o">/</span><span class="n">Jupyter</span><span class="o">/</span><span class="n">kernels</span><span class="o">/</span><span class="n">python3</span><span class="o">/</span><span class="n">jupyter_notebook_config</span><span class="o">.</span><span class="n">py</span>

<span class="err">$</span> <span class="n">c</span><span class="o">.</span><span class="n">NotebookApp</span><span class="o">.</span><span class="n">ip</span> <span class="o">=</span> <span class="s">'127.0.0.1'</span>
<span class="err">$</span> <span class="n">c</span><span class="o">.</span><span class="n">NotebookApp</span><span class="o">.</span><span class="n">open_browser</span> <span class="o">=</span> <span class="bp">False</span>
<span class="err">$</span> <span class="n">c</span><span class="o">.</span><span class="n">NotebookApp</span><span class="o">.</span><span class="n">port</span> <span class="o">=</span> <span class="mi">8888</span>
<span class="err">$</span> <span class="n">c</span><span class="o">.</span><span class="n">NotebookApp</span><span class="o">.</span><span class="n">password</span> <span class="o">=</span> <span class="p">[</span><span class="n">SHA</span> <span class="n">password</span><span class="p">]</span></code></pre></figure>

<p>​</p>

<h5 id="ipykernel----">4. ipykernel 설정 (마찬가지로 각각 실행)</h5>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="err">$</span> <span class="n">pyenv</span> <span class="n">shell</span> <span class="n">python2</span>
<span class="err">$</span> <span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">ipykernel</span> <span class="n">install</span> <span class="o">--</span><span class="n">user</span>
<span class="n">Installed</span> <span class="n">kernelspec</span> <span class="n">python2</span> <span class="ow">in</span> <span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">seen</span><span class="o">/.</span><span class="n">local</span><span class="o">/</span><span class="n">share</span><span class="o">/</span><span class="n">jupyter</span><span class="o">/</span><span class="n">kernels</span><span class="o">/</span><span class="n">python2</span></code></pre></figure>

<p>​</p>

<h5 id="kerneljson-----">5. kernel.json 확인 (원하는 경우에만 커스텀 설정)</h5>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="err">$</span> <span class="n">vi</span> <span class="o">/</span><span class="n">home</span><span class="o">/</span><span class="n">seen</span><span class="o">/.</span><span class="n">local</span><span class="o">/</span><span class="n">share</span><span class="o">/</span><span class="n">jupyter</span><span class="o">/</span><span class="n">kernels</span><span class="o">/</span><span class="n">python2</span><span class="o">/</span><span class="n">kernel</span><span class="o">.</span><span class="n">json</span>
<span class="p">{</span>
  <span class="s">"display_name"</span><span class="p">:</span> <span class="s">"Python 2"</span><span class="p">,</span>
  <span class="s">"language"</span><span class="p">:</span> <span class="s">"python"</span><span class="p">,</span>
  <span class="s">"argv"</span><span class="p">:</span> <span class="p">[</span>
    <span class="s">"/home/seen/.pyenv/versions/py27/bin/python"</span><span class="p">,</span>
    <span class="s">"-m"</span><span class="p">,</span>
    <span class="s">"ipykernel"</span><span class="p">,</span>
    <span class="s">"-f"</span><span class="p">,</span>
    <span class="s">"{connection_file}"</span>
    <span class="p">]</span>
  <span class="p">}</span>
<span class="p">}</span></code></pre></figure>

<p>​</p>

<h5 id="jupyter-notebook--1">6. jupyter notebook을 실행</h5>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="err">$</span> <span class="n">jupyter</span> <span class="n">notebook</span>

<span class="c"># background running</span>
<span class="err">$</span> <span class="n">nohup</span> <span class="n">jupyter</span> <span class="n">notebook</span> <span class="o">&amp;</span>

<span class="c"># kill process</span>
<span class="err">$</span> <span class="n">ps</span> <span class="o">-</span><span class="n">a</span>
<span class="mi">37788</span> <span class="n">ttys000</span> <span class="mi">0</span><span class="p">:</span><span class="mo">00</span><span class="p">:</span><span class="mo">00</span> <span class="o">...</span><span class="n">python</span> <span class="p">(</span><span class="err">노트북을</span> <span class="err">실행한</span> <span class="err">프로세스</span><span class="p">)</span>
<span class="err">$</span> <span class="n">kill</span> <span class="mi">37788</span></code></pre></figure>

<p>​</p>

<h3 id="section">정리</h3>

<p>윈도우10 에서 아주 고생했던 환경설정이 맥 OS에서는 아주 간편하게 됩니다…
잘 안되거나 오류가 생기시면 댓글로 알려주시면 감사하겠습니다!</p>

<p>​</p>

<h3 id="section-1">참고링크</h3>

<ul>
  <li><a href="https://github.com/yyuu/pyenv">https://github.com/yyuu/pyenv</a></li>
  <li>
    <p><a href="https://github.com/yyuu/pyenv-virtualenv">https://github.com/yyuu/pyenv-virtualenv</a></p>

    <p>​</p>
  </li>
</ul>

	  ]]></description>
	</item>

	<item>
	  <title>DB 테이블을 DataFrame으로 읽어오는 방법</title>
	  <link>//db-to-dataframe</link>
	  <author>Swalloow</author>
	  <pubDate>2017-01-14T19:18:00+09:00</pubDate>
	  <guid>//db-to-dataframe</guid>
	  <description><![CDATA[
	     <p>​</p>

<p>본 포스팅에서는 예시를 MySQL로 들지만 sqlalchemy의 커넥터만 변경해주면,
MySQL 뿐만 아니라 모든 데이터베이스에 적용가능합니다.</p>

<p>먼저 sqlalchemy가 설치되어 있지 않다면 설치해줍니다.
sqlalchemy와 mysql을 연결하는 패키지가 필요합니다.</p>

<p>파이썬2를 사용한다면 <code class="highlighter-rouge">mysql-python</code>,
3을 사용한다면 <code class="highlighter-rouge">pymysql</code>을 설치해주면 됩니다.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c"># python2</span>
<span class="err">$</span> <span class="n">pip</span> <span class="n">install</span> <span class="n">mysql</span><span class="o">-</span><span class="n">python</span>
<span class="err">$</span> <span class="n">pip</span> <span class="n">install</span> <span class="n">sqlalchemy</span>

<span class="c"># python3</span>
<span class="err">$</span> <span class="n">pip</span> <span class="n">install</span> <span class="n">pymysql</span>
<span class="err">$</span> <span class="n">pip</span> <span class="n">install</span> <span class="n">sqlalchemy</span></code></pre></figure>

<p>​</p>

<p>이제 sqlalchemy를 통해 DB에 연결해보겠습니다.
주소에서 root, password, table은 DB에 맞게 변경해야 합니다.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sqlalchemy</span> <span class="kn">import</span> <span class="n">create_engine</span>

<span class="n">engine</span> <span class="o">=</span> <span class="n">create_engine</span><span class="p">(</span><span class="s">'mysql://root:password@localhost/table'</span><span class="p">,</span> <span class="n">convert_unicode</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">conn</span> <span class="o">=</span> <span class="n">engine</span><span class="o">.</span><span class="n">connect</span><span class="p">()</span></code></pre></figure>

<p>​</p>

<p>마지막으로 pandas를 통해 table을 읽어들일 차례입니다.
pandas의 <code class="highlighter-rouge">read_sql()</code> 은 0.19 버전부터 생겨났으며, sqlalchemy를 필수로 사용하도록 되어 있습니다.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_sql_table</span><span class="p">(</span><span class="s">'table_name'</span><span class="p">,</span> <span class="n">conn</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span></code></pre></figure>

<p>​</p>

<h2 id="mysql-dump---">MySQL dump 파일을 읽어오는 방법</h2>

<p>추가로 외부로부터 데이터를 넘겨받을 때 DB dump 파일 (.sql) 을 넘겨받는 경우가 있습니다.
데이터베이스 전체를 받은 dump 파일이라면, 커멘드에 다음과 같이 입력합니다.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c"># root, database, data.sql은 알아서 수정</span>
<span class="err">$</span> <span class="n">mysqldump</span> <span class="o">-</span><span class="n">u</span> <span class="n">root</span> <span class="o">-</span><span class="n">p</span> <span class="n">database</span> <span class="o">&gt;</span> <span class="n">data</span><span class="o">.</span><span class="n">sql</span></code></pre></figure>

<p>​</p>

<p>특정 테이블만 받고 싶다면, 커멘드에 다음과 같이 입력합니다.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c"># root, table, database, data.sql은 알아서 수정</span>
<span class="err">$</span> <span class="n">mysqldump</span> <span class="o">-</span><span class="n">u</span> <span class="n">root</span> <span class="o">-</span><span class="n">p</span> <span class="n">database</span> <span class="n">table</span> <span class="o">&gt;</span> <span class="n">data</span><span class="o">.</span><span class="n">sql</span></code></pre></figure>

<p>​</p>

<p>위와 같은 과정이 끝나면, 나의 MySQL 계정에 데이터가 저장된 것을 확인할 수 있습니다.
이후에는 앞에서 설명한대로 pandas를 통해 DataFrame으로 변환하면 됩니다.</p>

<p>​</p>

	  ]]></description>
	</item>


</channel>
</rss>
