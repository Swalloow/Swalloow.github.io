<?xml version="1.0" encoding="UTF-8" ?>

<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
   
      <title>swalloow.github.io/</title>
   
   <link>http://swalloow.github.io/</link>
   <description>About Data Science, Data Engineering</description>
   <language>ko-KO</language>
   <managingEditor> Swalloow</managingEditor>
   <atom:link href="rss" rel="self" type="application/rss+xml" />
   
	<item>
	  <title>Terraform 입문자를 위한 미세 팁</title>
	  <link>//tf-tips</link>
	  <author>Swalloow</author>
	  <pubDate>2019-09-20T19:18:00+09:00</pubDate>
	  <guid>//tf-tips</guid>
	  <description><![CDATA[
	     <p>​   ​</p>

<p>클라우드를 활용하는 경우, 인프라 구성 관리 도구로 테라폼을 많이 사용합니다.
오늘은 처음 테라폼을 도입하려고 할때 알아두면 좋은 점들에 대해 정리해보려 합니다.</p>

<p>​</p>

<h3 id="procedural-vs-declarative">Procedural vs Declarative</h3>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># Ansible</span>
- ec2:
  count: 10
  image: ami-v1
  instance_type: t2.micro

<span class="c"># Terraform</span>
resource <span class="s2">"aws_instance"</span> <span class="s2">"example"</span> <span class="o">{</span>
   count         <span class="o">=</span> 10
   ami           <span class="o">=</span> <span class="s2">"ami-v1"</span>
   instance_type <span class="o">=</span> <span class="s2">"t2.micro"</span>
<span class="o">}</span></code></pre></figure>

<p>위에 나와있는 코드는 Ansible과 Terraform으로 EC2 인스턴스를 구성하는 코드입니다.
만일 여기서 둘의 count 값을 15로 변경한다면 어떻게 변할까요?</p>

<p>먼저 Ansible의 경우, declarative이며 mutable infrastructure를 지향합니다.
따라서 이미 생성된 10개의 인스턴스에 15개의 인스턴스가 추가로 생성되어 총 25개의 인스턴스가 떠있게 됩니다.
반면에 Terraform의 경우, procedural이며 immutable infrastructure를 지향합니다.
count를 15로 선언했기 때문에 Terraform은 이전 상태와 비교한다음, 5만큼의 변경에 대해 교체를 수행합니다.
결과적으로 총 15개의 인스턴스가 떠있게 됩니다.</p>

<p>서로 지향하는 성격이 다르다보니 적절한 상황에 사용하거나 함께 사용하면 좋습니다.
예를 들어 Provisioning 단계에서 Terraform을 사용하고 
Configuration, Dependency 설정 단계에서 Ansible을 사용하실 수 있습니다.</p>

<p><br /></p>

<h3 id="terraform-vs-cloudformation">Terraform vs CloudFormation</h3>

<p>AWS를 사용하는 경우, 클라우드 내에서 CloudFormation이라는 서비스를 제공합니다.
CloudFormation 역시 Terraform과 같은 기능을 제공하다보니 도입하기 전에 비교를 많이 합니다.
우선 모듈화, 개발, 문서 측면에서는 Terraform이 더 편했습니다.
이외의 큰 차이를 정리하자면 아래와 같습니다.</p>

<p><strong>CloudFormation은 AWS 지원이 빠릅니다.</strong>
신규 릴리즈된 서비스나 설정들은 Terraform AWS 모듈에 반영되기까지 시간이 좀 걸립니다.
반면에 CloudFormation은 대부분 바로 지원해주다보니 더 편할 수 있습니다.</p>

<p><strong>Terraform은 다른 클라우드 서비스도 지원합니다(Azure, Google Cloud).</strong>
만일 멀티클라우드 이슈에 대한 대응까지 고려하고 있다면 Terraform을 추천드립니다.</p>

<p><br /></p>

<h3 id="terraform-remote-backend">Terraform Remote Backend</h3>

<p><img src="http://drive.google.com/uc?export=view&amp;id=1NRXR-axT-hjEycpr3SigMI3x6e5m8Utx" alt="" /></p>

<p>Terraform은 상태를 <code class="highlighter-rouge">Consul, S3, Enterprise</code> 등의 원격 스토리지에 저장할 수 있습니다.
여러 명이 팀으로 일하는 경우, 인프라 변경 상태에 대한 동기화가 필요합니다.
이 경우 Remote Backend를 고려하시면 좋습니다.
state 파일은 workspace, env에 따라 서로 다른 파일로 관리할 수 있습니다.</p>

<p><br /></p>

<h3 id="terraform-migration">Terraform Migration</h3>

<p>이미 생성되어 있는 수 많은 인프라를 한번에 Terraform으로 옮기는 일은 정말 어렵습니다.
우선 모듈마다 점진적으로 마이그레이션 하는 방법을 추천드립니다.
Terraform은 아래의 코드처럼 이미 생성되어 있는 리소스를 불러올 수 있습니다.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">resource <span class="s2">"aws_vpc"</span> <span class="s2">"default"</span> <span class="o">{</span>
  <span class="c"># resource configuration...</span>
<span class="o">}</span>

<span class="c"># update remote state</span>
<span class="gp">$ </span>terraform import aws_vpc.default vpc-abc12345</code></pre></figure>

<p>또는 data 블럭을 이용해서 id, arn 등의 값을 불러올 수 있습니다.
예를 들어 아래는 Packer로 생성된 가장 최근 버전의 AMI를 불러오는 코드입니다.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">data <span class="s2">"aws_ami"</span> <span class="s2">"app"</span> <span class="o">{</span>
  most_recent <span class="o">=</span> <span class="nb">true
  </span>name_regex  <span class="o">=</span> <span class="s2">"app-</span><span class="se">\\</span><span class="s2">d{10}"</span>
  owners      <span class="o">=</span> <span class="o">[</span><span class="s2">"account_number"</span><span class="o">]</span>
<span class="o">}</span></code></pre></figure>

<p><br /></p>

<h3 id="terraform-module">Terraform Module</h3>

<p>Terraform은 모듈화를 통해 인프라를 재사용할 수 있습니다.
하지만 먼저 기존의 인프라를 어떻게 모듈화할지 많은 고민이 필요합니다.
자주 변경되어야 하는 일부분은 Terraform 관리 대상에서 제외시키는 방법도 있습니다.
또한 인프라 장애 대응이 필요한 부분은 쉽게 HA를 구성할 수 있도록 작성해야 합니다.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">module <span class="s2">"network"</span> <span class="o">{</span>
   <span class="nb">source</span> <span class="o">=</span> <span class="s2">"./network"</span>
   name   <span class="o">=</span> <span class="s2">"default"</span>
   cidr   <span class="o">=</span> <span class="s2">"000.0.0.0/16"</span>

   azs    <span class="o">=</span> <span class="o">[</span><span class="s2">"ap-northeast-2a"</span>, <span class="s2">"ap-northeast-2c"</span><span class="o">]</span>
   public_subnets <span class="o">=</span> <span class="o">[</span><span class="s2">"000.0.0.0/22"</span>, <span class="s2">"111.1.1.1/22"</span><span class="o">]</span>

   tags <span class="o">=</span> <span class="o">{</span>
      dept    <span class="o">=</span> <span class="s2">"mydept"</span>
      service <span class="o">=</span> <span class="s2">"app"</span>
   <span class="o">}</span>
<span class="o">}</span>

<span class="c"># common tags</span>
tags <span class="o">=</span> <span class="s2">"</span><span class="k">${</span><span class="nv">merge</span><span class="p">(var.tags, map(</span><span class="s2">"Name"</span><span class="p">, format(</span><span class="s2">"%s-public-%s"</span><span class="p">, var.name, var.azs[count.index])))</span><span class="k">}</span><span class="s2">"</span></code></pre></figure>

<p>각 모듈은 Input과 Output Variable을 가집니다.
위의 예시는 네트워크에 관련된 모듈입니다.
모듈을 통해 생성된 모든 리소스는 공통된 태그를 통해 관리할 수 있으며
만일 네트워크 구성을 변경해야하는 경우, CIDR 값만 수정하면 됩니다.</p>

<p><br /></p>

<h3 id="terraform-loop-conditionls-012">Terraform Loop, Conditionls (0.12)</h3>

<p>Terraform은 0.12 버전을 기점으로 더 효율적인 코드를 작성할 수 있게 되었습니다.
따라서 새로 시작하신다면 0.12+ 버전 사용을 권장드립니다.
예시를 통해 Terraform에서 루프를 어떻게 정의하는지 설명드리겠습니다.
아래의 예시는 IAM Role에 Policy를 연결하는 코드입니다.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">locals <span class="o">{</span>
   lambda_backend_policy_arns <span class="o">=</span> <span class="o">[</span>
      <span class="s2">"arn:aws:iam::aws:policy/AmazonRDSFullAccess"</span>,
      <span class="s2">"arn:aws:iam::aws:policy/CloudWatchFullAccess"</span>,
      <span class="s2">"arn:aws:iam::aws:policy/AmazonDynamoDBFullAccess"</span>,
   <span class="o">]</span>
<span class="o">}</span>

resource <span class="s2">"aws_iam_role_policy_attachment"</span> <span class="s2">"attach"</span> <span class="o">{</span>
   count <span class="o">=</span> <span class="s2">"</span><span class="k">${</span><span class="nv">length</span><span class="p">(local.lambda_backend_policy_arns)</span><span class="k">}</span><span class="s2">"</span>

   role <span class="o">=</span> <span class="s2">"</span><span class="k">${</span><span class="nv">aws_iam_role</span><span class="p">.lambda_backend.name</span><span class="k">}</span><span class="s2">"</span>
   policy_arn <span class="o">=</span> <span class="s2">"</span><span class="k">${</span><span class="nv">local</span><span class="p">.lambda_backend_arns[count.index]</span><span class="k">}</span><span class="s2">"</span>
<span class="o">}</span></code></pre></figure>

<p>이전에는 위와 같이 Array 타입의 인덱스를 통해 Loop를 정의해야 했습니다.
하지만 0.12 버전부터 for-loop, for-each 구문을 지원하기 시작했습니다.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">variable <span class="s2">"subnet_numbers"</span> <span class="o">{</span>
   default <span class="o">=</span> <span class="o">{</span>
      <span class="s2">"ap-northeast-2a"</span> <span class="o">=</span> 1
      <span class="s2">"ap-northeast-2b"</span> <span class="o">=</span> 2
      <span class="s2">"ap-northeast-2c"</span> <span class="o">=</span> 3
   <span class="o">}</span>
<span class="o">}</span>

resource <span class="s2">"aws_subnet"</span> <span class="s2">"example"</span> <span class="o">{</span>
   for_each <span class="o">=</span> var.subnet_numbers
   
   vpc_id            <span class="o">=</span> aws_vpc.example.id
   availability_zone <span class="o">=</span> each.key
   cidr_block        <span class="o">=</span> cidrsubset<span class="o">(</span>
      aws_vpc.example.cidr_block, each.value
   <span class="o">)</span>
<span class="o">}</span></code></pre></figure>

<p>이외에도 찾아보시면 다양한 타입과 연산을 지원합니다.
이 글이 처음 입문하시는데 조금 도움이 되셨으면 좋겠습니다!</p>

<p>​</p>

	  ]]></description>
	</item>

	<item>
	  <title>KOPS로 AWS에 Kubernetes 클러스터 구축하기</title>
	  <link>//aws-kops</link>
	  <author>Swalloow</author>
	  <pubDate>2019-02-10T19:18:00+09:00</pubDate>
	  <guid>//aws-kops</guid>
	  <description><![CDATA[
	     <p>​   ​</p>

<p>Kubernetes 클러스터를 구성하는 방법은 여러 가지가 있습니다.
그 중에서 kubeadam은 온프레미스 환경에서 많이 사용하고 kops는 클라우드 환경에서 많이 사용하고 있습니다.
이번 글에서는 kops로 AWS EC2에 Kubernetes 클러스터 구축하는 방법에 대해 정리해보겠습니다.</p>

<p>​   ​</p>

<h3 id="kops-kubectl-awscli--linux">kops, kubectl, awscli 설치 (Linux)</h3>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># kops 설치</span>
wget -O kops https://github.com/kubernetes/kops/releases/download/<span class="k">$(</span>curl -s https://api.github.com/repos/kubernetes/kops/releases/latest | grep tag_name | cut -d <span class="s1">'"'</span> -f 4<span class="k">)</span>/kops-linux-amd64
chmod +x ./kops
sudo mv ./kops /usr/local/bin/

<span class="c"># kubectl 설치</span>
wget -O kubectl https://storage.googleapis.com/kubernetes-release/release/<span class="k">$(</span>curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt<span class="k">)</span>/bin/linux/amd64/kubectl
chmod +x ./kubectl
sudo mv ./kubectl /usr/local/bin/kubectl

<span class="c"># aws-cli 설치 (amazon linux라면 불필요)</span>
pip install awscli</code></pre></figure>

<p>​   ​</p>

<h3 id="iam-user-">IAM User 설정</h3>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># 아래의 권한이 필요</span>
AmazonEC2FullAccess
AmazonRoute53FullAccess
AmazonS3FullAccess
IAMFullAccess
AmazonVPCFullAccess</code></pre></figure>

<p>​   ​</p>

<h3 id="aws-cli-iam--">aws-cli로 IAM 계정 생성</h3>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">aws iam create-group --group-name kops

aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonEC2FullAccess --group-name kops
aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonRoute53FullAccess --group-name kops
aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonS3FullAccess --group-name kops
aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/IAMFullAccess --group-name kops
aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonVPCFullAccess --group-name kops

aws iam create-user --user-name kops
aws iam add-user-to-group --user-name kops --group-name kops
aws iam create-access-key --user-name kops

aws configure   <span class="c"># AccessKeyID와 SecretAccessKey 등록</span></code></pre></figure>

<p>​   ​</p>

<h3 id="dns-cluster-state-storage-">DNS, Cluster State storage 설정</h3>

<ul>
  <li>kops 1.6.2 버전 이상이라면 DNS 설정은 옵션 (gossip-based cluster)</li>
  <li>Cluster Configuration Storage로 S3를 사용 (Bucket 미리 생성해야 함)</li>
  <li>S3 default bucket encryption을 사용할 수 있음</li>
  <li>default encryption 설정이 안되어 있다면 kops에서 AES256 encryption</li>
</ul>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># Create Bucket</span>
aws s3api create-bucket <span class="se">\</span>
    --bucket prefix-example-com-state-store <span class="se">\</span>
    --region ap-northeast-2

<span class="c"># S3 versioning</span>
aws s3api put-bucket-versioning <span class="se">\</span>
    --bucket prefix-example-com-state-store <span class="se">\</span>
    --versioning-configuration <span class="nv">Status</span><span class="o">=</span>Enabled</code></pre></figure>

<p>​   ​</p>

<h3 id="kubernetes-cluster-">Kubernetes Cluster 생성</h3>

<ul>
  <li>kops를 통해 생성된 인스턴스는 자동으로 Auto Scaling 그룹에 들어감</li>
  <li><code class="highlighter-rouge">kops create</code>: cluster configuration을 생성, SSH-Key가 필요</li>
  <li><code class="highlighter-rouge">kops edit</code>: cluster configuation을 수정</li>
  <li><code class="highlighter-rouge">kops update</code>: Build 단계, kubernetes component를 모두 설치하고 나면 ready 상태로 전환</li>
  <li><code class="highlighter-rouge">kops delete</code>: cluster 제거, –yes (구성요소까지 전부 삭제)</li>
  <li><code class="highlighter-rouge">kops rolling-update</code>: downtime이 없는 rolling-update 실행</li>
</ul>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># Environment</span>
<span class="nb">export </span><span class="nv">NAME</span><span class="o">=</span>myfirstcluster.example.com  <span class="c"># DNS가 설정되어 있는 경우</span>
<span class="nb">export </span><span class="nv">NAME</span><span class="o">=</span>myfirstcluster.k8s.local    <span class="c"># DNS가 설정되어 있지 않은 경우</span>
<span class="nb">export </span><span class="nv">KOPS_STATE_STORE</span><span class="o">=</span>s3://prefix-example-com-state-store

<span class="c"># Seoul region</span>
aws ec2 describe-availability-zones --region ap-northeast-2
kops create cluster --zones ap-northeast-2 <span class="k">${</span><span class="nv">NAME</span><span class="k">}</span>
kops edit cluster <span class="k">${</span><span class="nv">NAME</span><span class="k">}</span>
kops update cluster <span class="k">${</span><span class="nv">NAME</span><span class="k">}</span> --yes
kops validate cluster

<span class="c"># Kubectl</span>
kubectl get nodes
kubectl cluster-info
kubectl -n kube-system get po   <span class="c"># system pod</span>

<span class="c"># Dashboard</span>
kops get secrets admin -oplaintext
kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml

<span class="c"># Access https://&lt;kubernetes-master-hostname&gt;/ui</span>
kops get secrets admin --type secret -oplaintext

<span class="c"># Stop cluster</span>
<span class="c"># Change minSize, MaxSize to 0</span>
kops get ig
kops edit ig nodes
kops edit ig master</code></pre></figure>

<p>​   ​</p>

<h3 id="advanced">Advanced</h3>

<ul>
  <li>Network topology를 설정할 수 있음 (public, private)</li>
  <li>Private: VPC내의 private subnet으로 생성</li>
  <li>Public: VPC내의 public subnet으로 생성 (routed to Internet Gateway)</li>
  <li>Multiple zone, HA Master를 구성할 수 있음 (–master-zones=us-east-1b,us-east-1c,us-east-1d)</li>
  <li>Instance Group을 지정 가능 (https://github.com/kubernetes/kops/blob/master/docs/instance_groups.md)</li>
  <li>AMI를 지정가능, CoreOS AMI</li>
  <li>Container Network Interface (CNI) 지정 가능 (https://kubernetes.io/docs/concepts/cluster-administration/networking/)</li>
  <li>Authorization (https://kubernetes.io/docs/reference/access-authn-authz/authorization/)</li>
</ul>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># SSH Key</span>
ssh-keygen -t rsa -f <span class="nv">$NAME</span>.key -N <span class="s1">''</span>
<span class="nb">export </span><span class="nv">PUBKEY</span><span class="o">=</span><span class="s2">"</span><span class="nv">$NAME</span><span class="s2">.key.pub"</span>

<span class="c"># CoreOS Image</span>
<span class="nb">export </span><span class="nv">IMAGE</span><span class="o">=</span><span class="k">$(</span>curl -s https://coreos.com/dist/aws/aws-stable.json|sed <span class="s1">'s/-/_/g'</span>|jq <span class="s1">'.'</span><span class="nv">$REGION</span><span class="s1">'.hvm'</span>|sed <span class="s1">'s/_/-/g'</span> | sed <span class="s1">'s/\"//g'</span><span class="k">)</span>

<span class="c"># Create Cluster</span>
kops create cluster --kubernetes-version<span class="o">=</span>1.12.1 <span class="se">\</span>
    --ssh-public-key <span class="nv">$PUBKEY</span> <span class="se">\</span>
    --networking flannel <span class="se">\</span>
    --api-loadbalancer-type public <span class="se">\</span>
    --admin-access 0.0.0.0/0 <span class="se">\</span>
    --authorization RBAC <span class="se">\</span>
    --zones ap-northeast-2 <span class="se">\</span>
    --master-zones ap-northeast-2 <span class="se">\</span>
    --master-size t2.medium <span class="se">\</span>
    --node-size t2.medium <span class="se">\</span>
    --image <span class="nv">$IMAGE</span> <span class="se">\</span>
    --node-count 3 <span class="se">\</span>
    --cloud aws <span class="se">\</span>
    --bastion <span class="se">\</span>
    --name <span class="nv">$NAME</span> <span class="se">\</span>
    --yes</code></pre></figure>

<p>​   ​</p>

<h3 id="reference">Reference</h3>

<ul>
  <li>https://github.com/kubernetes/kops</li>
  <li>
    <p>https://kubernetes.io/ko/docs/setup/custom-cloud/kops/</p>

    <p>​</p>
  </li>
</ul>

	  ]]></description>
	</item>

	<item>
	  <title>influxDB와 Grafana로 실시간 서버 모니터링 구축하기(2)</title>
	  <link>//influx-grafana2</link>
	  <author>Swalloow</author>
	  <pubDate>2017-04-05T21:18:00+09:00</pubDate>
	  <guid>//influx-grafana2</guid>
	  <description><![CDATA[
	     <p>​   ​</p>

<p><a href="https://swalloow.github.io/influx-grafana1">지난 포스팅</a>에 이어서 Grafana를 연동해보도록 하겠습니다.</p>

<p>​</p>

<h3 id="grafana">Grafana</h3>

<p><img src="/assets/images/grafana.png" alt="Grafana" /></p>

<p>지난 번에 설치했던 Grafana 도커 이미지를 컨테이너로 실행하면 위와 같이 로그인 화면이 나타납니다.
아이디는 admin, 비밀번호는 admin으로 접속하시면 됩니다.
이제 아까 만들었던 database를 Grafana의 data source에 등록할 차례입니다.</p>

<p><img src="/assets/images/grafana-ds.png" alt="Grafana-ds" /></p>

<p>Type을 InfluxDB로 맞추고, Url과 Database만 잘 설정해주시면 됩니다.
이제 새로운 대시보드를 생성하고 <code class="highlighter-rouge">Add Graph</code>로 그래프를 추가합니다.</p>

<p>​<img src="/assets/images/grafana-graph.png" alt="Grafana-graph" /></p>

<p>위와 같이 cpu, memory 지표 외에도 다양한 지표를 쉽게 추가할 수 있습니다.</p>

<p><img src="/assets/images/grafana-result.png" alt="Mac" /></p>

<p>​   ​</p>

	  ]]></description>
	</item>

	<item>
	  <title>influxDB와 Grafana로 실시간 서버 모니터링 구축하기(1)</title>
	  <link>//influx-grafana1</link>
	  <author>Swalloow</author>
	  <pubDate>2017-04-05T19:18:00+09:00</pubDate>
	  <guid>//influx-grafana1</guid>
	  <description><![CDATA[
	     <p>​   ​</p>

<p>요즘 실시간 로그 수집 및 분석 도구로 <strong>ELK (Elastic Search)</strong> 를 많이 사용하지만,
간단한 서버 모니터링이나 시계열 데이터 분석도구를 찾으신다면, <strong>influxDB-Grafana</strong> 도 좋습니다.
이 포스팅에서는 간단한 예제를 통해 influxDB와 Telegraf, Grafana에 대해 알아보겠습니다.</p>

<p>​</p>

<h3 id="influxdb">influxDB</h3>

<p><img src="/assets/images/influxdb.png" alt="influxDB" /></p>

<p>influxDB는 시계열 데이터베이스입니다.
다른 시계열 데이터베이스도 많지만, 설치가 쉽고 간편합니다.
그리고 SQL 구문과 graphite 등 여러 프로토콜을 지원하여 확장성이 높습니다.</p>

<p>작년 9월에 1.0 버전을 릴리즈했으며, 현재 기준 1.2가 최신 버전입니다.
시계열 데이터베이스는 로그, 시스템 모니터링 도구로 활용될 수도 있지만,
주식, 환율과 같은 시계열 데이터의 분석 도구로도 많이 사용됩니다.</p>

<p>그렇다면 바로 로컬에 설치해보도록 하겠습니다.
여기서는 OS X 기준이며, 다른 OS는 <a href="https://docs.influxdata.com/influxdb/v1.2/introduction/installation/">설치 페이지를</a> 참조하시면 됩니다.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="gp">$ </span>brew update influxdb
<span class="gp">$ </span>brew install influxdb</code></pre></figure>

<p>​</p>

<p>실습은 Docker를 통해 진행하도록 하겠습니다.
DockerHub로부터 influxdb와 Grafana 이미지를 받아옵니다.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="gp">$ </span>docker pull tutum/influxdb
<span class="gp">$ </span>docker pull grafana/grafana</code></pre></figure>

<p><img src="/assets/images/influx-port.png" alt="influx-port" /></p>

<p>받아온 이미지를 컨테이너로 실행시키고, 위와 같이 포트를 변경해줍니다.
8083 포트는 웹 클라이언트로 사용되며, 8086 포트는 데이터를 주입하고 가져가는 용도로 사용됩니다.
이제 호스트의 8086 주소로 들어가보면 influxDB의 관리자 페이지를 볼 수 있습니다.</p>

<p><img src="/assets/images/influx-admin.png" alt="influx-admin" /></p>

<p>쿼리를 잘 모르더라도 좌측의 Query Templates를 통해 쉽게 입력할 수 있습니다.
스키마는 기존의 데이터베이스와 비슷하면서도 조금 다릅니다.
HTTP로 데이터를 핸들링 할 수 있으며, 이외에도 여러 가지 특징이 있지만
여기서 설명하기보다는 공식 래퍼런스를 참조하는 편이 나을 것 같습니다.</p>

<p>​</p>

<h3 id="telegraf">Telegraf</h3>

<p>이제 Telegraf로 실시간 시스템 지표를 influxDB에 넣어보겠습니다.
Telegraf는 다양한 데이터 소스에서 plugin을 통해 데이터를 수집하고 저장합니다.
제공하는 input plugin은 <a href="https://github.com/influxdata/telegraf#input-plugins">다음 페이지</a>에서 확인하실 수 있습니다.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="gp">$ </span>brew update
<span class="gp">$ </span>brew install telegraf</code></pre></figure>

<p>위와 같이 설치한 다음, system plugin을 사용해보도록 하겠습니다.
<code class="highlighter-rouge">--sample-config</code>를 통해 .conf 파일을 생성할 수 있습니다.
input filter는 cpu와 memory 지표로, output은 influxDB에 저장됩니다.
.conf 파일을 열어 <code class="highlighter-rouge">output host url</code>을 본인의 호스트에 맞게 변경해주어야 합니다.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="gp">$ </span>telegraf --sample-config  --input-filter cpu:mem --output-filter influxdb &gt; telegraf.conf
<span class="gp">$ </span>telegraf -config telegraf.conf</code></pre></figure>

<p>이제 influxDB로 돌아와서 보시면, telegraf 라는 데이터베이스가 생성되어 있습니다.
measurement를 확인해보시거나 쿼리를 날려 데이터를 확인할 수 있습니다.</p>

<p><img src="/assets/images/influx-admin2.png" alt="influx-admin2" /></p>

<p>influxDB는 언젠가 디스크가 찰 수 있어서, 데이터 보관 또는 삭제에 대한 정책이 필요합니다.
이에 대해서는 <code class="highlighter-rouge">Retention Policy</code>를 찾아보시면 됩니다.</p>

<p>​</p>

	  ]]></description>
	</item>

	<item>
	  <title>Docker와 Gitlab CI를 활용한 빌드, 테스트 자동화</title>
	  <link>//gitlabci-docker</link>
	  <author>Swalloow</author>
	  <pubDate>2017-03-31T19:18:00+09:00</pubDate>
	  <guid>//gitlabci-docker</guid>
	  <description><![CDATA[
	     <p>​   ​</p>

<p>Gitlab은 설치형 GitHub이라고 이해하시면 편합니다.
무료로 private repository와 CI 서버를 제공해줍니다.
심지어 Docker Registry도 무료로 제공하고 있습니다.
아직 많은 분들이 Gitlab CI의 여러 장점들을 잘 모르시는 것 같아 정리해보았습니다.</p>

<p>​</p>

<h3 id="gitlab-ci">Gitlab CI</h3>

<p>Gitlab CI는 Gitlab에서 무료로 제공하는 CI 툴 입니다.
Gitlab과 완벽하게 연동되며 CI를 위해 <strong>CI linter, pipeline, cycle analytics</strong> 등 다양한 서비스를 제공합니다.</p>

<p><img src="/assets/images/gitlab-ci.png" alt="Gitlab-CI" /></p>

<p>travis, circle CI와 마찬가지로 Gitlab CI는 <code class="highlighter-rouge">gitlab-ci.yml</code> 파일로 설정할 수 있습니다.
Gitlab은 DigitalOcean과 제휴하여 CI 서버(Runner)를 따로 제공합니다.
따라서 <code class="highlighter-rouge">Runner</code>에 job을 할당하여 돌아가도록 설정할 수 있습니다.</p>

<p><img src="/assets/images/gitlab-pipe.png" alt="Gitlab-Pipe" /></p>

<p>그리고 Runner는 <strong>Docker 컨테이너</strong> 를 기반으로 돌아갑니다.
Gitlab CI를 실행해보면 처음에 Ruby 이미지를 받아와서 컨테이너를 실행시키는 것을 볼 수 있습니다.
따라서, <strong>Base Image를 내 어플리케이션 이미지로 바꾸면 빌드 및 테스트 속도가 빠르게 향상됩니다</strong>.</p>

<p>​</p>

<h3 id="gitlab-registry">Gitlab Registry</h3>

<p><img src="/assets/images/gitlab-registry.png" alt="Gitlab-Registry" /></p>

<p>Docker 친화적인 Gitlab은 Docker Registry도 무료로 제공해줍니다.
<code class="highlighter-rouge">Gitlab Registry</code> 탭에 들어가면 Docker Registry의 주소가 적혀있고 친절하게 명령어까지 써있습니다.</p>

<p>아마 많은 분들이 DockerHub를 결제하거나, AWS S3를 이용하여 Docker Registry를 구축하셨을 겁니다.
하지만 Gitlab에서는 그럴 필요가 없습니다.</p>

<p>​</p>

<h3 id="docker-with-gitlab-ci">Docker with Gitlab CI</h3>

<p>gitlab-ci 설정파일은 대략 다음과 같습니다.</p>

<figure class="highlight"><pre><code class="language-yaml" data-lang="yaml"><span class="s">image</span><span class="pi">:</span> <span class="s">gitlab-registry</span>
<span class="s">stages</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s">build</span>
  <span class="pi">-</span> <span class="s">test</span>
  <span class="pi">-</span> <span class="s">deploy</span>

<span class="s">job-build</span><span class="pi">:</span>
  <span class="s">stage</span><span class="pi">:</span> <span class="s">build</span>
  <span class="s">script</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s">pip install -r requirements.txt</span>
  <span class="pi">-</span> <span class="s">python -m py_compile run.py</span>

<span class="s">job-test</span><span class="pi">:</span>
  <span class="s">stage</span><span class="pi">:</span> <span class="s">test</span>
  <span class="s">script</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s">pytest --pep8 -m pep8 backend/</span>

<span class="s">job-deploy</span><span class="pi">:</span>
  <span class="s">stage</span><span class="pi">:</span> <span class="s">deploy</span>
  <span class="s">script</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s">deployment</span></code></pre></figure>

<p>Gitlab CI와 Docker를 활용한 빌드 테스트 자동화는 위의 그림과 같이 이루어집니다.</p>

<p><img src="/assets/images/ci-process.png" alt="CI" /></p>

<ol>
  <li>사용자가 Gitlab 저장소에 push를 하면, Gitlab CI Runner로 전달됩니다.</li>
  <li>Gitlab CI는 Gitlab Registry로부터 Docker 이미지를 받아옵니다. Docker 이미지에는 어플리케이션 환경이 설정되어 있습니다.</li>
  <li>Docker 컨테이너가 실행되면 첫번째 job에 정의된 대로 필요한 패키지를 설치하고 빌드를 수행합니다.</li>
  <li>빌드가 통과되면 두번째 job에 정의된 대로 테스트를 수행합니다.</li>
  <li>테스트가 통과되면 세번째 job에 정의된 대로 배포 과정을 수행합니다.</li>
  <li>
    <p>각 과정은 모두 Slack 알림으로 확인할 수 있습니다.</p>

    <p>​</p>
  </li>
</ol>

<p><img src="/assets/images/gitlab-pipeline.png" alt="Gitlab" /></p>

<p>위와 같이 모든 과정을 <code class="highlighter-rouge">Gitlab Pipeline</code>을 통해 확인하실 수 있습니다.</p>

<p>Gitlab의 단점이라면 Community 버전의 서버가 조금 불안정하다는 점입니다.
물론 설치형 Gitlab을 사용하신다면 이런 단점마저 존재하지 않습니다.
소규모의 팀이라면 충분히 도입을 검토해볼만 하다고 생각합니다.</p>

<p>​   ​</p>

	  ]]></description>
	</item>

	<item>
	  <title>올바른 Dockerfile 작성을 위한 가이드라인</title>
	  <link>//dockerfile-ignore</link>
	  <author>Swalloow</author>
	  <pubDate>2017-03-28T19:18:00+09:00</pubDate>
	  <guid>//dockerfile-ignore</guid>
	  <description><![CDATA[
	     <p>​   ​</p>

<p>Docker가 처음이라면, 이전 포스팅을 참고하시기 바랍니다.</p>

<ul>
  <li><a href="https://swalloow.github.io/docker-install">Docker 간편한 설치부터 실행까지</a></li>
  <li><a href="https://swalloow.github.io/docker-command">Docker, DockerHub 명령어 정리</a></li>
  <li><a href="https://swalloow.github.io/dockerfile">파이썬을 위한 Dockerfile 작성하기</a></li>
  <li>
    <p><a href="https://swalloow.github.io/dockerfile-ignore">올바른 Dockerfile 작성은 위한 가이드라인</a></p>

    <p>​</p>
  </li>
</ul>

<h2 id="dockerfile">Dockerfile</h2>

<p>Dockerfile은 일종의 이미지 설정파일입니다.
생긴 모양새는 쉘 스크립트와 유사하지만 자체의 문법을 가지고 있습니다.
이렇게 작성된 Dockerfile은 <code class="highlighter-rouge">build</code> 명령어를 통해 이미지를 생성할 수 있습니다.</p>

<p>이 포스팅에서는 Dockerfile 레퍼런스에 나와 있는 가이드라인을 정리해보도록 하겠습니다.
<a href="https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices/">https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices/</a>에 자세한 내용이 설명되어 있습니다.</p>

<p>​</p>

<h4 id="section">컨테이너는 일시적이어야 한다</h4>

<p>일시적이라는 말은 가능한 최소한의 설정 및 구성으로 이루어져있어야 한다는 것을 의미합니다.
이에 대한 내용은 <a href="https://12factor.net/">Twelve Factors Application</a>을 참고하시면 좋습니다.</p>

<p>​   ​</p>

<h4 id="dockerignore-">.dockerignore을 활용하자</h4>

<p>대부분의 경우 각 Docker 파일을 빈 디렉토리에 저장하는 것이 가장 좋습니다.
그런 다음 Dockerfile을 빌드하는 데 필요한 파일만 해당 디렉토리에 추가하시면 됩니다.
빌드의 성능을 높이려면 해당 디렉토리에 <code class="highlighter-rouge">.dockerignore</code> 파일을 추가하여 파일 및 디렉토리를 제외 할 수 있습니다.
<code class="highlighter-rouge">.dockerignore</code> 파일은 <code class="highlighter-rouge">.gitignore</code> 파일과 유사하게 동작한다고 보시면 됩니다.</p>

<figure class="highlight"><pre><code class="language-markdown" data-lang="markdown"><span class="err">*</span>.md
!README.md</code></pre></figure>

<p>위와 같은 <code class="highlighter-rouge">.dockerignore</code> 파일은 <em>README.md</em> 파일을 제외한 모든 마크다운 파일을 제외시킵니다.
이런식으로 원하지 않는 파일 및 디렉토리를 제외시켜 이미지의 용량을 줄일 수 있습니다.</p>

<p>​</p>

<h4 id="section-1">불필요한 패키지를 설치하지 말자</h4>

<p>복잡성, 의존성, 파일 크기 및 빌드 시간을 줄이기 위해서는 불필요한 패키지를 설치하지 말아야 합니다.
예를 들어, 데이터베이스 이미지에 텍스트 편집기를 포함시킨다거나 하는 일은 없어야 합니다.</p>

<p>​</p>

<h4 id="section-2">컨테이너는 오직 하나의 관심사만 갖는다</h4>

<p>애플리케이션을 여러 컨테이너로 분리하면 컨테이너를 확장하고 재사용하는 것이 훨씬 쉬워집니다.
예를 들어, 일반적인 어플리케이션은 웹 어플리케이션, 데이터베이스, 인메모리-캐시와 같이 세 개의 컨테이너로 구성 될 수 있습니다.</p>

<p><strong>컨테이너 당 하나의 프로세스</strong> 가 있어야한다는 말을 들어 보셨을 겁니다.
하지만, 언제나 컨테이너 당 하나의 운영 체제 프로세스만 있어야 하는 것은 아닙니다.
컨테이너가 init 프로세스로 생성 될 수 있다는 사실 외에도 일부 프로그램은 자체적으로 추가 프로세스를 생성 할 수 있습니다.
예를 들어 Celery는 여러 작업자 프로세스를 생성하거나 Apache 스스로 요청에 따른 프로세스를 생성 할 수 있습니다.
컨테이너를 깔끔한 모듈 형식으로 유지하기 위해 신중히 선택해야 합니다.
컨테이너에 서로 의존성이 생기는 경우 Docker 컨테이너 네트워크를 사용하여 서로 통신 할 수 있습니다.</p>

<p>​</p>

<h4 id="section-3">레이어의 수를 최소화하자</h4>

<p>사용하는 레이어의 수에 대해 전략적이고 신중해야합니다.
장기적인 관점에서 보았을 때 유지보수를 위해서는 레이어의 수를 최소화하는 것이 현명한 선택이 될 수 있습니다.</p>

<p>​</p>

<h4 id="section-4">줄바꿈을 사용하여 정렬하자</h4>

<figure class="highlight"><pre><code class="language-dockerfile" data-lang="dockerfile">RUN apt-get update &amp;&amp; apt-get install -y \
  bzr \
  cvs \
  git</code></pre></figure>

<p>위와 같이 줄바꿈을 사용하면, 패키지의 중복을 피하고 목록을 훨씬 쉽게 업데이트 할 수 있습니다.
백 슬래시 (<code class="highlighter-rouge">\</code>) 앞에 공백을 추가하면 가독성을 높이는 데에 도움이됩니다.</p>

<p>​</p>

<h4 id="section-5">캐시를 활용하여 빌드하자</h4>

<p>이미지를 작성하는 과정에서 Docker는 지정한 순서대로 Dockerfile을 단계 별로 실행합니다.
각 명령을 실행할 때 Docker는 매번 새로운 이미지를 만드는 대신 캐시에서 기존 이미지를 찾아 재사용 할 수 있습니다.
캐시를 전혀 사용하지 않으려는 경우 docker 빌드 명령에서 <code class="highlighter-rouge">--no-cache = true</code> 옵션을 사용하시면 됩니다.</p>

<p>Docker가 캐시를 사용하게하려면 일치하는 이미지를 찾을 때와 그렇지 않을 때를 이해하는 것이 매우 중요합니다.
Docker cache의 기본 규칙은 다음과 같습니다.</p>

<ul>
  <li>
    <p>이미 캐시에 있는 기본 이미지로 시작하여 다음 명령어가 해당 기본 이미지에서 파생된 모든 하위 이미지와 비교되어 그 중 하나가 정확히 동일한 명령어를 사용하여 빌드되었는지 확인합니다. 그렇지 않으면 캐시가 무효화됩니다.</p>
  </li>
  <li>
    <p><code class="highlighter-rouge">ADD, COPY</code> 명령을 제외하고 캐시 검사는 컨테이너의 파일을보고 캐시 일치를 판별하지 않습니다. 예를 들어 <code class="highlighter-rouge">RUN apt-get -y update</code> 명령을 처리 할 때 컨테이너에서 업데이트 된 파일은 캐시 히트가 있는지 여부를 확인하기 위해 검사되지 않습니다. 이 경우 명령 문자열 자체만 일치하는지 확인합니다.</p>
  </li>
  <li>
    <p>캐시가 무효화되면 이후의 모든 Dockerfile 명령은 새로운 이미지를 생성하고 캐시는 사용되지 않습니다.</p>
  </li>
</ul>

<p>​   ​</p>

	  ]]></description>
	</item>

	<item>
	  <title>파이썬을 위한 Dockerfile 작성하기</title>
	  <link>//dockerfile</link>
	  <author>Swalloow</author>
	  <pubDate>2017-03-27T19:18:00+09:00</pubDate>
	  <guid>//dockerfile</guid>
	  <description><![CDATA[
	     <p>​   ​</p>

<p>Docker가 처음이라면, 이전 포스팅을 참고하시기 바랍니다.</p>

<ul>
  <li><a href="https://swalloow.github.io/docker-install">Docker 간편한 설치부터 실행까지</a></li>
  <li><a href="https://swalloow.github.io/docker-command">Docker, DockerHub 명령어 정리</a></li>
  <li>
    <p><a href="https://swalloow.github.io/dockerfile">파이썬을 위한 Dockerfile 작성하기</a></p>

    <p>​</p>
  </li>
</ul>

<h3 id="flask-application">Flask Application</h3>

<p>Dockerfile은 일종의 이미지 설정파일입니다. <code class="highlighter-rouge">build</code> 명령어를 통해 이미지를 생성할 수 있습니다.
파이썬 웹 어플리케이션을 Docker로 실행시키는 예제를 통해 천천히 정리해보겠습니다.</p>

<script src="https://gist.github.com/Swalloow/deef1f6d161198ad65d74db54466b921.js"></script>

<p>먼저 위와 같이 간단한 플라스크 웹 어플리케이션을 작성합니다.
필요한 패키지는 requirements.txt로 관리합니다.
<code class="highlighter-rouge">pip freeze &gt; requirements.txt</code> 명령어를 통해 파일을 생성할 수 있습니다.</p>

<figure class="highlight"><pre><code class="language-markdown" data-lang="markdown">Flask==0.12</code></pre></figure>

<p>​   ​</p>

<h3 id="dockerfile-">Dockerfile 작성하기</h3>

<figure class="highlight"><pre><code class="language-markdown" data-lang="markdown">FROM ubuntu:latest
MAINTAINER your_name "email@gmail.com"
RUN apt-get update -y
RUN apt-get install -y python-pip python-dev build-essential
COPY . /app
WORKDIR /app
RUN pip install -r requirements.txt
ENTRYPOINT <span class="p">[</span><span class="nv">"python"</span><span class="p">]</span>
CMD <span class="p">[</span><span class="nv">"app.py"</span><span class="p">]</span></code></pre></figure>

<p>위와 같이 Dockerfile을 작성하시면 됩니다.
간단히 설명하자면, ubuntu 이미지를 받아와서 파이썬 환경설정을 하고
현재 경로에 있는 폴더를 복사해서 파이썬 패키지를 설치하고 앱을 실행시키는 이미지입니다.</p>

<p>​   ​</p>

<h3 id="dockerfile---">Dockerfile 빌드 및 실행하기</h3>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="gp">$ </span>docker build -t flask-application:latest .
<span class="gp">$ </span>docker run -d -p 5000:5000 flask-application</code></pre></figure>

<p><code class="highlighter-rouge">docker build [name]</code> 명령어를 통해 이미지를 빌드합니다.
그리고 <code class="highlighter-rouge">docker run [image]</code> 명령어를 통해 컨테이너를 실행시킵니다.
<code class="highlighter-rouge">-p</code> 옵션은 포트를 지정하며, <code class="highlighter-rouge">-d</code> 옵션은 백그라운드로 실행시키는 옵션입니다.
5000번 포트를 확인해보면 플라스크 어플리케이션이 실행된 것을 확인할 수 있습니다.</p>

<p>​   ​</p>

	  ]]></description>
	</item>

	<item>
	  <title>리눅스 시스템 모니터링 명령어 정리</title>
	  <link>//system-monitoring</link>
	  <author>Swalloow</author>
	  <pubDate>2017-03-24T19:18:00+09:00</pubDate>
	  <guid>//system-monitoring</guid>
	  <description><![CDATA[
	     <p>​   ​</p>

<p>리눅스 시스템 모니터링을 위한 명령어에 대해 정리해보았습니다.</p>

<p>​   ​</p>

<h2 id="top">프로세스 모니터링 명령어 - top</h2>

<p><img src="/assets/images/linux_top.png" alt="top" /></p>

<p><strong>top</strong> 명령어는 커널을 통하여 관리되는 프로세스들의 정보(메모리 사용률, CPU 사용률, 상태정보 등)를 확인할 수 있는 명령어입니다.
응용프로그램을 강제로 종료시키고 싶을 때, 실행중인 프로세스를 찾아 <code class="highlighter-rouge">kill</code> 명령어를 통해 강제종료시킬 수도 있습니다.</p>

<p>OS X에서는 <code class="highlighter-rouge">-o</code> 옵션을 통해, 리눅스에서는 <code class="highlighter-rouge">shift + f</code> 명령어를 통해 프로세스를 key에 따라 정렬할 수 있습니다.</p>

<p>​   ​</p>

<h2 id="vmstat-iostat-sar">시스템 리소스 정보 - vmstat, iostat, sar</h2>

<p><img src="/assets/images/linux_vmstat.png" alt="vmstat" /></p>

<p><strong>vmstat</strong> 명령어는 <em>virtual memory statistics</em> 의 줄임말로 가상메모리 등 다양한 리소스 정보를 제공합니다.
OS X에서는 <code class="highlighter-rouge">vm_stat</code> 명령어로, 리눅스에서는 <code class="highlighter-rouge">vmstat</code> 명령어로 확인하실 수 있습니다.</p>

<p><img src="/assets/images/linux_iostat.png" alt="iostat" /></p>

<p><strong>iostat</strong> 명령어는 sysstat에서 가장 기본적인 명령어로 CPU 및 디스크 입출력에 대한 기본정보를 제공합니다.</p>

<p><img src="/assets/images/linux_sar.png" alt="sar" /></p>

<p><strong>sar</strong> 명령어는 시스템 활동 모니터링에 유용합니다.
특히 <code class="highlighter-rouge">-r, -f</code> 옵션을 통해 CPU, 메모리 사용률을 날짜, 시간 대 별로 확인할 수 있습니다.</p>

<p>​   ​</p>

<h2 id="linux-sysstat--">Linux sysstat 패키지 설치</h2>

<p>CentOS, Ubuntu에서는 앞서 말씀드린 <code class="highlighter-rouge">sar, vmstat</code> 등의 명령어를 사용하기 위해서 <code class="highlighter-rouge">sysstat</code> 패키지를 설치해야 합니다.
아래의 명령어를 통해 설치할 수 있습니다.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash">// CentOS, Ubuntu
<span class="gp">$ </span>yum install sysstat -y
<span class="gp">$ </span>apt install sysstat -y</code></pre></figure>

<p>만일 권한 오류나 명령어를 찾을 수 없다는 오류가 나타난다면 아래의 설정을 통해 해결할 수 있습니다.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="gp">$ </span>sudo vi /etc/default/sysstat
<span class="gp">$ </span><span class="nv">ENABLED</span><span class="o">=</span>”true”</code></pre></figure>

<p>​   ​</p>

	  ]]></description>
	</item>

	<item>
	  <title>SSH 프로토콜과 Tunneling 이해하기</title>
	  <link>//ssh-tunneling</link>
	  <author>Swalloow</author>
	  <pubDate>2017-03-20T19:18:00+09:00</pubDate>
	  <guid>//ssh-tunneling</guid>
	  <description><![CDATA[
	     <p>​   ​</p>

<p>지금까지 아무 생각없이 SSH를 사용하다가 한번 정리해보았습니다.</p>

<p>​   ​</p>

<h2 id="ssh-protocol">SSH Protocol</h2>

<p>SSH는 Secure Shell의 약자입니다. SSH는 한마디로 정의하면,
네트워크 상의 다른 컴퓨터에 로그인하거나 원격 시스템에서 명령을 실행하고
다른 시스템으로 파일을 복사할 수 있도록 해 주는 프로토콜입니다.
VPN을 구성하는 것보다 가격이 저렴하고 쉽게 연결할 수 있어 많이 사용됩니다.</p>

<p>MacOS에는 <strong>OpenSSH</strong> 클라이언트와 서버가 내장되어 있기 때문에 바로 사용할 수 있습니다.
SSH는 <strong>22번 포트</strong> 를 사용하며, 크게 다음의 3가지를 제공합니다.</p>

<p>​   ​</p>

<h4 id="authentication">1. Authentication</h4>

<p><img src="/assets/images/ssh-key-auth-flow.png" alt="SSH-Auth" /></p>

<p>SSH는 public key와 private key를 사용하는 비대칭 암호방식을 사용합니다.
간단히 설명하면, <code class="highlighter-rouge">public key</code>와 <code class="highlighter-rouge">private key</code>가 모두 있어야 인증이 되는 방식입니다.
각자 private key는 외부 유출없이 가지고 있고, public key만 네트워크를 통해 전달합니다.
SSH는 RSA, DSA 등 다양한 인증 방식을 지원합니다.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="gp">$ </span>ssh-keygen
<span class="gp">$ </span>cat ~/.ssh/id_rsa.pub</code></pre></figure>

<p><code class="highlighter-rouge">ssh-keygen</code> 명령어를 통해 ssh 키를 생성하고
<code class="highlighter-rouge">~/.ssh/id_rsa.pub</code>에서 public key를 확인할 수 있습니다.</p>

<p>​   ​</p>

<h4 id="encryption--integrity">2. Encryption &amp; Integrity</h4>

<p>SSH는 네트워크를 통해 전달되는 데이터를 암호화합니다.
<code class="highlighter-rouge">3DES, blowfish</code> 등 여러 가지 암호화 방식을 제공하며,
새로운 암호화 기법을 추가할 수도 있습니다.</p>

<p>그리고 SSH는 네트워크를 통해 받은 데이터가 변경되지 않았음(무결성)을 보장해줍니다.
이를 위해 <strong>MAC(Message Authentication Code)</strong> 이라는 알고리즘을 사용합니다.</p>

<p><img src="/assets/images/mac-algo.jpg" alt="MAC-Algo" /></p>

<p>MAC 알고리즘은 다음과 같이 동작합니다.
SSH 클라이언트가 서버로 메세지를 보내면,
MAC 알고리즘을 통해 <code class="highlighter-rouge">secret key</code>를 입력받아 MAC 코드를 생성합니다.
그리고, 임의 길이의 암호화 된 메시지와 MAC 코드를 SSH 서버로 보냅니다.</p>

<p>서버에서는 다시 메세지와 서버의 <code class="highlighter-rouge">secret key</code>를 조합하여 MAC 코드를 만들고,
클라이언트로부터 받은 MAC 코드와 비교하여 인증을 진행하게 됩니다.</p>

<p>​   ​</p>

<h4 id="compression">4. Compression</h4>

<p>SSH는 네트워크 상에서 데이터를 전송하고 수신할 때 압축 과정을 거칩니다.
이를 통해 전송 데이터의 크기를 줄여 네트워크 비용을 낮출 수 있습니다.</p>

<p>​   ​</p>

<h2 id="ssh-tunneling">SSH Tunneling</h2>

<p>SSH Tunneling은 터널을 통해 데이터를 주고받는다 해서 붙여진 이름입니다.
앞서 얘기했던 것처럼 연결, 통신은 모두 암호화되며 <code class="highlighter-rouge">SMTP, IMAP</code> 등 여러 가지로 사용될 수 있습니다.</p>

<p>Direct로 보내면 네트워크 층에서 수 많은 공격을 받을 수 있기 때문에
SSH를 통해 다른 Application에 연결하는 것이 안전합니다.
SSH Tunneling에는 다음과 같이 두 가지 방법이 있습니다.</p>

<p>​   ​</p>

<h4 id="local-port-forwarding">Local port forwarding</h4>

<p><img src="/assets/images/ssh-local.png" alt="SSH-Local" /></p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="gp">$ </span>ssh -L port1:host_name:port2 server_name</code></pre></figure>

<p>로컬에서 서버에 있는 MySQL과 SSH 연결을 한다고 가정해보겠습니다.
<code class="highlighter-rouge">Local port forwarding</code>은
로컬에 설치된 MySQL 클라이언트의 3306 포트가
연결된 SSH Tunnel을 거쳐 서버에 있는 MySQL 서버의 3306 포트와 연결됩니다.
이를 통해 직접 서버의 데이터베이스에 안전하게 접근할 수 있으며
요청을 보내서 서로 데이터를 주고 받을 수 있습니다.</p>

<p>​   ​</p>

<h4 id="remote-port-forwarding">Remote port forwarding</h4>

<p><img src="/assets/images/ssh-remote.png" alt="SSH-Remote" /></p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="gp">$ </span>ssh -R port1:host_name:port2 server_name</code></pre></figure>

<p>이번에는 로컬에서 파이썬 웹 애플리케이션을 개발 중인데 친구에게 보여주고 싶다고 가정 해보겠습니다.
아직 공개 IP 주소를 제공하지 않기 때문에 인터넷을 통해 직접 기기에 연결할 수 없을 겁니다.
라우터에서 NAT를 구성하여 해결할 수 있지만 라우터의 구성을 변경해야하므로 번거롭습니다.
이럴때 <code class="highlighter-rouge">Remote port forwarding</code>을 통해 쉽게 해결할 수 있습니다.</p>

<p>먼저 port1의 서버에서 port2로 로컬 트래픽을 전달하는 SSH 터널을 생성합니다.
이후 로컬에서 port2의 서버에 연결하면 실제로 SSH 터널을 통해 데이터를 요청하는 것을 확인할 수 있습니다.</p>

<p>OSI 7계층에서 생각해보면 SSH는 <code class="highlighter-rouge">Application - Transport - Network</code> 계층에 걸쳐있습니다.
Application 계층에서 포트를 연결하면 Transport 계층의 TCP 통신을 통해 전달되고,
Network 계층을 통해 목적지로 이동하게 됩니다.</p>

<p>​   ​</p>

	  ]]></description>
	</item>

	<item>
	  <title>AWS EC2 인스턴스 SSH 접속을 위한 초기설정 그리고 주의사항</title>
	  <link>//aws-config</link>
	  <author>Swalloow</author>
	  <pubDate>2017-03-10T19:18:00+09:00</pubDate>
	  <guid>//aws-config</guid>
	  <description><![CDATA[
	     <p>​   ​</p>

<p>이 포스팅의 모든 내용은 OS X에 최적화되어 있습니다.
그리고, 정리한 내용은 AWS 공식문서에 아주 잘 소개되어 있습니다.</p>

<p>​   ​</p>

<h2 id="aws-cli">AWS CLI</h2>

<p>AWS CLI는 여러 AWS 서비스를 명령줄에서 제어하고 스크립트를 통해 자동화할 수 있는 커멘드라인 인터페이스입니다.
이를 사용하기 전에 먼저, brew를 통해 <code class="highlighter-rouge">awscli</code>를 설치해야 합니다.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="gp">$ </span>brew install awscli</code></pre></figure>

<p>설치하고 나면 이제 aws 명령어를 사용할 수 있습니다.
가장 먼저 configure 명령어를 통해 Access key를 입력해야합니다.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="gp">$ </span>aws configure
AWS Access Key ID <span class="o">[</span>None]: AKIAIOSFODNN7EXAMPLE
AWS Secret Access Key <span class="o">[</span>None]: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
Default region name <span class="o">[</span>None]: us-west-2
Default output format <span class="o">[</span>None]: ENTER</code></pre></figure>

<p>여기에서 Access Key ID는 <code class="highlighter-rouge">[IAM - Security credentials]</code>에서 확인할 수 있습니다.</p>

<p>​   ​</p>

<h2 id="aws-ec2-">AWS EC2 접속</h2>

<p>EC2 인스턴스를 만들면 .pem이라는 파일을 발급받게 됩니다.
이 파일은 절대 외부로 유출되면 안되기 때문에 조심해야합니다.
.pem 파일이 있는 경로로 이동한 다음 아래의 명령어를 통해 접속하면 됩니다.</p>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="gp">$ </span>chmod 400 /path/my-key-pair.pem
<span class="gp">$ </span>ssh -i /path/my-key-pair.pem ec2-user@ec2-198-51-100-1.compute-1.amazonaws.com</code></pre></figure>

<p>“Permission denied” 에러가 발생하면 <code class="highlighter-rouge">-vvv</code> 옵션을 통해 디버깅 할 수 있습니다.
(가장 많이 하는 실수가 user_id에 ubuntu를 안적어주는 경우)</p>

<p>​   ​</p>

<h2 id="aws---">AWS를 사용하면서 조심해야할 사항</h2>

<p>​   ​</p>

<h4 id="section">1.인스턴스 관리</h4>

<p>프리티어를 사용하는 경우, 다 사용하고 나서 인스턴스를 항상 꺼주는 습관을 들여 과도한 요금이 과금되지 않도록 해야합니다.
특히 여러 개의 인스턴스를 돌리는 경우 순식간에 청구서가 날아올 수 있습니다.</p>

<h4 id="root---">2. ROOT 계정 사용 자제</h4>

<p>많은 경우에 ROOT 계정의 키가 털려서 과금이 발생됩니다. IAM을 통해 Admin 계정을 만들어서 사용하고,
GitHub 같은 곳에 설정파일을 올리지 말아야합니다.</p>

<h4 id="cloudwatch--">3. CloudWatch로 요금 확인</h4>

<p>CloudWatch를 통해 Billing Cost가 일정 금액을 넘어가면 메일이나 Slack 메세지로 보내도록 설정해두면 편합니다.</p>

<h4 id="section-1">4. 네트워크 확인</h4>

<p>네트워크에서 모든 포트를 여는 것도 위험합니다. 이렇게 되면 DDoS 공격을 받을 위험이 있습니다.</p>

<p>​   ​</p>

<h2 id="section-2">참고링크</h2>
<ul>
  <li><a href="http://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/AccessingInstancesLinux.html">SSH를 사용하여 Linux 인스턴스에 연결</a></li>
  <li><a href="http://docs.aws.amazon.com/ko_kr/AWSEC2/latest/UserGuide/TroubleshootingInstancesConnecting.html#TroubleshootingInstancesConnectingMindTerm">인스턴스 연결문제 해결방법</a></li>
</ul>

<p>​   ​</p>

	  ]]></description>
	</item>


</channel>
</rss>
