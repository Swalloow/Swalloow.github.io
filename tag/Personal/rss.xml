<?xml version="1.0" encoding="UTF-8" ?>

<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
   
      <title>swalloow.github.io/</title>
   
   <link>http://swalloow.github.io/</link>
   <description>About Data Science, Data Engineering</description>
   <language>ko-KO</language>
   <managingEditor> Swalloow</managingEditor>
   <atom:link href="rss" rel="self" type="application/rss+xml" />
   
	<item>
	  <title>AWS Solutions Architect Associate 취득 후기</title>
	  <link>//aws-cert</link>
	  <author>Swalloow</author>
	  <pubDate>2019-11-30T19:18:00+09:00</pubDate>
	  <guid>//aws-cert</guid>
	  <description><![CDATA[
	     <p>​</p>

<p>그동안 관심은 있었지만 굳이 내 돈주고 시험볼 생각이 없었기에 미루고 있다가
12월까지 취득하면 50달러를 준다는 이벤트에 눈이 돌아가 시험을 신청했다.
시험 비용이 약 19만원이기 때문에 당연히 회사 지원금으로 봐야 한다.</p>

<p>처음엔 그냥 시험봐도 상관없겠지라고 생각했지만 AWS에 생각보다 많은 기능과 서비스가 있어서
준비안하고 보면 떨어질거라 생각한다. 이미 AWS에 익숙한 개발자 또는 인프라 엔지니어라면 Udemy에서
<strong>AWS Solutions Architect Associate Practice Test</strong>를 통해 준비하면 충분하다.
5~6회 정도의 실전 모의고사를 제공해주며 오답에 대한 풀이까지 친절하게 설명해준다.
다만 영어로 말장난치는 문제들도 가끔 존재하는데 실제 시험에서 그런 문제는 안나온다고 보면 된다.</p>

<p>시험을 보자마자 결과가 나오고 다음날 점수와 자격증 pdf 파일을 확인할 수 있다.
기대안했던 것과 달리 준비하면서 새로 알게된 정보도 많아 관심있다면 보는 걸 추천한다.</p>

<p><img src="http://drive.google.com/uc?export=view&amp;id=1TEZtk4Z65bzOmmEdgxcejTMEkkKaxTY0" alt="" /></p>

	  ]]></description>
	</item>

	<item>
	  <title>Open Infra Days 2019 후기</title>
	  <link>//openinfra</link>
	  <author>Swalloow</author>
	  <pubDate>2019-07-20T19:18:00+09:00</pubDate>
	  <guid>//openinfra</guid>
	  <description><![CDATA[
	     <p>​</p>

<p>19일부터 진행했던 <a href="https://openinfradays.kr/#schedule">Open Infra Days 2019</a>에 참여하면서
배운 점들을 간단히 정리해보고자 한다. 해외의 CNCF 컨퍼런스처럼 사람들의 관심이 높아지고 있다는걸 느낄 수 있었다.
그리고 돈 많은 후원사가 많아서 그런지 먹거리와 경품이 풍성했다. 하지만 내 번호는 한번도 당첨되지 않았다.</p>

<p>내가 들었던 세션들은 주로 Kubernetes Scheduler, Controller, Kubernetes 기반의 ML Workflow에 대한 내용이었다.</p>

<p>​</p>

<h3 id="kubernetes-scheduler-deep-dive">kubernetes scheduler deep dive</h3>

<p><img src="http://drive.google.com/uc?export=view&amp;id=1yIIsllw24U7pTsytGg38t1OapYsLo0UT" alt="" /></p>

<ul>
  <li>kube default 스케줄러가 어떻게 동작하는지, custom 스케줄러를 어떻게 적용시킬 수 있는지에 대한 내용</li>
  <li>어려운 내용을 단계 별로 도식화하여 쉽게 설명해주셔서 좋았음</li>
  <li>
    <p><a href="https://drive.google.com/file/d/1bqkUrXOEUvNZxf0iXghlPZ5DSJhRZ85t/view?fbclid=IwAR34JIei_4nzEgZfZkk8knwLQN-ldyRI5t1x-VQN9dVSq4b1CjAcZQ_LTpk">발표자료 링크</a></p>

    <p>​</p>
  </li>
</ul>

<h3 id="kubernetes-kafka-flink----">Kubernetes에서 kafka와 flink를 사용하여 실시간 스트리밍 구현하기</h3>

<ul>
  <li>주로 적용하면서 겪었던 문제들에 대한 내용을 공유</li>
  <li>kafka, flink의 state가 크게 증가하는 경우 이슈 발생 가능 (retension으로 정리)</li>
  <li><a href="https://www.slideshare.net/secret/xLiHQcuZoRWhZd?fbclid=IwAR34j570PitRo3lwwDpU1LvJ5CI5MmsJky3pYXE5PVRyY29J5XBmqXKQt3I">발표자료 링크</a></li>
  <li>
    <p><a href="https://github.com/protess/k3a-f3k-k8s">핸즈온 링크</a></p>

    <p>​</p>
  </li>
</ul>

<h3 id="line-kubernetes----">LINE에서 Kubernetes를 쓰는 방법, 배운 것들</h3>

<p><img src="http://drive.google.com/uc?export=view&amp;id=1RXRMOZYuyVSOvXGcZwFb9l5yTiW5I_aX" alt="" /></p>

<ul>
  <li>사내 프라이빗 클라우드 Verda에 Kubernetes 기반의 서비스를 올리면서 겪은 이슈</li>
  <li>Kubernetes as a Service를 개발하면서 겪은 이슈</li>
  <li>
    <p>Kube Custom Controller를 구현하는 방법</p>

    <p>​</p>
  </li>
</ul>

<h3 id="t----kubernetes-as-a-service">카카오 T택시를 통해 살펴보는 카카오의 kubernetes as a service</h3>

<ul>
  <li>사내 프라이빗 클라우드에 Kubernetes as a Service 개발하면서 이슈 공유</li>
  <li>기존 LDAP 통합 인증을 위해 kubectl login plugin 개발</li>
  <li>In-House Custom DNS Controller 개발 과정 (Operator SDK 사용)</li>
  <li>
    <p>카카오 T 택시를 Kubernetes 기반으로 마이그레이션 했던 과정 공유</p>

    <p>​</p>
  </li>
</ul>

<h3 id="kakao-automatic-k8s-monitoring">Kakao automatic k8s monitoring</h3>

<ul>
  <li>카카오의 대용량 K8S 클러스터 모니터링 자동화 서비스 개발 공유</li>
  <li>pod, ingress, api-server, system 지표를 자동으로 수집, 알림, 모니터링</li>
  <li>자동으로 리소스 정리, 플러그인을 Helm으로 배포</li>
  <li>EFK + prometheus 기반으로 개발</li>
  <li>
    <p>OOM 이슈 해결을 위한 불필요 메트릭 제거 (카디널리티 분석)</p>

    <p>​</p>
  </li>
</ul>

<h3 id="efficient-job-scheduling-for-ml-workloads-in-kube-env">Efficient Job scheduling for ML workloads in kube env</h3>

<ul>
  <li>삼성전자의 ML Workflow 플랫폼 개발하면서 겪은 이슈 공유</li>
  <li>kube default scheduler가 ML Workflow에 안맞는 이유 설명</li>
  <li>Kube 기반의 분산 DL 학습에서 병목이 가능한 지점들 설명</li>
  <li>kube-batch로 스케줄링 최적화하는 과정 (PodGroup을 기준으로 스케줄링)</li>
  <li>
    <p>기타 ML Job에서 발생할 수 있는 이슈 (GPU Staggler, Locality…)</p>

    <p>​</p>
  </li>
</ul>

<h3 id="gpu--k8s-cluster--ml-training-">대규모 GPU 기반 k8s cluster를 활용한 ml training 이슈</h3>
<ul>
  <li>삼성전자의 Kube 기반 GPU 클러스터를 운영하면서 겪은 이슈 공유</li>
  <li>CPU-GPU, GPU-GPU 간의 연결 파이프라인 (NVIDIA/DALI)</li>
  <li>GPGPU 간 데이터 복제 오버헤드 문제, CNI 이슈</li>
  <li>
    <p>Processing 단계에서 Feeding Bottleneck 문제</p>

    <p>​</p>
  </li>
</ul>

<h3 id="kubernetes---ml-pipeline-">kubernetes를 활용하여 효율적인 ml pipeline 만들기</h3>

<ul>
  <li>AWS 에서 ML 플랫폼 개발, 설계 단계에 대해 공유</li>
  <li>학습 데이터를 전달하기 위해 EC2 NFS 서버를 PV로 사용 (S3FS로 했다가 수정)</li>
  <li>Inference 서버는 TensorRT를 활용 (Sync, Async)</li>
  <li>
    <p><a href="https://on-demand.gputechconf.com/gtc/2019/presentation/_/s9264-how-to-build-efficient-ml-pipelines-from-the-startup-perspective.pdf">발표자료 링크</a></p>

    <p>​</p>
  </li>
</ul>

<h2 id="section">정리하면서</h2>

<p>발표를 통해 Scheduler, Controller에 대한 내용을 더 잘 이해할 수 있었고, 기술 세션 뿐만 아니라 Kubernetes에 대한 생각과
향후 개발 방향을 공유하는 발표도 많았던 점이 좋았다.</p>

<p>여러 세션에서 공유했던 이슈들을 다시 보니 Ingreess/Egress, DNS Controller, RBAC에 대한 내용이 특히 많았다.
사내에 적용하면서 당연히 마주하게 될 부분일테니 네트워크, 인증 관련 부분은 다시 공부해보려한다.</p>

<p>​</p>

	  ]]></description>
	</item>

	<item>
	  <title>19년 상반기 회고</title>
	  <link>//start-3</link>
	  <author>Swalloow</author>
	  <pubDate>2019-07-06T19:18:00+09:00</pubDate>
	  <guid>//start-3</guid>
	  <description><![CDATA[
	     <p>​</p>

<p>상반기에 많은 일이 있었지만 가장 많은 부분을 차지한 졸업과 이직에 대한 글을 남겨두려 한다.
졸업을 하기 이전에 가고 싶었던 IT 회사에 운이 좋게 입사할 수 있었다.
그러나 내가 기대했던 것과 많이 달라서 1년 만에 이직을 결심하게 되었다.
이직을 준비하면서 기본기를 빠르게 다시 공부할 수 있었고 많은 도움이 되었다.</p>

<p>보통 신입으로 입사하게 되면 본인이 어떤 팀으로 들어가게 될지 모르는 경우가 많다.
게다가 팀에 대한 정보도 적은 편이라 많은 학생들이 회사의 이름 또는 이미지를 보고 들어간다.
하지만 회사의 알려진 문화가 모든 팀에 해당하는 것은 아니다.
흔히 팀바팀이라고 말하는데 팀마다 다르고 사람마다 다를 수 있다.
이 부분이 내가 신입이었기에 놓친 부분이었다.
이후에 이직 준비를 하면서 주변 사람들을 통해 미리 알아보고 선택하게 되었다.</p>

<p>사실 지금 입사하게 된 회사도 들어가기 이전에는 걱정과 선입견이 있었지만
결과적으로 매우 만족하면서 다니고 있다. 역시 팀바팀이 중요하다는 걸 다시 한번 깨닫는 중.
하반기에는 클라우드 인프라, 데이터 엔지니어링을 주제로 다양한 글을 남겨보려고 한다.</p>

<p>​</p>

	  ]]></description>
	</item>

	<item>
	  <title>Apache Airflow에 기여하면서 배운 점들</title>
	  <link>//airflow-contrib</link>
	  <author>Swalloow</author>
	  <pubDate>2018-12-08T19:18:00+09:00</pubDate>
	  <guid>//airflow-contrib</guid>
	  <description><![CDATA[
	     <p>​</p>

<p>Apache Airflow는 코드를 통해 워크플로우를 관리하고 모니터링 할 수 있도록 도와주는 플랫폼이다.
Airflow 프로젝트에 대한 설명은 다른 글에서도 많이 다루기 때문에 생략하고
이 글에서는 처음으로 아파치 프로젝트에 기여해본 경험을 정리해보려 한다.</p>

<p>​</p>

<h2 id="section">기여하게 된 배경</h2>

<p>당시에 관리하던 데이터 인프라에는 의존성이 얽혀있는 배치 작업이 상당히 많았다.
여기에서 의존성이 얽혀있다는 말은 A 작업과 B 작업이 성공적으로 끝나고 난 뒤 C 작업을 해야하는 경우를 말한다.
또한 각 작업들은 서로 다른 시간에 스케줄링 되어야 했고, 작업이 실패하는 경우 재시도 또는 특정 로직을 실행시킬 수 있어야 했다.</p>

<p>처음에는 단순한 구조이다 보니 스크립트로 관리했지만 점차 늘어나는 운영 이슈에 대응하기 위해 Airflow를 활용하기로 결정했다.
하지만 운영하다 보니 AWS 관련 컴포넌트들의 여러 버그를 발견하게 되었고 이를 수정하기 위해 PR을 추가했었다.</p>

<p>​</p>

<h2 id="pr-">아파치 프로젝트 PR 프로세스</h2>

<p>아파치 프로젝트는 이슈 관리 도구로 JIRA를 사용한다. CI 도구는 프로젝트마다 다른 편인데 Airflow의 경우 TravisCI를 사용한다.
모든 프로젝트에는 처음 프로젝트에 기여하려는 개발자를 위해 <strong>CONTRIBUTING.md</strong> 라는 문서를 제공한다.
문서에는 개발 및 테스트 환경을 어떻게 구축해야하는지, 지켜야할 규칙, PR 가이드라인 등에 대해 설명되어 있다.
그리고 PR template를 준수해야 하는데 잘 모르겠다면, 이전 PR들을 확인하고 비슷한 양식으로 작성하면 된다.</p>

<p>내가 처음 접했던 Airflow 문서에는 AWS 관련 Hook, Operator도 반영되어 있지 않았다.
그래서 첫 PR로 AWS, GCP 관련 컴포넌트를 업데이트하는 문서 기여를 하게 되었다.
문서 관리에는 <a href="https://readthedocs.org/">readthedocs</a>를 사용하고 있었고 Sphinx 빌드를 통해 문서를 확인할 수 있었다.</p>

<p>사용하다보니 특히 EMR 관련 Hook과 Operator에 버그가 많았다.
만일 JIRA에 이미 등록되어 있는 이슈가 아니라면 이슈를 새로 생성한 다음 PR을 추가해주어야 한다.</p>

<p><img src="http://drive.google.com/uc?export=view&amp;id=1d0SNiE9qJza0CtmU8S2k8h4Q3iRPE8vN" alt="" /></p>

<p>비슷한 이슈를 겪고 있는 사람들이 있어서 좀 신기했다.
그리고 <strong>아주 작은 수정이라도 테스트 케이스를 추가</strong>해야 한다는 사실을 알게 되었다.</p>

<p><img src="http://drive.google.com/uc?export=view&amp;id=1Re-gmGnEOlB8hxPhAkbjYQpQ-6kOzm6j" alt="" /></p>

<p>양식만 잘 지키면 커미터들은 정말 친절하다. 내가 파악하지 못한 부분까지 알려주고, 코드 리뷰도 받을 수 있다.
다른 PR을 참고하면서 많이 배울 수 있었다.</p>

<p>​</p>

<h2 id="section-1">클라우드 인프라 테스트 방법</h2>

<p>AWS는 기본적으로 클라우드 환경이다.
따라서 과금문제로 인해 실제로 추가, 변경한 오퍼레이터가 잘 동작하는지 매번 확인해보기가 힘들다.
Airflow에서는 AWS 서비스를 Mocking 하기 위해 <a href="https://github.com/spulec/moto">moto</a> 라는 라이브러를 활용해서 테스트를 작성한다.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="nd">@mock_s3</span>
<span class="k">def</span> <span class="nf">test_my_model_save</span><span class="p">():</span>
    <span class="c"># Create Bucket so that test can run</span>
    <span class="n">conn</span> <span class="o">=</span> <span class="n">boto3</span><span class="o">.</span><span class="n">resource</span><span class="p">(</span><span class="s">'s3'</span><span class="p">,</span> <span class="n">region_name</span><span class="o">=</span><span class="s">'us-east-1'</span><span class="p">)</span>
    <span class="n">conn</span><span class="o">.</span><span class="n">create_bucket</span><span class="p">(</span><span class="n">Bucket</span><span class="o">=</span><span class="s">'mybucket'</span><span class="p">)</span>
    <span class="n">model_instance</span> <span class="o">=</span> <span class="n">MyModel</span><span class="p">(</span><span class="s">'steve'</span><span class="p">,</span> <span class="s">'is awesome'</span><span class="p">)</span>
    <span class="n">model_instance</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>
    <span class="n">body</span> <span class="o">=</span> <span class="n">conn</span><span class="o">.</span><span class="n">Object</span><span class="p">(</span><span class="s">'mybucket'</span><span class="p">,</span> <span class="s">'steve'</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">()[</span><span class="s">'Body'</span><span class="p">]</span><span class="o">.</span><span class="n">read</span><span class="p">()</span><span class="o">.</span><span class="n">decode</span><span class="p">()</span>

    <span class="k">assert</span> <span class="n">body</span> <span class="o">==</span> <span class="s">'is awesome'</span></code></pre></figure>

<p>위와 같이 moto에서 미리 정의한 mock object를 decorator를 사용하여 쉽게 활용할 수 있다.
하지만 AWS에서 공식으로 지원하는 라이브러리가 아니다보니 업데이트가 늦어지기도 한다.
이런 이유로 인해 unittest의 mock으로 작성된 테스트 코드도 많이 있다.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">TestEmrAddStepsOperator</span><span class="p">(</span><span class="n">unittest</span><span class="o">.</span><span class="n">TestCase</span><span class="p">):</span>
    <span class="c"># When</span>
    <span class="n">_config</span> <span class="o">=</span> <span class="p">[{</span>
        <span class="s">'Name'</span><span class="p">:</span> <span class="s">'test_step'</span><span class="p">,</span>
        <span class="s">'ActionOnFailure'</span><span class="p">:</span> <span class="s">'CONTINUE'</span><span class="p">,</span>
        <span class="s">'HadoopJarStep'</span><span class="p">:</span> <span class="p">{</span>
            <span class="s">'Jar'</span><span class="p">:</span> <span class="s">'command-runner.jar'</span><span class="p">,</span>
            <span class="s">'Args'</span><span class="p">:</span> <span class="p">[</span>
                <span class="s">'/usr/lib/spark/bin/run-example'</span>
            <span class="p">]</span>
        <span class="p">}</span>
    <span class="p">}]</span>

    <span class="k">def</span> <span class="nf">setUp</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">configuration</span><span class="o">.</span><span class="n">load_test_config</span><span class="p">()</span>

        <span class="c"># Mock out the emr_client (moto has incorrect response)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">emr_client_mock</span> <span class="o">=</span> <span class="n">MagicMock</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">operator</span> <span class="o">=</span> <span class="n">EmrAddStepsOperator</span><span class="p">(</span>
            <span class="n">task_id</span><span class="o">=</span><span class="s">'test_task'</span><span class="p">,</span>
            <span class="n">job_flow_id</span><span class="o">=</span><span class="s">'j-8989898989'</span><span class="p">,</span>
            <span class="n">aws_conn_id</span><span class="o">=</span><span class="s">'aws_default'</span><span class="p">,</span>
            <span class="n">steps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_config</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">test_init</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">operator</span><span class="o">.</span><span class="n">aws_conn_id</span><span class="p">,</span> <span class="s">'aws_default'</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">operator</span><span class="o">.</span><span class="n">emr_conn_id</span><span class="p">,</span> <span class="s">'emr_default'</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">test_render_template</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">ti</span> <span class="o">=</span> <span class="n">TaskInstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">operator</span><span class="p">,</span> <span class="n">DEFAULT_DATE</span><span class="p">)</span>
        <span class="n">ti</span><span class="o">.</span><span class="n">render_templates</span><span class="p">()</span>

        <span class="n">expected_args</span> <span class="o">=</span> <span class="p">[{</span>
            <span class="s">'Name'</span><span class="p">:</span> <span class="s">'test_step'</span><span class="p">,</span>
            <span class="s">'ActionOnFailure'</span><span class="p">:</span> <span class="s">'CONTINUE'</span><span class="p">,</span>
            <span class="s">'HadoopJarStep'</span><span class="p">:</span> <span class="p">{</span>
                <span class="s">'Jar'</span><span class="p">:</span> <span class="s">'command-runner.jar'</span><span class="p">,</span>
                <span class="s">'Args'</span><span class="p">:</span> <span class="p">[</span>
                    <span class="s">'/usr/lib/spark/bin/run-example'</span>
                <span class="p">]</span>
            <span class="p">}</span>
        <span class="p">}]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">assertListEqual</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">operator</span><span class="o">.</span><span class="n">steps</span><span class="p">,</span> <span class="n">expected_args</span><span class="p">)</span>


<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">'__main__'</span><span class="p">:</span>
    <span class="n">unittest</span><span class="o">.</span><span class="n">main</span><span class="p">()</span></code></pre></figure>

<p>unittest로 작성된 테스트 케이스는 API로 주고 받는 json을 직접 정의해줘야 하는 번거로움이 있다.
테스트 케이스를 작성하고 난 다음 바로 PR을 추가하는 것보다 로컬 CI를 미리 돌려보는게 좋다.</p>

<p><img src="http://drive.google.com/uc?export=view&amp;id=1MEOqsKocQTV8y5y_y2xrpIppkw2ndOvT" alt="" /></p>

<p>TravisCI는 오픈소스인 경우 무료로 사용할 수 있으며, yml 파일에 미리 정의되어 있으니 참고하면 된다.
로컬에서 CI가 통과되고 나면 PR을 추가해도 좋다.
작업이 길어지면서 커밋이 여러 개로 늘어나는 경우, <strong>commit을 squash</strong> 해주는 것이 좋다.
(나중에 문제가 생겼을 때 쉽게 rebase 하기 위함)</p>

<p>​</p>

<h2 id="section-2">잡다한 정리</h2>

<ul>
  <li><a href="https://issues.apache.org/jira/browse/AIRFLOW-713">[AIRFLOW-713] EmrCreateJobFlowOperator and EmrAddStepsOperator attributes are not jinjafied</a></li>
  <li><a href="https://issues.apache.org/jira/browse/AIRFLOW-950">[AIRFLOW-950] Missing AWS integrations on documentation::integrations</a></li>
  <li><a href="https://issues.apache.org/jira/browse/AIRFLOW-1453">[AIRFLOW-1453] Add ‘steps’ into template_fields in EmrAddSteps</a></li>
  <li><a href="https://issues.apache.org/jira/browse/AIRFLOW-1436">[AIRFLOW-1436, AIRFLOW-1475] EmrJobFlowSensor consideres Cancelled step as Successful</a></li>
</ul>

<p>그 동안 5개 정도의 버그를 해결했고 수정했던 AWS EMR 관련 버그들은 1.9 - 10 버전에 모두 반영 되었다.
이외에도 Airflow에는 여전히 자잘한 버그가 많이 남아있다.
(Docker로 운영했을 때 로그가 이상하게 나타난다거나, SubDag Deadlock 문제 등)
당시에 블로그를 열심히 했다면 운영 관련해서 글을 남겼을텐데 하는 아쉬움이 남아있다.</p>

<p>어쨋든 Airflow를 적용하고 난 뒤, 편히 새벽에 잠들 수 있게 되었다.
지금은 머신러닝 파이프라인 관련 도구가 많이 나왔지만, Airflow도 충분히 해당 영역을 커버할 수 있다.</p>

<p>그리고 오픈소스에 대해 다시 한번 생각해보게 되었다.
많은 사람들이 참여하는 오픈소스이다 보니 당연히 버그나 이슈가 생길 수 있고,
문제가 생겼을 때 고쳐달라고 강요하거나 기다리는 것보다 스스로 수정해서 기여하는 것이 올바른 태도가 아닌가 싶다.</p>

	  ]]></description>
	</item>

	<item>
	  <title>17-18년 블로그 회고 및 다짐</title>
	  <link>//start</link>
	  <author>Swalloow</author>
	  <pubDate>2018-11-09T19:18:00+09:00</pubDate>
	  <guid>//start</guid>
	  <description><![CDATA[
	     <p>​</p>

<p>지킬 블로그로 이사한지도 벌써 2년이 다 되어 간다.
항상 이 맘때쯤이면 글쓰는 횟수가 줄어들고 블로그를 또 이사하고 싶은 욕구가 생긴다.
하지만 지금 운영하고 있는 블로그도 전혀 문제가 없기 때문에 올해까지는 참기로 결정했다.</p>

<p><img src="http://drive.google.com/uc?export=view&amp;id=1BC2DMbBuEZCL8oBNSNPTD6PM4rOs8y5B" alt="" /></p>

<p>18년 들어서 글을 정말 안쓰기 시작했는데 이상하게도 방문자 수는 계속 증가했다.
특히 최근 몇달 간 방문자 수가 6천 - 8천 사이에만 있는 걸 보니 다시 글을 써야겠다는 생각이 들었다.
가장 많이 방문한 페이지 리스트를 보면 어려운 주제에 대한 글보다
간단한 주제이면서 잊지 않기 위해 기록해 둔 글들이 더 인기가 많았다.</p>

<p>글또를 시작하면서 다시 2주에 1번 정도 글을 써보려 한다.
주로 백엔드, 데이터 엔지니어링에 대한 내용이겠지만, 가끔씩 금융 도메인에 대한 내용도 올릴 예정이다.</p>

<p>​</p>

	  ]]></description>
	</item>

	<item>
	  <title>넷플릭스 본사 방문 후기</title>
	  <link>//netflix</link>
	  <author>Swalloow</author>
	  <pubDate>2017-06-05T21:18:00+09:00</pubDate>
	  <guid>//netflix</guid>
	  <description><![CDATA[
	     <p>​</p>

<p><img src="/assets/images/travel/netflix.jpg" alt="netflix" /></p>

<p>미국 여행하면서 다양한 경험을 했지만, 넷플릭스는 그 중 가장 기억에 남았던 장소다.
우연히 넷플릭스의 추천 팀 데이터 엔지니어로 근무하시는 선배님과 연락이 되었고,
덕분에 많은 이야기를 들을 수 있었다.</p>

<p><img src="/assets/images/travel/netflix3.jpg" alt="netflix" /></p>

<p>넷플릭스의 연봉은 실리콘밸리에서도 많이 주는 편이다.
자세한 금액은 <a href="https://www.glassdoor.com/">https://www.glassdoor.com/</a> 에서 확인해보자.</p>

<p>넷플릭스의 기반인 마이크로 아키텍쳐로 인해 팀 구성원도 그에 맞게 쪼개어져 있다.
적은 팀은 3명까지도 있고, 그 중에서 추천 팀은 10명 정도로 구성되어 있다고 한다.</p>

<p><img src="/assets/images/travel/prize.jpg" alt="netflix" /></p>

<p>회사 내부는 마치 영화관처럼 꾸며져 있었다.
실제로 넷플릭스 내에는 영화를 볼 수 있는 영화관도 있다.
계단에는 카페트가 깔려있고 벽면에는 영화 포스터들이 붙어있었다.
각 층마다 회의실, 세미나실이 정말 많았는데, 모두 영화 이름이 붙어 있었다.
예를 들면, 회의실의 이름이 닥터 지바고, 어벤져스 이런 식이다.</p>

<p><img src="/assets/images/travel/food.jpg" alt="netflix" /></p>

<p>그리고 층마다, 건물마다 전혀 다른 분위기다.
엔지니어링 팀이 있는 곳은 모니터가 여러 개에 집중하는 분위기였고,
UI/UX 팀이 위치한 곳은 전부 오픈된 공간에 자유로운 분위기였다.
벽면에는 목업디자인 샘플이 많이 붙어있었고 포스트잇을 통해 누구나 피드백을 주는 듯 했다.
밖에 나가면 산책로와 함께 거대한 공원이 있다.</p>

<p><img src="/assets/images/travel/park.jpg" alt="netflix" /></p>

<p>넷플릭스의 추천 시스템은 실시간, 전 세계 사용자를 대상으로 돌아간다.
셀제로 각 국가 별 실시간 인기 영화 순위를 보여주는 대시보드를 볼 수 있었다.
넷플릭스의 추천 시스템은 정말 유명하지만 여전히 고민하는 부분이 많다고 한다.
(비인기지역의 데이터를 어떻게 처리할 것인지, Cold start problem을 어떻게 해결할 것인지 등)
최근에는 딥러닝을 이용한 추천 시스템도 개발 중이라고 한다.</p>

<p>데이터 관련 팀은 데이터 분석 팀과 데이터 엔지니어링 팀이 나뉘어 있고 추천 팀은 그 사이에 존재한다.
데이터 분석 팀은 주로 머신러닝 쪽 일을 한다. (Model training, Parameter tuning)
중요한 것은 연구를 한다기보다 기존에 나온 여러 연구들 중에
넷플릭스에 어울리는 것을 찾아 빠르게 적용해보고 성능 테스트를 하는 것이다.</p>

<p>그리고 데이터 엔지니어링 팀은 사용자들의 다양한 로그 데이터를 수집하고 이를 빠르게 프로세싱한다.
흔히 말하는 데이터 파이프라인에 관련된 일을 한다.
그리고 또 한 가지 일은 실제 어플리케이션에 모델이 잘 동작하도록 만드는 일이다.
데이터 엔지니어링 팀에서 주로 사용하는 것은 Apache Spark 그리고 Scala 언어다.
미국에서도 Spark의 인기는 엄청나다고 한다.
년, 월, 일, 시간, 분 단위로 데이터를 나누어 저장하고 이를 불러와서 사용한다.</p>

<p>추천이 중요한 이유는 명확하다.
넷플릭스의 유저가 전 세계 몇 억명인데 이 중에 0.5% 리텐션이 늘게 되었을 때,
얻을 수 있는 매출 효과가 어마어마하기 때문이다.</p>

<p>​</p>

	  ]]></description>
	</item>

	<item>
	  <title>실리콘밸리 여행 후기</title>
	  <link>//sanfran-travel</link>
	  <author>Swalloow</author>
	  <pubDate>2017-06-05T19:18:00+09:00</pubDate>
	  <guid>//sanfran-travel</guid>
	  <description><![CDATA[
	     <p>​</p>

<p>실리콘밸리는 미국 캘리포니아 주 샌프란시스코 만 지역 남부에 위치한다.
우연히 좋은 기회를 얻게 되어 여러 회사에 들어가볼 수 있었다.</p>

<p>먼저 여행 계획 단계부터 대충 정리하자면,
어떤 IT 회사든지 방문증이 없으면 사내에 들어갈 수 없다.
나 같은 경우, 고민 끝에 링크드인에 있는 지인들을 수소문하거나
컨퍼런스에서 처음 만난 분에게 부탁해서 들어갈 수 있었다.</p>

<p>미국에서는 흔히 CS과 대학생들이 실리콘밸리 회사 투어를 하기도 하는데
누군가가 멋진 구글 지도를 만들어 주어서 편하게 다닐 수 있었다.</p>

<p><a href="https://www.google.com/maps/d/viewer?mid=1Inhyh5iUl-incqCMwzdXirUbWUk&amp;ll=37.54682624469536%2C-122.17239440000003&amp;z=9">https://www.google.com/maps/d/viewer?mid=1Inhyh5iUl-incqCMwzdXirUbWUk&amp;ll=37.54682624469536%2C-122.17239440000003&amp;z=9</a></p>

<p>간단히 살펴보면, 샌프란 위쪽에 있는 BayArea 지역에 몰려있고
다음으로 Palo Alto, SunneyVale, SanJose 까지 널려있다.
보통 시내에서 떨어진 지역에 위치한 회사들은 대부분 캠퍼스처럼 자리잡고 있다.</p>

<p><img src="/assets/images/travel/wework.jpg" alt="wework" /></p>

<p>직원들은 대부분 정말 자유롭게 일한다.
소파같은 곳에 누워서 코딩하는 사람도 많았고,
개발 팀에는 개인 책상 + 스탠드 책상이 있어서 서서 개발하는 사람도 많았다.</p>

<p>그 곳에서 일하는 사람들과 이야기를 나눠보면 자유로운 만큼 책임이 따른다고 한다.
실력이 많이 부족하거나 회사에 맞지 않다고 판단되면 가차 없이 짜른다.
그리고 그렇게 짐싸는 직원들은 회사를 욕하는게 아니라,
‘아 내가 부족하구나’를 느끼고 스스로 발전하기 위한 발판으로 삼는다.</p>

<p><img src="/assets/images/travel/linkedin.jpg" alt="" /></p>

<p>링크드인은 메인 로비에 카페와 라운지가 있다.
그 공간에서 링크드인 회원들을 위한 커리어 상담 서비스를 제공한다.</p>

<p><img src="/assets/images/travel/github2.jpg" alt="" />
<img src="/assets/images/travel/sticker.jpg" alt="" />
<img src="/assets/images/travel/github.jpg" alt="" /></p>

<p>친절한 GitHub Help 직원이 스티커를 계속 가져가라고 해서 챙겨왔다.
그리고 로비에는 ‘생각하는 옥토캣’ 조각상이 있다.</p>

<p><img src="/assets/images/travel/firefox.jpg" alt="" />
<img src="/assets/images/travel/google.jpg" alt="" />
<img src="/assets/images/travel/sanfran.jpg" alt="" /></p>

<p>파이어폭스와 구글 오피스는 바다 바로 앞에 위치한다.
구글은 오직 직원에게만 출입이 허용된다.</p>

<p>​</p>

	  ]]></description>
	</item>

	<item>
	  <title>폴리글랏 프로그래밍 후기</title>
	  <link>//polyglot-programming</link>
	  <author>Swalloow</author>
	  <pubDate>2017-03-25T19:18:00+09:00</pubDate>
	  <guid>//polyglot-programming</guid>
	  <description><![CDATA[
	     <p>​</p>

<p>임백준 작가님의 <strong>폴리글랏 프로그래밍</strong> 을 읽고 핵심내용만 간략하게 정리해보려고 한다.
시대의 흐름에 따라 재미있게 설명해주기 때문에, 킬링타임 용으로 가볍게 읽기 좋은 책인 것 같다.</p>

<ul>
  <li>모든 언어의 발전은 추상수준을 상승시켜서 프로그래머가 작성해야 하는 코드의 분량을 줄이는 방향으로 움직인다. (파이썬, 루비가 대표적인 예)</li>
  <li>
    <p>한 사람이 여러 명의 배우자와 함께 살아가는 것을 <code class="highlighter-rouge">폴리가미(polygamy)</code> 라고 한다. 이와 비슷하게 여러 언어를 사용하는 것을 <code class="highlighter-rouge">폴리글랏(polyglot)</code> 이라고 한다.</p>
  </li>
  <li>사람들은 C언어가 어느 날 갑자기 새롭게 만들어진 언어라고 착각하는 경향이 있다. 하지만 C는 B라는 더 작은 언어로부터 조금씩 성장해서 만들어진 언어다.</li>
  <li>
    <p>프로그래밍 언어의 구체적인 모습을 떠나서 언어를 개발하는 과정 자체가 공통적인 패턴을 가지고 있다. 우리는 이 본질적인 패턴에 집중해야 한다. 또한, 모든 언어는 나타나게 된 배경이 있다.</p>
  </li>
  <li>자바가 가진 문제점은 복잡성을 해결하기 위해 수많은 오픈소스 라이브러리를 만들었다는 것이다. 이 때문에 불필요한 코드가 많아 생산성이 떨어지고, 부자연스러운 확장이 이루어진다. 자바는 이미 정점을 지났다. 더 이상 간단해지거나 의미있는 발전을 할 수 없는 언어이다.</li>
  <li>최근 마이크로 아키텍쳐, 멀티코어, 분산처리 등의 복잡한 환경을 커버할 수 있는 언어로 스칼라를 소개한다.</li>
</ul>

<p>앞으로 프로그래머는 어느 하나의 언어에 안주할 수 없다.
폴리그랏 프로그래밍 시대에는 패러다임을 달리하는 여러 개의 언어를 자유롭게 구사하지 않으면 살아남기 힘들다.
따라서 앞으로 필요에 따라 언어를 빨리 습득하는 능력 또한 중요하다.</p>

<p>​</p>

	  ]]></description>
	</item>

	<item>
	  <title>Awesome Developer Roadmap</title>
	  <link>//developer-roadmap</link>
	  <author>Swalloow</author>
	  <pubDate>2017-03-18T19:18:00+09:00</pubDate>
	  <guid>//developer-roadmap</guid>
	  <description><![CDATA[
	     <p>​</p>

<p><a href="https://github.com/kamranahmedse/developer-roadmap">https://github.com/kamranahmedse/developer-roadmap</a></p>

<p>오직 Awesome만으로 별 1만개를 넘게 달았다.
저분 GitHub에 들어가보니 완전 Awesome 전문가이시다.</p>

<p>그래도 공부해야 할 내용이 잘 정리되어 있어 참고할만 하다.
앞으로 시간 날 때 기본 상식이라고 되어 있는 노란부분을 정리해봐야겠다.</p>

<p>​</p>

	  ]]></description>
	</item>

	<item>
	  <title>맥북프로 터치바를 커스터마이징 해보자</title>
	  <link>//macbook-touchbar-customizing</link>
	  <author>Swalloow</author>
	  <pubDate>2017-01-30T19:18:00+09:00</pubDate>
	  <guid>//macbook-touchbar-customizing</guid>
	  <description><![CDATA[
	     <p>터치바를 쓰다보면 지문과 시스템 환경설정 말고 딱히 건드릴 일이 없다는 생각이 든다.</p>

<p>터치바를 아직 지원하지 않는 앱들이 많고, 익숙하지 않기 때문이다.</p>

<p>그래서 터치바를 좀 더 아름답게 꾸며보기로 했다.</p>

<p>준비할 것은 BetterTouchTool 이라는 앱이다. 올해부터 유료로 전환된 것으로 알고 있다.</p>

<p>하지만 무료 평가판 버전이 있으니 써보고 맘에 들면 결제해도 좋다.</p>

<p>​</p>

<p><img src="assets/images/BTT1.png" alt="BTT" /></p>

<p>BTT를 설치하고 켜보면 다음과 같은 화면이 난다. 먼저 Global을 설정해보자.</p>

<p>​</p>

<h3 id="global--">Global 버튼 생성하기</h3>

<p>아래의 TouchBar Button을 누르면 새로운 버튼이 생성된다.</p>

<p><code class="highlighter-rouge">Custom Keyboard Shortcut</code>은 단축키를 바로 실행하도록 설정할 수 있고,</p>

<p><code class="highlighter-rouge">Predefined Action</code>은 시스템 설정까지 다양하게 실행하도록 설정할 수 있다.</p>

<p>​</p>

<p><img src="assets/images/BTT2.png" alt="BTT" /></p>

<p>나 같은 경우 크롬을 켜는 과정조차 귀찮아서 Global은 즐겨찾기처럼 세팅해두었다.</p>

<p>먼저 네이버 바로가기 버튼을 만들어 보자.</p>

<p>Add Icon에 아이콘을 넣어주고 Naver라고 이름을 적는다.</p>

<p>그리고 <code class="highlighter-rouge">Advanced Configuration</code>에 들어가서 다음과 같이 설정해준다.</p>

<p><code class="highlighter-rouge">Extra padding</code>을 통해 아이콘 양 옆의 여백을 조정할 수 있다.</p>

<p>​</p>

<p><img src="assets/images/BTT3.png" alt="BTT" /></p>

<p>마지막으로 <code class="highlighter-rouge">Predefined Action</code>에 들어가서 <code class="highlighter-rouge">Utility Actions - Open URL</code>을 누르고,</p>

<p>이동할 홈페이지의 주소를 입력한다.</p>

<p>​</p>

<p><img src="assets/images/BTT4.png" alt="BTT" /></p>

<p>이와 같은 과정을 반복하면 이렇게 버튼을 만들 수 있다 !</p>

<p>​</p>

<h3 id="pycharm--">PyCharm에 단축키 등록하기</h3>

<p>이번에는 PyCharm에 나만의 단축키를 등록해보자.</p>

<p><code class="highlighter-rouge">App Specific</code>에 + 버튼을 누르면 PyCharm을 좌측에 등록시킬 수 있다.</p>

<p>가장 많이 사용하던 자동 들여쓰기를 등록시켜보겠다.</p>

<p>​</p>

<p>마찬가지로 TouchBar Button을 생성하고, 이름을 적어준다음</p>

<p>이번에는 <code class="highlighter-rouge">Custom Keyboard Shortcut</code>에 <code class="highlighter-rouge">Ctrl + option + i</code> 를 입력하면 끝</p>

<p>​</p>

<h3 id="section">이미지 리소스</h3>

<p><a href="https://github.com/Swalloow/Swalloow.github.io/tree/master/assets/images/logo">https://github.com/Swalloow/Swalloow.github.io/tree/master/assets/images/logo</a></p>

<p>혹시 이미지 리소스가 필요하신 분들을 위해 올려드립니다.</p>

<p>이것저것 만들다보면 시간이 많이 걸리므로 연휴 때 하는 것을 추천드립니다 !</p>

<p>​</p>

	  ]]></description>
	</item>


</channel>
</rss>
