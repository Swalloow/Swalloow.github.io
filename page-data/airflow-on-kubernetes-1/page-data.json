{"componentChunkName":"component---src-templates-post-js","path":"/airflow-on-kubernetes-1/","result":{"data":{"contentfulPost":{"id":"8a8dd949-d905-5883-8781-94ee011c3522","title":"Airflow on Kubernetes (1)","slug":"airflow-on-kubernetes-1","metaDescription":null,"publishDate":"June 05, 2020","publishDateISO":"2020-06-05","tags":[{"title":"DataEngineering","id":"6d3fb203-7cdf-53d7-be6f-12ba3e82d74d","slug":"dataengineering"}],"heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"c12fefe6-aab9-599e-b87d-9d996a4e0bb5","childMarkdownRemark":{"id":"a96aecc2-d61d-5567-9728-1f9760a46ebc","timeToRead":5,"html":"<p>최근 Airflow에는 Kubernetes 지원을 위해 다양한 컴포넌트들이 추가되고 있습니다. 저도 이러한 변화의 흐름에 따라 Airflow를 Kubernetes 위에 배포하고 운영하는 방법에 대해 글을 작성해보고자 합니다. 이 글은 시리즈로 연재됩니다.</p>\n<ul>\n<li><a href=\"https://swalloow.github.io/airflow-on-kubernetes-1\">Airflow on Kubernetes (1): CeleryExecutor</a></li>\n<li>Airflow on Kubernetes (2): KubernetesExecutor</li>\n<li>Airflow on Kubernetes (3): Prometheus를 활용한 Airflow 모니터링</li>\n</ul>\n<br>\n<h2 id=\"airflow-on-kubernetes\" style=\"position:relative;\"><a href=\"#airflow-on-kubernetes\" aria-label=\"airflow on kubernetes permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Airflow on Kubernetes</h2>\n<p>Airflow를 Kubernetes 인프라 위에서 운영하는 방법은 크게 두 가지로 나눌 수 있습니다.\n이 글에서 소개할 방법은 <strong>CeleryExecutor의 각 모듈을 Kubernetes 위에 올리는 방식</strong>입니다. 기존에 운영하던 형태와 유사하기 때문에 쉽게 적용할 수 있으나 Celery에 대한 의존성이 강하다보니 완전히 Cloud Native한 형태는 아닙니다. 아키텍쳐는 가장 많이 사용하는 <a href=\"https://github.com/helm/charts/blob/master/stable/airflow\">stable/airflow</a> Helm Chart를 참고하였습니다. 이제 몇 가지 컴포넌트 설정과 함께 자세히 알아보겠습니다.</p>\n<br>\n<h2 id=\"config\" style=\"position:relative;\"><a href=\"#config\" aria-label=\"config permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Config</h2>\n<p>Airflow는 <code class=\"language-text\">airflow.cfg</code> 파일 또는 <code class=\"language-text\">AIRFLOW__[SECTOR]__[VARIABLES]</code> 환경 변수를 통해 각 컴포넌트의 설정을 관리할 수 있었습니다. Helm Chart에서는 <code class=\"language-text\">values.yaml</code>의 config 필드를 통해 설정을 관리할 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">config:\n  # CORE\n  AIRFLOW__CORE__DEFAULT_TIMEZONE: &quot;Asia/Seoul&quot;\n  AIRFLOW__CORE__PARALLELISM: &quot;32&quot;\n  AIRFLOW__CORE__DAG_CONCURRENCY: &quot;16&quot;\n  AIRFLOW__CORE__MAX_ACTIVE_RUNS_PER_DAG: &quot;16&quot;\n\n  # WEBSERVER\n  AIRFLOW__WEBSERVER__DEFAULT_UI_TIMEZONE: &quot;Asia/Seoul&quot;\n  AIRFLOW__WEBSERVER__WORKER_REFRESH_INTERVAL: &quot;60&quot;\n  \n  # CELERY\n  AIRFLOW__CELERY__WORKER_CONCURRENCY: &quot;16&quot;\n\n  # SCHEDULER\n  AIRFLOW__SCHEDULER__SCHEDULER_HEARTBEAT_SEC: &quot;30&quot;\n  AIRFLOW__SCHEDULER__SCHEDULER_HEALTH_CHECK_THRESHOLD: &quot;120&quot;\n  AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL: &quot;30&quot;\n  AIRFLOW__SCHEDULER__RUN_DURATION: &quot;10800&quot;\n  AIRFLOW__SCHEDULER__MAX_THREADS: &quot;2&quot;</code></pre></div>\n<br>\n<p>위에 정의한 설정 변수들은 Airflow의 성능과 관련되어 있기 때문에 각자 할당된 리소스에 맞게 설정해주셔야 합니다. 자세한 내용은 <a href=\"https://airflow.apache.org/docs/stable/faq.html#how-can-my-airflow-dag-run-faster\">공식문서 링크</a>를 참고하시기 바랍니다. 위와 같은 방식으로 DAG에서 활용하는 connection, variables도 정의할 수 있습니다.</p>\n<br>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\"># config.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: airflow-webserver-config\n  namespace: airflow\ndata:\n  webserver_config.py: |\n    APP_THEME = &quot;flatly.css&quot;\n\n---\n# values.yaml\nextraConfigmapMounts:\n  - name: airflow-webserver-config\n    mountPath: /opt/airflow/webserver_config.py\n    configMap: airflow-webserver-config\n    readOnly: true\n    subPath: webserver_config.py</code></pre></div>\n<br>\n<p>위와 같이 <code class=\"language-text\">ConfigMap</code>이나 <code class=\"language-text\">Secret</code>을 따로 만들고 참조하도록 연결하는 방식도 가능합니다. 특히 Airflow 1.10의 RBAC을 사용한다면 <code class=\"language-text\">webserver_config.py</code>를 통해 <code class=\"language-text\">APP_THEME</code>를 변경해줄 수 있는데 이런 경우에 extraConfigmap을 통해 적용할 수 있습니다. 제가 주로 사용하는 테마는 <code class=\"language-text\">flatly.css</code>에 NAVBAR <code class=\"language-text\">#18bc9c</code> 컬러 조합입니다. 적용된 화면은 아래와 같습니다. (+ 태그 기능도 1.10.10 버전에 추가되었습니다)</p>\n<br>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=1RzSP5YX2EyH3xDnk0VM4wB57lsn55j1o\" alt=\"airflow-webserver\"></p>\n<br>\n<h2 id=\"celery-worker\" style=\"position:relative;\"><a href=\"#celery-worker\" aria-label=\"celery worker permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Celery Worker</h2>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=1N81eEP8AT1ddwCDtHnDKblgwkZsc2FFB\" alt=\"celery\"></p>\n<br>\n<p>CeleryExecutor에서 worker는 실제 task를 수행을 담당하는 컴포넌트입니다. K8S에서는 celery worker가 StatefulSet으로 배포됩니다. 기존에는 worker가 <code class=\"language-text\">AutoScalingGroup</code> 등을 통해 인스턴스가 자동 확장되도록 구성했다면, K8S에서는 <code class=\"language-text\">HorizontalPodAutoscaler</code>를 통해 Pod 단위로 확장 가능하도록 구성할 수 있습니다.</p>\n<br>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">workers:\n  replicas: 1\n\n  resources:\n    requests:\n      memory: &quot;2Gi&quot;\n\n  autoscaling:\n    enabled: true\n    maxReplicas: 16\n    metrics:\n    - type: Resource\n      resource:\n        name: memory\n        target:\n          type: Utilization\n          averageUtilization: 80</code></pre></div>\n<br>\n<h2 id=\"airflow-ingress\" style=\"position:relative;\"><a href=\"#airflow-ingress\" aria-label=\"airflow ingress permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Airflow Ingress</h2>\n<p>보통 K8S 클러스터에 Ingress Controller를 설정하고 path를 통해 여러 서비스에 접속하는 경우가 많습니다. Airflow Chart 역시 Webserver와 Flower UI에 대한 ingress를 지원합니다. 저는 nginx-ingress controller를 사용해서 진행해보겠습니다. 아래 예시는 각자의 ingress-controller 설정에 맞게 바꾸시면 됩니다.</p>\n<br>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">web:\n  service:\n    annotations: {}\n    type: ClusterIP\n    externalPort: 8080\n    loadBalancerIP: &quot;&quot;\n    loadBalancerSourceRanges: []\n\n...\n\ningress:\n  enabled: true\n  web:\n    annotations:\n      kubernetes.io/ingress.class: nginx\n      ingress.kubernetes.io/rewrite-target: /\n      nginx.ingress.kubernetes.io/ssl-redirect: &quot;false&quot;\n    \n    path: &quot;/airflow&quot;\n    host: &quot;myloadbalancer-domain.com&quot;</code></pre></div>\n<p>예를 들어 web path에 <code class=\"language-text\">/airflow</code> 라고 설정하셨다면, UI 접속 주소는 <code class=\"language-text\">myloadbalancer-domain.com/airflow</code>가 됩니다. flower도 위와 동일한 방식으로 설정하시면 됩니다.</p>\n<br>\n<h2 id=\"airflow-auth\" style=\"position:relative;\"><a href=\"#airflow-auth\" aria-label=\"airflow auth permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Airflow Auth</h2>\n<p>Airflow 에서는 다양한 인증 방식을 지원하지만 여기에서는 가장 기본이 되는 Password Auth 방식으로 배포하겠습니다. 새로 추가된 RBAC 설정도 함께 추가해보겠습니다. 먼저 <code class=\"language-text\">extraPipPackages</code> 설정을 통해 의존성 패키지를 설치해주고 상단에 환경 변수도 추가해줍니다.</p>\n<br>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">config:\n  AIRFLOW__WEBSERVER__RBAC: &quot;True&quot;\n  AIRFLOW__WEBSERVER__AUTHENTICATE: &quot;True&quot;\n  AIRFLOW__WEBSERVER__AUTH_BACKEND: &quot;airflow.contrib.auth.backends.password_auth&quot;\n\n...\n\nweb:\n  extraPipPackages:\n    - &quot;flask-bcrypt&quot;\n    - &quot;flask-oauthlib&gt;=0.9&quot;</code></pre></div>\n<br>\n<p>이제 로그인할 사용자를 추가해주어야 합니다. Scheduler Pod의 Bash에서 create_user 명령어를 통해 생성해주시면 됩니다.</p>\n<br>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ kubectl exec \\\n  -it \\\n  --namespace airflow \\\n  --container airflow-scheduler \\\n  Deployment/airflow-scheduler \\\n  /bin/bash\n\n$ airflow create_user \\\n--username=admin \\\n--email=test@example.com \\\n--password=mypassword \\\n--role=Admin \\\n--firstname=test \\\n--lastname=park</code></pre></div>\n<br>\n<h2 id=\"airflow-iam-role\" style=\"position:relative;\"><a href=\"#airflow-iam-role\" aria-label=\"airflow iam role permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Airflow IAM Role</h2>\n<p>AWS EKS와 같은 클라우드 서비스 위에 배포한다면 각 컴포넌트의 세부 권한을 지정해주어야 합니다. 만일 Pod에 IAM Role을 할당하지 않는다면 Airflow는 클러스터의 기본 IAM Role인 EKS worker 설정을 따르게 됩니다. 따라서 보안을 신경쓰셔야 한다면 설정하는 것이 바람직합니다. 특히 Airflow에서 다른 AWS Managed Service(EMR, Athena, Lambda)와 연계하는 DAG이 존재하신다면 필수적입니다.</p>\n<br>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">serviceAccount:\n  create: true\n  name: &quot;airflow&quot;\n  annotations:\n    eks.amazonaws.com/role-arn: arn:aws:iam::123456789999:role/airflow\n\n...\n\nsecurityContext:\n  fsGroup: 1000</code></pre></div>\n<br>\n<p><code class=\"language-text\">values.yaml</code>에는 포함되어 있지 않지만 각 컴포넌트마다 <code class=\"language-text\">securityContext</code>를 지정해주셔야 IAM Role을 매핑할 수 있습니다. <code class=\"language-text\">IAM Role for Service Account</code>가 내부적으로 K8S TokenProjection을 사용하기 때문에 설정을 안하면 토큰을 읽을 수 없다면 오류가 발생합니다. IAM Role 설정에 대한 자세한 내용은 <a href=\"https://docs.aws.amazon.com/ko_kr/eks/latest/userguide/iam-roles-for-service-accounts-technical-overview.html\">EKS 공식 문서</a>를 참고하시기 바랍니다.</p>\n<br>\n<h2 id=\"dags\" style=\"position:relative;\"><a href=\"#dags\" aria-label=\"dags permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>DAGs</h2>\n<p>Airflow는 Scheduler가 DAG 파일을 주기적으로 동기화하며 문법적 오류가 없는지 체크하는 역할을 수행합니다. 단일 노드에서는 로컬에 있는 DAG 파일을 읽으면 되지만 K8S에서는 worker pod가 여러 노드에 걸쳐있기 때문에 모두 같은 DAG 파일을 바라보도록 하는 동기화 설정이 필요합니다. Helm Chart에서는 이를 지원하기 위해 두 가지 옵션을 제공합니다.</p>\n<br>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\"># git-sync sidecar\ndags:\n  git:\n    url: ssh://git@repo.example.com/example.git\n    repoHost: repo.example.com\n    secret: airflow-git-keys\n    privateKeyName: id_rsa\n\n    gitSync:\n      enabled: true\n      refreshTime: 60</code></pre></div>\n<br>\n<p>첫 번째 방식은 <strong>git-sync 사이드카 컨테이너</strong>를 활용하는 방법입니다. 사이드카 패턴이 생소하시다면 이전에 작성한 <a href=\"https://swalloow.github.io/container-patterns/#sidecar-pattern\">분산 컨테이너에서의 디자인 패턴</a> 글을 참고하시기 바랍니다.</p>\n<br>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\"># EFS PV, PVC\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: airflow-dags\n  namespace: airflow\n  labels:\n    name: airflow-dags\n    storage: airflow\nspec:\n  capacity:\n    storage: 20Gi\n  accessModes:\n    - ReadWriteMany\n  nfs:\n    server: 0.0.0.0 &lt;- EFS endpoint\n    path: &quot;/airflow&quot;\n\n---\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: airflow-dags\n  namespace: airflow\n  labels:\n    storage: airflow\nspec:\n  storageClassName: &quot;&quot;\n  accessModes:\n    - ReadWriteMany\n  resources:\n    requests:\n      storage: 10Gi\n  selector:\n    matchLabels:\n      name: airflow-dags\n\n---\n# shared persistent volume\ndags:\n  persistence:\n    enabled: true\n    existingClaim: &quot;airflow-dags&quot;\n    accessMode: ReadWriteMany\n    size: 1Gi</code></pre></div>\n<br>\n<p>두 번째 방식은 EFS와 같은 공유 파일시스템을 활용한 방법입니다. 저는 EFS PV와 PVC를 먼저 추가한다음 existingClaim을 통해 참조하도록 설정해주었습니다.</p>\n<br>\n<h2 id=\"deploy\" style=\"position:relative;\"><a href=\"#deploy\" aria-label=\"deploy permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Deploy</h2>\n<p>필요한 설정을 완료했다면 배포는 아래 Helm 명령어를 통해 할 수 있습니다. 가능하다면 데이터베이스는 external로 사용하는 방법을 추천드립니다. DB 암호는 secret을 통해 생성하고 참조하도록 설정해주시면 됩니다.</p>\n<br>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">helm install stable/airflow \\\n--version 7.1.1 \\\n--namespace airflow \\\n--name airflow \\\n-f ./values.yaml</code></pre></div>\n<br>\n<p>배포 이후에 namespace를 보면 아래와 같은 Pod이 존재하는걸 확인할 수 있습니다.</p>\n<br>\n<p><img src=\"https://carbon.now.sh/\"></p>\n<br>\n<p>이 글에서 언급한 설정은 FIXME 주석을 해두었으니 <a href=\"https://github.com/Swalloow/airflow-helm\">https://github.com/Swalloow/airflow-helm</a> 저장소를 확인하시기 바랍니다.</p>","excerpt":"최근 Airflow에는 Kubernetes 지원을 위해 다양한 컴포넌트들이 추가되고 있습니다. 저도 이러한 변화의 흐름에 따라 Airflow를 Kubernetes 위에 배포하고 운영하는 방법에 대해 글을 작성해보고자 합니다. 이 글은 시리즈로 연재됩니다. Airflow on Kubernetes (1): CeleryExecutor Airflow on Kubernetes (2): KubernetesExecutor Airflow on Kubernetes (3): Prometheus를 활용한 Airflow 모니터링 Airflow on Kubernetes Airflow…"}}}},"pageContext":{"slug":"airflow-on-kubernetes-1","basePath":"","prev":null,"next":{"slug":"gatsby-contentful","publishDate":"2020-04-25"}}}}