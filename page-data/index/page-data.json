{"componentChunkName":"component---src-templates-posts-js","path":"/","result":{"data":{"allContentfulPost":{"edges":[{"node":{"title":"EKS Karpenter를 활용한 Groupless AutoScaling","id":"573e9f5f-beea-54d9-aff8-918f477ae03a","slug":"eks-karpenter-groupless-autoscaling","publishDate":"May 13, 2022","heroImage":{"id":"f36c235f-3e3e-517d-bd80-697bc6183072","title":"cover-devops","fluid":{"aspectRatio":1.5,"src":"//images.ctfassets.net/tushy4jlcik7/7KaSTt3mdmrYq2ZK1RiJku/dafd981ff3686217ac151b562e8b1412/cover_devops.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7KaSTt3mdmrYq2ZK1RiJku/dafd981ff3686217ac151b562e8b1412/cover_devops.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7KaSTt3mdmrYq2ZK1RiJku/dafd981ff3686217ac151b562e8b1412/cover_devops.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7KaSTt3mdmrYq2ZK1RiJku/dafd981ff3686217ac151b562e8b1412/cover_devops.jpg?w=1080&h=720&q=50 1080w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7KaSTt3mdmrYq2ZK1RiJku/dafd981ff3686217ac151b562e8b1412/cover_devops.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7KaSTt3mdmrYq2ZK1RiJku/dafd981ff3686217ac151b562e8b1412/cover_devops.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7KaSTt3mdmrYq2ZK1RiJku/dafd981ff3686217ac151b562e8b1412/cover_devops.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7KaSTt3mdmrYq2ZK1RiJku/dafd981ff3686217ac151b562e8b1412/cover_devops.jpg?w=1080&h=720&q=50&fm=webp 1080w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7KaSTt3mdmrYq2ZK1RiJku/dafd981ff3686217ac151b562e8b1412/cover_devops.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"ac3a803f-1cdb-5459-9902-a5c10a366151","childMarkdownRemark":{"id":"b1939eae-8e3c-597c-8e20-a18f9cad131d","timeToRead":5,"html":"<p>21년 12월 EKS에서 새로운 쿠버네티스 클러스터 오토스케일러인 <a href=\"https://aws.amazon.com/ko/blogs/korea/introducing-karpenter-an-open-source-high-performance-kubernetes-cluster-autoscaler/\">Karpenter</a>를 발표했습니다.<br>\n이후로 많은 사용자들이 오픈소스에 참여하면서 버전도 많이 올라갔고 안정적으로 사용하고 있습니다. 이 글에서는 Karpenter와 기존에 사용하던 Cluster AutoScaler를 비교하고 이관할 때 알아두면 좋은 내용에 대해 정리해보려 합니다.</p>\n<br>\n<h2 id=\"cluster-autoscaler가-가진-한계점\" style=\"position:relative;\"><a href=\"#cluster-autoscaler%EA%B0%80-%EA%B0%80%EC%A7%84-%ED%95%9C%EA%B3%84%EC%A0%90\" aria-label=\"cluster autoscaler가 가진 한계점 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Cluster AutoScaler가 가진 한계점</h2>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1qGi_2q3niqMYxOuKSUauMHzDE7JQEB_5\" alt=\"eksasg\"></p>\n<p>그 동안 EKS의 Cluster AutoScaler는 <strong>AWS의 AutoScaling Group(ASG)</strong>을 활용하고 있었습니다. ASG는 주기적으로 현재 상태를 확인하고 Desired State로 변화하는 방식으로 동작합니다. 사용자는 목적에 맞게 노드 그룹을 나누고 ASG의 Min, Max 설정을 통해 클러스터 노드 수를 제한할 수 있습니다. 이를 통해 기존 AWS 사용자가 직관적인 구조를 그대로 활용할 수 있었습니다. 하지만 클러스터의 규모가 커질수록 ASG 활용으로 인해 불편한 점이 존재했습니다.</p>\n<p><strong>1. 번거로운 ASG 노드 그룹 관리</strong><br>\nK8S 클러스터는 여러 조직이 함께 사용할 수 있는 멀티테넌트 구조를 지원합니다. 두 조직이 서비스의 안정적인 운영을 위해 노드 그룹을 격리해야 하는 요구사항이 생기면 EKS 운영자는 새로운 ASG 노드 그룹을 생성하고 관리해주어야 합니다. 많은 운영자가 EKS의 IaC 구현을 위해 <a href=\"https://github.com/terraform-aws-modules/terraform-aws-eks\">terraform-aws-eks</a> 모듈을 사용하는데 여기에 매번 설정을 업데이트하고 반영하는 일은 번거롭고 각 조직에게 역할을 위임하기도 애매합니다.</p>\n<p>또 다른 예시는 리소스 활용 목적에 따라 노드 그룹을 분리할 때 입니다. 많은 CPU가 필요한 워크로드는 컴퓨팅 최적화 인스턴스 유형을 사용하고 메모리가 필요한 워크로드는 메모리 최적화 인스턴스 유형을 사용하는 것이 효율적입니다. 그리고 비용 최적화를 위해 spot 인스턴스 유형을 사용할 수도 있습니다. 이를 구현하기 위해 ASG에서는 c타입, r타입, spot 인스턴스를 가지는 각 노드 그룹을 만들어주어야 합니다.</p>\n<p><strong>2. ASG로 인한 노드 프로비저닝 시간 지연</strong><br>\nEKS Cluster AutoScaler는 K8S의 Cluster AutoScaler에 ASG를 활용하여 AWS cloud provider를 구현한 형태입니다. 클러스터 내에서 어플리케이션 로드를 감지한 이후, 중간에 AWS 리소스 요청을 거치기 때문에 즉시 처리되기가 어렵습니다.</p>\n<br>\n<h2 id=\"karpenter-소개\" style=\"position:relative;\"><a href=\"#karpenter-%EC%86%8C%EA%B0%9C\" aria-label=\"karpenter 소개 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Karpenter 소개</h2>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1boQKLPL8qFLzZtkTwriGRH00PqjX1f3N\" alt=\"karpenter\"></p>\n<p>Karpenter는 다음과 같이 세 가지 컴포넌트로 구성되어 있습니다.</p>\n<ul>\n<li><strong>Controller</strong>: K8S controller 형태로 구현되어 pod 상태를 감시하고 노드 확장 및 축소</li>\n<li><strong>Webhook</strong>: Provisioner CRD에 대한 유효성 검사 및 기본값을 지정</li>\n<li><strong>Provisioner</strong>: Karpenter에 의해 생성되는 노드와 Pod에 대한 제약조건을 지정</li>\n</ul>\n<p><a href=\"https://github.com/aws/karpenter/tree/main/charts/karpenter\">Karpenter Helm Chart</a>를 통해 설치하면 controller와 webhook pod가 생성됩니다. 이후에 <a href=\"https://karpenter.sh/v0.10.0/provisioner/\">provisioner CRD</a>를 정의하고 클러스터에 배포하면 사용할 수 있습니다. provisioner는 ASG 노드 그룹과 유사한 개념입니다. 따라서 default를 사용하는게 아니라 기존에 사용하던 설정에 맞게 새로 만들어야 합니다. Scale In/Out 관련된 내용은 다음과 같습니다.</p>\n<h3 id=\"scale-out-기준\" style=\"position:relative;\"><a href=\"#scale-out-%EA%B8%B0%EC%A4%80\" aria-label=\"scale out 기준 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Scale Out 기준</h3>\n<ul>\n<li>pending 상태의 pod 수, 리소스 요청량에 따라 수행</li>\n<li>신규 노드가 15분 동안 NotReady 상태라면 종료하고 새로 생성</li>\n<li>kubernetes well-known label 설정 가능</li>\n</ul>\n<h3 id=\"scale-in-기준\" style=\"position:relative;\"><a href=\"#scale-in-%EA%B8%B0%EC%A4%80\" aria-label=\"scale in 기준 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Scale In 기준</h3>\n<ul>\n<li>노드에 예약된 pod가 없는 경우</li>\n<li>해당 노드에 대해 cordon, drain을 수행하고 삭제</li>\n<li><code class=\"language-text\">karpenter.sh/do-not-evict</code> 설정을 통해 보호 가능</li>\n</ul>\n<br>\n<h2 id=\"karpenter-vs-autoscaler\" style=\"position:relative;\"><a href=\"#karpenter-vs-autoscaler\" aria-label=\"karpenter vs autoscaler permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Karpenter vs AutoScaler</h2>\n<p>앞서 언급했던 Cluster AutoScaler와 Karpenter를 비교해보면 다음과 같습니다.</p>\n<p><strong>1. Provisioner API를 통해 간편한 노드 관리</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">requirements:\n  - key: &quot;node.kubernetes.io/instance-type&quot;\n    operator: In\n    values: [&quot;m5.large&quot;, &quot;m5.2xlarge&quot;]\n  - key: &quot;topology.kubernetes.io/zone&quot;\n    operator: In\n    values: [&quot;ap-northeast-2a&quot;, &quot;ap-northeast-2c&quot;]\n  - key: &quot;karpenter.sh/capacity-type&quot;\n    operator: In\n    values: [&quot;spot&quot;, &quot;on-demand&quot;]</code></pre></div>\n<p>Karpenter는 노드 프로비저닝을 위해 ASG 노드 그룹을 생성할 필요가 없습니다. 대신 yaml을 통해 Provisioner CRD만 생성하면 됩니다. 현재 노드 프로비저닝을 위한 instance type, subnet, volume, SG 등 대부분의 설정을 지원하고 있습니다.</p>\n<p><strong>2. 수 많은 인스턴스 유형에 대해 유연하게 처리</strong><br>\nKarpenter는 노드 프로비저닝을 위해 EC2 Fleet API를 사용합니다. 사용자는\n여러 유형의 인스턴스를 지정할 수 있으며 어떤 유형의 인스턴스를 생성할지는 Karpenter가 결정합니다. 예를 들어 pending 상태의 pod가 1CPU, 4GB 리소스를 요청한다면 m5.large 인스턴스를 생성합니다. spot 인스턴스의 경우, Fleet API의 최저 입찰 경쟁에 따라 저렴한 비용으로 사용할 수 있습니다.</p>\n<p><strong>3. 노드 프로비저닝 시간 단축</strong><br>\nKarpenter는 Cluster AutoScaler와 동일한 역할을 하지만 자체 구현된 오픈소스로 JIT(Just-In-Time)을 지원합니다. 적용한 이후 실제로 약 2배 정도 프로비저닝 시간이 단축되었습니다. Karpenter를 통해 생성된 노드는 pre-pulling을 통해 이미지를 미리 받아올 수 있으며 빠른 컨테이너 런타임 준비를 통해 pod를 즉시 바인딩할 수 있습니다.</p>\n<p>두 가지 AutoScaler는 여러 장단점이 존재하기 때문에 적절하게 선택할 필요가 있습니다. 데이터 영역에서 활용하는 클러스터는 다양한 인스턴스 유형을 사용하고 빈번하게 스케일 조정이 일어나는 경우가 많습니다. 따라서 Karpenter가 가지는 장점을 최대로 활용할 수 있습니다.</p>\n<br>\n<h2 id=\"karpenter-이관-가이드\" style=\"position:relative;\"><a href=\"#karpenter-%EC%9D%B4%EA%B4%80-%EA%B0%80%EC%9D%B4%EB%93%9C\" aria-label=\"karpenter 이관 가이드 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Karpenter 이관 가이드</h2>\n<p>최근에 <a href=\"https://karpenter.sh/v0.10.0/getting-started/migrating-from-cas/\">공식 이관 가이드</a>가 나와서 제가 사용했던 이관 방법들과 주의사항 위주로 정리해보았습니다.</p>\n<h3 id=\"이관-방법\" style=\"position:relative;\"><a href=\"#%EC%9D%B4%EA%B4%80-%EB%B0%A9%EB%B2%95\" aria-label=\"이관 방법 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>이관 방법</h3>\n<ul>\n<li>기존에 사용하던 설정들과 Scale In/Out에 대한 테스트는 karpenter 문서에서 안내하는 inflate pod을 통해 진행할 수 있습니다.</li>\n<li>Cluster AutoScaler의 일부 노드 그룹을 Provisioner로 이관하는 방식으로 진행하면 점진적으로 옮겨갈 수 있습니다.</li>\n<li>Provisioner yaml 설정에 익숙하지 않다면 <a href=\"https://karpenter.sh/v0.10.0/aws/launch-templates/\">launch template을 만들어 정의하는 방법</a>도 있습니다. 하지만 동일 설정이 있다면 Karpenter에서는 Provisioner yaml을 우선시하기 때문에 launch template 사용하는 방법을 권장하지 않습니다.</li>\n<li>Scale In에서 노드가 종료되는 시간을 조정하기 위해 TTL 설정을 사용하는 것이 좋습니다. TTL 설정이 너무 작으면 잠시 재시작하는 상황에서도 Scale In/Out이 빈번하게 발생할 수 있습니다.</li>\n<li>karpenter 관련 pod는 karpenter에 의해 생성된 노드에 띄울 수 없습니다. 따라서 ASG 노드 그룹이 적어도 하나는 존재해야 합니다.</li>\n</ul>\n<br>\n<h3 id=\"karpenter가-가지는-제한-사항\" style=\"position:relative;\"><a href=\"#karpenter%EA%B0%80-%EA%B0%80%EC%A7%80%EB%8A%94-%EC%A0%9C%ED%95%9C-%EC%82%AC%ED%95%AD\" aria-label=\"karpenter가 가지는 제한 사항 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Karpenter가 가지는 제한 사항</h3>\n<ul>\n<li>Karpenter에 의해 생성되는 노드는 현재 ASG max 설정과 같은 클러스터 상한선 기준이 없습니다. 따라서 노드에 대한 모니터링과 알림이 필요합니다. Karpenter에서는 프로메테우스 메트릭을 제공하고 있습니다.</li>\n<li>Karpenter의 Binpacking 로직은 VPC CNI 네트워크 사용을 가정하기 때문에 커스텀 CNI를 사용한다면 제대로 동작하지 않을 수 있습니다.</li>\n<li>0.10 이전 버전에서는 <code class=\"language-text\">podAffinity</code>, <code class=\"language-text\">podAntiAffinity</code>를 지원하지 않습니다. 따라서 하위 버전을 사용한다면 <code class=\"language-text\">nodeSelector</code>, <code class=\"language-text\">topologySpreadConstraints</code>를 활용하셔야 합니다.</li>\n</ul>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<ul>\n<li><a href=\"https://karpenter.sh/\">https://karpenter.sh/</a></li>\n<li><a href=\"https://aws.github.io/aws-eks-best-practices/karpenter/\">https://aws.github.io/aws-eks-best-practices/karpenter/</a></li>\n</ul>","excerpt":"21년 12월 EKS에서 새로운 쿠버네티스 클러스터 오토스케일러인 Karpenter…"}}}},{"node":{"title":"개발자가 의사결정을 기록하는 방법 (feat. ADR)","id":"89a1d9f0-062b-52b6-8ad6-66b6275cd043","slug":"feat-adr","publishDate":"December 04, 2021","heroImage":{"id":"1563c3af-a4e8-5db4-acb2-9bfd9fdb294d","title":"cover-develop","fluid":{"aspectRatio":1.5,"src":"//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=1800&h=1200&q=50 1800w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=1800&h=1200&q=50&fm=webp 1800w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"61cf49e6-420d-569a-85c0-4425ba1b08fe","childMarkdownRemark":{"id":"716ac876-fcb8-585f-ad39-b9244afecf29","timeToRead":2,"html":"<p>개발자들에게는 항상 다양한 선택지 중에 하나를 골라야 하는 상황이 주어집니다.<br>\n가장 간단한 예시로는 어떤 언어/프레임워크를 사용할지, 어느 버전을 사용할지에 대한 결정입니다.<br>\n오늘은 위와 같은 의사결정을 기록하기 위한 ADR에 대해 소개하려고 합니다.</p>\n<br>\n<h2 id=\"adr이란\" style=\"position:relative;\"><a href=\"#adr%EC%9D%B4%EB%9E%80\" aria-label=\"adr이란 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>ADR이란?</h2>\n<p>ADR은 Architectural Decision Records의 약자로 <strong>아키텍쳐와 관련된 결정을 내렸을 때 그 과정을 기록해 두는 문서</strong>를 말합니다. 아마 ADR이라는 단어를 몰라도 큰 규모의 오픈소스를 사용하다보면 많이 접해보셨을거라 생각합니다. 예를 들어 Kubernetes 프로젝트에서는 개선 과제를 제안할 때 <a href=\"https://github.com/kubernetes/enhancements/tree/master/keps\">KEP 템플릿</a>을 사용하여 문서를 작성하도록 가이드하고 있습니다.</p>\n<p>ADR은 간단한 양식을 통해 마크다운 형식으로 작성되며 문제 정의, 결정에 영향을 주는 기본 요구사항, 설계 결정 등의 내용이 포함되어 있습니다. GitHub, Spotify, Google 등 다양한 tech 기업들이 ADR형식을 사용하고 있습니다.</p>\n<br>\n<h2 id=\"adr이-필요한-이유\" style=\"position:relative;\"><a href=\"#adr%EC%9D%B4-%ED%95%84%EC%9A%94%ED%95%9C-%EC%9D%B4%EC%9C%A0\" aria-label=\"adr이 필요한 이유 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>ADR이 필요한 이유</h2>\n<p>우리는 어떤 방식으로든 팀원들과 함께 의사결정하고 공유하게 됩니다. 그런데 새로운 팀원이 들어오고 히스토리에 대해 묻는다면 기억을 더듬어 당시에 왜 그렇게 했는지 설명합니다. 이러한 과정을 반복하며 시간을 낭비하고 있다면 ADR을 통해 해결할 수 있습니다. 많은 사람들이 말하는 ADR 도입의 장점은 아래와 같습니다.</p>\n<p><strong>명확하고 합리적인 의사결정을 내릴 수 있습니다</strong><br>\n정의된 ADR 템플릿에 따라 문서화하면 일관된 방식으로 의사결정할 수 있습니다.\n저자는 문서를 작성하는 과정에서 더 합리적인 결론을 도출해낼 수 있으며 독자는 문제에 대해 쉽게 이해할 수 있습니다.</p>\n<p><strong>새로운 팀원이 적응하는데 많은 도움이 됩니다</strong><br>\n새로운 팀원이 들어오면 새로운 개발환경, 아키텍쳐를 이해하기까지 많은 시간을 할애합니다.\n만약 ADR을 통해 과거 의사결정 과정까지 알게 된다면 더 쉽게 이해할 수 있습니다.</p>\n<br>\n<h2 id=\"adr-template\" style=\"position:relative;\"><a href=\"#adr-template\" aria-label=\"adr template permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>ADR template</h2>\n<p>ADR 형식은 정하기 나름이지만 이 글에서는 가장 알려진 템플릿을 기준으로 설명하겠습니다.\n<a href=\"https://github.com/joelparkerhenderson/architecture-decision-record\">architecture-decision-record GitHub</a>에서 더 다양한 템플릿과 예시 문서를 확인할 수 있습니다.</p>\n<p><strong>1. Status</strong><br>\n<img src=\"http://drive.google.com/uc?export=view&#x26;id=1urCNDlBKQav3MhkzZzJX6kwwFEJMSjgj\" alt=\"adr-status\"></p>\n<p>먼저 status는 위와 같은 상태 다이어그램으로 표현되며 현재 문서의 상태를 나타냅니다.</p>\n<p><strong>2. Context</strong><br>\nContext는 해결하고자 하는 문제를 정의하는 목차입니다.</p>\n<p><strong>3. Decision</strong><br>\n<img src=\"http://drive.google.com/uc?export=view&#x26;id=1CnhoR26bTnQfpaarLFjmSrs8-7mbjWLP\" alt=\"adt-table\"></p>\n<p>Decision에서는 제안하고자 하는 내용 및 해당 결정의 이유에 대해 설명합니다.<br>\n의사결정 과정에서 고려했던 대안들과 장단점에 대한 내용도 포함됩니다.<br>\n위와 같이 간단히 비교하는 표를 추가한다면 읽는 사람들이 더 쉽게 이해할 수 있습니다.</p>\n<p><strong>4. Consequences</strong><br>\nConsequences에서는 결정을 통해 사용자가 받는 영향에 대해 정의합니다.\n예를 들어 이 결정이 도입된다면 어떤 효과가 나타날 수 있는지, 마이그레이션 과제라면 다운타임이 발생하는지, 사용자들의 코드 변경이 필요한지 등을 작성합니다.</p>\n<br>\n<p>새로 도입할 때는 ADR이 부담스러운 업무가 되지 않도록 가능한 가볍게 유지할 수 있어야 합니다.<br>\nADR은 나를 위한 것이 아니라 현재 그리고 미래의 팀원들을 위한 것이라고 합니다.<br>\n그 동안 문서로 작성 안했다면 아주 간단하게 시작해보는건 어떨까요?</p>\n<br>\n<h2 id=\"참고-자료\" style=\"position:relative;\"><a href=\"#%EC%B0%B8%EA%B3%A0-%EC%9E%90%EB%A3%8C\" aria-label=\"참고 자료 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>참고 자료</h2>\n<ul>\n<li><a href=\"https://github.blog/2020-08-13-why-write-adrs/\">GitHub Blog: Why write ADRs?</a></li>\n<li><a href=\"https://cloud.google.com/architecture/architecture-decision-records\">Google Cloud Architecture ADR Docs</a></li>\n<li><a href=\"https://github.com/alphagov/govuk-aws/tree/master/docs/architecture/decisions\">govuk-aws ADR docs example</a></li>\n</ul>","excerpt":"…"}}}},{"node":{"title":"JupyterHub on Kubernetes","id":"784b5b9c-9d53-5ffd-9cb1-e61df96893dd","slug":"jupyterhub-on-kubernetes","publishDate":"October 23, 2021","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"861d6065-30d6-5b6e-9d02-e2e7e4f7ddea","childMarkdownRemark":{"id":"ccc6a49d-08cc-55e8-90e0-5dece449d643","timeToRead":4,"html":"<p>일반적으로 JupyterHub를 Kubernetes 환경에 배포할 때 Helm Chart를 많이 사용합니다.<br>\n이 글에서는 <a href=\"https://github.com/jupyterhub/zero-to-jupyterhub-k8s\">zero-to-jupyterhub-k8s Helm Chart</a>에 포함된 다양한 기능들에 대해 소개해보려 합니다.</p>\n<p><strong>목차</strong></p>\n<ul>\n<li><a href=\"https://swalloow.github.io/jupyterhub-on-kubernetes/#kubespawner\">kubespawner</a></li>\n<li><a href=\"https://swalloow.github.io/jupyterhub-on-kubernetes/#zero-to-jupyterhub-k8s-chart\">zero-to-jupyterhub-k8s chart</a></li>\n<li><a href=\"https://swalloow.github.io/jupyterhub-on-kubernetes/#proxy\">proxy</a></li>\n<li><a href=\"https://swalloow.github.io/jupyterhub-on-kubernetes/#singleuser-profile\">singleuser, profile</a></li>\n<li><a href=\"https://swalloow.github.io/jupyterhub-on-kubernetes/#idle-culler\">idle-culler</a></li>\n<li><a href=\"https://swalloow.github.io/jupyterhub-on-kubernetes/#user-scheduler\">user-scheduler</a></li>\n<li><a href=\"https://swalloow.github.io/jupyterhub-on-kubernetes/#image-pre-puller\">image-pre-puller</a></li>\n<li><a href=\"https://swalloow.github.io/jupyterhub-on-kubernetes/#monitoring\">monitoring</a></li>\n</ul>\n<p><br><br></p>\n<h2 id=\"kubespawner\" style=\"position:relative;\"><a href=\"#kubespawner\" aria-label=\"kubespawner permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>KubeSpawner</h2>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1OaKRO1t73IJoFz267WhZGspKHIvzztFB\" alt=\"jhub\"></p>\n<p>먼저 JupyterHub의 기본 아키텍쳐에 대해 간단히 짚고 넘어가보겠습니다.\nJupyterHub에는 노트북 서버를 다양한 방법을 통해 프로비저닝하기 위해 <strong>Spawner</strong>라는 인터페이스가 존재합니다. K8S 환경이라면 KubeSpawner를 사용하게 됩니다. 이를 통해 프로비저닝 단계에서 kube-scheduler 기반으로 다양한 K8S 리소스를 노트북 서버와 함께 사용할 수 있습니다. 또한 KubeSpawner는 <strong>사용자에게 격리된 환경과 컴퓨팅 리소스를 제공</strong>할 수 있습니다.</p>\n<p><strong>노트북 Pod 생성 이벤트</strong><br>\n노트북이 생성되는 과정은 다음과 같습니다.</p>\n<ul>\n<li>할당 가능한 노드 탐색 (NodeSelector, Affinity)</li>\n<li>없으면 CA에 의해 노드 추가, 노드가 Ready 상태가 될 때까지 대기</li>\n<li>Pod을 추가된 노드에 할당</li>\n<li>노트북 이미지 pull</li>\n<li>노트북 컨테이너 실행</li>\n</ul>\n<br>\n<h2 id=\"zero-to-jupyterhub-k8s-chart\" style=\"position:relative;\"><a href=\"#zero-to-jupyterhub-k8s-chart\" aria-label=\"zero to jupyterhub k8s chart permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>zero-to-jupyterhub-k8s Chart</h2>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1j1PF9_mQPo3pic6ywAsG3wxOABVxshf-\" alt=\"jhub-chart-arc\"></p>\n<p><a href=\"https://github.com/jupyterhub/zero-to-jupyterhub-k8s\">zero-to-jupyterhub-k8s Helm Chart</a> 의 아키텍쳐는 위의 그림과 같습니다. 기존 JupyterHub와 달리 hook-image-awaiter, jupyterhub-idle-culler 등의 컴포넌트가 추가된 모습을 확인하실 수 있습니다. 이제 대략적으로 어떤 기능을 제공하는지 알아보겠습니다.</p>\n<br>\n<h2 id=\"proxy\" style=\"position:relative;\"><a href=\"#proxy\" aria-label=\"proxy permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Proxy</h2>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">proxy</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">service</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">type</span><span class=\"token punctuation\">:</span> ClusterIP\n  <span class=\"token key atrule\">chp</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">networkPolicy</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">enabled</span><span class=\"token punctuation\">:</span> <span class=\"token boolean important\">false</span></code></pre></div>\n<p>먼저 CHP(configurable-http-proxy) 설정 부분입니다. JupyterHub에서 <strong>Proxy는 인증, 사용자 노트북 라우팅, 헬스 체크 등 다양한 역할을 수행</strong>합니다. 차트에서는 유연한 Proxy 설정을 위해 CHP, Traefik 등 다양한 옵션을 지원합니다. 아키텍쳐는 aws-load-balancer-controller를 사용한다는 가정하에 구성한 예시입니다. 위 그림과 같이 사용자는 중간의 Proxy 컴포넌트를 거쳐 JupyterHub에 접속하게 됩니다.</p>\n<br>\n<h2 id=\"singleuser-profile\" style=\"position:relative;\"><a href=\"#singleuser-profile\" aria-label=\"singleuser profile permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>SingleUser, Profile</h2>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1C60z5F13WvN3HzsFkv2A09Ja8yMzIGtL\" alt=\"spawner-op\"></p>\n<p>singleUser는 사용자의 노트북 환경을 의미하며 사용자는 미리 정의된 프로필(이미지)을 선택하여 원하는 노트북 환경을 생성할 수 있습니다. 위 아키텍쳐에서는 <strong>PV, PVC를 통해 사용자에게 개인, 공용 볼륨을 할당</strong>해주었습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">profileList</span><span class=\"token punctuation\">:</span>\n  <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">display_name</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"Python Notebook\"</span>\n    <span class=\"token key atrule\">description</span><span class=\"token punctuation\">:</span> <span class=\"token key atrule\">\"Spec</span><span class=\"token punctuation\">:</span> CPU 2<span class=\"token punctuation\">,</span> Memory 4G / Spark 3.1\"\n    <span class=\"token key atrule\">kubespawner_override</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">image</span><span class=\"token punctuation\">:</span> jupyter/python<span class=\"token punctuation\">-</span>notebook<span class=\"token punctuation\">:</span>hub<span class=\"token punctuation\">-</span>1.4.2\n      <span class=\"token key atrule\">cpu_limit</span><span class=\"token punctuation\">:</span> <span class=\"token number\">2</span>\n      <span class=\"token key atrule\">mem_limit</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"4G\"</span>\n      <span class=\"token key atrule\">cpu_guarantee</span><span class=\"token punctuation\">:</span> <span class=\"token number\">1</span>\n      <span class=\"token key atrule\">mem_guarantee</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"2G\"</span>\n      <span class=\"token key atrule\">environment</span><span class=\"token punctuation\">:</span>\n        <span class=\"token key atrule\">TZ</span><span class=\"token punctuation\">:</span> Asia/Seoul\n      <span class=\"token key atrule\">lifecycle_hooks</span><span class=\"token punctuation\">:</span>\n        <span class=\"token key atrule\">postStart</span><span class=\"token punctuation\">:</span>\n          <span class=\"token key atrule\">exec</span><span class=\"token punctuation\">:</span>\n            command<span class=\"token punctuation\">:</span></code></pre></div>\n<p>프로필에는 리소스 뿐만 아니라 lifecycle_hook, environment 등 K8S의 다양한 리소스를 함께 정의하여 유연하게 구성할 수 있습니다. 노트북 기본 이미지는 <a href=\"https://github.com/jupyter/docker-stacks\">jupyter/docker-stacks</a> 저장소로부터 생성한다면 편하게 패키지 의존성을 관리할 수 있습니다.</p>\n<p><strong>resource guarantee</strong><br>\nresource guarantee는 모든 사용자가 최소한 <code class=\"language-text\">_guarantee</code> 만큼의 리소스를 사용할 수 있으며 최대 <code class=\"language-text\">_limit</code> 만큼의 리소스를 제공받을 수 있음을 의미합니다. 예를 들어 사용자에게 2G의 RAM이 보장되는 경우, 사용자는 2G 이상의 RAM을 사용할 수 있습니다. 문서에서는 guarantee 값을 limit의 반으로 설정하는 것을 권장하고 있습니다.</p>\n<br>\n<h2 id=\"idle-culler\" style=\"position:relative;\"><a href=\"#idle-culler\" aria-label=\"idle culler permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Idle Culler</h2>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">cull</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">enabled</span><span class=\"token punctuation\">:</span> <span class=\"token boolean important\">true</span>\n  <span class=\"token key atrule\">timeout</span><span class=\"token punctuation\">:</span> <span class=\"token number\">86400</span>\n  <span class=\"token key atrule\">every</span><span class=\"token punctuation\">:</span> <span class=\"token number\">600</span>\n  <span class=\"token key atrule\">concurrency</span><span class=\"token punctuation\">:</span> <span class=\"token number\">10</span></code></pre></div>\n<p>idle-culler는 일정 주기 동안 미사용된 노트북 리소스를 정리합니다.\n이를 통해 노트북 리소스를 최적화하여 운영할 수 있습니다.\nidle-culler를 활성화하면 JupyterHub Service에 등록되며 이후 JupyterHub API를 통해 사용자 활동을 주기적으로 확인합니다.</p>\n<br>\n<h2 id=\"user-scheduler\" style=\"position:relative;\"><a href=\"#user-scheduler\" aria-label=\"user scheduler permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>User Scheduler</h2>\n<p>user scheduler는 노트북 리소스를 적절한 노드에 할당하기 위해 추가되었습니다.\n기본 K8S 스케줄러는 여러 노드에 분산하여 리소스를 할당하지만, user scheduler는 가장 리소스를 많이 점유하고 있는 노드에 리소스를 할당합니다. 이를 통해 <strong>Cluster AutoScaler, idle-culler와 연계하여 노트북 리소스를 최적화하여 운영</strong>할 수 있습니다.</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1XIgeSDAIxdXAvM0V2y1wQJvlwGoQOnwB\" alt=\"user-scheduler\"></p>\n<p>예를 들어 일반적인 설정이라면, pod가 다양한 노드에 분산되어 클러스터 scale-in 조건까지 도달하기가 어렵습니다. 하지만 user-scheduler를 사용한다면, 위 그림과 같이 노드에 할당된 pod의 수가 점진적으로 줄어들게 됩니다.</p>\n<br>\n<h2 id=\"image-pre-puller\" style=\"position:relative;\"><a href=\"#image-pre-puller\" aria-label=\"image pre puller permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Image Pre Puller</h2>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">prePuller</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">resources</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">requests</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">cpu</span><span class=\"token punctuation\">:</span> 10m\n      <span class=\"token key atrule\">memory</span><span class=\"token punctuation\">:</span> 8Mi\n  <span class=\"token key atrule\">hook</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">enabled</span><span class=\"token punctuation\">:</span> <span class=\"token boolean important\">true</span>\n    <span class=\"token key atrule\">pullOnlyOnChanges</span><span class=\"token punctuation\">:</span> <span class=\"token boolean important\">true</span></code></pre></div>\n<p>Image prePuller는 사용자가 노트북을 실행하기 전에 노드에 미리 이미지를 준비하여 노트북 환경 생성 시간을 단축시켜 줍니다. 예를 들어 CA에 의해 노드가 새로 추가된다거나 새로운 이미지가 프로필에 등록된 경우, 미리 노드에 프로필 이미지를 pull 하게 됩니다.</p>\n<br>\n<h2 id=\"monitoring\" style=\"position:relative;\"><a href=\"#monitoring\" aria-label=\"monitoring permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Monitoring</h2>\n<p>JupyterHub는 <code class=\"language-text\">/metrics</code> endpoint를 통해 prometheus 메트릭을 지원합니다. 주요 지표로는 활성 사용자 수, 노트북 서버 생성까지 소요되는 시간 등이 있습니다. 사용 가능한 전체 메트릭은 <a href=\"https://jupyterhub.readthedocs.io/en/stable/reference/metrics.html\">JupyterHub 문서</a>에서 확인하실 수 있습니다.\n또한  <a href=\"https://github.com/jupyterhub/grafana-dashboards\">jupyterhub/grafana-dashboards</a> 저장소를 통해 미리 정의된 운영 대시보드를 제공합니다. 이를 통해 쉽게 모니터링을 구성할 수 있습니다.</p>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<ul>\n<li><a href=\"https://zero-to-jupyterhub.readthedocs.io/en/latest/index.html\">https://zero-to-jupyterhub.readthedocs.io/en/latest/index.html</a></li>\n<li><a href=\"https://jupyterhub.readthedocs.io/en/stable/index.html\">https://jupyterhub.readthedocs.io/en/stable/index.html</a></li>\n</ul>","excerpt":"일반적으로 JupyterHub를 Kubernetes 환경에 배포할 때 Helm Chart를 많이 사용합니다.\n이 글에서는 zero-to…"}}}},{"node":{"title":"JupyterHub에 Tensorboard 연동하기","id":"8f863c41-ab16-5084-9ee1-f00bba67af7f","slug":"jupyterhub-tensorboard","publishDate":"October 23, 2021","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"eba6ee8a-eb29-50ba-97f2-89eece6cf63a","childMarkdownRemark":{"id":"20b1d52e-ca00-582b-a661-02275bf14cb9","timeToRead":1,"html":"<p>이 글에서는 JupyterHub 사용자 환경에 tensorboard를 proxy 형태로 연동하는 방법에 대해 정리해보려고 합니다. 연동 과정으로 jupyter-server-proxy 라는 extension을 사용합니다.</p>\n<br>\n<h2 id=\"기존-연동-방식\" style=\"position:relative;\"><a href=\"#%EA%B8%B0%EC%A1%B4-%EC%97%B0%EB%8F%99-%EB%B0%A9%EC%8B%9D\" aria-label=\"기존 연동 방식 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>기존 연동 방식</h2>\n<p>Jupyter Notebook에 Tensorboard를 연동하는 가장 쉬운 방법은 공식문서에 나와있는 <strong>%tensorboard</strong> 를 사용하는 방법입니다. </p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">%load_ext tensorboard\n%tensorboard --logdir logs</code></pre></div>\n<p>이 방법은 간단하지만 노트북 내에서 접근하거나 IP주소:포트번호를 통해 접근하게 됩니다.</p>\n<p>따라서 JupyterHub와 같이 여러 사용자가 쓰는 환경이라면 나의 Tensorboard 프로세스에 어떤 주소를 통해 접근해야 하는지 매번 찾아야 합니다.\n또한 JupyterHub는 인증 과정을 거치는 반면 프로세스로 직접 띄우는 텐서보드는 인증 없이 접근이 가능해집니다.</p>\n<br>\n<h2 id=\"jupyter-server-proxy\" style=\"position:relative;\"><a href=\"#jupyter-server-proxy\" aria-label=\"jupyter server proxy permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>jupyter-server-proxy</h2>\n<p>jupyter-server-proxy는 외부 웹 서비스의 프록시를 지원하는 extension 입니다.\njupyter-server-proxy를 통해 연동하면 다음과 같은 이점을 가질 수 있습니다.</p>\n<ul>\n<li>tensorboard 프로세스는 JupyterLab Launcher를 통해 생성됩니다</li>\n<li>프록시를 통해 /hub/proxy/ 하위의 주소로 연결되므로 인증이 그대로 사용됩니다</li>\n</ul>\n<br>\n<h2 id=\"jupyter-tensorboard-proxy-설치\" style=\"position:relative;\"><a href=\"#jupyter-tensorboard-proxy-%EC%84%A4%EC%B9%98\" aria-label=\"jupyter tensorboard proxy 설치 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>jupyter-tensorboard-proxy 설치</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># pip install jupyter-tensorboard-proxy</span>\n\n<span class=\"token comment\"># log path</span>\nlog_dir <span class=\"token operator\">=</span> <span class=\"token string\">\"/home/jovyan/logs/\"</span> <span class=\"token operator\">+</span> datetime<span class=\"token punctuation\">.</span>datetime<span class=\"token punctuation\">.</span>now<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>strftime<span class=\"token punctuation\">(</span><span class=\"token string\">\"%Y%m%d-%H%M\"</span><span class=\"token punctuation\">)</span>\ntensorboard_callback <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>callbacks<span class=\"token punctuation\">.</span>TensorBoard<span class=\"token punctuation\">(</span>log_dir<span class=\"token operator\">=</span>log_dir<span class=\"token punctuation\">,</span> histogram_freq<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>설치 방법은 아주 간단합니다. singleuser profile 이미지에 위의 패키지만 설치해주면 됩니다. 기본으로 바라보는 로그 경로는 $HOME/logs 입니다. 따라서 tensorflow 코드에서 로그 경로를 연결해주어야 합니다.</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=161QSE21LbDPZzQzG6Szq3-IiER1dqbgT\" alt=\"extension\"></p>\n<br>\n<h2 id=\"정리\" style=\"position:relative;\"><a href=\"#%EC%A0%95%EB%A6%AC\" aria-label=\"정리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>정리</h2>\n<p>tensorboard가 아니더라도 jupyter-server-proxy를 사용하면 Spark UI, R Studio Session 등 다양한 외부 웹 서비스들과 연동할 수 있습니다.</p>\n<ul>\n<li><a href=\"https://github.com/jupyterhub/jupyter-server-proxy\">https://github.com/jupyterhub/jupyter-server-proxy</a></li>\n<li><a href=\"https://github.com/kopwei/jupyter-tensorboard-proxy\">https://github.com/kopwei/jupyter-tensorboard-proxy</a></li>\n</ul>","excerpt":"이 글에서는 JupyterHub 사용자 환경에 tensorboard를 proxy…"}}}},{"node":{"title":"Data Mesh 아키텍쳐의 네 가지 원칙","id":"f4493d83-09a7-5393-83bc-85f0047f4b7a","slug":"data-mesh-principle","publishDate":"September 25, 2021","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"1f16465f-7355-5975-a52c-8fd36c5a3819","childMarkdownRemark":{"id":"fc0295d1-3d94-50ed-be82-a4cd9f724dc7","timeToRead":5,"html":"<p>이 글은 martinfowler.com의 <a href=\"https://martinfowler.com/articles/data-mesh-principles.html\">Data Mesh Principles and Logical Architecture</a> 원문을 정리한 내용입니다. Data Mesh 아키텍쳐의 네 가지 원칙에 대한 내용은 <a href=\"https://martinfowler.com/articles/data-monolith-to-mesh.html\">How to Move Beyond a Monolithic Data Lake to a Distributed Data Mesh</a>의 후속글 입니다.</p>\n<br>\n<h2 id=\"the-great-divide-of-data\" style=\"position:relative;\"><a href=\"#the-great-divide-of-data\" aria-label=\"the great divide of data permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>The great divide of data</h2>\n<p>오늘 날의 데이터 환경은 <strong>운영 데이터 영역</strong>과 <strong>분석 데이터 영역</strong>으로 나누어 볼 수 있습니다. 운영 데이터는 주로 마이크로서비스에서 사용하는 데이터베이스에 해당하며 트랜잭션과 비즈니스 요구사항을 담고 있습니다. 분석 데이터는 특정 시간 경과에 따라 집계된 비즈니스 데이터이며 주로 BI / 분석 리포트나 ML 모델링에 사용됩니다.</p>\n<p><img src=\"https://martinfowler.com/articles/data-mesh-principles/data-planes.png\" alt=\"data-planes\"></p>\n<p>데이터 아키텍쳐와 조직 구조 또한 두 가지 데이터 영역을 반영합니다.\n운영 환경으로부터 데이터를 가져오고 ETL 프로세스를 거쳐 분석 데이터를 생성합니다.\n그리고 분석 데이터를 또 다시 운영 환경에 활용하는 경우가 많습니다.\n이러한 데이터 흐름은 빈번한 ETL 프로세스의 실패와 복잡한 파이프라인으로 이어졌습니다.</p>\n<p><img src=\"https://martinfowler.com/articles/data-mesh-principles/data-warehouse.png\" alt=\"dw\"></p>\n<p>분석 데이터 영역은 <strong>데이터 레이크와 데이터 웨어하우스</strong>라는 아키텍쳐로 나누어집니다.\n데이터 레이크는 데이터 사이언스 환경을 지원하며 데이터 웨어하우스는 분석 리포트 및 BI 도구를 지원합니다.</p>\n<p><img src=\"https://martinfowler.com/articles/data-mesh-principles/data-lake.png\" alt=\"datalake\"></p>\n<p>Data Mesh에서는 분석 데이터 영역에 중점을 두고 두 가지 데이터 영역을 연결하고 합니다.\n두 가지 영역의 데이터를 관리하기 위해 기술 스택을 나누고 조직과 팀을 분리하면 안 됩니다.\n마이크로서비스 아키텍쳐로 인해 운영 데이터도 과거에 비해 많이 성숙해졌으며 데이터는 각 마이크로서비스의 API를 통해 제어됩니다. 하지만 분석 데이터에 대한 관리 및 접근 제어는 여전히 어려운 과제로 남아있습니다. Data Mesh는 이 부분을 중점적으로 해결하고 합니다.</p>\n<p>Data Mesh의 목표는 분석 데이터와 히스토리로부터 가치를 얻기 위한 기반을 만드는 것 입니다.\n데이터 환경의 지속적인 변화에도 대응하고 데이터의 품질과 무결성을 제공하면서 데이터 사용에 대한 다양한 요구사항을 지원할 수 있어야 합니다. 이 글에서는 이를 달성하기 위한 네 가지 원칙을 제안합니다.</p>\n<br>\n<h2 id=\"domain-ownership\" style=\"position:relative;\"><a href=\"#domain-ownership\" aria-label=\"domain ownership permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Domain Ownership</h2>\n<p>Data Mesh는 지속적인 변화와 확장성을 지원하기 위해 데이터를 가장 잘 이해하는 사람들에게 <strong>책임을 분산하고 탈중앙화</strong>하는데 기반을 두고 있습니다. 여기서 분석 데이터, 메타 데이터에 대한 소유권을 어떻게 나누어야 하는지에 대한 의문이 생기게 됩니다.</p>\n<p>요즘 조직 구조는 비즈니스 도메인을 기준으로 나누어집니다. 이러한 구조를 통해 도메인 경계에 따라 지속적인 발전을 할 수 있게 만듭니다. 따라서 비즈니스 도메인의 경계(Bounded Context)를 기준으로 나누는 것이 적절하다고 볼 수 있습니다.</p>\n<p>이러한 기준을 가지고 분리하려면 분석 데이터를 도메인 별로 나누는 아키텍쳐를 모델링해야 합니다. 이 아키텍처에서 도메인의 인터페이스에는 운영 데이터 뿐만 아니라 도메인이 제공하는 분석 데이터도 포함됩니다.</p>\n<p><img src=\"https://martinfowler.com/articles/data-mesh-principles/domain-notation.png\" alt=\"domain-not\"></p>\n<p>각 도메인은 하나 이상의 운영 API와 하나 이상의 분석 데이터를 제공합니다.\n또한 각 도메인은 다른 도메인의 운영 및 분석 데이터와 의존 관계를 가질 수도 있습니다.</p>\n<p><img src=\"https://martinfowler.com/articles/data-mesh-principles/domains.png\" alt=\"domains\"></p>\n<p>위의 예시와 같이 Podcasts 도메인은 Users 도메인의 데이터를 통해 Podcast 청취자들의 정보를 데이터화 할 수 있습니다.</p>\n<br>\n<h2 id=\"data-as-a-product\" style=\"position:relative;\"><a href=\"#data-as-a-product\" aria-label=\"data as a product permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Data as a product</h2>\n<p>기존 데이터 분석 아키텍쳐에서 어떤 데이터가 있는지 탐색하고 이해하고 데이터 품질을 유지하는 것이 큰 과제로 남아있었습니다. 이를 해결하지 않으면 Data Mesh 아키텍쳐에서 더 큰 문제로 다가올 수 있습니다. 탈중앙화 원칙에 따라 데이터를 제공하는 곳과 팀의 수가 늘어나기 때문입니다.</p>\n<p><strong>Data as a product 원칙은 데이터 사일로와 데이터 품질 문제를 해결하기 위한 방법</strong>입니다.\n도메인에서 제공하는 분석 데이터는 product로 취급되어야 하며 데이터의 소비자는 고객으로 받아들여야 합니다.</p>\n<p>조직에서는 도메인 데이터에 대한 PO(Product Owner)를 지정해야 하며 PO는 데이터가 프로덕트로써 전달되기 위한 여러 역할을 담당합니다. PO는 데이터 사용자가 누구인지, 어떻게 사용하는지 정의하고 데이터에 대해 깊이 이해하고 있어야 합니다. 데이터 품질, 데이터 사용 만족도를 측정하고 데이터에는 이를 지원하기 위한 표준 인터페이스가 개발되어야 합니다. 데이터 사용자와 PO는 꾸준히 커뮤니케이션을 통해 data product를 발전시킬 수 있습니다.</p>\n<p>각 도메인에는 도메인의 data product를 구축하고 운영 및 제공하는 데이터 개발자 역할도 있어야 합니다. 각 도메인 팀은 하나 이상의 data product를 제공할 수 있습니다.</p>\n<p><img src=\"https://martinfowler.com/articles/data-mesh-principles/data-product-components.png\" alt=\"dataproduct\"></p>\n<p>data product는 위와 같이 세 가지 구성 요소로 이루어져 있습니다.</p>\n<h3 id=\"1-code\" style=\"position:relative;\"><a href=\"#1-code\" aria-label=\"1 code permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. Code</h3>\n<ul>\n<li>업스트림 데이터에 대한 ETL 프로세스를 제공하는 데이터 파이프라인 코드</li>\n<li>데이터 스키마, 데이터 품질에 대한 지표, 메타데이터 적용을 위한 API</li>\n<li>접근 제어 정책, 데이터 정책을 적용하기 위한 코드 (비식별화 등)</li>\n</ul>\n<br>\n<h3 id=\"2-data-and-metadata\" style=\"position:relative;\"><a href=\"#2-data-and-metadata\" aria-label=\"2 data and metadata permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. Data and Metadata</h3>\n<ul>\n<li>이벤트, 배치, 관계형 테이블, 그래프 등 다양하게 소비되는 데이터</li>\n<li>각 데이터에 대한 메타데이터 정의</li>\n<li>생성 로직과 접근 제어 정책</li>\n</ul>\n<br>\n<h3 id=\"3-infrastructure\" style=\"position:relative;\"><a href=\"#3-infrastructure\" aria-label=\"3 infrastructure permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. Infrastructure</h3>\n<ul>\n<li>data product 코드를 구축, 배포 및 실행할 수 있는 인프라</li>\n<li>데이터 및 메타데이터에 대한 저장 및 접근을 가능하게 하는 플랫폼</li>\n</ul>\n<br>\n<p><img src=\"https://martinfowler.com/articles/data-mesh-principles/data-product-notation.png\" alt=\"notation\"></p>\n<p>이를 다이어그램으로 표현하면 위와 같습니다.</p>\n<br>\n<h2 id=\"self-serve-data-platform\" style=\"position:relative;\"><a href=\"#self-serve-data-platform\" aria-label=\"self serve data platform permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Self-serve data platform</h2>\n<p>위와 같이 data product를 구축, 배포, 실행 및 모니터링하려면 이를 위해 많은 인프라가 필요합니다. 이를 구성하는데 필요한 기술은 전문적인 영역이라 각 도메인에서 운영하기 어렵습니다. 각 팀이 data product를 자율적으로 개발하고 운영하기 위해 제품의 수명 주기를 프로비저닝하고 관리할 수 있는 추상화된 인프라가 필요합니다. <strong>Self-serve data platform 원칙은 도메인 자율성을 가능하도록 지원하는 플랫폼을 말합니다.</strong></p>\n<p>셀프 서비스 데이터 플랫폼은 데이터 개발자의 워크플로우를 지원할 수 있어야 합니다.\n데이터 제품을 생성하기 위해 필요한 비용과 진입장벽을 낮추고 스키마, 파이프라인 개발, 데이터 리니지, 컴퓨팅 클러스터 등을 지원해야 합니다.</p>\n<p><img src=\"https://martinfowler.com/articles/data-mesh-principles/platform.png\" alt=\"platform\"></p>\n<br>\n<p>셀프 서비스 플랫폼에는 위와 같이 여러 기능을 제공하는 영역이 존재합니다.\n위 그림에서는 아래와 같이 세 가지 영역으로 나누고 있습니다.</p>\n<h3 id=\"1-data-infrastructure-provisioning-plane\" style=\"position:relative;\"><a href=\"#1-data-infrastructure-provisioning-plane\" aria-label=\"1 data infrastructure provisioning plane permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. Data infrastructure provisioning plane</h3>\n<ul>\n<li>경험이 많은 데이터 개발자만 직접 사용</li>\n<li>data product를 실행하는데 필요한 기본 인프라 프로비저닝을 지원</li>\n<li>분산 스토리지, 스토리지 계정과 접근 제어 시스템</li>\n<li>데이터에 대한 분산 쿼리 엔진 프로비저닝</li>\n</ul>\n<h3 id=\"2-data-product-developer-experience-plane\" style=\"position:relative;\"><a href=\"#2-data-product-developer-experience-plane\" aria-label=\"2 data product developer experience plane permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. Data product developer experience plane</h3>\n<ul>\n<li>일반적인 데이터 개발자가 사용하는 기본 인터페이스</li>\n<li>워크플로우 정의를 위해 필요한 복잡성을 추상화해서 제공</li>\n<li>data product에 대한 빌드, 배포, 모니터링 지원</li>\n<li>미리 정의된 표준 규칙을 통해 자동으로 구현</li>\n</ul>\n<h3 id=\"3-data-mesh-supervision-plane\" style=\"position:relative;\"><a href=\"#3-data-mesh-supervision-plane\" aria-label=\"3 data mesh supervision plane permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. Data mesh supervision plane</h3>\n<ul>\n<li>Data Mesh 수준에서 한눈에 볼 수 있는 인터페이스</li>\n<li>data product를 검색할 수 있는 기능</li>\n<li>여러 data product에 걸쳐 필요한 기능</li>\n</ul>\n<br>\n<h2 id=\"federated-computational-governance\" style=\"position:relative;\"><a href=\"#federated-computational-governance\" aria-label=\"federated computational governance permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Federated computational governance</h2>\n<p>지금까지 정의한 내용과 같이 Data Mesh 모델은 분산 아키텍쳐 형태를 가지고 있습니다.\n독립적인 data product를 가지며 각 팀이 구축하고 배포합니다.\n그러나 ML 영역과 같은 곳에서 가치를 얻으려면 각 data product가 상호적으로 운용되어야 합니다. 이러한 상호 운용을 위해 <strong>플랫폼에 의한 의사 결정을 자동화하기 위한 거버넌스 모델</strong>이 필요합니다. 이를 Federated computational governance 원칙이라고 합니다.\n데이터 PO와 데이터 플랫폼 PO가 함께 주도하는 의사 결정 모델은 도메인 의사 결정 권한을 가지며 여러 규칙을 만들고 준수합니다. 이러한 거버넌스를 통해 중앙 집중화와 분산화 사이의 균형을 유지할 수 있습니다.</p>\n<p><img src=\"https://martinfowler.com/articles/data-mesh-principles/governance.png\" alt=\"governance\"></p>\n<p>거버넌스 모델을 구현하기 위해 참여해야 하는 조직과 인센티브 모델을 정의해야 합니다.\n데이터 플랫폼은 거버넌스로부터 정의된 정책을 자동으로 적용하기 위한 기능을 제공해야 합니다.</p>\n<br>\n<h2 id=\"principles-summary\" style=\"position:relative;\"><a href=\"#principles-summary\" aria-label=\"principles summary permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Principles Summary</h2>\n<p><strong>Domain Ownership</strong>을 통해 데이터 생성과 사용자 수의 증가, 데이터 접근 정책의 다양성과 데이터의 확장에 대응할 수 있습니다.</p>\n<p><strong>Data as a product</strong>를 통해 데이터 사용자가 데이터를 쉽게 검색이 가능하고 품질이 보장된 데이터를 사용하며 데이터에 대한 이해도가 올라가고 안전하게 사용할 수 있습니다.</p>\n<p><strong>Self-serve data platform</strong>을 통해 각 도메인 팀이 자율적으로 제품을 만들고 사용할 수 있도록 하며 data product를 쉽게 구축, 실행 및 운영할 수 있습니다.</p>\n<p><strong>Federated computational governance</strong>를 통해 데이터 사용자가 상호 운용을 위한 표준을 따르는 생태계로 운영할 수 있습니다. 이러한 표준 정책은 플랫폼에 반영됩니다.</p>\n<br>","excerpt":"이 글은 martinfowler.com의 Data Mesh Principles and Logical Architecture…"}}}},{"node":{"title":"Spark on Kubernetes 성능 최적화 방법들","id":"026096e5-5d5d-5809-a3c9-1481f1909414","slug":"spark-on-kubernetes-perf","publishDate":"September 11, 2021","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"66c09a28-a712-595b-b711-4741ad2681b1","childMarkdownRemark":{"id":"048a4410-1e86-5140-9739-04bd0e8c5793","timeToRead":3,"html":"<p>Spark 3.1 버전부터 Spark on Kubernetes가 GA로 변경되었습니다.\n이 글에서는 Spark on YARN 만큼의 성능을 내기 위해서 필요한 설정들에 대해 알아보겠습니다.</p>\n<br>\n<h2 id=\"교차-az-전송-지연-개선\" style=\"position:relative;\"><a href=\"#%EA%B5%90%EC%B0%A8-az-%EC%A0%84%EC%86%A1-%EC%A7%80%EC%97%B0-%EA%B0%9C%EC%84%A0\" aria-label=\"교차 az 전송 지연 개선 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>교차 AZ 전송 지연 개선</h2>\n<p>대부분 사용자들은 가용성을 우려하여 Multi-AZ 사용을 선호합니다.\n하지만 driver, executor pod가 여러 AZ에 분산되어 있는 어플리케이션은 AZ 간 <strong>추가 데이터 전송 비용</strong>이 발생할 수 있습니다. 특히 spark shuffle은 disk IO, network IO에 대한 비용이 많이 드는 연산이므로 latency가 낮은 단일 AZ가 좋은 성능을 보일 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">--conf spark.kubernetes.node.selector.zone=&#39;&lt;availability zone&gt;&#39;</code></pre></div>\n<p>Spark on Kubernetes에서는 Pod Template 또는 node selector 설정을 통해 단일 AZ 노드 그룹에서 실행되도록 설정할 수 있습니다.</p>\n<br>\n<h2 id=\"클러스터-노드-가용성-계산하기\" style=\"position:relative;\"><a href=\"#%ED%81%B4%EB%9F%AC%EC%8A%A4%ED%84%B0-%EB%85%B8%EB%93%9C-%EA%B0%80%EC%9A%A9%EC%84%B1-%EA%B3%84%EC%82%B0%ED%95%98%EA%B8%B0\" aria-label=\"클러스터 노드 가용성 계산하기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>클러스터 노드 가용성 계산하기</h2>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1GLAMXGewFey6ymOrL5ZZDo_oaAW1uE5C\" alt=\"k8s-resource\"></p>\n<p>노드 전체의 리소스를 최대로 사용하기 위해 어느 정도의 리소스를 할당할 수 있는지 계산할 수 있어야 합니다. 모든 Kubernetes 노드는 클러스터 운영을 위해 <strong>OS 시스템과 Kubelet에서 일정량의 리소스를 점유</strong>하고 있습니다. 따라서 Pod에 할당 가능한 리소스를 계산할 때 이 부분은 제외하고 계산해야 합니다. 만약 노드마다 뜨는 daemonset이나 agent와 같은 어플리케이션을 띄웠다면 해당 리소스도 제외되어야 합니다.</p>\n<p>클라우드 인스턴스 유형에 따라 빠르게 보고 싶을 때 <a href=\"https://learnk8s.io/kubernetes-instance-calculator\">Kubernetes Instance Calculator</a>를 사용하면 쉽게 계산할 수 있습니다.</p>\n<br>\n<h2 id=\"셔플-단계에서의-scratch-space-개선\" style=\"position:relative;\"><a href=\"#%EC%85%94%ED%94%8C-%EB%8B%A8%EA%B3%84%EC%97%90%EC%84%9C%EC%9D%98-scratch-space-%EA%B0%9C%EC%84%A0\" aria-label=\"셔플 단계에서의 scratch space 개선 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>셔플 단계에서의 scratch space 개선</h2>\n<p>Spark Shuffle 발생 시 중간 파일들이 생기게 되는데, 보통 driver나 executor의 로컬 디렉토리를 사용합니다. 하지만 Kubernetes의 경우, 기본 값으로 Pod 내부의 볼륨(emptyDir)을 사용하고 있습니다.</p>\n<p>emptyDir 유형의 볼륨은 Docker Storage Driver의 CoW(Copy-On-Write) 오버헤드로 인해 작은 파일 쓰기를 반복하는 경우 속도가 느려질 수 있습니다. 이를 개선하기 위해 Spark on Kubernetes GA 버전에서는 2가지의 설정이 추가되었습니다.</p>\n<br>\n<h3 id=\"1-spark-25262-support-tmpfs-for-local-dirs-in-k8s\" style=\"position:relative;\"><a href=\"#1-spark-25262-support-tmpfs-for-local-dirs-in-k8s\" aria-label=\"1 spark 25262 support tmpfs for local dirs in k8s permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. [SPARK-25262] Support tmpfs for local dirs in k8s</h3>\n<p>먼저 tmpfs를 local dir로 활용하는 방법입니다.\ntmpfs는 RAM 기반 파일 시스템으로 노드 재부팅 시 지워지고, 파일이 컨테이너 메모리 제한에 포함됩니다. 설정 방법은 아래와 같이 간단하지만 tmpfs 사이즈가 커질 수록 Pod OOM이 발생할 가능성이 크다보니 운영할 때는 번거로울 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">&quot;spark.kubernetes.local.dirs.tmpfs&quot;: &quot;true&quot;</code></pre></div>\n<br>\n<h3 id=\"2-spark-27499-support-mapping-sparklocaldir-to-hostpath-volume\" style=\"position:relative;\"><a href=\"#2-spark-27499-support-mapping-sparklocaldir-to-hostpath-volume\" aria-label=\"2 spark 27499 support mapping sparklocaldir to hostpath volume permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. [SPARK-27499] Support mapping spark.local.dir to hostPath volume</h3>\n<p>다음은 host에 마운트된 볼륨을 직접 사용하는 방법입니다. hostPath 볼륨을 spark.local.dir에 할당해서 셔플 과정에서의 디스크 성능을 향상시킬 수 있습니다. 다만 인스턴스에 SSD 또는 NVMe와 같은 볼륨을 추가로 마운트하는 경우에 더 좋은 효과를 볼 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">spec</span><span class=\"token punctuation\">:</span>\n  <span class=\"token punctuation\">...</span>\n  <span class=\"token key atrule\">volumes</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"spark-local-dir-1\"</span>\n      <span class=\"token key atrule\">hostPath</span><span class=\"token punctuation\">:</span>\n        <span class=\"token key atrule\">path</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"/tmp/spark-local-dir\"</span>\n  <span class=\"token key atrule\">executor</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">instances</span><span class=\"token punctuation\">:</span> <span class=\"token number\">10</span>\n    <span class=\"token key atrule\">cores</span><span class=\"token punctuation\">:</span> <span class=\"token number\">2</span>\n    <span class=\"token punctuation\">...</span>.\n    <span class=\"token key atrule\">volumeMounts</span><span class=\"token punctuation\">:</span>\n      <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"spark-local-dir-1\"</span></code></pre></div>\n<br>\n<h2 id=\"executor-pod-batch-관련-설정\" style=\"position:relative;\"><a href=\"#executor-pod-batch-%EA%B4%80%EB%A0%A8-%EC%84%A4%EC%A0%95\" aria-label=\"executor pod batch 관련 설정 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Executor Pod Batch 관련 설정</h2>\n<p>보통 무거운 작업은 executor 여러 개가 떠서 처리하는 경우가 많습니다.\nSpark on Kubernetes에는 executor pod을 생성할 때 <strong>batch size와 delay</strong>가 존재합니다.</p>\n<p>예를 들어 executor 10개를 띄울 때 기본 설정 값이 <code class=\"language-text\">batch size = 5, delay = 1</code>로 되어 있다면, executor pod 5개가 동시에 뜨고 1초 지연 이후에 5개가 추가로 생성됩니다.\n이 설정 값은 Kubernetes Scheduler와 driver pod의 부하를 고려해서 설정해주어야 합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">&quot;spark.kubernetes.allocation.batch.size&quot;: &quot;5&quot;\n&quot;spark.kubernetes.allocation.batch.delay&quot;: &quot;1s&quot;</code></pre></div>\n<br>\n<p>반면 아직 3.1 버전 기준으로 지원하지 않는 설정들은 아래와 같습니다.</p>\n<ul>\n<li>External Shuffle Service는 지원하지 않음</li>\n<li>Job Queue 없음 (Future Work)</li>\n</ul>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<ul>\n<li><a href=\"https://aws.amazon.com/ko/blogs/containers/optimizing-spark-performance-on-kubernetes\">https://aws.amazon.com/ko/blogs/containers/optimizing-spark-performance-on-kubernetes</a></li>\n<li><a href=\"https://aws.github.io/aws-emr-containers-best-practices\">https://aws.github.io/aws-emr-containers-best-practices</a></li>\n<li><a href=\"https://spark.apache.org/docs/latest/running-on-kubernetes.html\">https://spark.apache.org/docs/latest/running-on-kubernetes.html</a></li>\n</ul>","excerpt":"Spark 3.1 버전부터 Spark on Kubernetes가 GA로 변경되었습니다.\n이 글에서는 Spark on YARN…"}}}},{"node":{"title":"여러 조직이 함께 사용하는 Airflow 만들기","id":"1287610b-f42e-5418-85fd-7b80bac6222f","slug":"airflow-multi-tenent-1","publishDate":"August 15, 2021","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"5a118100-3719-5895-9fd0-bf3c690e91e8","childMarkdownRemark":{"id":"070cdd72-3f88-5a52-b46d-48a515c1b70a","timeToRead":6,"html":"<p>사내 데이터가 다양해지고 사용자가 많아지면 접근 제어와 권한 등 다양한 고민이 생기게 됩니다.\n이 글에서는 여러 조직이 함께 사용하는 Airflow를 만들 때 알아두면 좋은 내용들에 대해 정리해보려고 합니다.</p>\n<ul>\n<li><a href=\"https://swalloow.github.io/airflow-multi-tenent-1/#airflow-rbac\">Airflow RBAC</a></li>\n<li><a href=\"https://swalloow.github.io/airflow-multi-tenent-1/#dag-level-permissions\">DAG-Level Permissions</a></li>\n<li><a href=\"https://swalloow.github.io/airflow-multi-tenent-1/#connection-variable-access-control\">Connection, Variable Permissions</a></li>\n<li><a href=\"https://swalloow.github.io/airflow-multi-tenent-1/#cluster-policy\">Cluster Policy</a></li>\n</ul>\n<br>\n<h2 id=\"접근-제어가-필요한-경우\" style=\"position:relative;\"><a href=\"#%EC%A0%91%EA%B7%BC-%EC%A0%9C%EC%96%B4%EA%B0%80-%ED%95%84%EC%9A%94%ED%95%9C-%EA%B2%BD%EC%9A%B0\" aria-label=\"접근 제어가 필요한 경우 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>접근 제어가 필요한 경우</h2>\n<p>먼저 접근 제어는 모든 조직에 필요한 내용은 아닙니다. 다만 아래와 같은 경우에는 필요할 수 있습니다.</p>\n<ul>\n<li>다른 사람이 실행, 중지 권한을 가져서는 안될 만큼 중요한 DAG이 존재하는 경우</li>\n<li>민감한 데이터를 다루는 DAG이 존재하는 경우 (HR, 매출 데이터 등)</li>\n<li>팀에서 운영하는 DAG, Connection, Variable을 우리 팀만 보고 싶은 경우</li>\n</ul>\n<p>특히 Airflow Connections, Variable에는 DB 또는 클러스터 접속 정보, API키 등 민감한 정보가 많이 저장됩니다. 물론 마스킹 기능을 통해 UI에서 볼 수 없게 만들 수 있지만 id는 볼 수 있기 때문에 쉽게 값을 가져올 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> airflow<span class=\"token punctuation\">.</span>models <span class=\"token keyword\">import</span> Variable\n<span class=\"token keyword\">from</span> airflow<span class=\"token punctuation\">.</span>hooks<span class=\"token punctuation\">.</span>base_hook <span class=\"token keyword\">import</span> BaseHook\n\nvariable <span class=\"token operator\">=</span> Variable<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">\"myvar\"</span><span class=\"token punctuation\">)</span>\nconnection <span class=\"token operator\">=</span> BaseHook<span class=\"token punctuation\">.</span>get_connection<span class=\"token punctuation\">(</span><span class=\"token string\">\"myconn\"</span><span class=\"token punctuation\">)</span></code></pre></div>\n<br>\n<p>이 문제를 해결하기 위한 방법으로 조직마다 Airflow 환경을 분리하는 방법이 있습니다.\n하지만 이 방법은 운영과 모니터링이 힘들 수 있어 프라이빗 클라우드를 운영해야하는 상황이 아니라면 추천하지 않습니다. 두 번째 방법은 <strong>Airflow의 RBAC 기능</strong>을 활용하는 방법 입니다.</p>\n<br>\n<h2 id=\"airflow-rbac\" style=\"position:relative;\"><a href=\"#airflow-rbac\" aria-label=\"airflow rbac permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Airflow RBAC</h2>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=1tfr6zzzwrDkMIsTMJFOsNVzDwCchvzjo\" alt=\"security-model\"></p>\n<p>Airflow RBAC은 1.10 버전부터 추가되었고 2.0 버전부터 기본 설정으로 제공됩니다.\nAirflow의 Security Model은 위의 그림과 같은 구조를 따르고 있습니다.\n사용자는 User, Role로 구성되어 있습니다. 여기서 User는 하나 이상의 Role을 가질 수 있습니다.</p>\n<p>접근 권한은 <strong>Permission, ViewMenu</strong> 그리고 이를 조합한 <strong>PermissionView</strong>로 구성되어 있습니다.\nRole은 여러 개의 Permission을 가질 수 있습니다. PermissionView에 대한 예시는 아래와 같습니다.</p>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=1CsfVPlTQL_hqtY4a3_dXxz2kTAFjFqVo\" alt=\"permission-view\"></p>\n<p>Connections <strong>ViewMenu</strong> 와 can_edit <strong>Permission</strong> 을 조합하면 <code class=\"language-text\">can edit on Connections</code>라는 <strong>PermissionView</strong> 가 생성됩니다. 이 권한을 가진 사용자만 Connections UI에서 편집을 할 수 있습니다. 이러한 방식을 Airflow에서는 <strong>Resource-Based permissions</strong>라고 정의하고 있습니다.</p>\n<p>Airflow에는 다양한 리소스에 대해 권한이 이미 정의되어 있고, 기본적으로 Admin을 포함한 5개의 Role을 제공합니다. 조직마다 다른 Role을 가지고 싶은 경우, BaseRole을 정의하고 Copy Role을 통해 새로 만들면 편하게 운영할 수 있습니다.</p>\n<p>리소스 기반의 권한 제어도 필요하지만 이 기능에서는 DAGs 라는 단일 리소스로 보고 있기 때문에 DAG 단위로 접근 제어를 할 수 없습니다. 이를 지원하기 위해 2.0+ 버전부터 <strong>DAG-level Permission</strong>이 추가되었습니다.</p>\n<br>\n<h2 id=\"dag-level-permissions\" style=\"position:relative;\"><a href=\"#dag-level-permissions\" aria-label=\"dag level permissions permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>DAG-level Permissions</h2>\n<p>DAG-level Permission을 사용하면 다음과 같은 접근 제어를 할 수 있습니다.</p>\n<ul>\n<li>A 사용자는 A 사용자의 DAG만 볼 수 있음</li>\n<li>A 사용자는 B 사용자의 DAG을 볼 수 없음</li>\n<li>B 사용자가 A 사용자에게 권한을 부여하면 볼 수 있음</li>\n</ul>\n<p>DAG-level Permission은 앞서 얘기했던 리소스 기반 접근 제어에 <code class=\"language-text\">DAG:dag_id</code>라는 리소스를 추가하는 방식으로 구현되었습니다. 예를 들어 A 사용자와 B 사용자에게 example DAG에 대한 읽기 권한을 부여하고 싶은 경우, <code class=\"language-text\">DAG:example.can_read</code>라는 권한을 추가해주어야 합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">with</span> DAG<span class=\"token punctuation\">(</span>\n    <span class=\"token string\">\"example_dag\"</span><span class=\"token punctuation\">,</span>\n    default_args<span class=\"token operator\">=</span>default_args<span class=\"token punctuation\">,</span>\n    description<span class=\"token operator\">=</span><span class=\"token string\">\"example dags\"</span><span class=\"token punctuation\">,</span>\n    schedule_interval<span class=\"token operator\">=</span><span class=\"token string\">\"@once\"</span><span class=\"token punctuation\">,</span>\n    access_control<span class=\"token operator\">=</span><span class=\"token punctuation\">{</span><span class=\"token string\">\"myrole\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span><span class=\"token string\">\"can_dag_read\"</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    start_date<span class=\"token operator\">=</span>days_ago<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> dag<span class=\"token punctuation\">:</span></code></pre></div>\n<p>위와 같이 DAG을 정의하는 단계에서도 <code class=\"language-text\">access_control</code> 파라메터를 통해 DAG의 접근 권한을 정의해주어야 합니다. 이후 BaseRole에 DAGs 리소스 접근 권한을 제거하면 사용자는 오직 허용된 DAG에 대해서만 접근할 수 있게 됩니다.</p>\n<p>DAG access_control이 변경될 때마다 Role에 권한을 추가하는 일은 보통 번거로운 일이 아닙니다. 이를 위해 Airflow에서는 <code class=\"language-text\">airflow sync-perm</code> 이라는 명령어를 제공합니다. 해당 명령어를 실행하면 모든 DAG에 정의된 권한이 연관된 Role에 반영됩니다. Permission Sync 사이드카 컨테이너를 webserver에 배포하면 이 과정을 자동화할 수 있습니다. 관련 내용은 <a href=\"https://swalloow.github.io/airflow-sidecar/#2-permission-sync-container\">사이드카 컨테이너로 Airflow 기능 확장하기</a> 글을 참고해주시면 됩니다.</p>\n<br>\n<h2 id=\"connection-variable-access-control\" style=\"position:relative;\"><a href=\"#connection-variable-access-control\" aria-label=\"connection variable access control permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Connection, Variable Access Control</h2>\n<p>앞서 DAG-level Permission을 보셨다면 느끼셨겠지만 Connection, Variable 또한 각 변수에 대해 접근 제어를 할 수 없고 관련 기능도 없습니다. 하지만 <strong>Alternative Secrets Backend</strong> 라는 기능을 통해 Custom Backend 클래스를 만들면 접근 제어를 구현할 수 있습니다.</p>\n<br>\n<h3 id=\"alternative-secrets-backend\" style=\"position:relative;\"><a href=\"#alternative-secrets-backend\" aria-label=\"alternative secrets backend permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Alternative Secrets Backend</h3>\n<p>원래 Connection, Variable은 Meta DB에 저장됩니다. 하지만 이 기능을 사용하면 AWS Parameter Store, Vault 등 외부 자원을 저장소로 사용할 수 있습니다. airflow에 구현된 코드는 아래와 같습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token decorator annotation punctuation\">@classmethod</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">get_connection_from_secrets</span><span class=\"token punctuation\">(</span>cls<span class=\"token punctuation\">,</span> conn_id<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token string\">'Connection'</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    Get connection by conn_id.\n    :param conn_id: connection id\n    :return: connection\n    \"\"\"</span>\n    <span class=\"token keyword\">for</span> secrets_backend <span class=\"token keyword\">in</span> ensure_secrets_loaded<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        conn <span class=\"token operator\">=</span> secrets_backend<span class=\"token punctuation\">.</span>get_connection<span class=\"token punctuation\">(</span>conn_id<span class=\"token operator\">=</span>conn_id<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> conn<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">return</span> conn\n    <span class=\"token keyword\">raise</span> AirflowNotFoundException<span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"The conn_id `</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>conn_id<span class=\"token punctuation\">}</span></span><span class=\"token string\">` not defined\"</span></span><span class=\"token punctuation\">)</span></code></pre></div>\n<br>\n<p><code class=\"language-text\">BaseHook</code>에서 호출하는 <code class=\"language-text\">get_connection_from_secrets</code> 메서드는 여러 backend로부터 conn_id에 대한 값을 받아오고 리턴합니다. 즉 기존 Meta DB를 사용하고 있더라도 유지하면서 새로운 backend와 호환 가능합니다.</p>\n<p>AWS Parameter Store는 Path 단위로 키를 다르게 값을 저장할 수 있습니다.\n이 점을 활용해서 id 상위 경로로 role을 지정한다면 role 단위로 접근 제어가 가능해집니다.\n접근 제어를 위한 AWS Parameter Store에 저장되는 규칙은 아래와 같습니다.\nAirflow 환경, 역할 별로 구분해서 저장합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">secrets</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">backend</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"airflow...SystemsManagerParameterStoreBackend\"</span>\n    <span class=\"token key atrule\">backend_kwargs</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token key atrule\">\"connections_prefix\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"/airflow/prod/connections\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token key atrule\">\"variables_prefix\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"/airflow/prod/variables\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token key atrule\">\"profile_name\"</span><span class=\"token punctuation\">:</span> <span class=\"token null important\">null</span>\n    <span class=\"token punctuation\">}</span></code></pre></div>\n<ul>\n<li>/airflow/prod/connections/myrole/connection_id</li>\n<li>/airflow/prod/variables/myrole/variable_id</li>\n</ul>\n<p>기본으로 제공하는 Connections, Variables UI는 세부 경로로 값을 가져오는게 아니기 때문에 secrets backend 설정과 함께 Custom UI Plugin이 필요합니다.</p>\n<br>\n<h2 id=\"access-control-ui-plugin\" style=\"position:relative;\"><a href=\"#access-control-ui-plugin\" aria-label=\"access control ui plugin permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Access Control UI Plugin</h2>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=1QhjXiETQQLqnLo3iJbmcPMtfGcTXRSgV\" alt=\"acl-plugin\"></p>\n<p>플러그인의 역할은 다음과 같습니다. myrole이라는 Airflow Role을 가진 사용자가 Connections UI 페이지에 접근하면 Custom Backend를 통해 Paramter Store의 <code class=\"language-text\">/airflow/prod/connections/myrole</code> 경로 하위의 값들을 받아오도록 요청해야 합니다. list 뿐만 아니라 create, edit, delete에 대한 기능도 추가해주어야 합니다.</p>\n<p>이를 위해 UI 플러그인에서 현재 접속한 사용자의 Role 이름을 받아올 수 있어야 합니다. 이 때 flask의 global session을 활용하면 쉽게 받아올 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> flask <span class=\"token keyword\">import</span> g\n\nrole_name <span class=\"token operator\">=</span> g<span class=\"token punctuation\">.</span>user<span class=\"token punctuation\">.</span>roles<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>name</code></pre></div>\n<p>이제 UI에서 추가, 편집, 삭제 시 Secrets Backend를 통해 AWS Parameter Store에 반영됩니다. 오직 권한을 가진 사용자만이 DAG, Connection, Variable에 접근할 수 있습니다.</p>\n<br>\n<h2 id=\"cluster-policy\" style=\"position:relative;\"><a href=\"#cluster-policy\" aria-label=\"cluster policy permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Cluster Policy</h2>\n<p>DAG 작성에 대한 가이드가 있더라도 모두 만족하는지 체크하는건 상당히 번거로운 일 입니다.\nAirflow 2.0+에서는 Cluster Policy를 통해 클러스터 전체에서 DAG 또는 task에 대한 정책을 정의하고 강제하도록 설정할 수 있습니다. 예를 들면 다음과 같은 정책을 정의할 수 있습니다.</p>\n<ul>\n<li>모든 DAG에는 적어도 하나의 태그를 달아야 한다</li>\n<li>특정 task의 timeout은 48시간을 넘을 수 없다</li>\n</ul>\n<p><code class=\"language-text\">airflow_local_settings.py</code> 파일을 만들고 정의하면 적용할 수 있습니다.\n태그를 강제하는 정책 예시는 아래와 같습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">dag_policy</span><span class=\"token punctuation\">(</span>dag<span class=\"token punctuation\">:</span> DAG<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"Ensure that DAG has at least one tag\"\"\"</span>\n    <span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> dag<span class=\"token punctuation\">.</span>tags<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">raise</span> AirflowClusterPolicyViolation<span class=\"token punctuation\">(</span>\n            <span class=\"token string-interpolation\"><span class=\"token string\">f\"DAG </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>dag<span class=\"token punctuation\">.</span>dag_id<span class=\"token punctuation\">}</span></span><span class=\"token string\"> has no tags. At least one tag required. File path: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>dag<span class=\"token punctuation\">.</span>filepath<span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span>\n        <span class=\"token punctuation\">)</span></code></pre></div>\n<p>위 정책이 적용된 클러스터에 태그가 없는 DAG을 배포하는 경우, <code class=\"language-text\">AirflowClusterPolicyViolation</code> 오류가 발생하기 때문에 DAG을 등록할 수 없습니다.\n자세한 내용은 <a href=\"https://airflow.apache.org/docs/apache-airflow/stable/concepts/cluster-policies.html\">공식문서</a>를 참고하시면 됩니다.</p>\n<br>\n<h2 id=\"정리\" style=\"position:relative;\"><a href=\"#%EC%A0%95%EB%A6%AC\" aria-label=\"정리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>정리</h2>\n<p>최근 Airflow Summit에서 Multi-Tenent와 관련된 영상들이 많이 올라와서 함께 참고하면 도움이 될 것 같습니다.</p>\n<ul>\n<li><a href=\"https://airflow.apache.org/docs/apache-airflow/stable/security/access-control.html\">https://airflow.apache.org/docs/apache-airflow/stable/security/access-control.html</a></li>\n<li><a href=\"https://eng.lyft.com/securing-apache-airflow-ui-with-dag-level-access-a7bc649a2821\">https://eng.lyft.com/securing-apache-airflow-ui-with-dag-level-access-a7bc649a2821</a></li>\n<li><a href=\"https://airflow.apache.org/docs/apache-airflow/stable/security/secrets/secrets-backend/index.html\">https://airflow.apache.org/docs/apache-airflow/stable/security/secrets/secrets-backend/index.html</a></li>\n</ul>","excerpt":"…"}}}}]}},"pageContext":{"basePath":"","paginationPath":"","pageNumber":0,"humanPageNumber":1,"skip":0,"limit":7,"numberOfPages":15,"previousPagePath":"","nextPagePath":"/2"}}}