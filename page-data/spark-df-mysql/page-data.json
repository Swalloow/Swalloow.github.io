{"componentChunkName":"component---src-templates-post-js","path":"/spark-df-mysql/","result":{"data":{"contentfulPost":{"id":"521ef7ff-15d1-5f53-b269-e5e9a75838d1","title":"Spark DataFrame을 MySQL에 저장하는 방법","slug":"spark-df-mysql","metaDescription":null,"publishDate":"July 17, 2017","publishDateISO":"2017-07-17","tags":[{"title":"DataEngineering","id":"6d3fb203-7cdf-53d7-be6f-12ba3e82d74d","slug":"dataengineering"}],"heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"11db5a37-d4e3-5555-90b2-7f2f8aae6d79","childMarkdownRemark":{"id":"02bdf521-be03-59df-87f6-df899fda1460","timeToRead":1,"html":"<p>Spark에서 MySQL에 접근하고 DataFrame을 read, write 하는 방법에 대해 정리해보았습니다.\n참고로 저는 Spark 2.1.0 버전을 사용 중 입니다.</p>\n<br>\n<h2 id=\"mysql-jdbc-driver\" style=\"position:relative;\"><a href=\"#mysql-jdbc-driver\" aria-label=\"mysql jdbc driver permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>MySQL JDBC Driver</h2>\n<p>JDBC를 통해 접근하기 때문에 드라이버가 필요합니다.\n만일 SBT를 사용하신다면, build.sbt에 maven의 <code class=\"language-text\">mysql-connector-java</code> 를 추가하시면 됩니다.</p>\n<p>직접 jar 파일을 사용해야하는 상황이라면, 다음 링크를 통해 다운받으시면 됩니다.\n<a href=\"https://dev.mysql.com/downloads/connector/j/\">https://dev.mysql.com/downloads/connector/j/</a></p>\n<p>그리고 받으신 jar 파일을 -jars 옵션으로 추가해주셔야 합니다.</p>\n<p><code class=\"language-text\">–jars /home/example/jars/mysql-connector-java-5.1.26.jar</code></p>\n<p>마지막으로 spark-submit 을 사용하신다면, --packages 옵션을 추가해주시면 됩니다.</p>\n<p><code class=\"language-text\">--packages mysql:mysql-connector-java:5.1.39</code></p>\n<br>\n<h2 id=\"spark-dataframe-mysql\" style=\"position:relative;\"><a href=\"#spark-dataframe-mysql\" aria-label=\"spark dataframe mysql permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Spark DataFrame MySQL</h2>\n<p>Spark의 DataFrame은 read, write 함수를 통해 쉽게 데이터를 가져오거나 저장할 수 있습니다.\n아래 예시는 Scala 언어로 작성했습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"scala\"><pre class=\"language-scala\"><code class=\"language-scala\"><span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>sql</span><span class=\"token punctuation\">.</span>SaveMode\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">java<span class=\"token punctuation\">.</span>util</span><span class=\"token punctuation\">.</span>Properties\n\n<span class=\"token keyword\">val</span> tempDF <span class=\"token operator\">=</span> List<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"1\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"2017-06-01\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"2017-06-03\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>toDF<span class=\"token punctuation\">(</span><span class=\"token string\">\"id\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"start\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"end\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">val</span> properties <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> Properties<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nproperties<span class=\"token punctuation\">.</span>put<span class=\"token punctuation\">(</span><span class=\"token string\">\"user\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"userId\"</span><span class=\"token punctuation\">)</span>\nproperties<span class=\"token punctuation\">.</span>put<span class=\"token punctuation\">(</span><span class=\"token string\">\"password\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"password\"</span><span class=\"token punctuation\">)</span>\ntempDF<span class=\"token punctuation\">.</span>write<span class=\"token punctuation\">.</span>mode<span class=\"token punctuation\">(</span>SaveMode<span class=\"token punctuation\">.</span>Append<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>jdbc<span class=\"token punctuation\">(</span><span class=\"token string\">\"jdbc:mysql://url/database\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"table\"</span><span class=\"token punctuation\">,</span> properties<span class=\"token punctuation\">)</span></code></pre></div>\n<p>위 예제에서는 Properties를 통해 설정값을 넣어주었습니다.\n유저 정보나 주소는 맞게 변경해주시면 됩니다.</p>\n<p>mode 라는 것이 있는데 <code class=\"language-text\">SaveMode.Append</code>는 기존의 테이블에 추가하는 방식이고\n<code class=\"language-text\">SaveMode.Overwrite</code>의 경우 기존의 테이블을 새로운 데이터로 대체하는 방식입니다.</p>\n<br>","excerpt":"Spark에서 MySQL에 접근하고 DataFrame을 read, write 하는 방법에 대해 정리해보았습니다.\n참고로 저는 Spark 2.1.0 버전을 사용 중 입니다. MySQL JDBC Driver JDBC를 통해 접근하기 때문에 드라이버가 필요합니다.\n만일 SBT를 사용하신다면, build.sbt에 maven의  를 추가하시면 됩니다. 직접 jar 파일을 사용해야하는 상황이라면, 다음 링크를 통해 다운받으시면 됩니다.\nhttps://dev.mysql.com/downloads/connector/j/ 그리고 받으신 jar 파일을 -jars…"}}}},"pageContext":{"slug":"spark-df-mysql","basePath":"","prev":{"slug":"bagging-boosting","publishDate":"2017-07-19"},"next":{"slug":"spark22","publishDate":"2017-07-14"}}}}