{"componentChunkName":"component---src-templates-tag-js","path":"/tag/dataengineering","result":{"data":{"contentfulTag":{"title":"DataEngineering","id":"6d3fb203-7cdf-53d7-be6f-12ba3e82d74d","slug":"dataengineering","post":[{"id":"8f863c41-ab16-5084-9ee1-f00bba67af7f","title":"JupyterHub에 Tensorboard 연동하기","slug":"jupyterhub-tensorboard","publishDate":"October 23, 2021","publishDateISO":"2021-10-23","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"eba6ee8a-eb29-50ba-97f2-89eece6cf63a","childMarkdownRemark":{"id":"20b1d52e-ca00-582b-a661-02275bf14cb9","timeToRead":1,"html":"<p>이 글에서는 JupyterHub 사용자 환경에 tensorboard를 proxy 형태로 연동하는 방법에 대해 정리해보려고 합니다. 연동 과정으로 jupyter-server-proxy 라는 extension을 사용합니다.</p>\n<br>\n<h2 id=\"기존-연동-방식\" style=\"position:relative;\"><a href=\"#%EA%B8%B0%EC%A1%B4-%EC%97%B0%EB%8F%99-%EB%B0%A9%EC%8B%9D\" aria-label=\"기존 연동 방식 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>기존 연동 방식</h2>\n<p>Jupyter Notebook에 Tensorboard를 연동하는 가장 쉬운 방법은 공식문서에 나와있는 <strong>%tensorboard</strong> 를 사용하는 방법입니다. </p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">%load_ext tensorboard\n%tensorboard --logdir logs</code></pre></div>\n<p>이 방법은 간단하지만 노트북 내에서 접근하거나 IP주소:포트번호를 통해 접근하게 됩니다.\nJupyterHub와 같이 여러 사용자가 쓰는 환경이라면 나의 Tensorboard 프로세스에 어떤 주소를 통해 접근해야 하는지 매번 찾아야 합니다. 또한 JupyterHub는 인증 과정을 거치는 반면 프로세스로 직접 띄우는 텐서보드는 인증 없이 접근이 가능해집니다.</p>\n<br>\n<h2 id=\"jupyter-server-proxy\" style=\"position:relative;\"><a href=\"#jupyter-server-proxy\" aria-label=\"jupyter server proxy permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>jupyter-server-proxy</h2>\n<p>jupyter-server-proxy는 외부 웹 서비스의 프록시를 지원하는 extension 입니다.\njupyter-server-proxy를 통해 연동하면 다음과 같은 이점을 가질 수 있습니다.</p>\n<ul>\n<li>tensorboard 프로세스는 JupyterLab Launcher를 통해 생성됩니다</li>\n<li>프록시를 통해 /hub/proxy/ 하위의 주소로 연결되므로 인증이 그대로 사용됩니다</li>\n</ul>\n<br>\n<p><strong>jupyter-tensorboard-proxy 설치</strong></p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=15wd7UkqnuwUFdqJizB7BXad9I_UIflQ_\" alt=\"extension\"></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># pip install jupyter-tensorboard-proxy</span>\n\n<span class=\"token comment\"># log path</span>\nlog_dir <span class=\"token operator\">=</span> <span class=\"token string\">\"/home/jovyan/logs/\"</span> <span class=\"token operator\">+</span> datetime<span class=\"token punctuation\">.</span>datetime<span class=\"token punctuation\">.</span>now<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>strftime<span class=\"token punctuation\">(</span><span class=\"token string\">\"%Y%m%d-%H%M\"</span><span class=\"token punctuation\">)</span>\ntensorboard_callback <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>callbacks<span class=\"token punctuation\">.</span>TensorBoard<span class=\"token punctuation\">(</span>log_dir<span class=\"token operator\">=</span>log_dir<span class=\"token punctuation\">,</span> histogram_freq<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>설치 방법은 아주 간단합니다. singleuser profile 이미지에 위의 패키지만 설치해주면 됩니다. 기본으로 바라보는 로그 경로는 $HOME/logs 입니다. 따라서 tensorflow 코드에서 로그 경로를 연결해주어야 합니다.</p>\n<h2 id=\"정리\" style=\"position:relative;\"><a href=\"#%EC%A0%95%EB%A6%AC\" aria-label=\"정리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>정리</h2>\n<p>tensorboard가 아니더라도 jupyter-server-proxy를 사용하면 Spark UI, R Studio Session 등 다양한 외부 웹 서비스들과 연동할 수 있습니다.</p>\n<ul>\n<li><a href=\"https://github.com/jupyterhub/jupyter-server-proxy\">https://github.com/jupyterhub/jupyter-server-proxy</a></li>\n<li><a href=\"https://github.com/kopwei/jupyter-tensorboard-proxy\">https://github.com/kopwei/jupyter-tensorboard-proxy</a></li>\n</ul>","excerpt":"이 글에서는 JupyterHub 사용자 환경에 tensorboard를 proxy…"}}},{"id":"f4493d83-09a7-5393-83bc-85f0047f4b7a","title":"Data Mesh 아키텍쳐의 네 가지 원칙","slug":"data-mesh-principle","publishDate":"September 25, 2021","publishDateISO":"2021-09-25","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"1f16465f-7355-5975-a52c-8fd36c5a3819","childMarkdownRemark":{"id":"fc0295d1-3d94-50ed-be82-a4cd9f724dc7","timeToRead":5,"html":"<p>이 글은 martinfowler.com의 <a href=\"https://martinfowler.com/articles/data-mesh-principles.html\">Data Mesh Principles and Logical Architecture</a> 원문을 정리한 내용입니다. Data Mesh 아키텍쳐의 네 가지 원칙에 대한 내용은 <a href=\"https://martinfowler.com/articles/data-monolith-to-mesh.html\">How to Move Beyond a Monolithic Data Lake to a Distributed Data Mesh</a>의 후속글 입니다.</p>\n<br>\n<h2 id=\"the-great-divide-of-data\" style=\"position:relative;\"><a href=\"#the-great-divide-of-data\" aria-label=\"the great divide of data permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>The great divide of data</h2>\n<p>오늘 날의 데이터 환경은 <strong>운영 데이터 영역</strong>과 <strong>분석 데이터 영역</strong>으로 나누어 볼 수 있습니다. 운영 데이터는 주로 마이크로서비스에서 사용하는 데이터베이스에 해당하며 트랜잭션과 비즈니스 요구사항을 담고 있습니다. 분석 데이터는 특정 시간 경과에 따라 집계된 비즈니스 데이터이며 주로 BI / 분석 리포트나 ML 모델링에 사용됩니다.</p>\n<p><img src=\"https://martinfowler.com/articles/data-mesh-principles/data-planes.png\" alt=\"data-planes\"></p>\n<p>데이터 아키텍쳐와 조직 구조 또한 두 가지 데이터 영역을 반영합니다.\n운영 환경으로부터 데이터를 가져오고 ETL 프로세스를 거쳐 분석 데이터를 생성합니다.\n그리고 분석 데이터를 또 다시 운영 환경에 활용하는 경우가 많습니다.\n이러한 데이터 흐름은 빈번한 ETL 프로세스의 실패와 복잡한 파이프라인으로 이어졌습니다.</p>\n<p><img src=\"https://martinfowler.com/articles/data-mesh-principles/data-warehouse.png\" alt=\"dw\"></p>\n<p>분석 데이터 영역은 <strong>데이터 레이크와 데이터 웨어하우스</strong>라는 아키텍쳐로 나누어집니다.\n데이터 레이크는 데이터 사이언스 환경을 지원하며 데이터 웨어하우스는 분석 리포트 및 BI 도구를 지원합니다.</p>\n<p><img src=\"https://martinfowler.com/articles/data-mesh-principles/data-lake.png\" alt=\"datalake\"></p>\n<p>Data Mesh에서는 분석 데이터 영역에 중점을 두고 두 가지 데이터 영역을 연결하고 합니다.\n두 가지 영역의 데이터를 관리하기 위해 기술 스택을 나누고 조직과 팀을 분리하면 안 됩니다.\n마이크로서비스 아키텍쳐로 인해 운영 데이터도 과거에 비해 많이 성숙해졌으며 데이터는 각 마이크로서비스의 API를 통해 제어됩니다. 하지만 분석 데이터에 대한 관리 및 접근 제어는 여전히 어려운 과제로 남아있습니다. Data Mesh는 이 부분을 중점적으로 해결하고 합니다.</p>\n<p>Data Mesh의 목표는 분석 데이터와 히스토리로부터 가치를 얻기 위한 기반을 만드는 것 입니다.\n데이터 환경의 지속적인 변화에도 대응하고 데이터의 품질과 무결성을 제공하면서 데이터 사용에 대한 다양한 요구사항을 지원할 수 있어야 합니다. 이 글에서는 이를 달성하기 위한 네 가지 원칙을 제안합니다.</p>\n<br>\n<h2 id=\"domain-ownership\" style=\"position:relative;\"><a href=\"#domain-ownership\" aria-label=\"domain ownership permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Domain Ownership</h2>\n<p>Data Mesh는 지속적인 변화와 확장성을 지원하기 위해 데이터를 가장 잘 이해하는 사람들에게 <strong>책임을 분산하고 탈중앙화</strong>하는데 기반을 두고 있습니다. 여기서 분석 데이터, 메타 데이터에 대한 소유권을 어떻게 나누어야 하는지에 대한 의문이 생기게 됩니다.</p>\n<p>요즘 조직 구조는 비즈니스 도메인을 기준으로 나누어집니다. 이러한 구조를 통해 도메인 경계에 따라 지속적인 발전을 할 수 있게 만듭니다. 따라서 비즈니스 도메인의 경계(Bounded Context)를 기준으로 나누는 것이 적절하다고 볼 수 있습니다.</p>\n<p>이러한 기준을 가지고 분리하려면 분석 데이터를 도메인 별로 나누는 아키텍쳐를 모델링해야 합니다. 이 아키텍처에서 도메인의 인터페이스에는 운영 데이터 뿐만 아니라 도메인이 제공하는 분석 데이터도 포함됩니다.</p>\n<p><img src=\"https://martinfowler.com/articles/data-mesh-principles/domain-notation.png\" alt=\"domain-not\"></p>\n<p>각 도메인은 하나 이상의 운영 API와 하나 이상의 분석 데이터를 제공합니다.\n또한 각 도메인은 다른 도메인의 운영 및 분석 데이터와 의존 관계를 가질 수도 있습니다.</p>\n<p><img src=\"https://martinfowler.com/articles/data-mesh-principles/domains.png\" alt=\"domains\"></p>\n<p>위의 예시와 같이 Podcasts 도메인은 Users 도메인의 데이터를 통해 Podcast 청취자들의 정보를 데이터화 할 수 있습니다.</p>\n<br>\n<h2 id=\"data-as-a-product\" style=\"position:relative;\"><a href=\"#data-as-a-product\" aria-label=\"data as a product permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Data as a product</h2>\n<p>기존 데이터 분석 아키텍쳐에서 어떤 데이터가 있는지 탐색하고 이해하고 데이터 품질을 유지하는 것이 큰 과제로 남아있었습니다. 이를 해결하지 않으면 Data Mesh 아키텍쳐에서 더 큰 문제로 다가올 수 있습니다. 탈중앙화 원칙에 따라 데이터를 제공하는 곳과 팀의 수가 늘어나기 때문입니다.</p>\n<p><strong>Data as a product 원칙은 데이터 사일로와 데이터 품질 문제를 해결하기 위한 방법</strong>입니다.\n도메인에서 제공하는 분석 데이터는 product로 취급되어야 하며 데이터의 소비자는 고객으로 받아들여야 합니다.</p>\n<p>조직에서는 도메인 데이터에 대한 PO(Product Owner)를 지정해야 하며 PO는 데이터가 프로덕트로써 전달되기 위한 여러 역할을 담당합니다. PO는 데이터 사용자가 누구인지, 어떻게 사용하는지 정의하고 데이터에 대해 깊이 이해하고 있어야 합니다. 데이터 품질, 데이터 사용 만족도를 측정하고 데이터에는 이를 지원하기 위한 표준 인터페이스가 개발되어야 합니다. 데이터 사용자와 PO는 꾸준히 커뮤니케이션을 통해 data product를 발전시킬 수 있습니다.</p>\n<p>각 도메인에는 도메인의 data product를 구축하고 운영 및 제공하는 데이터 개발자 역할도 있어야 합니다. 각 도메인 팀은 하나 이상의 data product를 제공할 수 있습니다.</p>\n<p><img src=\"https://martinfowler.com/articles/data-mesh-principles/data-product-components.png\" alt=\"dataproduct\"></p>\n<p>data product는 위와 같이 세 가지 구성 요소로 이루어져 있습니다.</p>\n<h3 id=\"1-code\" style=\"position:relative;\"><a href=\"#1-code\" aria-label=\"1 code permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. Code</h3>\n<ul>\n<li>업스트림 데이터에 대한 ETL 프로세스를 제공하는 데이터 파이프라인 코드</li>\n<li>데이터 스키마, 데이터 품질에 대한 지표, 메타데이터 적용을 위한 API</li>\n<li>접근 제어 정책, 데이터 정책을 적용하기 위한 코드 (비식별화 등)</li>\n</ul>\n<br>\n<h3 id=\"2-data-and-metadata\" style=\"position:relative;\"><a href=\"#2-data-and-metadata\" aria-label=\"2 data and metadata permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. Data and Metadata</h3>\n<ul>\n<li>이벤트, 배치, 관계형 테이블, 그래프 등 다양하게 소비되는 데이터</li>\n<li>각 데이터에 대한 메타데이터 정의</li>\n<li>생성 로직과 접근 제어 정책</li>\n</ul>\n<br>\n<h3 id=\"3-infrastructure\" style=\"position:relative;\"><a href=\"#3-infrastructure\" aria-label=\"3 infrastructure permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. Infrastructure</h3>\n<ul>\n<li>data product 코드를 구축, 배포 및 실행할 수 있는 인프라</li>\n<li>데이터 및 메타데이터에 대한 저장 및 접근을 가능하게 하는 플랫폼</li>\n</ul>\n<br>\n<p><img src=\"https://martinfowler.com/articles/data-mesh-principles/data-product-notation.png\" alt=\"notation\"></p>\n<p>이를 다이어그램으로 표현하면 위와 같습니다.</p>\n<br>\n<h2 id=\"self-serve-data-platform\" style=\"position:relative;\"><a href=\"#self-serve-data-platform\" aria-label=\"self serve data platform permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Self-serve data platform</h2>\n<p>위와 같이 data product를 구축, 배포, 실행 및 모니터링하려면 이를 위해 많은 인프라가 필요합니다. 이를 구성하는데 필요한 기술은 전문적인 영역이라 각 도메인에서 운영하기 어렵습니다. 각 팀이 data product를 자율적으로 개발하고 운영하기 위해 제품의 수명 주기를 프로비저닝하고 관리할 수 있는 추상화된 인프라가 필요합니다. <strong>Self-serve data platform 원칙은 도메인 자율성을 가능하도록 지원하는 플랫폼을 말합니다.</strong></p>\n<p>셀프 서비스 데이터 플랫폼은 데이터 개발자의 워크플로우를 지원할 수 있어야 합니다.\n데이터 제품을 생성하기 위해 필요한 비용과 진입장벽을 낮추고 스키마, 파이프라인 개발, 데이터 리니지, 컴퓨팅 클러스터 등을 지원해야 합니다.</p>\n<p><img src=\"https://martinfowler.com/articles/data-mesh-principles/platform.png\" alt=\"platform\"></p>\n<br>\n<p>셀프 서비스 플랫폼에는 위와 같이 여러 기능을 제공하는 영역이 존재합니다.\n위 그림에서는 아래와 같이 세 가지 영역으로 나누고 있습니다.</p>\n<h3 id=\"1-data-infrastructure-provisioning-plane\" style=\"position:relative;\"><a href=\"#1-data-infrastructure-provisioning-plane\" aria-label=\"1 data infrastructure provisioning plane permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. Data infrastructure provisioning plane</h3>\n<ul>\n<li>경험이 많은 데이터 개발자만 직접 사용</li>\n<li>data product를 실행하는데 필요한 기본 인프라 프로비저닝을 지원</li>\n<li>분산 스토리지, 스토리지 계정과 접근 제어 시스템</li>\n<li>데이터에 대한 분산 쿼리 엔진 프로비저닝</li>\n</ul>\n<h3 id=\"2-data-product-developer-experience-plane\" style=\"position:relative;\"><a href=\"#2-data-product-developer-experience-plane\" aria-label=\"2 data product developer experience plane permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. Data product developer experience plane</h3>\n<ul>\n<li>일반적인 데이터 개발자가 사용하는 기본 인터페이스</li>\n<li>워크플로우 정의를 위해 필요한 복잡성을 추상화해서 제공</li>\n<li>data product에 대한 빌드, 배포, 모니터링 지원</li>\n<li>미리 정의된 표준 규칙을 통해 자동으로 구현</li>\n</ul>\n<h3 id=\"3-data-mesh-supervision-plane\" style=\"position:relative;\"><a href=\"#3-data-mesh-supervision-plane\" aria-label=\"3 data mesh supervision plane permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. Data mesh supervision plane</h3>\n<ul>\n<li>Data Mesh 수준에서 한눈에 볼 수 있는 인터페이스</li>\n<li>data product를 검색할 수 있는 기능</li>\n<li>여러 data product에 걸쳐 필요한 기능</li>\n</ul>\n<br>\n<h2 id=\"federated-computational-governance\" style=\"position:relative;\"><a href=\"#federated-computational-governance\" aria-label=\"federated computational governance permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Federated computational governance</h2>\n<p>지금까지 정의한 내용과 같이 Data Mesh 모델은 분산 아키텍쳐 형태를 가지고 있습니다.\n독립적인 data product를 가지며 각 팀이 구축하고 배포합니다.\n그러나 ML 영역과 같은 곳에서 가치를 얻으려면 각 data product가 상호적으로 운용되어야 합니다. 이러한 상호 운용을 위해 <strong>플랫폼에 의한 의사 결정을 자동화하기 위한 거버넌스 모델</strong>이 필요합니다. 이를 Federated computational governance 원칙이라고 합니다.\n데이터 PO와 데이터 플랫폼 PO가 함께 주도하는 의사 결정 모델은 도메인 의사 결정 권한을 가지며 여러 규칙을 만들고 준수합니다. 이러한 거버넌스를 통해 중앙 집중화와 분산화 사이의 균형을 유지할 수 있습니다.</p>\n<p><img src=\"https://martinfowler.com/articles/data-mesh-principles/governance.png\" alt=\"governance\"></p>\n<p>거버넌스 모델을 구현하기 위해 참여해야 하는 조직과 인센티브 모델을 정의해야 합니다.\n데이터 플랫폼은 거버넌스로부터 정의된 정책을 자동으로 적용하기 위한 기능을 제공해야 합니다.</p>\n<br>\n<h2 id=\"principles-summary\" style=\"position:relative;\"><a href=\"#principles-summary\" aria-label=\"principles summary permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Principles Summary</h2>\n<p><strong>Domain Ownership</strong>을 통해 데이터 생성과 사용자 수의 증가, 데이터 접근 정책의 다양성과 데이터의 확장에 대응할 수 있습니다.</p>\n<p><strong>Data as a product</strong>를 통해 데이터 사용자가 데이터를 쉽게 검색이 가능하고 품질이 보장된 데이터를 사용하며 데이터에 대한 이해도가 올라가고 안전하게 사용할 수 있습니다.</p>\n<p><strong>Self-serve data platform</strong>을 통해 각 도메인 팀이 자율적으로 제품을 만들고 사용할 수 있도록 하며 data product를 쉽게 구축, 실행 및 운영할 수 있습니다.</p>\n<p><strong>Federated computational governance</strong>를 통해 데이터 사용자가 상호 운용을 위한 표준을 따르는 생태계로 운영할 수 있습니다. 이러한 표준 정책은 플랫폼에 반영됩니다.</p>\n<br>","excerpt":"이 글은 martinfowler.com의 Data Mesh Principles and Logical Architecture…"}}},{"id":"026096e5-5d5d-5809-a3c9-1481f1909414","title":"Spark on Kubernetes 성능 최적화 방법들","slug":"spark-on-kubernetes-perf","publishDate":"September 11, 2021","publishDateISO":"2021-09-11","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"66c09a28-a712-595b-b711-4741ad2681b1","childMarkdownRemark":{"id":"048a4410-1e86-5140-9739-04bd0e8c5793","timeToRead":3,"html":"<p>Spark 3.1 버전부터 Spark on Kubernetes가 GA로 변경되었습니다.\n이 글에서는 Spark on YARN 만큼의 성능을 내기 위해서 필요한 설정들에 대해 알아보겠습니다.</p>\n<br>\n<h2 id=\"교차-az-전송-지연-개선\" style=\"position:relative;\"><a href=\"#%EA%B5%90%EC%B0%A8-az-%EC%A0%84%EC%86%A1-%EC%A7%80%EC%97%B0-%EA%B0%9C%EC%84%A0\" aria-label=\"교차 az 전송 지연 개선 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>교차 AZ 전송 지연 개선</h2>\n<p>대부분 사용자들은 가용성을 우려하여 Multi-AZ 사용을 선호합니다.\n하지만 driver, executor pod가 여러 AZ에 분산되어 있는 어플리케이션은 AZ 간 <strong>추가 데이터 전송 비용</strong>이 발생할 수 있습니다. 특히 spark shuffle은 disk IO, network IO에 대한 비용이 많이 드는 연산이므로 latency가 낮은 단일 AZ가 좋은 성능을 보일 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">--conf spark.kubernetes.node.selector.zone=&#39;&lt;availability zone&gt;&#39;</code></pre></div>\n<p>Spark on Kubernetes에서는 Pod Template 또는 node selector 설정을 통해 단일 AZ 노드 그룹에서 실행되도록 설정할 수 있습니다.</p>\n<br>\n<h2 id=\"클러스터-노드-가용성-계산하기\" style=\"position:relative;\"><a href=\"#%ED%81%B4%EB%9F%AC%EC%8A%A4%ED%84%B0-%EB%85%B8%EB%93%9C-%EA%B0%80%EC%9A%A9%EC%84%B1-%EA%B3%84%EC%82%B0%ED%95%98%EA%B8%B0\" aria-label=\"클러스터 노드 가용성 계산하기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>클러스터 노드 가용성 계산하기</h2>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1GLAMXGewFey6ymOrL5ZZDo_oaAW1uE5C\" alt=\"k8s-resource\"></p>\n<p>노드 전체의 리소스를 최대로 사용하기 위해 어느 정도의 리소스를 할당할 수 있는지 계산할 수 있어야 합니다. 모든 Kubernetes 노드는 클러스터 운영을 위해 <strong>OS 시스템과 Kubelet에서 일정량의 리소스를 점유</strong>하고 있습니다. 따라서 Pod에 할당 가능한 리소스를 계산할 때 이 부분은 제외하고 계산해야 합니다. 만약 노드마다 뜨는 daemonset이나 agent와 같은 어플리케이션을 띄웠다면 해당 리소스도 제외되어야 합니다.</p>\n<p>클라우드 인스턴스 유형에 따라 빠르게 보고 싶을 때 <a href=\"https://learnk8s.io/kubernetes-instance-calculator\">Kubernetes Instance Calculator</a>를 사용하면 쉽게 계산할 수 있습니다.</p>\n<br>\n<h2 id=\"셔플-단계에서의-scratch-space-개선\" style=\"position:relative;\"><a href=\"#%EC%85%94%ED%94%8C-%EB%8B%A8%EA%B3%84%EC%97%90%EC%84%9C%EC%9D%98-scratch-space-%EA%B0%9C%EC%84%A0\" aria-label=\"셔플 단계에서의 scratch space 개선 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>셔플 단계에서의 scratch space 개선</h2>\n<p>Spark Shuffle 발생 시 중간 파일들이 생기게 되는데, 보통 driver나 executor의 로컬 디렉토리를 사용합니다. 하지만 Kubernetes의 경우, 기본 값으로 Pod 내부의 볼륨(emptyDir)을 사용하고 있습니다.</p>\n<p>emptyDir 유형의 볼륨은 Docker Storage Driver의 CoW(Copy-On-Write) 오버헤드로 인해 작은 파일 쓰기를 반복하는 경우 속도가 느려질 수 있습니다. 이를 개선하기 위해 Spark on Kubernetes GA 버전에서는 2가지의 설정이 추가되었습니다.</p>\n<br>\n<h3 id=\"1-spark-25262-support-tmpfs-for-local-dirs-in-k8s\" style=\"position:relative;\"><a href=\"#1-spark-25262-support-tmpfs-for-local-dirs-in-k8s\" aria-label=\"1 spark 25262 support tmpfs for local dirs in k8s permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. [SPARK-25262] Support tmpfs for local dirs in k8s</h3>\n<p>먼저 tmpfs를 local dir로 활용하는 방법입니다.\ntmpfs는 RAM 기반 파일 시스템으로 노드 재부팅 시 지워지고, 파일이 컨테이너 메모리 제한에 포함됩니다. 설정 방법은 아래와 같이 간단하지만 tmpfs 사이즈가 커질 수록 Pod OOM이 발생할 가능성이 크다보니 운영할 때는 번거로울 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">&quot;spark.kubernetes.local.dirs.tmpfs&quot;: &quot;true&quot;</code></pre></div>\n<br>\n<h3 id=\"2-spark-27499-support-mapping-sparklocaldir-to-hostpath-volume\" style=\"position:relative;\"><a href=\"#2-spark-27499-support-mapping-sparklocaldir-to-hostpath-volume\" aria-label=\"2 spark 27499 support mapping sparklocaldir to hostpath volume permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. [SPARK-27499] Support mapping spark.local.dir to hostPath volume</h3>\n<p>다음은 host에 마운트된 볼륨을 직접 사용하는 방법입니다. hostPath 볼륨을 spark.local.dir에 할당해서 셔플 과정에서의 디스크 성능을 향상시킬 수 있습니다. 다만 인스턴스에 SSD 또는 NVMe와 같은 볼륨을 추가로 마운트하는 경우에 더 좋은 효과를 볼 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">spec</span><span class=\"token punctuation\">:</span>\n  <span class=\"token punctuation\">...</span>\n  <span class=\"token key atrule\">volumes</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"spark-local-dir-1\"</span>\n      <span class=\"token key atrule\">hostPath</span><span class=\"token punctuation\">:</span>\n        <span class=\"token key atrule\">path</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"/tmp/spark-local-dir\"</span>\n  <span class=\"token key atrule\">executor</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">instances</span><span class=\"token punctuation\">:</span> <span class=\"token number\">10</span>\n    <span class=\"token key atrule\">cores</span><span class=\"token punctuation\">:</span> <span class=\"token number\">2</span>\n    <span class=\"token punctuation\">...</span>.\n    <span class=\"token key atrule\">volumeMounts</span><span class=\"token punctuation\">:</span>\n      <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"spark-local-dir-1\"</span></code></pre></div>\n<br>\n<h2 id=\"executor-pod-batch-관련-설정\" style=\"position:relative;\"><a href=\"#executor-pod-batch-%EA%B4%80%EB%A0%A8-%EC%84%A4%EC%A0%95\" aria-label=\"executor pod batch 관련 설정 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Executor Pod Batch 관련 설정</h2>\n<p>보통 무거운 작업은 executor 여러 개가 떠서 처리하는 경우가 많습니다.\nSpark on Kubernetes에는 executor pod을 생성할 때 <strong>batch size와 delay</strong>가 존재합니다.</p>\n<p>예를 들어 executor 10개를 띄울 때 기본 설정 값이 <code class=\"language-text\">batch size = 5, delay = 1</code>로 되어 있다면, executor pod 5개가 동시에 뜨고 1초 지연 이후에 5개가 추가로 생성됩니다.\n이 설정 값은 Kubernetes Scheduler와 driver pod의 부하를 고려해서 설정해주어야 합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">&quot;spark.kubernetes.allocation.batch.size&quot;: &quot;5&quot;\n&quot;spark.kubernetes.allocation.batch.delay&quot;: &quot;1s&quot;</code></pre></div>\n<br>\n<p>반면 아직 3.1 버전 기준으로 지원하지 않는 설정들은 아래와 같습니다.</p>\n<ul>\n<li>External Shuffle Service는 지원하지 않음</li>\n<li>Job Queue 없음 (Future Work)</li>\n</ul>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<ul>\n<li><a href=\"https://aws.amazon.com/ko/blogs/containers/optimizing-spark-performance-on-kubernetes\">https://aws.amazon.com/ko/blogs/containers/optimizing-spark-performance-on-kubernetes</a></li>\n<li><a href=\"https://aws.github.io/aws-emr-containers-best-practices\">https://aws.github.io/aws-emr-containers-best-practices</a></li>\n<li><a href=\"https://spark.apache.org/docs/latest/running-on-kubernetes.html\">https://spark.apache.org/docs/latest/running-on-kubernetes.html</a></li>\n</ul>","excerpt":"Spark 3.1 버전부터 Spark on Kubernetes가 GA로 변경되었습니다.\n이 글에서는 Spark on YARN…"}}},{"id":"1287610b-f42e-5418-85fd-7b80bac6222f","title":"여러 조직이 함께 사용하는 Airflow 만들기","slug":"airflow-multi-tenent-1","publishDate":"August 15, 2021","publishDateISO":"2021-08-15","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"5a118100-3719-5895-9fd0-bf3c690e91e8","childMarkdownRemark":{"id":"070cdd72-3f88-5a52-b46d-48a515c1b70a","timeToRead":6,"html":"<p>사내 데이터가 다양해지고 사용자가 많아지면 접근 제어와 권한 등 다양한 고민이 생기게 됩니다.\n이 글에서는 여러 조직이 함께 사용하는 Airflow를 만들 때 알아두면 좋은 내용들에 대해 정리해보려고 합니다.</p>\n<ul>\n<li><a href=\"https://swalloow.github.io/airflow-multi-tenent-1/#airflow-rbac\">Airflow RBAC</a></li>\n<li><a href=\"https://swalloow.github.io/airflow-multi-tenent-1/#dag-level-permissions\">DAG-Level Permissions</a></li>\n<li><a href=\"https://swalloow.github.io/airflow-multi-tenent-1/#connection-variable-access-control\">Connection, Variable Permissions</a></li>\n<li><a href=\"https://swalloow.github.io/airflow-multi-tenent-1/#cluster-policy\">Cluster Policy</a></li>\n</ul>\n<br>\n<h2 id=\"접근-제어가-필요한-경우\" style=\"position:relative;\"><a href=\"#%EC%A0%91%EA%B7%BC-%EC%A0%9C%EC%96%B4%EA%B0%80-%ED%95%84%EC%9A%94%ED%95%9C-%EA%B2%BD%EC%9A%B0\" aria-label=\"접근 제어가 필요한 경우 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>접근 제어가 필요한 경우</h2>\n<p>먼저 접근 제어는 모든 조직에 필요한 내용은 아닙니다. 다만 아래와 같은 경우에는 필요할 수 있습니다.</p>\n<ul>\n<li>다른 사람이 실행, 중지 권한을 가져서는 안될 만큼 중요한 DAG이 존재하는 경우</li>\n<li>민감한 데이터를 다루는 DAG이 존재하는 경우 (HR, 매출 데이터 등)</li>\n<li>팀에서 운영하는 DAG, Connection, Variable을 우리 팀만 보고 싶은 경우</li>\n</ul>\n<p>특히 Airflow Connections, Variable에는 DB 또는 클러스터 접속 정보, API키 등 민감한 정보가 많이 저장됩니다. 물론 마스킹 기능을 통해 UI에서 볼 수 없게 만들 수 있지만 id는 볼 수 있기 때문에 쉽게 값을 가져올 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> airflow<span class=\"token punctuation\">.</span>models <span class=\"token keyword\">import</span> Variable\n<span class=\"token keyword\">from</span> airflow<span class=\"token punctuation\">.</span>hooks<span class=\"token punctuation\">.</span>base_hook <span class=\"token keyword\">import</span> BaseHook\n\nvariable <span class=\"token operator\">=</span> Variable<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">\"myvar\"</span><span class=\"token punctuation\">)</span>\nconnection <span class=\"token operator\">=</span> BaseHook<span class=\"token punctuation\">.</span>get_connection<span class=\"token punctuation\">(</span><span class=\"token string\">\"myconn\"</span><span class=\"token punctuation\">)</span></code></pre></div>\n<br>\n<p>이 문제를 해결하기 위한 방법으로 조직마다 Airflow 환경을 분리하는 방법이 있습니다.\n하지만 이 방법은 운영과 모니터링이 힘들 수 있어 프라이빗 클라우드를 운영해야하는 상황이 아니라면 추천하지 않습니다. 두 번째 방법은 <strong>Airflow의 RBAC 기능</strong>을 활용하는 방법 입니다.</p>\n<br>\n<h2 id=\"airflow-rbac\" style=\"position:relative;\"><a href=\"#airflow-rbac\" aria-label=\"airflow rbac permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Airflow RBAC</h2>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=1tfr6zzzwrDkMIsTMJFOsNVzDwCchvzjo\" alt=\"security-model\"></p>\n<p>Airflow RBAC은 1.10 버전부터 추가되었고 2.0 버전부터 기본 설정으로 제공됩니다.\nAirflow의 Security Model은 위의 그림과 같은 구조를 따르고 있습니다.\n사용자는 User, Role로 구성되어 있습니다. 여기서 User는 하나 이상의 Role을 가질 수 있습니다.</p>\n<p>접근 권한은 <strong>Permission, ViewMenu</strong> 그리고 이를 조합한 <strong>PermissionView</strong>로 구성되어 있습니다.\nRole은 여러 개의 Permission을 가질 수 있습니다. PermissionView에 대한 예시는 아래와 같습니다.</p>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=1CsfVPlTQL_hqtY4a3_dXxz2kTAFjFqVo\" alt=\"permission-view\"></p>\n<p>Connections <strong>ViewMenu</strong> 와 can_edit <strong>Permission</strong> 을 조합하면 <code class=\"language-text\">can edit on Connections</code>라는 <strong>PermissionView</strong> 가 생성됩니다. 이 권한을 가진 사용자만 Connections UI에서 편집을 할 수 있습니다. 이러한 방식을 Airflow에서는 <strong>Resource-Based permissions</strong>라고 정의하고 있습니다.</p>\n<p>Airflow에는 다양한 리소스에 대해 권한이 이미 정의되어 있고, 기본적으로 Admin을 포함한 5개의 Role을 제공합니다. 조직마다 다른 Role을 가지고 싶은 경우, BaseRole을 정의하고 Copy Role을 통해 새로 만들면 편하게 운영할 수 있습니다.</p>\n<p>리소스 기반의 권한 제어도 필요하지만 이 기능에서는 DAGs 라는 단일 리소스로 보고 있기 때문에 DAG 단위로 접근 제어를 할 수 없습니다. 이를 지원하기 위해 2.0+ 버전부터 <strong>DAG-level Permission</strong>이 추가되었습니다.</p>\n<br>\n<h2 id=\"dag-level-permissions\" style=\"position:relative;\"><a href=\"#dag-level-permissions\" aria-label=\"dag level permissions permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>DAG-level Permissions</h2>\n<p>DAG-level Permission을 사용하면 다음과 같은 접근 제어를 할 수 있습니다.</p>\n<ul>\n<li>A 사용자는 A 사용자의 DAG만 볼 수 있음</li>\n<li>A 사용자는 B 사용자의 DAG을 볼 수 없음</li>\n<li>B 사용자가 A 사용자에게 권한을 부여하면 볼 수 있음</li>\n</ul>\n<p>DAG-level Permission은 앞서 얘기했던 리소스 기반 접근 제어에 <code class=\"language-text\">DAG:dag_id</code>라는 리소스를 추가하는 방식으로 구현되었습니다. 예를 들어 A 사용자와 B 사용자에게 example DAG에 대한 읽기 권한을 부여하고 싶은 경우, <code class=\"language-text\">DAG:example.can_read</code>라는 권한을 추가해주어야 합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">with</span> DAG<span class=\"token punctuation\">(</span>\n    <span class=\"token string\">\"example_dag\"</span><span class=\"token punctuation\">,</span>\n    default_args<span class=\"token operator\">=</span>default_args<span class=\"token punctuation\">,</span>\n    description<span class=\"token operator\">=</span><span class=\"token string\">\"example dags\"</span><span class=\"token punctuation\">,</span>\n    schedule_interval<span class=\"token operator\">=</span><span class=\"token string\">\"@once\"</span><span class=\"token punctuation\">,</span>\n    access_control<span class=\"token operator\">=</span><span class=\"token punctuation\">{</span><span class=\"token string\">\"myrole\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span><span class=\"token string\">\"can_dag_read\"</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    start_date<span class=\"token operator\">=</span>days_ago<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> dag<span class=\"token punctuation\">:</span></code></pre></div>\n<p>위와 같이 DAG을 정의하는 단계에서도 <code class=\"language-text\">access_control</code> 파라메터를 통해 DAG의 접근 권한을 정의해주어야 합니다. 이후 BaseRole에 DAGs 리소스 접근 권한을 제거하면 사용자는 오직 허용된 DAG에 대해서만 접근할 수 있게 됩니다.</p>\n<p>DAG access_control이 변경될 때마다 Role에 권한을 추가하는 일은 보통 번거로운 일이 아닙니다. 이를 위해 Airflow에서는 <code class=\"language-text\">airflow sync-perm</code> 이라는 명령어를 제공합니다. 해당 명령어를 실행하면 모든 DAG에 정의된 권한이 연관된 Role에 반영됩니다. Permission Sync 사이드카 컨테이너를 webserver에 배포하면 이 과정을 자동화할 수 있습니다. 관련 내용은 <a href=\"https://swalloow.github.io/airflow-sidecar/#2-permission-sync-container\">사이드카 컨테이너로 Airflow 기능 확장하기</a> 글을 참고해주시면 됩니다.</p>\n<br>\n<h2 id=\"connection-variable-access-control\" style=\"position:relative;\"><a href=\"#connection-variable-access-control\" aria-label=\"connection variable access control permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Connection, Variable Access Control</h2>\n<p>앞서 DAG-level Permission을 보셨다면 느끼셨겠지만 Connection, Variable 또한 각 변수에 대해 접근 제어를 할 수 없고 관련 기능도 없습니다. 하지만 <strong>Alternative Secrets Backend</strong> 라는 기능을 통해 Custom Backend 클래스를 만들면 접근 제어를 구현할 수 있습니다.</p>\n<br>\n<h3 id=\"alternative-secrets-backend\" style=\"position:relative;\"><a href=\"#alternative-secrets-backend\" aria-label=\"alternative secrets backend permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Alternative Secrets Backend</h3>\n<p>원래 Connection, Variable은 Meta DB에 저장됩니다. 하지만 이 기능을 사용하면 AWS Parameter Store, Vault 등 외부 자원을 저장소로 사용할 수 있습니다. airflow에 구현된 코드는 아래와 같습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token decorator annotation punctuation\">@classmethod</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">get_connection_from_secrets</span><span class=\"token punctuation\">(</span>cls<span class=\"token punctuation\">,</span> conn_id<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token string\">'Connection'</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    Get connection by conn_id.\n    :param conn_id: connection id\n    :return: connection\n    \"\"\"</span>\n    <span class=\"token keyword\">for</span> secrets_backend <span class=\"token keyword\">in</span> ensure_secrets_loaded<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        conn <span class=\"token operator\">=</span> secrets_backend<span class=\"token punctuation\">.</span>get_connection<span class=\"token punctuation\">(</span>conn_id<span class=\"token operator\">=</span>conn_id<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> conn<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">return</span> conn\n    <span class=\"token keyword\">raise</span> AirflowNotFoundException<span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"The conn_id `</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>conn_id<span class=\"token punctuation\">}</span></span><span class=\"token string\">` not defined\"</span></span><span class=\"token punctuation\">)</span></code></pre></div>\n<br>\n<p><code class=\"language-text\">BaseHook</code>에서 호출하는 <code class=\"language-text\">get_connection_from_secrets</code> 메서드는 여러 backend로부터 conn_id에 대한 값을 받아오고 리턴합니다. 즉 기존 Meta DB를 사용하고 있더라도 유지하면서 새로운 backend와 호환 가능합니다.</p>\n<p>AWS Parameter Store는 Path 단위로 키를 다르게 값을 저장할 수 있습니다.\n이 점을 활용해서 id 상위 경로로 role을 지정한다면 role 단위로 접근 제어가 가능해집니다.\n접근 제어를 위한 AWS Parameter Store에 저장되는 규칙은 아래와 같습니다.\nAirflow 환경, 역할 별로 구분해서 저장합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">secrets</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">backend</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"airflow...SystemsManagerParameterStoreBackend\"</span>\n    <span class=\"token key atrule\">backend_kwargs</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token key atrule\">\"connections_prefix\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"/airflow/prod/connections\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token key atrule\">\"variables_prefix\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"/airflow/prod/variables\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token key atrule\">\"profile_name\"</span><span class=\"token punctuation\">:</span> <span class=\"token null important\">null</span>\n    <span class=\"token punctuation\">}</span></code></pre></div>\n<ul>\n<li>/airflow/prod/connections/myrole/connection_id</li>\n<li>/airflow/prod/variables/myrole/variable_id</li>\n</ul>\n<p>기본으로 제공하는 Connections, Variables UI는 세부 경로로 값을 가져오는게 아니기 때문에 secrets backend 설정과 함께 Custom UI Plugin이 필요합니다.</p>\n<br>\n<h2 id=\"access-control-ui-plugin\" style=\"position:relative;\"><a href=\"#access-control-ui-plugin\" aria-label=\"access control ui plugin permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Access Control UI Plugin</h2>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=1QhjXiETQQLqnLo3iJbmcPMtfGcTXRSgV\" alt=\"acl-plugin\"></p>\n<p>플러그인의 역할은 다음과 같습니다. myrole이라는 Airflow Role을 가진 사용자가 Connections UI 페이지에 접근하면 Custom Backend를 통해 Paramter Store의 <code class=\"language-text\">/airflow/prod/connections/myrole</code> 경로 하위의 값들을 받아오도록 요청해야 합니다. list 뿐만 아니라 create, edit, delete에 대한 기능도 추가해주어야 합니다.</p>\n<p>이를 위해 UI 플러그인에서 현재 접속한 사용자의 Role 이름을 받아올 수 있어야 합니다. 이 때 flask의 global session을 활용하면 쉽게 받아올 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> flask <span class=\"token keyword\">import</span> g\n\nrole_name <span class=\"token operator\">=</span> g<span class=\"token punctuation\">.</span>user<span class=\"token punctuation\">.</span>roles<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>name</code></pre></div>\n<p>이제 UI에서 추가, 편집, 삭제 시 Secrets Backend를 통해 AWS Parameter Store에 반영됩니다. 오직 권한을 가진 사용자만이 DAG, Connection, Variable에 접근할 수 있습니다.</p>\n<br>\n<h2 id=\"cluster-policy\" style=\"position:relative;\"><a href=\"#cluster-policy\" aria-label=\"cluster policy permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Cluster Policy</h2>\n<p>DAG 작성에 대한 가이드가 있더라도 모두 만족하는지 체크하는건 상당히 번거로운 일 입니다.\nAirflow 2.0+에서는 Cluster Policy를 통해 클러스터 전체에서 DAG 또는 task에 대한 정책을 정의하고 강제하도록 설정할 수 있습니다. 예를 들면 다음과 같은 정책을 정의할 수 있습니다.</p>\n<ul>\n<li>모든 DAG에는 적어도 하나의 태그를 달아야 한다</li>\n<li>특정 task의 timeout은 48시간을 넘을 수 없다</li>\n</ul>\n<p><code class=\"language-text\">airflow_local_settings.py</code> 파일을 만들고 정의하면 적용할 수 있습니다.\n태그를 강제하는 정책 예시는 아래와 같습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">dag_policy</span><span class=\"token punctuation\">(</span>dag<span class=\"token punctuation\">:</span> DAG<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"Ensure that DAG has at least one tag\"\"\"</span>\n    <span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> dag<span class=\"token punctuation\">.</span>tags<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">raise</span> AirflowClusterPolicyViolation<span class=\"token punctuation\">(</span>\n            <span class=\"token string-interpolation\"><span class=\"token string\">f\"DAG </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>dag<span class=\"token punctuation\">.</span>dag_id<span class=\"token punctuation\">}</span></span><span class=\"token string\"> has no tags. At least one tag required. File path: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>dag<span class=\"token punctuation\">.</span>filepath<span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span>\n        <span class=\"token punctuation\">)</span></code></pre></div>\n<p>위 정책이 적용된 클러스터에 태그가 없는 DAG을 배포하는 경우, <code class=\"language-text\">AirflowClusterPolicyViolation</code> 오류가 발생하기 때문에 DAG을 등록할 수 없습니다.\n자세한 내용은 <a href=\"https://airflow.apache.org/docs/apache-airflow/stable/concepts/cluster-policies.html\">공식문서</a>를 참고하시면 됩니다.</p>\n<br>\n<h2 id=\"정리\" style=\"position:relative;\"><a href=\"#%EC%A0%95%EB%A6%AC\" aria-label=\"정리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>정리</h2>\n<p>최근 Airflow Summit에서 Multi-Tenent와 관련된 영상들이 많이 올라와서 함께 참고하면 도움이 될 것 같습니다.</p>\n<ul>\n<li><a href=\"https://airflow.apache.org/docs/apache-airflow/stable/security/access-control.html\">https://airflow.apache.org/docs/apache-airflow/stable/security/access-control.html</a></li>\n<li><a href=\"https://eng.lyft.com/securing-apache-airflow-ui-with-dag-level-access-a7bc649a2821\">https://eng.lyft.com/securing-apache-airflow-ui-with-dag-level-access-a7bc649a2821</a></li>\n<li><a href=\"https://airflow.apache.org/docs/apache-airflow/stable/security/secrets/secrets-backend/index.html\">https://airflow.apache.org/docs/apache-airflow/stable/security/secrets/secrets-backend/index.html</a></li>\n</ul>","excerpt":"…"}}},{"id":"8a8dd949-d905-5883-8781-94ee011c3522","title":"Airflow on Kubernetes (1)","slug":"airflow-on-kubernetes-1","publishDate":"June 05, 2020","publishDateISO":"2020-06-05","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"c12fefe6-aab9-599e-b87d-9d996a4e0bb5","childMarkdownRemark":{"id":"a96aecc2-d61d-5567-9728-1f9760a46ebc","timeToRead":5,"html":"<p>최근 Airflow에는 Kubernetes 지원을 위해 다양한 컴포넌트들이 추가되고 있습니다. 이러한 변화의 흐름에 따라 Airflow를 Kubernetes 위에 배포하고 운영하는 방법에 대해 글을 작성해보고자 합니다. 이 글은 시리즈로 연재됩니다.</p>\n<ul>\n<li><a href=\"https://swalloow.github.io/airflow-on-kubernetes-1\">Airflow on Kubernetes (1): CeleryExecutor</a></li>\n<li><a href=\"https://swalloow.github.io/airflow-on-kubernetes-2\">Airflow on Kubernetes (2): KubernetesExecutor</a></li>\n<li><a href=\"https://swalloow.github.io/airflow-on-kubernetes-3\">Airflow on Kubernetes (3): Airflow Logging, Monitoring</a></li>\n</ul>\n<br>\n<h2 id=\"airflow-on-kubernetes\" style=\"position:relative;\"><a href=\"#airflow-on-kubernetes\" aria-label=\"airflow on kubernetes permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Airflow on Kubernetes</h2>\n<p>Airflow를 Kubernetes 인프라 위에서 운영하는 방법은 크게 두 가지로 나눌 수 있습니다.\n이 글에서 소개할 방법은 <strong>CeleryExecutor의 각 모듈을 Kubernetes 위에 올리는 방식</strong>입니다. 기존에 운영하던 형태와 유사하기 때문에 쉽게 적용할 수 있으나 Celery에 대한 의존성이 강하다보니 완전히 Cloud Native한 형태는 아닙니다. 아키텍쳐는 가장 많이 사용하는 <a href=\"https://github.com/helm/charts/blob/master/stable/airflow\">stable/airflow</a> Helm Chart를 참고하였습니다. 이제 몇 가지 컴포넌트 설정과 함께 자세히 알아보겠습니다.</p>\n<br>\n<h2 id=\"config\" style=\"position:relative;\"><a href=\"#config\" aria-label=\"config permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Config</h2>\n<p>Airflow는 <code class=\"language-text\">airflow.cfg</code> 파일 또는 <code class=\"language-text\">AIRFLOW__[SECTOR]__[VARIABLES]</code> 환경 변수를 통해 각 컴포넌트의 설정을 관리할 수 있었습니다. Helm Chart에서는 <code class=\"language-text\">values.yaml</code>의 config 필드를 통해 설정을 관리할 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">config</span><span class=\"token punctuation\">:</span>\n  <span class=\"token comment\"># CORE</span>\n  <span class=\"token key atrule\">AIRFLOW__CORE__DEFAULT_TIMEZONE</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"Asia/Seoul\"</span>\n  <span class=\"token key atrule\">AIRFLOW__CORE__PARALLELISM</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"32\"</span>\n  <span class=\"token key atrule\">AIRFLOW__CORE__DAG_CONCURRENCY</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"16\"</span>\n  <span class=\"token key atrule\">AIRFLOW__CORE__MAX_ACTIVE_RUNS_PER_DAG</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"16\"</span>\n\n  <span class=\"token comment\"># WEBSERVER</span>\n  <span class=\"token key atrule\">AIRFLOW__WEBSERVER__DEFAULT_UI_TIMEZONE</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"Asia/Seoul\"</span>\n  <span class=\"token key atrule\">AIRFLOW__WEBSERVER__WORKER_REFRESH_INTERVAL</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"60\"</span>\n\n  <span class=\"token comment\"># CELERY</span>\n  <span class=\"token key atrule\">AIRFLOW__CELERY__WORKER_CONCURRENCY</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"16\"</span>\n\n  <span class=\"token comment\"># SCHEDULER</span>\n  <span class=\"token key atrule\">AIRFLOW__SCHEDULER__SCHEDULER_HEARTBEAT_SEC</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"30\"</span>\n  <span class=\"token key atrule\">AIRFLOW__SCHEDULER__SCHEDULER_HEALTH_CHECK_THRESHOLD</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"120\"</span>\n  <span class=\"token key atrule\">AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"30\"</span>\n  <span class=\"token key atrule\">AIRFLOW__SCHEDULER__RUN_DURATION</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"10800\"</span>\n  <span class=\"token key atrule\">AIRFLOW__SCHEDULER__MAX_THREADS</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"2\"</span></code></pre></div>\n<br>\n<p>위에 정의한 설정 변수들은 Airflow의 성능과 관련되어 있기 때문에 각자 할당된 리소스에 맞게 설정해주셔야 합니다. 자세한 내용은 <a href=\"https://airflow.apache.org/docs/stable/faq.html#how-can-my-airflow-dag-run-faster\">공식문서 링크</a>를 참고하시기 바랍니다. 위와 같은 방식으로 DAG에서 활용하는 connection, variables도 정의할 수 있습니다.</p>\n<br>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token comment\"># config.yaml</span>\n<span class=\"token key atrule\">apiVersion</span><span class=\"token punctuation\">:</span> v1\n<span class=\"token key atrule\">kind</span><span class=\"token punctuation\">:</span> ConfigMap\n<span class=\"token key atrule\">metadata</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> airflow<span class=\"token punctuation\">-</span>webserver<span class=\"token punctuation\">-</span>config\n  <span class=\"token key atrule\">namespace</span><span class=\"token punctuation\">:</span> airflow\n<span class=\"token key atrule\">data</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">webserver_config.py</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">|</span><span class=\"token scalar string\">\n    APP_THEME = \"flatly.css\"</span>\n\n<span class=\"token punctuation\">---</span>\n<span class=\"token comment\"># values.yaml</span>\n<span class=\"token key atrule\">extraConfigmapMounts</span><span class=\"token punctuation\">:</span>\n  <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> airflow<span class=\"token punctuation\">-</span>webserver<span class=\"token punctuation\">-</span>config\n    <span class=\"token key atrule\">mountPath</span><span class=\"token punctuation\">:</span> /opt/airflow/webserver_config.py\n    <span class=\"token key atrule\">configMap</span><span class=\"token punctuation\">:</span> airflow<span class=\"token punctuation\">-</span>webserver<span class=\"token punctuation\">-</span>config\n    <span class=\"token key atrule\">readOnly</span><span class=\"token punctuation\">:</span> <span class=\"token boolean important\">true</span>\n    <span class=\"token key atrule\">subPath</span><span class=\"token punctuation\">:</span> webserver_config.py</code></pre></div>\n<br>\n<p>위와 같이 <code class=\"language-text\">ConfigMap</code>이나 <code class=\"language-text\">Secret</code>을 따로 만들고 참조하도록 연결하는 방식도 가능합니다. 특히 Airflow 1.10의 RBAC을 사용한다면 <code class=\"language-text\">webserver_config.py</code>를 통해 <code class=\"language-text\">APP_THEME</code>를 변경해줄 수 있는데 이런 경우에 <strong>extraConfigmap</strong>을 통해 적용할 수 있습니다.</p>\n<br>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=1RzSP5YX2EyH3xDnk0VM4wB57lsn55j1o\" alt=\"airflow-webserver\"></p>\n<br>\n<p>제가 주로 사용하는 테마는 <code class=\"language-text\">flatly.css</code>에 <code class=\"language-text\">NAVBAR #18bc9c</code> 컬러 조합입니다. 적용된 화면은 위와 같습니다. (+ 태그 기능도 1.10.10 버전에 추가되었습니다)</p>\n<br>\n<h2 id=\"celery-worker\" style=\"position:relative;\"><a href=\"#celery-worker\" aria-label=\"celery worker permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Celery Worker</h2>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=1N81eEP8AT1ddwCDtHnDKblgwkZsc2FFB\" alt=\"celery\"></p>\n<br>\n<p>CeleryExecutor에서 worker는 실제 task를 수행을 담당하는 컴포넌트입니다. K8S에서는 celery worker가 StatefulSet으로 배포됩니다. 기존에는 worker가 <code class=\"language-text\">AutoScalingGroup</code> 등을 통해 인스턴스가 자동 확장되도록 구성했다면, K8S에서는 <code class=\"language-text\">HorizontalPodAutoscaler</code>를 통해 Pod 단위로 확장 가능하도록 구성할 수 있습니다.</p>\n<br>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">workers</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">replicas</span><span class=\"token punctuation\">:</span> <span class=\"token number\">1</span>\n\n  <span class=\"token key atrule\">resources</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">requests</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">memory</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"2Gi\"</span>\n\n  <span class=\"token key atrule\">autoscaling</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">enabled</span><span class=\"token punctuation\">:</span> <span class=\"token boolean important\">true</span>\n    <span class=\"token key atrule\">maxReplicas</span><span class=\"token punctuation\">:</span> <span class=\"token number\">16</span>\n    <span class=\"token key atrule\">metrics</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">type</span><span class=\"token punctuation\">:</span> Resource\n      <span class=\"token key atrule\">resource</span><span class=\"token punctuation\">:</span>\n        <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> memory\n        <span class=\"token key atrule\">target</span><span class=\"token punctuation\">:</span>\n          <span class=\"token key atrule\">type</span><span class=\"token punctuation\">:</span> Utilization\n          <span class=\"token key atrule\">averageUtilization</span><span class=\"token punctuation\">:</span> <span class=\"token number\">80</span></code></pre></div>\n<br>\n<h2 id=\"airflow-ingress\" style=\"position:relative;\"><a href=\"#airflow-ingress\" aria-label=\"airflow ingress permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Airflow Ingress</h2>\n<p>보통 K8S 클러스터에 Ingress Controller를 설정하고 path를 통해 여러 서비스에 접속하는 경우가 많습니다. Airflow Chart 역시 Webserver와 Flower UI에 대한 ingress를 지원합니다. 저는 nginx-ingress controller를 사용해서 진행해보겠습니다. 아래 예시는 각자의 ingress-controller 설정에 맞게 바꾸시면 됩니다.</p>\n<br>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">web</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">service</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">annotations</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span><span class=\"token punctuation\">}</span>\n    <span class=\"token key atrule\">type</span><span class=\"token punctuation\">:</span> ClusterIP\n    <span class=\"token key atrule\">externalPort</span><span class=\"token punctuation\">:</span> <span class=\"token number\">8080</span>\n    <span class=\"token key atrule\">loadBalancerIP</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"\"</span>\n    <span class=\"token key atrule\">loadBalancerSourceRanges</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n\n<span class=\"token punctuation\">...</span>\n\n<span class=\"token key atrule\">ingress</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">enabled</span><span class=\"token punctuation\">:</span> <span class=\"token boolean important\">true</span>\n  <span class=\"token key atrule\">web</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">annotations</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">kubernetes.io/ingress.class</span><span class=\"token punctuation\">:</span> nginx\n      <span class=\"token key atrule\">ingress.kubernetes.io/rewrite-target</span><span class=\"token punctuation\">:</span> /\n      <span class=\"token key atrule\">nginx.ingress.kubernetes.io/ssl-redirect</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"false\"</span>\n\n    <span class=\"token key atrule\">path</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"/airflow\"</span>\n    <span class=\"token key atrule\">host</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"myloadbalancer-domain.com\"</span></code></pre></div>\n<p>예를 들어 web path에 <code class=\"language-text\">/airflow</code> 라고 설정하셨다면, UI 접속 주소는 <code class=\"language-text\">myloadbalancer-domain.com/airflow</code>가 됩니다. flower도 위와 동일한 방식으로 설정하시면 됩니다.</p>\n<br>\n<h2 id=\"airflow-auth\" style=\"position:relative;\"><a href=\"#airflow-auth\" aria-label=\"airflow auth permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Airflow Auth</h2>\n<p>Airflow 에서는 다양한 인증 방식을 지원하지만 여기에서는 가장 기본이 되는 Password Auth 방식으로 배포하겠습니다. 새로 추가된 RBAC 설정도 함께 추가해보겠습니다. 먼저 <code class=\"language-text\">extraPipPackages</code> 설정을 통해 의존성 패키지를 설치해주고 상단에 환경 변수도 추가해줍니다.</p>\n<br>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">config</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">AIRFLOW__WEBSERVER__RBAC</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"True\"</span>\n  <span class=\"token key atrule\">AIRFLOW__WEBSERVER__AUTHENTICATE</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"True\"</span>\n  <span class=\"token key atrule\">AIRFLOW__WEBSERVER__AUTH_BACKEND</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"airflow.contrib.auth.backends.password_auth\"</span>\n\n<span class=\"token punctuation\">...</span>\n\n<span class=\"token key atrule\">web</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">extraPipPackages</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> <span class=\"token string\">\"flask-bcrypt\"</span>\n    <span class=\"token punctuation\">-</span> <span class=\"token string\">\"flask-oauthlib>=0.9\"</span></code></pre></div>\n<br>\n<p>이제 로그인할 사용자를 추가해주어야 합니다. Scheduler Pod의 Bash에서 create_user 명령어를 통해 생성해주시면 됩니다.</p>\n<br>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ kubectl exec \\\n  -it \\\n  --namespace airflow \\\n  --container airflow-scheduler \\\n  Deployment/airflow-scheduler \\\n  /bin/bash\n\n$ airflow create_user \\\n--username=admin \\\n--email=test@example.com \\\n--password=mypassword \\\n--role=Admin \\\n--firstname=test \\\n--lastname=park</code></pre></div>\n<br>\n<h2 id=\"airflow-iam-role\" style=\"position:relative;\"><a href=\"#airflow-iam-role\" aria-label=\"airflow iam role permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Airflow IAM Role</h2>\n<p>AWS EKS와 같은 클라우드 서비스 위에 배포한다면 각 컴포넌트의 세부 권한을 지정해주어야 합니다. 만일 Pod에 IAM Role을 할당하지 않는다면 Airflow는 클러스터의 기본 IAM Role인 EKS worker 설정을 따르게 됩니다. 따라서 보안을 신경쓰셔야 한다면 설정하는 것이 바람직합니다. 특히 Airflow에서 다른 AWS Managed Service(EMR, Athena, Lambda)와 연계하는 DAG이 존재하신다면 필수적입니다.</p>\n<br>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">serviceAccount</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">create</span><span class=\"token punctuation\">:</span> <span class=\"token boolean important\">true</span>\n  <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"airflow\"</span>\n  <span class=\"token key atrule\">annotations</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">eks.amazonaws.com/role-arn</span><span class=\"token punctuation\">:</span> arn<span class=\"token punctuation\">:</span>aws<span class=\"token punctuation\">:</span>iam<span class=\"token punctuation\">:</span><span class=\"token punctuation\">:</span>123456789999<span class=\"token punctuation\">:</span>role/airflow\n\n<span class=\"token punctuation\">...</span>\n\n<span class=\"token key atrule\">securityContext</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">fsGroup</span><span class=\"token punctuation\">:</span> <span class=\"token number\">1000</span></code></pre></div>\n<br>\n<p><code class=\"language-text\">values.yaml</code>에는 포함되어 있지 않지만 각 컴포넌트마다 <code class=\"language-text\">securityContext</code>를 지정해주셔야 IAM Role을 매핑할 수 있습니다. <code class=\"language-text\">IAM Role for Service Account</code>가 내부적으로 K8S TokenProjection을 사용하기 때문에 설정을 안하면 토큰을 읽을 수 없다는 오류가 발생합니다. IAM Role 설정에 대한 자세한 내용은 <a href=\"https://docs.aws.amazon.com/ko_kr/eks/latest/userguide/iam-roles-for-service-accounts-technical-overview.html\">EKS 공식 문서</a>를 참고하시기 바랍니다.</p>\n<br>\n<h2 id=\"dags\" style=\"position:relative;\"><a href=\"#dags\" aria-label=\"dags permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>DAGs</h2>\n<p>Airflow는 Scheduler가 DAG 파일을 주기적으로 동기화하며 문법적 오류가 없는지 체크하는 역할을 수행합니다. 단일 노드에서는 로컬에 있는 DAG 파일을 읽으면 되지만 K8S에서는 worker pod가 여러 노드에 걸쳐있기 때문에 모두 같은 DAG 파일을 바라보도록 하는 동기화 설정이 필요합니다. Helm Chart에서는 이를 지원하기 위해 두 가지 옵션을 제공합니다.</p>\n<br>\n<p><strong>1. Git-Sync Sidecar</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token comment\"># git-sync sidecar</span>\n<span class=\"token key atrule\">dags</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">git</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">url</span><span class=\"token punctuation\">:</span> ssh<span class=\"token punctuation\">:</span>//git@repo.example.com/example.git\n    <span class=\"token key atrule\">repoHost</span><span class=\"token punctuation\">:</span> repo.example.com\n    <span class=\"token key atrule\">secret</span><span class=\"token punctuation\">:</span> airflow<span class=\"token punctuation\">-</span>git<span class=\"token punctuation\">-</span>keys\n    <span class=\"token key atrule\">privateKeyName</span><span class=\"token punctuation\">:</span> id_rsa\n\n    <span class=\"token key atrule\">gitSync</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">enabled</span><span class=\"token punctuation\">:</span> <span class=\"token boolean important\">true</span>\n      <span class=\"token key atrule\">refreshTime</span><span class=\"token punctuation\">:</span> <span class=\"token number\">60</span></code></pre></div>\n<br>\n<p>첫 번째 방식은 <strong>git-sync 사이드카 컨테이너</strong>를 활용하는 방법입니다. 간단히 말하자면 주기적으로 외부 저장소를 당겨오는 방식으로 git 인증이 필요합니다. 사이드카 패턴이 생소하시다면 이전에 작성한 <a href=\"https://swalloow.github.io/container-patterns/#sidecar-pattern\">분산 컨테이너에서의 디자인 패턴</a> 글을 참고하시기 바랍니다.</p>\n<br>\n<p><strong>2. Shared Persistent Volume</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token comment\"># EFS PV, PVC</span>\n<span class=\"token key atrule\">apiVersion</span><span class=\"token punctuation\">:</span> v1\n<span class=\"token key atrule\">kind</span><span class=\"token punctuation\">:</span> PersistentVolume\n<span class=\"token key atrule\">metadata</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> airflow<span class=\"token punctuation\">-</span>dags\n  <span class=\"token key atrule\">namespace</span><span class=\"token punctuation\">:</span> airflow\n  <span class=\"token key atrule\">labels</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> airflow<span class=\"token punctuation\">-</span>dags\n    <span class=\"token key atrule\">storage</span><span class=\"token punctuation\">:</span> airflow\n<span class=\"token key atrule\">spec</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">capacity</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">storage</span><span class=\"token punctuation\">:</span> 20Gi\n  <span class=\"token key atrule\">accessModes</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> ReadWriteMany\n  <span class=\"token key atrule\">nfs</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">server</span><span class=\"token punctuation\">:</span> 0.0.0.0 &lt;<span class=\"token punctuation\">-</span> EFS endpoint\n    <span class=\"token key atrule\">path</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"/airflow\"</span>\n\n<span class=\"token punctuation\">---</span>\n<span class=\"token key atrule\">apiVersion</span><span class=\"token punctuation\">:</span> v1\n<span class=\"token key atrule\">kind</span><span class=\"token punctuation\">:</span> PersistentVolumeClaim\n<span class=\"token key atrule\">metadata</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> airflow<span class=\"token punctuation\">-</span>dags\n  <span class=\"token key atrule\">namespace</span><span class=\"token punctuation\">:</span> airflow\n  <span class=\"token key atrule\">labels</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">storage</span><span class=\"token punctuation\">:</span> airflow\n<span class=\"token key atrule\">spec</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">storageClassName</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"\"</span>\n  <span class=\"token key atrule\">accessModes</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> ReadWriteMany\n  <span class=\"token key atrule\">resources</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">requests</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">storage</span><span class=\"token punctuation\">:</span> 10Gi\n  <span class=\"token key atrule\">selector</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">matchLabels</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> airflow<span class=\"token punctuation\">-</span>dags\n\n<span class=\"token punctuation\">---</span>\n<span class=\"token comment\"># shared persistent volume</span>\n<span class=\"token key atrule\">dags</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">persistence</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">enabled</span><span class=\"token punctuation\">:</span> <span class=\"token boolean important\">true</span>\n    <span class=\"token key atrule\">existingClaim</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"airflow-dags\"</span>\n    <span class=\"token key atrule\">accessMode</span><span class=\"token punctuation\">:</span> ReadWriteMany\n    <span class=\"token key atrule\">size</span><span class=\"token punctuation\">:</span> 1Gi</code></pre></div>\n<br>\n<p>두 번째 방식은 <strong>EFS와 같은 공유 파일시스템을 활용한 방법</strong>입니다. EFS의 특정 경로에 DAG 파일을 저장하고 마운트를 통해 모든 Pod이 같은 경로를 바라보도록 설정하는 방식입니다. 저는 EFS PV와 PVC를 먼저 추가한다음 existingClaim을 통해 참조하도록 설정해주었습니다.</p>\n<br>\n<h2 id=\"deploy\" style=\"position:relative;\"><a href=\"#deploy\" aria-label=\"deploy permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Deploy</h2>\n<p>필요한 설정을 완료했다면 배포는 아래 Helm 명령어를 통해 할 수 있습니다. 가능하다면 데이터베이스는 external로 사용하는 방법을 추천드립니다. DB 암호는 secret을 통해 생성하고 참조하도록 설정해주시면 됩니다.</p>\n<br>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">helm install stable/airflow \\\n--version 7.1.1 \\\n--namespace airflow \\\n--name airflow \\\n-f ./values.yaml</code></pre></div>\n<br>\n<p>배포 이후에 namespace를 보면 아래와 같은 Pod이 존재하는걸 확인할 수 있습니다.</p>\n<br>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=1Ep52ZE0lhsbp2R3FOGlC3uFyq7CYPu1D\" alt=\"airflow-po\"></p>\n<br>\n<p>이 글에서 언급한 설정은 FIXME 주석을 해두었으니 궁금하신분들은 <a href=\"https://github.com/Swalloow/airflow-helm\">https://github.com/Swalloow/airflow-helm</a> 저장소를 확인하시기 바랍니다.</p>","excerpt":"최근 Airflow에는 Kubernetes 지원을 위해 다양한 컴포넌트들이 추가되고 있습니다. 이러한 변화의 흐름에 따라 Airflow…"}}},{"id":"c97edb01-df3d-53e4-bc7a-47e2e5d6feb2","title":"사이드카 컨테이너로 Airflow 기능 확장하기","slug":"airflow-sidecar","publishDate":"August 01, 2021","publishDateISO":"2021-08-01","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"943e8b84-7c33-5c3d-9d5a-ac780a6c7746","childMarkdownRemark":{"id":"9370d60d-b64f-5b01-9e00-d82e32fe4218","timeToRead":4,"html":"<p>Airflow 2.1 버전부터 공식 Helm Chart가 정식 릴리즈 되었습니다.\n오늘은 공식 차트에서 사용할 수 있는 기능 중 <code class=\"language-text\">extraContainers</code> 옵션을 활용하는 방법을 3가지 예시를 통해 소개해보려 합니다.</p>\n<ul>\n<li><a href=\"https://swalloow.github.io/airflow-sidecar/#1-s3-sync-container\">S3 Sync Container</a></li>\n<li><a href=\"https://swalloow.github.io/airflow-sidecar/#2-permission-sync-container\">Permission Sync Container</a></li>\n<li><a href=\"https://swalloow.github.io/airflow-sidecar/#3-kerberos-container\">Kerberos Container</a></li>\n</ul>\n<br>\n<h2 id=\"sidecar-container\" style=\"position:relative;\"><a href=\"#sidecar-container\" aria-label=\"sidecar container permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Sidecar Container</h2>\n<p>분산 컨테이너 환경에서 사이드카 패턴이란 Pod 안에서 두 개 이상의 컨테이너로 구성되어 있는 형태를 말합니다. 컨테이너들은 서로 네트워크 또는 볼륨을 공유할 수 있습니다. 사이드카 컨테이너를 활용하면 다음과 장점을 가져갈 수 있습니다.</p>\n<p><strong>기존 로직의 변경 없이 새로운 기능 추가</strong>:\n가끔 일부 기능 추가를 위해 Airflow 저장소 코드를 수정하는 경우가 생길 수 있습니다.\n하지만 이렇게 한번 수정하고 나면 이후에 버전 업데이트할 때마다 새로운 버전 브랜치와 병합해야 하는 번거로움이 생깁니다. 만약 원하는 기능이 사이드카 컨테이너를 활용할 수 있다면 기존 저장소의 변경 없이 새로운 기능을 추가할 수 있습니다.</p>\n<p><strong>컨테이너 재사용</strong>:\n사내에서 개발 환경에 따라 또는 접근 권한에 따라 Airflow 인스턴스를 여러 개 구성하고 운영하는 경우가 많습니다. 사이드카 컨테이너로 구성한 기능은 재사용이 가능하기 때문에 새로 배포한 Airflow 인스턴스에 쉽게 적용할 수 있습니다.</p>\n<br>\n<h2 id=\"airflow-extracontainers\" style=\"position:relative;\"><a href=\"#airflow-extracontainers\" aria-label=\"airflow extracontainers permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Airflow extraContainers</h2>\n<p>Airflow Helm Chart에서는 <code class=\"language-text\">extraContainers</code> 옵션을 통해 사이드카 컨테이너를 scheduler, webserver, worker에 정의할 수 있습니다. <del>제가 기여한 옵션입니다!</del> (<a href=\"https://github.com/apache/airflow/pull/13735\">https://github.com/apache/airflow/pull/13735</a>)</p>\n<p>이제 몇 가지 예시를 통해 어떻게 활용할 수 있는지 알아보겠습니다.</p>\n<br>\n<h2 id=\"1-s3-sync-container\" style=\"position:relative;\"><a href=\"#1-s3-sync-container\" aria-label=\"1 s3 sync container permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. S3 Sync Container</h2>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=1Hh0f6l9jDLHHEaH5OyGU7Nhe5nUnnJU1\"></p>\n<p>AWS MWAA 처럼 <strong>S3를 DAG 저장소로 활용하고 싶은 경우</strong>에 S3 Sync 사이드카 컨테이너를 통해 구현할 수 있습니다. S3 Sync 사이드카 컨테이너는 S3 버킷에 올라간 파일을 DAG 경로에 주기적으로 동기화하는 컨테이너입니다. 만약 DAG Serialiaztion 옵션이 활성화되어 있다면 scheduler에만 정의하면 됩니다.</p>\n<p>예시는 아래와 같습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">scheduler</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">extraContainers</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> s3<span class=\"token punctuation\">-</span>sync\n      <span class=\"token key atrule\">image</span><span class=\"token punctuation\">:</span> myrepository/s3<span class=\"token punctuation\">-</span>sync<span class=\"token punctuation\">:</span>latest\n      <span class=\"token key atrule\">imagePullPolicy</span><span class=\"token punctuation\">:</span> Always\n      <span class=\"token key atrule\">volumeMounts</span><span class=\"token punctuation\">:</span>\n        <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> dags\n          <span class=\"token key atrule\">mountPath</span><span class=\"token punctuation\">:</span> /opt/airflow/dags\n      <span class=\"token key atrule\">env</span><span class=\"token punctuation\">:</span>\n        <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> AWS_BUCKET\n          <span class=\"token key atrule\">value</span><span class=\"token punctuation\">:</span> airflow<span class=\"token punctuation\">-</span>src\n        <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> KEY_PATH\n          <span class=\"token key atrule\">value</span><span class=\"token punctuation\">:</span> dags\n        <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> DEST_PATH\n          <span class=\"token key atrule\">value</span><span class=\"token punctuation\">:</span> /opt/airflow/dags\n        <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> INTERVAL\n          <span class=\"token key atrule\">value</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"10\"</span></code></pre></div>\n<br>\n<p>위와 같이 인스턴스마다 서로 다른 설정이 필요한 값들은 환경변수로 구성할 수 있도록 이미지를 정의합니다. S3 접근 권한은 직접 credential을 사용하는 것보다 EKS의 IRSA를 활용해서 Role 기반으로 제어하는 편이 좋습니다. Dockerfile은 <a href=\"https://github.com/Swalloow/s3-sync\">s3sync</a> 저장소를 참고하시면 됩니다.</p>\n<br>\n<h2 id=\"2-permission-sync-container\" style=\"position:relative;\"><a href=\"#2-permission-sync-container\" aria-label=\"2 permission sync container permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. Permission Sync Container</h2>\n<p>2.0 부터 추가된 <strong>DAG level Permission을 사용하는 경우</strong>, airflow sync-perm 명령어를 통해 DAG 권한을 갱신해주어야 Role에 권한제어가 정상적으로 반영됩니다. Permission Sync 컨테이너는 webserver에서 주기적으로 <code class=\"language-text\">sync-perm</code> 명령어를 수행하는 역할을 합니다.</p>\n<p>예시는 아래와 같습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">webserver</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">extraContainers</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> sync<span class=\"token punctuation\">-</span>perm\n      <span class=\"token key atrule\">image</span><span class=\"token punctuation\">:</span> apache/airflow<span class=\"token punctuation\">:</span>2.1.2<span class=\"token punctuation\">-</span>python3.7\n      <span class=\"token key atrule\">imagePullPolicy</span><span class=\"token punctuation\">:</span> Always\n      <span class=\"token key atrule\">command</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"/bin/sh\"</span><span class=\"token punctuation\">]</span>\n      <span class=\"token key atrule\">args</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"-c\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"while true; do airflow sync-perm; sleep 60; done\"</span><span class=\"token punctuation\">]</span>\n      <span class=\"token key atrule\">volumeMounts</span><span class=\"token punctuation\">:</span>\n        <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> dags\n          <span class=\"token key atrule\">mountPath</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"/opt/airflow/dags\"</span>\n      <span class=\"token key atrule\">env</span><span class=\"token punctuation\">:</span>\n        <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          <span class=\"token key atrule\">valueFrom</span><span class=\"token punctuation\">:</span>\n            <span class=\"token key atrule\">secretKeyRef</span><span class=\"token punctuation\">:</span>\n              <span class=\"token key atrule\">key</span><span class=\"token punctuation\">:</span> connection\n              <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> airflow<span class=\"token punctuation\">-</span>dev<span class=\"token punctuation\">-</span>airflow<span class=\"token punctuation\">-</span>metadata</code></pre></div>\n<br>\n<p>보시면 Airflow 이미지와 정의된 connection을 재활용 합니다. 컴포넌트 컨테이너와 분리되어 있으니 사이드카에서 발생하는 로그만 따로 확인할 수도 있습니다.</p>\n<br>\n<h2 id=\"3-kerberos-container\" style=\"position:relative;\"><a href=\"#3-kerberos-container\" aria-label=\"3 kerberos container permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. Kerberos Container</h2>\n<p>클러스터에 접근하기 위해 Kerberos 인증이 필요한 경우, Kerberos 컨테이너를 활용하면 인증 토큰 갱신을 자동화할 수 있습니다. <a href=\"https://airflow.apache.org/docs/apache-airflow/stable/production-deployment.html#kerberos-authenticated-workers\">Airflow 공식 문서</a>의 production-deployment 부분을 보면 아래와 같은 내용이 있습니다.</p>\n<blockquote>\n<p>In the Kubernetes environment, this can be realized by the\nconcept of side‐car, where both Kerberos token refresher and\nworker are part of the same Pod. Only the Kerberos side‐car has\naccess to Keytab secret and both containers in the same Pod\nshare the volume, where temporary token is written by the side‐\ncare container and read by the worker container.</p>\n</blockquote>\n<p>대략 K8S 환경에서 사이드카 형태로 구성하는 방법에 대한 내용입니다.\n이를 그림으로 그려보면 아래와 같습니다.</p>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=14rfnQmDROdWpqN4TNQJr02_sIT9E_K0i\" alt=\"krb\"></p>\n<p>kerberos 컨테이너는 keytab이 존재하는 볼륨에 접근하고 kinit 명령어를 통해 ccache를 갱신합니다. airflow 인스턴스들의 worker는 해당 볼륨의 갱신된 토큰을 통해 인증을 달성할 수 있습니다. prod, dev와 같이 여러 airflow를 사용하더라도 kerberos의 컨테이너에서 한번만 캐시 업데이트를 수행하면 됩니다. </p>\n<p>예시는 아래와 같습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">worker</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">extraContainers</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> worker<span class=\"token punctuation\">-</span>kerberos\n      <span class=\"token key atrule\">image</span><span class=\"token punctuation\">:</span> myrepository/kerberos<span class=\"token punctuation\">:</span>latest\n      <span class=\"token key atrule\">imagePullPolicy</span><span class=\"token punctuation\">:</span> Always\n      <span class=\"token key atrule\">volumeMounts</span><span class=\"token punctuation\">:</span>\n        <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> keytab\n          <span class=\"token key atrule\">mountPath</span><span class=\"token punctuation\">:</span> /etc/keytab\n      <span class=\"token key atrule\">env</span><span class=\"token punctuation\">:</span>\n        <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> INTERVAL\n          <span class=\"token key atrule\">value</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"3600\"</span>\n        <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> KRB5_CONFIG\n          <span class=\"token key atrule\">value</span><span class=\"token punctuation\">:</span> /etc/keytab/krb5.conf\n\n<span class=\"token punctuation\">...</span>\n\n<span class=\"token key atrule\">extraVolumes</span><span class=\"token punctuation\">:</span>\n  <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> keytab\n    <span class=\"token key atrule\">persistentVolumeClaim</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">claimName</span><span class=\"token punctuation\">:</span> airflow<span class=\"token punctuation\">-</span>keytab\n<span class=\"token key atrule\">extraVolumeMounts</span><span class=\"token punctuation\">:</span>\n  <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> keytab\n    <span class=\"token key atrule\">mountPath</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"/etc/keytab\"</span></code></pre></div>\n<br>\n<p>위와 같이 keytab이 존재하는 볼륨을 마운트해주어야 합니다.</p>\n<br>\n<h2 id=\"정리\" style=\"position:relative;\"><a href=\"#%EC%A0%95%EB%A6%AC\" aria-label=\"정리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>정리</h2>\n<p>이외에도 사이드카 컨테이너를 잘 활용한다면 다양한 기능으로 확장할 수 있습니다.\n<code class=\"language-text\">extraInitContainers</code> 옵션도 있으니 함께 활용해보면 좋을 것 같습니다.</p>\n<ul>\n<li><a href=\"https://airflow.apache.org/docs/helm-chart/stable/using-additional-containers.html\">https://airflow.apache.org/docs/helm-chart/stable/using-additional-containers.html</a></li>\n</ul>","excerpt":"Airflow 2.1 버전부터 공식 Helm Chart…"}}},{"id":"5a25926b-645a-574b-ba52-5085574c8619","title":"AWS EMR에서 S3 사용 시 주의사항","slug":"aws-emr-s3-spark","publishDate":"September 09, 2017","publishDateISO":"2017-09-09","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"0b9a2387-1599-568e-a5c4-5841d21e528b","childMarkdownRemark":{"id":"2f4a55d7-9be9-53d7-a09a-4da4630a4cde","timeToRead":3,"html":"<p>AWS EMR에서 Spark을 사용하는 경우, S3를 저장소로 사용하는 경우가 많습니다.\n이때 주의해야 할 사항들을 정리해보았습니다.</p>\n<ul>\n<li><strong>최근 수정사항</strong> : 해당 이슈는 EMR 최신 버전에서 대부분 해결되었습니다.</li>\n<li>자세한 내용은 <a href=\"https://aws.amazon.com/ko/blogs/korea/improve-apache-spark-write-performance-on-apache-parquet-formats-with-the-emrfs-s3-optimized-committer/\">Parquet 형식의 EMRFS S3 최적화 커미터를 통한 Apache Spark 쓰기 성능 개선하기</a> 에서 확인하시기 바랍니다.</li>\n</ul>\n<br>\n<h2 id=\"aws-emr-spark-그리고-s3\" style=\"position:relative;\"><a href=\"#aws-emr-spark-%EA%B7%B8%EB%A6%AC%EA%B3%A0-s3\" aria-label=\"aws emr spark 그리고 s3 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>AWS EMR, Spark 그리고 S3</h2>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1FWjProAZAa51cBO6nkLEq1kRhpeG8uhQ\"></p>\n<br>\n<p>Daily로 돌려야 하는 ETL 작업의 경우 위와 같이 간단한 아키텍쳐로 구성하는 경우가 많습니다.\n대부분의 경우 저장소로 S3를 적극 활용하게 됩니다.\n최초 입수되는 로그를 저장하기도 하고, Transformation 작업 이후 중간 또는 최종 데이터로 저장하기도 합니다.</p>\n<br>\n<h2 id=\"문제-상황\" style=\"position:relative;\"><a href=\"#%EB%AC%B8%EC%A0%9C-%EC%83%81%ED%99%A9\" aria-label=\"문제 상황 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>문제 상황</h2>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">java.io.IOException: Connection reset by peer\nERROR ContextCleaner: Error cleaning broadcast 5</code></pre></div>\n<p>최근 Spark RDD 코드를 DataFrame으로 리팩토링 하던 중에 위와 같은 오류를 겪었습니다.\n일별 로그를 불러와서 전처리하고 다시 저장하는데 s3 write 부분에서 갑자기 Executor의 Connection이 끊기는 문제였습니다.</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1jKeOxJk_fjDCXfmkLr_GVxTiMAY5IKAQ\"></p>\n<br>\n<p>Ganglia 모니터링 결과를 보면 중간에 약 15분의 공백이 있는데,\n이 부분이 Connection이 중간에 끊기고 다시 뜰 때까지 걸리는 시간입니다.</p>\n<br>\n<h2 id=\"s3n-s3a-s3\" style=\"position:relative;\"><a href=\"#s3n-s3a-s3\" aria-label=\"s3n s3a s3 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>S3N, S3A, S3</h2>\n<p>먼저 S3는 File System이 아닌 <strong>Object Storage</strong> 라는 점을 알고 계셔야 합니다.\n따라서, S3에 분산저장하는 경우, 우리는 Hadoop 클라이언트를 거쳐 저장하게 됩니다.\nHadoop은 <code class=\"language-text\">S3N, S3A, S3</code> 이렇게 세 가지 시스템 클라이언트를 제공합니다. 각 클라이언트는 URI 스키마를 통해 접근할 수 있습니다.</p>\n<ul>\n<li><strong>S3N (s3n://)</strong> : S3N은 S3에 일반 파일을 읽고 쓰는 기본 파일 시스템입니다. S3N은 안정적이며 널리 사용되고 있지만 현재는 업데이트가 중단되었습니다. S3N의 단점은 파일 엑세스가 한번에 5GB로 제한되어 있다는 점입니다.</li>\n<li><strong>S3A (s3a://)</strong> : S3A는 S3N을 개선한 다음 버전의 파일 시스템입니다. S3A는 Amazon의 라이브러리를 사용하여 S3와 상호 작용합니다. S3A는 5GB 이상의 파일 액세스를 지원하며 성능이 많이 향상되었습니다.</li>\n<li><strong>S3 (s3://)</strong> : S3는 Hadoop 0.10 버전부터 나온 블록 기반의 S3 파일 시스템 입니다. 따라서 파일이 HDFS에 있는 것과 같이 블록으로 저장됩니다.</li>\n</ul>\n<p>EMR은 EMRFS 라는 파일 시스템이 별도로 존재합니다.\nEMR의 S3 파일 시스템과 Hadoop에서의 S3 파일 시스템은 서로 다르기 때문에 항상 주의하셔야 합니다.\nEMR의 경우 <strong>s3</strong> 로 사용하는 것을 권장하고 있습니다. 반면에 s3a의 경우 EMRFS와 호환되지 않는다고 합니다.\n물론 실행 될 때도 있지만 위와 같은 오류가 발생할 수도 있습니다.</p>\n<br>\n<h2 id=\"parquet-저장-성능-개선하기\" style=\"position:relative;\"><a href=\"#parquet-%EC%A0%80%EC%9E%A5-%EC%84%B1%EB%8A%A5-%EA%B0%9C%EC%84%A0%ED%95%98%EA%B8%B0\" aria-label=\"parquet 저장 성능 개선하기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Parquet 저장 성능 개선하기</h2>\n<p>위의 오류는 URI를 s3로 수정해서 해결할 수 있었습니다.\n하지만 S3에 parquet로 저장하는 속도가 너무 느려 이 부분을 개선해보기로 했습니다.</p>\n<p>먼저 Spark에는 Parquet 빌드 속도를 개선하기 위해 <code class=\"language-text\">DirectParquetOutputCommitter</code>라는 기능이 있었습니다.\n하지만, S3에 저장할 때 이 기능을 사용하는 경우 데이터 유실이 발생할 수 있었습니다.\n<a href=\"https://issues.apache.org/jira/browse/SPARK-10063\">SPARK-10063 JIRA 티켓 참고</a></p>\n<p>이러한 이유로 Spark 2.0 버전부터 이 옵션은 사라졌습니다. 그러나, 성능 개선이 필요했기 때문에 Spark 사용자들은 대안을 요구했습니다.\n본래의 FileCommiter가 느린 이유는 rename 연산 때문이었습니다.\n실제 파일 시스템(HDFS)에서 rename 연산은 대상 파일 시스템의 임시 디렉토리로 출력 한 다음, 디렉토리의 이름을 커밋하는 방식으로 O(1)이 소요됩니다.\n하지만 Object Storage에 저장하는 경우, 데이터 사이즈만큼 O(N)이 소요됩니다.</p>\n<p>이 문제는 s3guard와 s3a의 도움으로 해결되었습니다.\ngetFileStatus()에서의 S3 HTTP 콜을 생략하고 dynamo metadata 저장 등을 통해 해결했다는데 자세한 내용은 <a href=\"https://issues.apache.org/jira/browse/MAPREDUCE-4815\">MAPREDUCE-4815 JIRA 티켓</a>을 보시는게 나을 듯 합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version 2\nspark.speculation False</code></pre></div>\n<p>적용하는 방법은 위의 Spark property 옵션을 추가해주시면 됩니다. Spark 2.1, Hadoop 2.7.2 버전 이상부터 사용가능 합니다.\n하지만 Spark 문서에도 나와있듯이 아직 failure에 대한 보장이 떨어집니다.\n따라서 먼저 로컬 HDFS에 임시저장 후 distcp 명령어를 사용하여 S3로 저장해주시면 됩니다.\nHadoop 2.8 버전부터는 s3guard가 기본으로 들어가기 때문에 안정화 될 것 이라고 합니다.</p>\n<p>결과는 로그 1억 건 기준 <strong>약 10배</strong> 의 성능 개선을 확인할 수 있었습니다.\n두서없이 정리하다보니 좀 글이 복잡해졌네요. 결론은 '옵션을 추가하자' 입니다.</p>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<ul>\n<li><a href=\"https://github.com/steveloughran/hadoop/blob/s3guard/HADOOP-13786-committer/hadoop-tools/hadoop-aws/src/site/markdown/tools/hadoop-aws/s3a_committer_architecture.md\">S3A Commiter가 아키텍쳐 및 구현 세부사항에 대하여 정리한 글</a></li>\n<li><a href=\"https://aws.amazon.com/ko/premiumsupport/knowledge-center/emr-file-system-s3/\">AWS 공식 문서에서 정리한 글 : S3N, S3A, S3</a></li>\n</ul>\n<br>","excerpt":"AWS EMR에서 Spark을 사용하는 경우, S…"}}},{"id":"d2deb481-7412-52bb-8ec1-07246c2aea6d","title":"Airflow on Kubernetes (3)","slug":"airflow-on-kubernetes-3","publishDate":"February 05, 2021","publishDateISO":"2021-02-05","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"785a541c-cdc7-5256-911b-4e9c1d0e2b40","childMarkdownRemark":{"id":"2d5e8de2-19ad-5003-bef6-aa09dbdc0f32","timeToRead":2,"html":"<p>최근 Airflow에는 Kubernetes 지원을 위해 다양한 컴포넌트들이 추가되고 있습니다. 이러한 변화의 흐름에 따라 Airflow를 Kubernetes 위에 배포하고 운영하는 방법에 대해 글을 작성해보고자 합니다. 이 글은 시리즈로 연재됩니다.</p>\n<ul>\n<li><a href=\"https://swalloow.github.io/airflow-on-kubernetes-1\">Airflow on Kubernetes (1): CeleryExecutor</a></li>\n<li><a href=\"https://swalloow.github.io/airflow-on-kubernetes-2\">Airflow on Kubernetes (2): KubernetesExecutor</a></li>\n<li><a href=\"https://swalloow.github.io/airflow-on-kubernetes-3\">Airflow on Kubernetes (3): Airflow Logging, Monitoring</a></li>\n</ul>\n<br>\n<h2 id=\"airflow-logging\" style=\"position:relative;\"><a href=\"#airflow-logging\" aria-label=\"airflow logging permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Airflow Logging</h2>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=1qGMB1yIsT06y3y9knBQ2T2G2O3xQs-8b\" alt=\"airflow-log\"></p>\n<p>Airflow의 Task 로그는 PV를 통해 영구 볼륨에 저장하거나 <strong>Remote Logging</strong> 설정을 통해 외부 저장소로 수집할 수 있습니다. S3, ES, GCS 등 다양한 저장소를 지원합니다.\n예를 들어 S3로 설정하면 Task 로그의 수명주기를 S3 Lifecycle에 의해 관리할 수 있게 됩니다.\n참고로 2.0 버전부터 로그 관련 설정은 <code class=\"language-text\">core</code>에서 <code class=\"language-text\">logging</code> 섹션으로 이동했습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">logging:\n  remote_logging: &quot;True&quot;\n  remote_base_log_folder: &quot;s3://mybucketname/airflow&quot;\n  remote_log_conn_id: &quot;aws_default&quot;\n  logging_level: INFO</code></pre></div>\n<br>\n<h2 id=\"airflow-metrics\" style=\"position:relative;\"><a href=\"#airflow-metrics\" aria-label=\"airflow metrics permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Airflow Metrics</h2>\n<p>Airflow는 <a href=\"https://airflow.apache.org/docs/apache-airflow/stable/logging-monitoring/metrics.html\">StatsD를 통한 메트릭 전송 방법</a>을 공식 지원합니다.\nK8S 환경에서 많이 사용하는 Prometheus을 통해 메트릭을 수집하는 방법은 아래와 같이 2가지가 있습니다.\nOfficial Helm Chart의 경우 statsd-export를 통해 전송하는 방법을 지원하고 있습니다.\n<code class=\"language-text\">Values.statsd.enabled</code> 옵션을 통해 쉽게 설정하실 수 있습니다.</p>\n<br>\n<p><strong>1. airflow-prometheus-exporter</strong>:\nairflow model 객체를 활용하여 prometheus metrics collector를 구현한 모듈입니다.\nstable/airflow chart에서 옵션을 통해 설정할 수 있으며 airflow plugin 형태로 구현되어 있어 UI의 /metrics 경로에서 로그를 확인할 수 있습니다.</p>\n<p><strong>2. airflow-statsd-exporter</strong>:\nstatsd는 UDP, TCP를 통해 메트릭을 수집에서 전송하는 프록시입니다.\nairflow에서는 공식적으로 statsd를 통해 메트릭을 지원하고 있습니다.\nofficial helm chart에서는 statsd를 통해 메트릭을 수집하고 exporter를 통해 prometheus에 저장할 수 있습니다.</p>\n<br>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=1T5teIwjMzfvxJGE37oFMOyGFtC9zqfJq\"></p>\n<p>수집하는 과정은 위의 그림과 같습니다. statsd-exporter는 Deployment 형태로 배포되며 수집 어노테이션이 정의되어 있습니다.</p>\n<br>\n<h2 id=\"monitoring\" style=\"position:relative;\"><a href=\"#monitoring\" aria-label=\"monitoring permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Monitoring</h2>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=1V3YNecz4_GRBV_5fgOFSu13ScbImFmjU\"></p>\n<p>Prometheus에 저장된 메트릭은 Grafana를 통해 데이터 소스로 지정하고 원하는 지표를 시각화할 수 있습니다. 위의 대시보드에 활용한 지표는 다음과 같습니다.</p>\n<ul>\n<li>Airflow Scheduler Health</li>\n<li>Number of Queued Tasks</li>\n<li>Number of Running Tasks</li>\n<li>Scheduling Delay by DAG</li>\n<li>DAG Import Time</li>\n<li>DAG Running Duration</li>\n</ul>\n<br>\n<p>사용자가 작성한 DAG은 Parser를 통해 객체로 변환되고 메타데이터 DB에 저장되는데 <code class=\"language-text\">DAG Import Time</code>은 이 과정을 수행하는데 있어 걸리는 시간을 의미합니다. 위에 언급된 지표 외에도 다양한 지표를 지원합니다. 자세한 리스트는 <a href=\"https://airflow.apache.org/docs/apache-airflow/stable/logging-monitoring/metrics.html#counters\">Airflow Metrics 공식 문서</a>를 통해 확인하실 수 있습니다.</p>\n<br>","excerpt":"최근 Airflow에는 Kubernetes 지원을 위해 다양한 컴포넌트들이 추가되고 있습니다. 이러한 변화의 흐름에 따라 Airflow…"}}},{"id":"5fc58fbf-a43f-5cc7-b43f-3f43770235d5","title":"Airflow on Kubernetes (2)","slug":"airflow-on-kubernetes-2","publishDate":"July 12, 2020","publishDateISO":"2020-07-12","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"166621a6-ce3b-537e-9ac0-f3c2b00413ff","childMarkdownRemark":{"id":"39523c20-8b80-5c48-889e-f9a249db1438","timeToRead":5,"html":"<p>최근 Airflow에는 Kubernetes 지원을 위해 다양한 컴포넌트들이 추가되고 있습니다. 이러한 변화의 흐름에 따라 Airflow를 Kubernetes 위에 배포하고 운영하는 방법에 대해 글을 작성해보고자 합니다. 이 글은 시리즈로 연재됩니다.</p>\n<ul>\n<li><a href=\"https://swalloow.github.io/airflow-on-kubernetes-1\">Airflow on Kubernetes (1): CeleryExecutor</a></li>\n<li><a href=\"https://swalloow.github.io/airflow-on-kubernetes-2\">Airflow on Kubernetes (2): KubernetesExecutor</a></li>\n<li><a href=\"https://swalloow.github.io/airflow-on-kubernetes-3\">Airflow on Kubernetes (3): Airflow Logging, Monitoring</a></li>\n</ul>\n<br>\n<h2 id=\"airflow-on-kubernetes\" style=\"position:relative;\"><a href=\"#airflow-on-kubernetes\" aria-label=\"airflow on kubernetes permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Airflow on Kubernetes</h2>\n<p>지난 글에서는 <a href=\"https://github.com/helm/charts/tree/master/stable/airflow\">stable/airflow</a> helm chart를 이용하여 CeleryExecutor의 각 모듈을 Kubernetes 위에 올리는 방식에 대해 설명하였습니다. 이번 글에서는 많이 사용하는 Airflow Helm Chart에 대해 알아보고 최근에 추가된 <strong>Official Airflow Helm Chart</strong>를 이용하여 KubernetesExecutor를 배포했을 때 어떤 아키텍쳐를 가지는지에 대해 설명드리려 합니다. 먼저 많이 사용하는 차트는 아래와 같이 3가지가 있습니다.</p>\n<br>\n<p><strong>1. stable/airflow</strong>:\n다양한 옵션을 지원하고 많이 사용하지만 커뮤니티 버전입니다.\n공식 릴리즈 이후에 개발이 중단될 예정입니다.</p>\n<p><strong>2. astronomer/airflow-chart</strong>:\nAirflow as a Service를 개발하는 astronomer에서 공개한 차트입니다.\nairflow 2.0의 공식 차트로 활용될 예정입니다. (merge된 상태)</p>\n<p><strong>3. apache/airflow-on-k8s-operator</strong>:\nKubernetes Operator를 활용한 방식으로 위와 다른 구성을 가지고 있습니다.\n구글에서 apache에 기증했으며 GCP의 Composer에서 활용되고 있다고 알려져 있습니다.</p>\n<br>\n<p>이외에도 최근에 공식 차트가 <a href=\"https://github.com/apache/airflow/pull/8777\">PR-8777</a>을 통해 merge 되었습니다.\n아직 정식 릴리즈는 아니지만 큰 이슈는 없는 것으로 보여 공식 차트 기준으로 설명하겠습니다.</p>\n<br>\n<h2 id=\"airflow-executor-on-kubernetes\" style=\"position:relative;\"><a href=\"#airflow-executor-on-kubernetes\" aria-label=\"airflow executor on kubernetes permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Airflow Executor on Kubernetes</h2>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=1Zi0Ql_Gfn9kQvz3i0P2Xgsh62n63TDYk\" alt=\"task_lifecycle\"></p>\n<p>먼저 공식 차트 기준으로 executor마다 컴포넌트가 어떤 형태로 올라가는지 알아보겠습니다.\n컴포넌트는 크게 아래와 같이 구분하고 있으며 위의 그림과 같은 라이프사이클에 따라 동작합니다.</p>\n<ul>\n<li><strong>webserver</strong>: Airflow UI, RBAC, DAG monitoring</li>\n<li><strong>scheduler</strong>: task monitoring, trigger, DAG sync, DAG processing</li>\n<li><strong>executor</strong>: how task instance running (pluggable)</li>\n<li><strong>worker</strong>: task instance processing</li>\n</ul>\n<br>\n<h2 id=\"localexecutor\" style=\"position:relative;\"><a href=\"#localexecutor\" aria-label=\"localexecutor permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>LocalExecutor</h2>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=1U7o-jJvDijVh842ueaZwG2joq4cdJZpc\" alt=\"localexecutor\"></p>\n<p>LocalExecutor는 Scheduler에서 각 task가 subprocess 형태로 돌아가는 구조입니다. Scale-Out이 어렵기 때문에 간단한 테스트 용도로 사용하는 경우가 많습니다.</p>\n<br>\n<h2 id=\"celeryexecutor--dag-pv\" style=\"position:relative;\"><a href=\"#celeryexecutor--dag-pv\" aria-label=\"celeryexecutor  dag pv permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>CeleryExecutor + DAG PV</h2>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=1Yitccb8iF2rDnzC22wp5lWyxLowiRQhV\" alt=\"celeryexecutor3\"></p>\n<p>CeleryExecutor는 Scheduler가 task queue에 작업을 전달하고 worker에서 작업이 수행되는 구조입니다. 지난 번 글에서 언급했듯이 여러 노드에 걸쳐 있는 DAG 파일을 동기화하기 위해 <strong>PV, git-sync</strong> 2가지 옵션을 지원합니다. 이 옵션은 KubernetesExecutor에서도 지원합니다.</p>\n<br>\n<p>위의 그림에서는 AWS EFS를 기준으로 표현했지만 NFS를 지원하는 스토리지에서 모두 활용 가능합니다. 이 방식은 스토리지를 별도로 두기 때문에 git과 다르게 배포 주기를 가져갈 수 있습니다.\n그리고 worker pod이 <strong>statefulset</strong> 형태로 변경되었습니다. 이를 통해 각 worker에 PV를 연결하고 airflow UI에서 각 task의 로그를 볼 수 있습니다.</p>\n<br>\n<h2 id=\"celeryexecutor--dag-git-sync\" style=\"position:relative;\"><a href=\"#celeryexecutor--dag-git-sync\" aria-label=\"celeryexecutor  dag git sync permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>CeleryExecutor + DAG git-sync</h2>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=1VodhbkJMzMbMWKookXTiGr8rPChS8Uwe\" alt=\"celeryexecutor4\"></p>\n<p>git-sync 옵션을 사용한다면 위와 같은 그림으로 구성됩니다.\nairflow의 각 컴포넌트에 git-sync 컨테이너가 sidecar 형태로 추가됩니다.\n이 방식은 <strong>DAG 전용 git repository가 있다면 자동으로 배포를 구성할 수 있다</strong>는 장점이 있습니다. 처음 차트를 배포할때 init container 단계에서 git clone을 수행하고 이후부터는 git-sync 사이드카 컨테이너를 통해 주기적으로 pull을 수행하게 됩니다.</p>\n<br>\n<h2 id=\"celeryexecutor--keda-autoscaler\" style=\"position:relative;\"><a href=\"#celeryexecutor--keda-autoscaler\" aria-label=\"celeryexecutor  keda autoscaler permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>CeleryExecutor + KEDA AutoScaler</h2>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=1gT38whMNgcmMLDhegS7TKjVXRO2bm38o\" alt=\"keda\"></p>\n<br>\n<p><strong>KEDA AutoScaler</strong>는 공식 차트에만 추가된 옵션입니다.\n기존의 Horizontal Pod Autoscaler는 리소스(CPU, Memory) 메트릭을 기반으로 스케일 여부를 결정하게 됩니다. 반면에 KEDA는 <strong>특정 이벤트를 기반으로 스케일 여부를 결정</strong>할 수 있습니다. 예를 들어 airflow는 metadb를 통해 현재 실행 중이거나 대기 중인 task가 얼마나 존재하는지 알 수 있습니다. 이러한 이벤트를 활용하여 worker의 scale을 결정한다면 queue에 task가 많이 추가되는 시점에 더 빠르게 확장할 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"sql\"><pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">SELECT</span> ceil<span class=\"token punctuation\">(</span><span class=\"token function\">COUNT</span><span class=\"token punctuation\">(</span><span class=\"token operator\">*</span><span class=\"token punctuation\">)</span>::<span class=\"token keyword\">decimal</span> <span class=\"token operator\">/</span> <span class=\"token number\">16</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">FROM</span> task_instance\n<span class=\"token keyword\">WHERE</span> state<span class=\"token operator\">=</span><span class=\"token string\">'running'</span> <span class=\"token operator\">OR</span> state<span class=\"token operator\">=</span><span class=\"token string\">'queued'</span></code></pre></div>\n<p>이를 위해 airflow에서는 KEDA의 <strong>PostgreSQL trigger</strong>를 활용하였고 실제 위와 같은 쿼리가 등록되어 있습니다. KEDA는 CRD와 custom controller로 구성되어 있기 때문에 기존 HPA와 함께 사용 가능하며 모든 K8S 클러스터에 추가할 수 있습니다.</p>\n<br>\n<h2 id=\"celeryexecutor-vs-kubernetesexecutor\" style=\"position:relative;\"><a href=\"#celeryexecutor-vs-kubernetesexecutor\" aria-label=\"celeryexecutor vs kubernetesexecutor permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>CeleryExecutor vs KubernetesExecutor</h2>\n<p>여기까지 CeleryExecutor에 대해 알아보았습니다. CeleryExecutor 또한 Kubernetes 위에 배포하면 Helm 차트를 통한 선언형 리소스 관리, 쉬운 버전 업데이트, DAG 배포 자동화, 쉬운 리소스 확장 등의 장점을 가질 수 있습니다. 하지만 Celery에 대한 의존성이 남아있기 때문에 Redis, Celery Worker에 대한 리소스를 계속 점유하고 있어야 합니다. 다시 말해서, <strong>Scale to Zero</strong>가 어렵다는 단점이 있습니다. KubernetesExecutor는 task가 존재할때만 pod이 생성되고 task가 완료되면 종료되기 때문에 더 리소스를 효율적으로 사용한다고 볼 수 있습니다.</p>\n<br>\n<h2 id=\"kubernetesexecutor-kubernetespodoperator\" style=\"position:relative;\"><a href=\"#kubernetesexecutor-kubernetespodoperator\" aria-label=\"kubernetesexecutor kubernetespodoperator permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>KubernetesExecutor, KubernetesPodOperator</h2>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=1dSfx9OxnCYpw7g0gMmOtnF7mNDb_k5Cg\" alt=\"kubernetesexecutor\"></p>\n<br>\n<p>위의 그림처럼 KubernetesExecutor는 Broker와 같은 리소스를 점유하고 있을 필요가 없습니다. 리소스를 할당하고 스케줄링 하는 역할은 Kubernetes Scheduler가 수행하게 됩니다. Airflow Scheduler는 API Server에게 task 수행을 위한 Pod 생성을 요청합니다. worker는 <code class=\"language-text\">images.airflow</code>에 설정한 이미지로 Pod이 생성되기 때문에 추가로 필요한 파이썬 패키지가 존재한다면 별도의 이미지를 만들어주어야 합니다. 만일 task pod 마다 다른 이미지와 리소스 설정을 가지도록 하고 싶다면 <strong>KubernetesPodOperator</strong>를 사용하시면 됩니다. KubernetesPodOperator는 worker를 통해 pod이 생성되는 구조이므로 파라메터를 통해 사용자가 원하는 설정으로 변경할 수 있습니다.</p>\n<br>\n<h2 id=\"kubernetesexecutor-process\" style=\"position:relative;\"><a href=\"#kubernetesexecutor-process\" aria-label=\"kubernetesexecutor process permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>KubernetesExecutor Process</h2>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=1mviHViGJS1tTQtl4JrgUFR9IdaersPoY\" alt=\"kubeexecutor2\"></p>\n<br>\n<p>KubernetesExecutor는 위와 같은 프로세스를 통해 동작합니다. 일반적으로 Pod이 생성되는 과정과 동일하며 airflow에서는 내부적으로 python kubernetes client library를 통해 k8s_model 이라는 객체로 K8S API를 추상화하여 사용하고 있습니다. </p>\n<br>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=1hzzK8Jx5olsXsQTiVdPyKPqNA-CA-ulT\" alt=\"kubeexecutor3\"></p>\n<br>\n<p>task가 완료되기 전에 Airflow DB 상태 업데이트 단계에서 OOM 등의 이유로 Pod Crash가 언제나 발생할 수 있기 때문에 이에 대한 장애 시나리오도 준비되어 있습니다. DB 업데이트에 실패하더라도 airflow scheduler는 Kubernetes Watch API를 통해 pod의 상태를 전달받아 다시 DB 상태를 업데이트 할 수 있습니다. CeleryExecutor의 경우, task 상태에 대한 처리를 celery에 주기적으로 확인하는 방식이라면 <strong>KubernetesExecutor는 이벤트 스트림으로 전달받기 때문에 스케줄러에 대한 부하가 더 낮다</strong>고 볼 수 있습니다.</p>\n<br>\n<h2 id=\"kubernetesexecutor-batch-cronjob\" style=\"position:relative;\"><a href=\"#kubernetesexecutor-batch-cronjob\" aria-label=\"kubernetesexecutor batch cronjob permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>KubernetesExecutor Batch, CronJob</h2>\n<p>공식 차트에서는 사용자의 편의를 위해 RBAC 초기 사용자를 생성해주는 <strong>create-user BatchJob</strong>이 추가되었습니다. <strong>Helm Hooks (post-install)</strong> 를 통해 차트 리소스가 모두 생성된 이후에 수행됩니다. 더 이상 exec 명령어로 bash에 들어가 create-user 명령어를 수행할 필요가 없습니다!</p>\n<p>추가로 <strong>cleanup CronJob</strong>이 있습니다. <code class=\"language-text\">AIRFLOW__KUBERNETES__DELETE_WORKER_PODS</code> 옵션을 통해 task가 끝나더라도 pod이 종료되지 않도록 설정할 수 있는데 이때 내가 원하는 주기마다 오래된 pod을 삭제할 수 있는 CronJob 입니다.</p>\n<br>\n<h2 id=\"official-helm-chart-issue\" style=\"position:relative;\"><a href=\"#official-helm-chart-issue\" aria-label=\"official helm chart issue permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Official Helm Chart Issue</h2>\n<p>공식 버전 차트는 아래와 같은 이슈가 남아있지만 2.0 정식 버전 출시와 함께 해결될 예정입니다.\n글을 작성하는 과정에서 DAG 동기화 관련 버그를 발견하였지만 리뷰를 통해 곧바로 수정되었습니다. (<a href=\"https://github.com/apache/airflow/pull/9371\">PR-9371</a>). stable/airflow 차트와 비교했을때 아쉬운 점은 아래와 같습니다.</p>\n<ul>\n<li>현재 버전에서는 backend로 postgresql만 지원 <a href=\"https://github.com/apache/airflow/issues/9627\">(ISSUE-9627)</a></li>\n<li>pip 등 작업 실행에 필요한 패키지 설치하는 옵션이 없음</li>\n<li>initContainer를 수정해서 설치하거나 이미지 별도로 생성해야함</li>\n<li>차트에 Ingress 설정에 대한 옵션이 부족</li>\n<li>KubernetesExecutor의 경우 remote logging 설정을 해야 UI에서 로그 확인 가능</li>\n</ul>\n<br>\n<h2 id=\"deploy\" style=\"position:relative;\"><a href=\"#deploy\" aria-label=\"deploy permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Deploy</h2>\n<p>사실 배포와 옵션에 대한 내용은 지난 글에서 말한 내용과 크게 다름이 없습니다. 아직 정식 릴리즈까지 변경될 여지가 많다보니 아래 공식 문서 따라하시는 방법을 추천드립니다 <a href=\"https://github.com/apache/airflow/tree/master/chart\">(apache/airflow/chart)</a>. 다음 글에서는 KubernetesExecutor의 로깅과 모니터링에 대해 다루어보겠습니다!</p>","excerpt":"최근 Airflow에는 Kubernetes 지원을 위해 다양한 컴포넌트들이 추가되고 있습니다. 이러한 변화의 흐름에 따라 Airflow…"}}},{"id":"795cadce-4a40-5a62-a2c3-15bbc6f787ac","title":"빅데이터 처리에 Scala가 필요한 이유","slug":"scala-for-bigdata","publishDate":"March 17, 2017","publishDateISO":"2017-03-17","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"a22dd3d7-109c-5d37-b360-e3581ff3a188","childMarkdownRemark":{"id":"ee0e0316-13da-5df2-a061-9f89f32f9e5d","timeToRead":4,"html":"<p>StackOverFlow나 Quora를 보면 <strong>Scala has taken over the Big Data world.</strong> 라는 글을 많이 볼 수 있습니다.\n게다가 Spark의 엔진은 Scala로 구현되어 있습니다. 이 포스팅에서는 데이터를 다루는데에 스칼라가 가지는 강점이 무엇인지 알아보고자 합니다.</p>\n<br>\n<h1 id=\"scala가-가지는-강점\" style=\"position:relative;\"><a href=\"#scala%EA%B0%80-%EA%B0%80%EC%A7%80%EB%8A%94-%EA%B0%95%EC%A0%90\" aria-label=\"scala가 가지는 강점 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Scala가 가지는 강점</h1>\n<h2 id=\"static-typing-type-inference\" style=\"position:relative;\"><a href=\"#static-typing-type-inference\" aria-label=\"static typing type inference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Static Typing, Type Inference</h2>\n<p>스칼라의 <code class=\"language-text\">val</code> 변수는 한번 지정된 값을 바꾸지 않습니다.\n이러한 변수를 <code class=\"language-text\">Immutable variable</code> 이라고 부릅니다. 예를 들면 아래와 같습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"scala\"><pre class=\"language-scala\"><code class=\"language-scala\"><span class=\"token keyword\">val</span> msg <span class=\"token operator\">=</span> <span class=\"token string\">\"Hello Scala\"</span>\n<span class=\"token builtin\">String</span> <span class=\"token operator\">=</span> Hello Scala\n\n<span class=\"token keyword\">val</span> msg <span class=\"token operator\">=</span> <span class=\"token string\">\"Reassign to val\"</span>\nerror<span class=\"token operator\">:</span> reassignment to <span class=\"token keyword\">val</span></code></pre></div>\n<p>위의 예제를 보면, msg 변수에 문자열을 할당했지만 어디에도 String 이라는 단어는 없습니다.\n스칼라는 알아서 타입을 추론하여 지정해주기 때문입니다.\n따라서, <code class=\"language-text\">val</code> 변수에 재할당을 시도하면 <code class=\"language-text\">reassignment to val</code> 이라는 오류가 발생하게 됩니다.</p>\n<p>이처럼 스칼라는 input 타입을 보고 함수나 출력 값의 타입을 추론해주며 이를 통해 코드를 깔끔하게 유지할 수 있습니다. 또한, 다양하고 많은 데이터가 사용되는 경우 정적변수가 문제를 단순화 해주는 효과가 있습니다.</p>\n<br>\n<h2 id=\"scalable-language\" style=\"position:relative;\"><a href=\"#scalable-language\" aria-label=\"scalable language permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Scalable Language</h2>\n<p>기존의 Hadoop 기반의 데이터 인프라는 자바 언어를 통해 MapReduce 연산 그리고 알고리즘을 구현해야했습니다.\n하지만 자바는 코드가 너무 길어 생산성 그리고 가독성이 매우 떨어집니다.</p>\n<p>스칼라는 모든 것들이 일관성있게 그리고 간결하게 구현되도록 설계되었습니다.\n이를 통해 얻을 수 있는 장점은 <strong>\"적은 양의 코드로 방대한 규모의 시스템을 작성할 수 있다\"</strong> 는 것입니다.</p>\n<p>연산자를 예로 들어보겠습니다.\n자바에서는 '==' 와 같은 비교연산자를 제공합니다.\n하지만 비교연산자는 주소값을 비교하기 때문에\nString과 같은 객체를 비교할 때는 <code class=\"language-text\">equal()</code> 메서드를 사용해서 비교해야 했습니다.\n이 또한 스칼라의 Scalable과 거리가 멉니다.\n스칼라에서는 모든 것이 Object이기 때문에 <code class=\"language-text\">==</code> 로 모든 비교가 가능합니다.</p>\n<br>\n<h2 id=\"object-oriented-functional-language\" style=\"position:relative;\"><a href=\"#object-oriented-functional-language\" aria-label=\"object oriented functional language permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Object Oriented, Functional Language</h2>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">y1 = 2x + 5\ny2 = 4(y1) = 4(2x + 5)</code></pre></div>\n<p>함수형 언어를 이해하기 전에 어렸을 때 배웠던 함수식을 떠올려보겠습니다.\n위의 식에서 x는 input, y는 output이 됩니다.\n우리는 어떤 함수에 input을 넣으면 output이 나온다고 이해하고 있습니다.\n그리고 아래의 식처럼 함수를 인자로 넣을 수도 있습니다 (합성함수).\n함수형 언어도 이와 비슷합니다.</p>\n<p>스칼라는 객체지향 프로그래밍과 함수형 프로그래밍을 모두 완벽하게 지원하는 언어입니다.\n스칼라에서는 모든 것이 객체이며 함수가 <code class=\"language-text\">first object</code> 입니다.\n함수를 마치 하나의 값으로 취급하며 이를 변수 또는 파라미터로 넘길 수 있습니다.</p>\n<p>모든 것을 함수로 해결하면 의도하지 않은 동작(Side Effect)이 발생할 일이 없고,\n한번 검증된 함수는 신뢰할 수 있기 때문에 버그가 줄어드는 효과가 있습니다.\n또한, Immutable 변수는 문제를 단순화시켜주기 때문에 데이터 공유, 병렬처리에 강합니다.</p>\n<br>\n<h2 id=\"java와-scala를-비교해보자\" style=\"position:relative;\"><a href=\"#java%EC%99%80-scala%EB%A5%BC-%EB%B9%84%EA%B5%90%ED%95%B4%EB%B3%B4%EC%9E%90\" aria-label=\"java와 scala를 비교해보자 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Java와 Scala를 비교해보자</h2>\n<p>Scala는 Interactive한 Shell을 제공합니다.\n이렇게 바로 확인할 수 있는 Shell을 통해 데이터의 탐색적 분석이 가능합니다.\nIntelliJ IDEA에서도 <code class=\"language-text\">Worksheet</code>이라는 기능을 통해 사용할 수 있습니다.\n스칼라 개발환경은 <strong>Scala 2.12.1</strong> 이며, IDE는 <strong>IntelliJ IDEA</strong> 를 사용하였습니다.</p>\n<p><img src=\"/assets/images/intellij.png\" alt=\"IntelliJ\"></p>\n<p>간단한 WordCount 예제를 통해 코드를 비교해보곘습니다.</p>\n<h2 id=\"java-hadoop-word-count\" style=\"position:relative;\"><a href=\"#java-hadoop-word-count\" aria-label=\"java hadoop word count permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>JAVA Hadoop Word Count</h2>\n<div class=\"gatsby-highlight\" data-language=\"java\"><pre class=\"language-java\"><code class=\"language-java\"><span class=\"token comment\">//package org.myorg;</span>\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">java<span class=\"token punctuation\">.</span>io</span><span class=\"token punctuation\">.</span><span class=\"token class-name\">IOException</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">java<span class=\"token punctuation\">.</span>util</span><span class=\"token punctuation\">.</span>*<span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>hadoop<span class=\"token punctuation\">.</span>fs</span><span class=\"token punctuation\">.</span><span class=\"token class-name\">Path</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>hadoop<span class=\"token punctuation\">.</span>conf</span><span class=\"token punctuation\">.</span>*<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>hadoop<span class=\"token punctuation\">.</span>io</span><span class=\"token punctuation\">.</span>*<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>hadoop<span class=\"token punctuation\">.</span>mapred</span><span class=\"token punctuation\">.</span>*<span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>hadoop<span class=\"token punctuation\">.</span>util</span><span class=\"token punctuation\">.</span>*<span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">WordCount</span> <span class=\"token punctuation\">{</span>\n\n\t<span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">Map</span> <span class=\"token keyword\">extends</span> <span class=\"token class-name\">MapReduceBase</span> <span class=\"token keyword\">implements</span> <span class=\"token class-name\">Mapper</span><span class=\"token generics\"><span class=\"token punctuation\">&lt;</span><span class=\"token class-name\">LongWritable</span><span class=\"token punctuation\">,</span> <span class=\"token class-name\">Text</span><span class=\"token punctuation\">,</span> <span class=\"token class-name\">Text</span><span class=\"token punctuation\">,</span> <span class=\"token class-name\">IntWritable</span><span class=\"token punctuation\">></span></span> <span class=\"token punctuation\">{</span>\n\t\t<span class=\"token keyword\">private</span> <span class=\"token keyword\">final</span> <span class=\"token keyword\">static</span> <span class=\"token class-name\">IntWritable</span> one <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">IntWritable</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token keyword\">private</span> <span class=\"token class-name\">Text</span> word <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Text</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n\t\t<span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">map</span><span class=\"token punctuation\">(</span><span class=\"token class-name\">LongWritable</span> key<span class=\"token punctuation\">,</span> <span class=\"token class-name\">Text</span> value<span class=\"token punctuation\">,</span> <span class=\"token class-name\">OutputCollector</span><span class=\"token generics\"><span class=\"token punctuation\">&lt;</span><span class=\"token class-name\">Text</span><span class=\"token punctuation\">,</span> <span class=\"token class-name\">IntWritable</span><span class=\"token punctuation\">></span></span> output<span class=\"token punctuation\">,</span> <span class=\"token class-name\">Reporter</span> reporter<span class=\"token punctuation\">)</span> <span class=\"token keyword\">throws</span> <span class=\"token class-name\">IOException</span> <span class=\"token punctuation\">{</span>\n\t\t\t<span class=\"token class-name\">String</span> line <span class=\"token operator\">=</span> value<span class=\"token punctuation\">.</span><span class=\"token function\">toString</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token class-name\">StringTokenizer</span> tokenizer <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">StringTokenizer</span><span class=\"token punctuation\">(</span>line<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span>tokenizer<span class=\"token punctuation\">.</span><span class=\"token function\">hasMoreTokens</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n\t\t\t\tword<span class=\"token punctuation\">.</span><span class=\"token function\">set</span><span class=\"token punctuation\">(</span>tokenizer<span class=\"token punctuation\">.</span><span class=\"token function\">nextToken</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\t\t\t\toutput<span class=\"token punctuation\">.</span><span class=\"token function\">collect</span><span class=\"token punctuation\">(</span>word<span class=\"token punctuation\">,</span> one<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token punctuation\">}</span>\n\t\t<span class=\"token punctuation\">}</span>\n\t<span class=\"token punctuation\">}</span>\n\n\t<span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">Reduce</span> <span class=\"token keyword\">extends</span> <span class=\"token class-name\">MapReduceBase</span> <span class=\"token keyword\">implements</span> <span class=\"token class-name\">Reducer</span><span class=\"token generics\"><span class=\"token punctuation\">&lt;</span><span class=\"token class-name\">Text</span><span class=\"token punctuation\">,</span> <span class=\"token class-name\">IntWritable</span><span class=\"token punctuation\">,</span> <span class=\"token class-name\">Text</span><span class=\"token punctuation\">,</span> <span class=\"token class-name\">IntWritable</span><span class=\"token punctuation\">></span></span> <span class=\"token punctuation\">{</span>\n\t\t<span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">reduce</span><span class=\"token punctuation\">(</span><span class=\"token class-name\">Text</span> key<span class=\"token punctuation\">,</span> <span class=\"token class-name\">Iterator</span><span class=\"token generics\"><span class=\"token punctuation\">&lt;</span><span class=\"token class-name\">IntWritable</span><span class=\"token punctuation\">></span></span> values<span class=\"token punctuation\">,</span> <span class=\"token class-name\">OutputCollector</span><span class=\"token generics\"><span class=\"token punctuation\">&lt;</span><span class=\"token class-name\">Text</span><span class=\"token punctuation\">,</span> <span class=\"token class-name\">IntWritable</span><span class=\"token punctuation\">></span></span> output<span class=\"token punctuation\">,</span> <span class=\"token class-name\">Reporter</span> reporter<span class=\"token punctuation\">)</span> <span class=\"token keyword\">throws</span> <span class=\"token class-name\">IOException</span> <span class=\"token punctuation\">{</span>\n\t\t\t<span class=\"token keyword\">int</span> sum <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span>values<span class=\"token punctuation\">.</span><span class=\"token function\">hasNext</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n\t\t\t\tsum <span class=\"token operator\">+=</span> values<span class=\"token punctuation\">.</span><span class=\"token function\">next</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span><span class=\"token function\">get</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\t\t\t<span class=\"token punctuation\">}</span>\n\t\t\toutput<span class=\"token punctuation\">.</span><span class=\"token function\">collect</span><span class=\"token punctuation\">(</span>key<span class=\"token punctuation\">,</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">IntWritable</span><span class=\"token punctuation\">(</span>sum<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token punctuation\">}</span>\n\t<span class=\"token punctuation\">}</span>\n\n\t<span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">void</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span><span class=\"token class-name\">String</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> args<span class=\"token punctuation\">)</span> <span class=\"token keyword\">throws</span> <span class=\"token class-name\">Exception</span> <span class=\"token punctuation\">{</span>\n\t\t<span class=\"token class-name\">JobConf</span> conf <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">JobConf</span><span class=\"token punctuation\">(</span><span class=\"token class-name\">WordCount</span><span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\t\tconf<span class=\"token punctuation\">.</span><span class=\"token function\">setJobName</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"wordcount\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n\t\tconf<span class=\"token punctuation\">.</span><span class=\"token function\">setOutputKeyClass</span><span class=\"token punctuation\">(</span><span class=\"token class-name\">Text</span><span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\t\tconf<span class=\"token punctuation\">.</span><span class=\"token function\">setOutputValueClass</span><span class=\"token punctuation\">(</span><span class=\"token class-name\">IntWritable</span><span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n\t\tconf<span class=\"token punctuation\">.</span><span class=\"token function\">setMapperClass</span><span class=\"token punctuation\">(</span><span class=\"token class-name\">Map</span><span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token comment\">//conf.setCombinerClass(Reduce.class);</span>\n\t\tconf<span class=\"token punctuation\">.</span><span class=\"token function\">setReducerClass</span><span class=\"token punctuation\">(</span><span class=\"token class-name\">Reduce</span><span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n\t\tconf<span class=\"token punctuation\">.</span><span class=\"token function\">setInputFormat</span><span class=\"token punctuation\">(</span><span class=\"token class-name\">TextInputFormat</span><span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\t\tconf<span class=\"token punctuation\">.</span><span class=\"token function\">setOutputFormat</span><span class=\"token punctuation\">(</span><span class=\"token class-name\">TextOutputFormat</span><span class=\"token punctuation\">.</span><span class=\"token keyword\">class</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n\t\t<span class=\"token class-name\">FileInputFormat</span><span class=\"token punctuation\">.</span><span class=\"token function\">setInputPaths</span><span class=\"token punctuation\">(</span>conf<span class=\"token punctuation\">,</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Path</span><span class=\"token punctuation\">(</span>args<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\t\t<span class=\"token class-name\">FileOutputFormat</span><span class=\"token punctuation\">.</span><span class=\"token function\">setOutputPath</span><span class=\"token punctuation\">(</span>conf<span class=\"token punctuation\">,</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Path</span><span class=\"token punctuation\">(</span>args<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n\t\t<span class=\"token class-name\">JobClient</span><span class=\"token punctuation\">.</span><span class=\"token function\">runJob</span><span class=\"token punctuation\">(</span>conf<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\t<span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<br>\n<h2 id=\"scala-spark-word-count\" style=\"position:relative;\"><a href=\"#scala-spark-word-count\" aria-label=\"scala spark word count permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Scala Spark Word Count</h2>\n<div class=\"gatsby-highlight\" data-language=\"scala\"><pre class=\"language-scala\"><code class=\"language-scala\"><span class=\"token keyword\">val</span> file <span class=\"token operator\">=</span> spark<span class=\"token punctuation\">.</span>textFile<span class=\"token punctuation\">(</span><span class=\"token string\">\"hdfs://...\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">val</span> counts <span class=\"token operator\">=</span> file<span class=\"token punctuation\">.</span>flatMap<span class=\"token punctuation\">(</span>line <span class=\"token keyword\">=></span> line<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token string\">\" \"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">.</span>map<span class=\"token punctuation\">(</span>word <span class=\"token keyword\">=></span> <span class=\"token punctuation\">(</span>word<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">.</span>reduceByKey<span class=\"token punctuation\">(</span>_ <span class=\"token operator\">+</span> _<span class=\"token punctuation\">)</span>\ncounts<span class=\"token punctuation\">.</span>saveAsTextFile<span class=\"token punctuation\">(</span><span class=\"token string\">\"hdfs://...\"</span><span class=\"token punctuation\">)</span></code></pre></div>\n<br>\n<h2 id=\"정리하자면\" style=\"position:relative;\"><a href=\"#%EC%A0%95%EB%A6%AC%ED%95%98%EC%9E%90%EB%A9%B4\" aria-label=\"정리하자면 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>정리하자면,</h2>\n<ul>\n<li>파이썬과 같이 아주 간결한 문법</li>\n<li>객체지향과 함수형 프로그래밍 모두 가능</li>\n<li>자바와 호환되며 JVM 위에서 실행되기 때문에 좋은 성능</li>\n<li>정적 타입을 지향</li>\n<li>REPL Shell을 활용하여 Scripting</li>\n</ul>\n<br>","excerpt":"StackOverFlow나 Quora를 보면 Scala has taken over the Big Data world…"}}},{"id":"c9c22c87-26a0-5eef-b26b-689b1f9b3819","title":"Serverless ETL 서비스들에 대한 리뷰","slug":"serverless-etl","publishDate":"August 23, 2019","publishDateISO":"2019-08-23","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"a5384ea3-80c9-5139-9665-b747d4894123","childMarkdownRemark":{"id":"30e59fb2-d022-54b7-9e6c-a50bdeeba8f1","timeToRead":5,"html":"<p>15년 AWS Lambda가 출시된 이후, 뜨거운 반응을 보이며 다양한 서버리스 서비스들이 출시되었다.\n그 중 ETL에 관련되어 있는 서비스들을 사용해보면서 느낀 점에 대해 정리해보려 한다.</p>\n<br>\n<h1 id=\"lambda와-athena를-활용한-쿼리\" style=\"position:relative;\"><a href=\"#lambda%EC%99%80-athena%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-%EC%BF%BC%EB%A6%AC\" aria-label=\"lambda와 athena를 활용한 쿼리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Lambda와 Athena를 활용한 쿼리</h1>\n<p>Athena는 Presto를 기반으로 만든 대화형 쿼리 서비스이다.\n쿼리 당 스캔한 데이터의 TB당 5 USD 만 내면 된다.\n보통 분석용 쿼리를 위한 클러스터는 리소스 요청이 불규칙적인 경우가 많다.\n운영을 위한 비용까지 고려한다면 정말 좋은 서비스라고 볼 수 있다.\n하지만 모든 서비스가 그렇듯 장점만 있는 것은 아니다.\n특히 Athena를 분석용 쿼리가 아닌 다른 용도로 사용한다면 몇 가지 제한사항을 마주칠 수도 있다.</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=13Q_Ke3ZJuJxwR3Ahy479hT5nPJcNiSRV\"></p>\n<p>Athena를 ETL 용도로 사용하고 싶다면 위 그림과 같이 Lambda, CloudWatch를 통해 트리거할 수 있다.\nAthena 뿐만 아니라 Glue, EMR 등 다른 서비스도 모두 Lambda를 통해 실행할 수 있기 때문에\n정말 온디멘드로 띄워놓는 인스턴스 하나도 없이 ETL을 구성할 수도 있다.\n하지만 정말 데이터가 많고 복잡한 작업이라면 아래와 같은 제약사항들을 잘 이해하고 선택해야 한다.</p>\n<br>\n<h2 id=\"구글의-빅쿼리와-달리-쿼리-비용을-추정하는-기능이-없다\" style=\"position:relative;\"><a href=\"#%EA%B5%AC%EA%B8%80%EC%9D%98-%EB%B9%85%EC%BF%BC%EB%A6%AC%EC%99%80-%EB%8B%AC%EB%A6%AC-%EC%BF%BC%EB%A6%AC-%EB%B9%84%EC%9A%A9%EC%9D%84-%EC%B6%94%EC%A0%95%ED%95%98%EB%8A%94-%EA%B8%B0%EB%8A%A5%EC%9D%B4-%EC%97%86%EB%8B%A4\" aria-label=\"구글의 빅쿼리와 달리 쿼리 비용을 추정하는 기능이 없다 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>구글의 빅쿼리와 달리 쿼리 비용을 추정하는 기능이 없다</h2>\n<p>Athena는 쿼리 비용을 추정하는 기능이 없기 때문에 잘 모르고 쿼리를 막 날린다면 과금 폭탄을 맞이할 수 있다.\n물론 처음 사용하는 경우, AWS에 실수한 상황을 설명하면 어느정도 과금을 물러주기도 한다.</p>\n<br>\n<h2 id=\"athena에는-동시-쿼리-제한과-시간-제한이-존재한다\" style=\"position:relative;\"><a href=\"#athena%EC%97%90%EB%8A%94-%EB%8F%99%EC%8B%9C-%EC%BF%BC%EB%A6%AC-%EC%A0%9C%ED%95%9C%EA%B3%BC-%EC%8B%9C%EA%B0%84-%EC%A0%9C%ED%95%9C%EC%9D%B4-%EC%A1%B4%EC%9E%AC%ED%95%9C%EB%8B%A4\" aria-label=\"athena에는 동시 쿼리 제한과 시간 제한이 존재한다 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Athena에는 동시 쿼리 제한과 시간 제한이 존재한다</h2>\n<p>Athena의 기본 계정 당 쿼리 한도는 20개이다. Support에 요청하면 늘려주기도 하지만 이 역시 제한이 있다. 또한 30분이라는 쿼리 제한 시간이 존재한다.\n따라서 오래걸리거나 무거운 작업에 Athena 쿼리를 활용하는 경우, 앞단에 큐를 두는 경우가 많다.</p>\n<br>\n<h2 id=\"athena는-udf를-지원하지-않는다\" style=\"position:relative;\"><a href=\"#athena%EB%8A%94-udf%EB%A5%BC-%EC%A7%80%EC%9B%90%ED%95%98%EC%A7%80-%EC%95%8A%EB%8A%94%EB%8B%A4\" aria-label=\"athena는 udf를 지원하지 않는다 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Athena는 UDF를 지원하지 않는다</h2>\n<p>어쩌면 크게 다가올 수 있는 제한사항 중에 하나이다.\nUDF를 많이 등록하고 사용했다면 사용자 입장에서 불편할 수 있다.</p>\n<br>\n<h2 id=\"athena의-ctas-쿼리에는-파티션-한도가-존재한다\" style=\"position:relative;\"><a href=\"#athena%EC%9D%98-ctas-%EC%BF%BC%EB%A6%AC%EC%97%90%EB%8A%94-%ED%8C%8C%ED%8B%B0%EC%85%98-%ED%95%9C%EB%8F%84%EA%B0%80-%EC%A1%B4%EC%9E%AC%ED%95%9C%EB%8B%A4\" aria-label=\"athena의 ctas 쿼리에는 파티션 한도가 존재한다 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Athena의 CTAS 쿼리에는 파티션 한도가 존재한다</h2>\n<p>CTAS 쿼리란 SELECT의 결과로 채워지는 새 테이블을 생성하는 쿼리를 말한다.\nCTAS 쿼리를 사용하는 경우, WITH 절의 external_location을 통해 저장될 위치를 지정한다.\n이 때 Athena가 생성하는 쿼리 결과 파티션이 100개를 넘어가는 경우 오류가 발생한다.</p>\n<br>\n<h1 id=\"glue-etl-data-catalog\" style=\"position:relative;\"><a href=\"#glue-etl-data-catalog\" aria-label=\"glue etl data catalog permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Glue ETL, Data Catalog</h1>\n<p>Glue와 S3 Batch는 Athena와 달리 태생부터 ETL을 위해 만들어진 서버리스 서비스이다.\n특히 Hive Metastore를 대체할 수 있는 Glue Data Catalog와\n자동으로 스키마를 생성해주는 Glue Crawler는 정말 편하게 사용할 수 있다.\nGlue Data Catalog를 사용한다면 Athena, EMR 내에서 Glue를 중심으로 데이터 소스를 통합할 수 있다.</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1rN1-SFqxqljQNQXhEqv0uTpC1ymrVXbo\"></p>\n<p>하지만 Glue ETL와 S3 Batch 서비스는 요금에 비해 활용도가 낮다고 생각한다.\n먼저 Glue ETL은 위 그림과 같이 input과 output을 정의하고 그 사이에 transform 작업을 정의할 수 있다.\nSpark의 DataFrame을 기반으로 하며 DynamicFrame, Built-In Transform 등을 사용하여 스크립트를 작성한다.\n서비스 중간에 추가되는 간단한 ETL Batch에 사용하기는 무난해보이지만 그게 아니라면 아래와 같은 사항들을 고려해야 한다.</p>\n<br>\n<h2 id=\"glue-etl은-dpu를-기준으로-요금이-계산된다\" style=\"position:relative;\"><a href=\"#glue-etl%EC%9D%80-dpu%EB%A5%BC-%EA%B8%B0%EC%A4%80%EC%9C%BC%EB%A1%9C-%EC%9A%94%EA%B8%88%EC%9D%B4-%EA%B3%84%EC%82%B0%EB%90%9C%EB%8B%A4\" aria-label=\"glue etl은 dpu를 기준으로 요금이 계산된다 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Glue ETL은 DPU를 기준으로 요금이 계산된다</h2>\n<p>Glue ETL의 요금은 DPU라는 하나의 처리 단위를 기준으로 산정되는데 1 DPU는 4CPU와 16GB의 메모리를 가진다.\nDPU 시간당 0.44 USD, 초 단위로 청구되며 Apache Spark 유형 ETL 작업당 최소 시간은 10분이다.\nSpark 기반의 ETL에서는 Executor에 대한 설정이 중요하다.\n작업에 따라 CPU가 많이 필요할 수도 있고 메모리가 많이 필요할 수도 있다.\n하지만 Glue는 DPU라는 단위로 고정되어 있다보니 비용 효율적으로 사용하기 어려웠다.\n만일 자체 클러스터를 사용하고 전체 파이프라인 내에서 리소스를 효율적으로 사용할 수 있다면\nGlueContext가 뜨는 시간까지 고려했을때 정말 저렴한 서비스인지 잘 모르겠다.</p>\n<br>\n<h2 id=\"glue-etl은-디버깅-모니터링-기능이-아직-부족하다\" style=\"position:relative;\"><a href=\"#glue-etl%EC%9D%80-%EB%94%94%EB%B2%84%EA%B9%85-%EB%AA%A8%EB%8B%88%ED%84%B0%EB%A7%81-%EA%B8%B0%EB%8A%A5%EC%9D%B4-%EC%95%84%EC%A7%81-%EB%B6%80%EC%A1%B1%ED%95%98%EB%8B%A4\" aria-label=\"glue etl은 디버깅 모니터링 기능이 아직 부족하다 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Glue ETL은 디버깅, 모니터링 기능이 아직 부족하다</h2>\n<p>Spark에는 Spark UI 라는 휼륭한 모니터링 대시보드가 존재하지만 Glue에서는 아직 이를 지원하지 않는다.\n대신 자체적으로 CloudWatch를 통해 메모리, 로그를 제공하는데 아직 지표가 많이 부족해보였다.\nDAG가 어떻게 구성되는지와 Shuffle 관련 지표도 볼 수가 없어 무거운 작업이라면 많은 노력이 필요하다. 아직 오픈한지 얼마 지나지 않은 서비스라 이 부분은 앞으로 많이 개선될거라 생각한다.</p>\n<br>\n<h1 id=\"step-function을-사용한-etl-workflow-관리\" style=\"position:relative;\"><a href=\"#step-function%EC%9D%84-%EC%82%AC%EC%9A%A9%ED%95%9C-etl-workflow-%EA%B4%80%EB%A6%AC\" aria-label=\"step function을 사용한 etl workflow 관리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Step Function을 사용한 ETL Workflow 관리</h1>\n<p>Step Function은 Serverless 기반의 Workflow 서비스다.\n여기에서는 가장 많이 사용하는 Airflow와 비교해가며 Serverless ETL이 가지는 특징을 설명해보려 한다.</p>\n<br>\n<h2 id=\"step-function은-asl이라는-언어로-정의된다\" style=\"position:relative;\"><a href=\"#step-function%EC%9D%80-asl%EC%9D%B4%EB%9D%BC%EB%8A%94-%EC%96%B8%EC%96%B4%EB%A1%9C-%EC%A0%95%EC%9D%98%EB%90%9C%EB%8B%A4\" aria-label=\"step function은 asl이라는 언어로 정의된다 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Step Function은 ASL이라는 언어로 정의된다</h2>\n<p>Step Function에 들어가는 각 단계에는 Lambda, Fargate 등의 서버리스 서비스가 들어갈 수 있다.\n그리고 각 단계는 Amazon States Language 라는 json 기반의 구조화된 언어로 정의된다.\nAirflow가 많이 사용되는 이유 중에 하나가 파이썬으로 DAG를 구성할 수 있다는 점인데\n이에 비해 json 기반의 Step Function은 너무 복잡하게 느껴졌다.</p>\n<br>\n<h2 id=\"step-function에는-operator-sensor가-없다\" style=\"position:relative;\"><a href=\"#step-function%EC%97%90%EB%8A%94-operator-sensor%EA%B0%80-%EC%97%86%EB%8B%A4\" aria-label=\"step function에는 operator sensor가 없다 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Step Function에는 Operator, Sensor가 없다</h2>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1u8wxsTHUK_TMh8ZUfuuY5d7OMbJSur4R\"></p>\n<p>Lambda와 같은 서버리스 서비스는 수행에 대한 제한 시간이 존재한다.\n각 단계가 대부분 람다 기반이다 보니 위 그림과 같이 Loop를 돌며 체크하는 패턴으로 Sensor를 구현한다. Airflow에는 리소스마다 미리 정의된 Operator, Sensor가 많지만 Step Function에서는 이를 다 구현해야 한다.\n만일 Loop를 피하고 싶다면 Fargate로 Sensor를 구현할 수 있지만 Fargate는 요금이 많이 나온다.</p>\n<br>\n<h2 id=\"정리하면서\" style=\"position:relative;\"><a href=\"#%EC%A0%95%EB%A6%AC%ED%95%98%EB%A9%B4%EC%84%9C\" aria-label=\"정리하면서 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>정리하면서</h2>\n<p>쓰다보니 단점만 나열한 것 같아 보이지만 AWS 서비스와 요금은 지속적으로 업데이트 되기 때문에\n나중에는 이러한 제한사항들이 해결될지도 모른다. 그리고 상황에 따라 적절히 사용한다면 장점이 많다.\n그리고 서버리스가 아니라 언급하지 않았지만 Managed Cluster 서비스인 EMR을 사용해서 모두 해결하는 방법도 있다.\n만일 Event 기반의 간단한 ETL 이라면 Serverless ETL이 가지는 장점을 크게 활용해보길 추천한다.</p>","excerpt":"15년 AWS Lambda가 출시된 이후, 뜨거운 반응을 보이며 다양한 서버리스 서비스들이 출시되었다.\n그 중 ETL…"}}},{"id":"c41958b4-0f03-5549-94c4-2e19fa5fcc89","title":"Amazon EKS에 Kubeflow 구축하기","slug":"eks-kubeflow","publishDate":"March 10, 2019","publishDateISO":"2019-03-10","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"46a42260-b4aa-51d5-aa64-b7247af33731","childMarkdownRemark":{"id":"fef60629-38e4-5c67-8b2f-f654ddcbf758","timeToRead":3,"html":"<p>AWS EKS는 Fully managed K8S 서비스 입니다. 이번 글에서는 EKS 환경에 Kubeflow를 구축하는 방법에 대해 정리해보겠습니다.</p>\n<ul>\n<li><a href=\"http://swalloow.github.io/why-kubeflow\">Why kubeflow in your Infrastructure</a></li>\n<li><a href=\"http://swalloow.github.io/eks-kubeflow\">Amazon EKS에 Kubeflow 구축하기</a></li>\n<li>Kubeflow의 ModelDB</li>\n<li>Kubeflow의 Hyper parameter Tuning (Katib)</li>\n</ul>\n<br>\n<h2 id=\"기본-환경-설치\" style=\"position:relative;\"><a href=\"#%EA%B8%B0%EB%B3%B8-%ED%99%98%EA%B2%BD-%EC%84%A4%EC%B9%98\" aria-label=\"기본 환경 설치 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>기본 환경 설치</h2>\n<p>Kubeflow를 설치하기 이전에 AWS CLI, Docker가 설치되어 있어야 합니다.\nEKS에서는 최근에 GPU 인스턴스인 P2, P3에 대한 지원을 제공하고 있습니다.\n이를 사용하기 위해 AWS Marketplace에서 <a href=\"https://aws.amazon.com/marketplace/pp/B07GRHFXGM\">EKS-optimized AMI with GPU Support</a>를 구독해주어야 합니다.</p>\n<p>EKS는 Web UI 또는 eksctl이라는 cli 도구를 사용해서 클러스터를 구성할 수 있습니다.\neksctl은 kubectl이나 kops와 유사한 명령어를 제공합니다.\n자세한 내용은 <a href=\"https://aws.amazon.com/ko/blogs/opensource/eksctl-eks-cluster-one-command/\">https://aws.amazon.com/ko/blogs/opensource/eksctl-eks-cluster-one-command/</a> 에서 참고하시면 됩니다.</p>\n<br>\n<h2 id=\"eks-클러스터-생성\" style=\"position:relative;\"><a href=\"#eks-%ED%81%B4%EB%9F%AC%EC%8A%A4%ED%84%B0-%EC%83%9D%EC%84%B1\" aria-label=\"eks 클러스터 생성 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>EKS 클러스터 생성</h2>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token comment\"># install eksctl</span>\n$ brew tap weaveworks/tap\n$ brew <span class=\"token function\">install</span> weaveworks/tap/eksctl\n\n<span class=\"token comment\"># create cluster</span>\n$ eksctl create cluster eks-cpu <span class=\"token punctuation\">\\</span>\n--node-type<span class=\"token operator\">=</span>c4.xlarge <span class=\"token punctuation\">\\</span>\n--timeout<span class=\"token operator\">=</span>40m <span class=\"token punctuation\">\\</span>\n--nodes<span class=\"token operator\">=</span><span class=\"token number\">2</span> <span class=\"token punctuation\">\\</span>\n--region<span class=\"token operator\">=</span>ap-northeast-2\n\n<span class=\"token comment\"># NVIDIA driver plugin</span>\nkubectl apply -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v1.11/nvidia-device-plugin.yml\nkubectl get nodes <span class=\"token string\">\"-o=custom-columns=NAME:.metadata.name,MEMORY:.status.allocatable.memory,CPU:.status.allocatable.cpu,GPU:.status.allocatable.nvidia\\.com/gpu\"</span></code></pre></div>\n<ul>\n<li>먼저 Homebrew로 <code class=\"language-text\">eksctl</code>을 설치합니다. 이후 아래의 명령어를 통해 c4 인스턴스 기반의 EKS 클러스터를 생성하고 Memory, CPU, GPU 정보를 확인해줍니다.</li>\n<li>GPU 인스턴스로 클러스터를 생성하고 싶다면 생성하기 이전에 EC2 Limit 페이지에서 p2 또는 p3 인스턴스의 limit을 확인해야 합니다. 0으로 되어있다면 <code class=\"language-text\">Request limit Increase</code>가 필요합니다.</li>\n<li>GPU-enabled worker를 가지는 EKS 클러스터를 생성한다면 NVIDIA driver plugin을 활성화시키는 과정이 필요합니다.</li>\n<li>Create cluster에서 <code class=\"language-text\">AccessDenied</code> 오류가 발생하는 경우, 사용할 IAM 유저를 생성하고 EKS 관련 permission과 <code class=\"language-text\">AWSCloudFormationReadOnlyAccess</code>를 추가해주어야 합니다. EKS는 현재 기준 1.11 버전을 default로 사용하고 있습니다.</li>\n</ul>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1y10f8hW0KFZGSn7WLFne_aqUV4YjPQqJ\" alt=\"eks\"></p>\n<p>EKS 메뉴에 가보시면 EC2 인스턴스, 네트워크 설정이 완료된 것을 확인하실 수 있습니다.\nAWS CloudFormation에서 cluster와 node-group에 대한 stack이 생성됩니다.</p>\n<p>K8S 대시보드는 <a href=\"https://docs.aws.amazon.com/ko_kr/eks/latest/userguide/dashboard-tutorial.html\">AWS EKS 공식 문서</a>를 참고하여 띄울 수 있습니다.</p>\n<br>\n<h2 id=\"ksonnet을-이용한-kubeflow-설치\" style=\"position:relative;\"><a href=\"#ksonnet%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-kubeflow-%EC%84%A4%EC%B9%98\" aria-label=\"ksonnet을 이용한 kubeflow 설치 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>ksonnet을 이용한 KubeFlow 설치</h2>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token comment\"># install ksonnet</span>\n$ brew <span class=\"token function\">install</span> ksonnet/tap/ks\n$ ks version\nksonnet version: <span class=\"token number\">0.13</span>.1\njsonnet version: v0.11.2\nclient-go version: kubernetes-1.10.4\n\n<span class=\"token comment\"># install kubeflow</span>\n$ <span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">KUBEFLOW_TAG</span><span class=\"token operator\">=</span>v0.4.1\n$ <span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">KUBEFLOW_SRC</span><span class=\"token operator\">=</span>/tmp/kubeflow_src\n$ <span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">KFAPP</span><span class=\"token operator\">=</span>eks-kubeflow\n\n$ <span class=\"token function\">mkdir</span> <span class=\"token variable\">${KUBEFLOW_SRC}</span> <span class=\"token operator\">&amp;&amp;</span> <span class=\"token builtin class-name\">cd</span> <span class=\"token variable\">${KUBEFLOW_SRC}</span>\n$ <span class=\"token function\">curl</span> https://raw.githubusercontent.com/kubeflow/kubeflow/<span class=\"token variable\">${KUBEFLOW_TAG}</span>/scripts/download.sh <span class=\"token operator\">|</span> <span class=\"token function\">bash</span>\n\n$ <span class=\"token function\">sh</span> <span class=\"token variable\">${KUBEFLOW_SRC}</span>/scripts/kfctl.sh init <span class=\"token variable\">${KFAPP}</span> --platform none\n$ <span class=\"token builtin class-name\">cd</span> <span class=\"token variable\">${KFAPP}</span>\n$ <span class=\"token function\">sh</span> <span class=\"token variable\">${KUBEFLOW_SRC}</span>/scripts/kfctl.sh generate k8s\n$ <span class=\"token function\">sh</span> <span class=\"token variable\">${KUBEFLOW_SRC}</span>/scripts/kfctl.sh apply k8s</code></pre></div>\n<p>ksonnet으로 KubeFlow를 설치하기 이전에 먼저 Homebrew로 ksonnet을 설치합니다.</p>\n<br>\n<h2 id=\"kubeflow\" style=\"position:relative;\"><a href=\"#kubeflow\" aria-label=\"kubeflow permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>KubeFlow</h2>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1W9rnEB-Bn5IZjLOymYXNxMPNclyY4eJn\" alt=\"kubeflow-pods\">\n<img src=\"http://drive.google.com/uc?export=view&#x26;id=15IWqbbib_vhB_k4FlUK_K39ERUbkVHr0\" alt=\"kubeflow-pvc\"></p>\n<p>KubeFlow를 설치하고 나면 Pods, Deployment, Service, ConfigMap 등 모든 컴포넌트들이 자동으로 배포됩니다. default로 PVC는 EBS gp2 볼륨이 설정된 것을 확인하실 수 있습니다.</p>\n<p>EKS에서는 IAM 기반의 RBAC 인증을 사용합니다.\n아래의 명령어를 통해 EKS의 JupyterHub를 로컬의 8080 포트로 포워딩해서 접속하실 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ kubectl port-forward svc/jupyter-lb -n kubeflow <span class=\"token number\">8080</span>:80</code></pre></div>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1XNiADQX6faiejXKz3OlpwYMhqZQ6xPoz\" alt=\"kubeflow-jupyterhub\"></p>\n<p>위와 같이 설치하고 난 이후에 KubeFlow 문서의 git summerization 튜토리얼을 그대로 따라하실 수 있습니다. 모든 컴포넌트가 자동으로 배포되다 보니 생략하고 넘어가는 경우가 많은데 production 환경에서 사용하려면 각 설정 YAML 파일을 내 환경에 맞도록 수정할 필요가 있습니다. 삭제는 아래의 명령어를 통해 실행시키면 됩니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token builtin class-name\">cd</span> <span class=\"token variable\">${KUBEFLOW_SRC}</span>/<span class=\"token variable\">${KFAPP}</span>\n$ <span class=\"token function\">sh</span> <span class=\"token variable\">${KUBEFLOW_SRC}</span>/scripts/kfctl.sh delete k8s</code></pre></div>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<ul>\n<li><a href=\"https://aws.amazon.com/ko/blogs/opensource/kubeflow-amazon-eks/\">https://aws.amazon.com/ko/blogs/opensource/kubeflow-amazon-eks/</a></li>\n<li><a href=\"https://github.com/aws-samples/machine-learning-using-k8s/blob/master/kubeflow.md\">https://github.com/aws-samples/machine-learning-using-k8s/blob/master/kubeflow.md</a></li>\n<li><a href=\"https://eksctl.io/\">https://eksctl.io/</a></li>\n</ul>\n<br>","excerpt":"AWS EKS는 Fully managed K8S 서비스 입니다. 이번 글에서는 EKS 환경에 Kubeflow…"}}},{"id":"b8091786-4329-5d05-802b-b6b069b38702","title":"Why Kubeflow in your Infrastructure?","slug":"why-kubeflow","publishDate":"March 09, 2019","publishDateISO":"2019-03-09","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"9ea4a340-b124-57db-977d-2a8c3a1a9cdf","childMarkdownRemark":{"id":"a056a78c-da2c-502e-8b6d-1656d874de89","timeToRead":2,"html":"<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1JO_ek8Dyr-i5-uvjd4NpzMKBqL6PICDV\" alt=\"Hidden Technical Dept in Machine Learning Systems\"></p>\n<p>실제 ML을 서비스에 적용시키는 일은 위 그림에 나타난 바와 같이 ML 모델링 보다 이외의 작업들이 많이 필요합니다. 특히 서비스의 여러 기능에 ML을 적용시키려 하는 경우, 이러한 파이프라인이 복잡해지고 유지보수가 힘든 방향으로 가는 경우가 많습니다. 이러한 이유로 규모있는 IT 서비스 회사들은 공통의 ML 플랫폼을 구축하곤 합니다.</p>\n<p>앞으로 소개하려는 Kubeflow는 Kubernetes를 기반으로 하는 오픈소스 ML Toolkit 입니다. 아직 버전이 낮아 production 환경에서 사용하는 곳이 많지 않지만 미리 알아두면 좋을 것 같아 컴포넌트들을 하나씩 분석해보려 합니다.</p>\n<ul>\n<li><a href=\"http://swalloow.github.io/why-kubeflow\">Why kubeflow in your Infrastructure</a></li>\n<li><a href=\"http://swalloow.github.io/eks-kubeflow\">Amazon EKS에 Kubeflow 구축하기</a></li>\n<li>Kubeflow의 ModelDB</li>\n<li>Kubeflow의 Hyper parameter Tuning (Katib)</li>\n</ul>\n<br>\n<h2 id=\"why-kubeflow\" style=\"position:relative;\"><a href=\"#why-kubeflow\" aria-label=\"why kubeflow permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Why Kubeflow?</h2>\n<p>이미 기존의 인프라를 기반으로 자동화된 ML Workflow가 구축되어 있다면, 굳이 Kubeflow로 옮길 필요는 없습니다. 하지만 아래와 같은 상황을 가진 팀이라면 Kubeflow는 좋은 선택지가 될 수 있습니다.</p>\n<ul>\n<li>이미 Kubernetes 기반의 인프라를 사용하고 있으며, ML 인프라를 구축하려는 경우</li>\n<li>서비스를 On-premise, Multi-cloud 환경에 배포해야 하는 경우</li>\n<li>Scalable ML이 필수적이며, 기존의 여러 ML 서비스를 쉽게 배포하고 리소스 관리 비용을 줄이려는 경우</li>\n<li>Research Engineer, Data Scientist 를 위한 인프라 관리의 복잡성을 최소화하고 일관된 인터페이스를 제공하여 몇 번의 클릭만으로 설정을 쉽게 하고 싶은 경우</li>\n</ul>\n<br>\n<h2 id=\"consistency-in-infrastructure\" style=\"position:relative;\"><a href=\"#consistency-in-infrastructure\" aria-label=\"consistency in infrastructure permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Consistency in Infrastructure</h2>\n<p>Kubeflow는 Kubernetes 기반의 인프라가 가지는 장점을 그대로 가지고 있습니다. 각 서비스에 대한 Monitoring, Health Check, Replication 등의 기본 요구사항을 갖추고 있으며 쉬운 배포 환경을 제공합니다. 이외에도 아래와 같은 usecase에서 활용될 수 있습니다.</p>\n<ul>\n<li>Research Engineer들이 인프라가 아닌 모델링에만 집중할 수 있는 환경을 제공할 수 있습니다. 모두가 Docker 기반의 추상화된 환경에서 연구를 할 수 있으며, 동일한 데이터, 연구 결과를 공유할 수 있습니다. 가상화된 GPU 환경에서 모델을 분산 학습시킬 수 있으며, TensorFlow, PyTorch, MXNet 등 다양한 프레임워크 환경을 지원할 수 있습니다.</li>\n<li>Kubeflow는 end-to-end를 제공하기 때문에 ML 프로젝트를 production에 반영하는 과정이 단순해집니다. 지속적인 데이터 파이프라인을 구축하여 <strong>argo</strong>를 통해 모델을 업데이트 하고, <strong>seldon</strong>을 통해 production 환경을 테스트해 볼 수 있습니다.</li>\n<li><strong>Katib</strong>을 통해 Hyper parameter tuning 과정을 쉽게 자동화 할 수 있습니다. <strong>Katib</strong>에서 제공하는 인터페이스를 통해 여러 어플리케이션으로 확장시킬 수 있으며, 튜닝 결과를 지속적으로 기록하고 공유할 수 있습니다.</li>\n</ul>\n<br>\n<h2 id=\"resource-utilization-by-the-training--serving-modules\" style=\"position:relative;\"><a href=\"#resource-utilization-by-the-training--serving-modules\" aria-label=\"resource utilization by the training  serving modules permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Resource utilization by the Training / Serving modules</h2>\n<p>테스트 환경을 쉽게 구축할 수 있으며, 클라우드 비용을 최적화시킬 수 있습니다. K8S 클러스터는 동일한 인스턴스에 여러 Pod을 실행시킬 수 있습니다. 따라서, 사용하는 리소스를 팀 또는 프로젝트 단위로 namespace를 분리시켜 리소스 사용량을 모니터링 할 수 있습니다.</p>\n<p>일반적인 클라우드 인프라 환경을 서비스 라이프사이클과 연계되어 있지 않기 때문에 training job이 끝난 이후에도 인스턴스가 켜져 있기 때문에 그에 대한 비용을 지불해야 합니다. 하지만 Kubeflow를 사용하는 경우, 사용량에 따라 클러스터를 auto scaling 한다거나 spot instance로 training job을 실행시킬 수 있습니다.</p>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<ul>\n<li><a href=\"https://medium.com/kubeflow/why-kubeflow-in-your-infrastructure-56b8fabf1f3e\">https://medium.com/kubeflow/why-kubeflow-in-your-infrastructure-56b8fabf1f3e</a></li>\n</ul>","excerpt":"Hidden Technical Dept in Machine Learning Systems 실제 ML…"}}},{"id":"50a917d3-58d2-56fb-b3c1-101b359f2f8a","title":"Apache Airflow에 기여하면서 배운 점들","slug":"airflow-contrib","publishDate":"December 08, 2018","publishDateISO":"2018-12-08","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"a216f939-c13e-5c9e-bf73-f38e51932651","childMarkdownRemark":{"id":"188eab1d-542f-5ef1-b928-da67dfe8eee5","timeToRead":4,"html":"<p>Apache Airflow는 코드를 통해 워크플로우를 관리하고 모니터링 할 수 있도록 도와주는 플랫폼이다.\nAirflow 프로젝트에 대한 설명은 다른 글에서도 많이 다루기 때문에 생략하고\n이 글에서는 처음으로 아파치 프로젝트에 기여해본 경험을 정리해보려 한다.</p>\n<br>\n<h2 id=\"기여하게-된-배경\" style=\"position:relative;\"><a href=\"#%EA%B8%B0%EC%97%AC%ED%95%98%EA%B2%8C-%EB%90%9C-%EB%B0%B0%EA%B2%BD\" aria-label=\"기여하게 된 배경 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>기여하게 된 배경</h2>\n<p>당시에 관리하던 데이터 인프라에는 의존성이 얽혀있는 배치 작업이 상당히 많았다.\n여기에서 의존성이 얽혀있다는 말은 A 작업과 B 작업이 성공적으로 끝나고 난 뒤 C 작업을 해야하는 경우를 말한다.\n또한 각 작업들은 서로 다른 시간에 스케줄링 되어야 했고, 작업이 실패하는 경우 재시도 또는 특정 로직을 실행시킬 수 있어야 했다.</p>\n<p>처음에는 단순한 구조이다 보니 스크립트로 관리했지만 점차 늘어나는 운영 이슈에 대응하기 위해 Airflow를 활용하기로 결정했다.\n하지만 운영하다 보니 AWS 관련 컴포넌트들의 여러 버그를 발견하게 되었고 이를 수정하기 위해 PR을 추가했었다.</p>\n<br>\n<h2 id=\"아파치-프로젝트-pr-프로세스\" style=\"position:relative;\"><a href=\"#%EC%95%84%ED%8C%8C%EC%B9%98-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-pr-%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4\" aria-label=\"아파치 프로젝트 pr 프로세스 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>아파치 프로젝트 PR 프로세스</h2>\n<p>아파치 프로젝트는 이슈 관리 도구로 JIRA를 사용한다. CI 도구는 프로젝트마다 다른 편인데 Airflow의 경우 TravisCI를 사용한다.\n모든 프로젝트에는 처음 프로젝트에 기여하려는 개발자를 위해 <strong>CONTRIBUTING.md</strong> 라는 문서를 제공한다.\n문서에는 개발 및 테스트 환경을 어떻게 구축해야하는지, 지켜야할 규칙, PR 가이드라인 등에 대해 설명되어 있다.\n그리고 PR template를 준수해야 하는데 잘 모르겠다면, 이전 PR들을 확인하고 비슷한 양식으로 작성하면 된다.</p>\n<p>내가 처음 접했던 Airflow 문서에는 AWS 관련 Hook, Operator도 반영되어 있지 않았다.\n그래서 첫 PR로 AWS, GCP 관련 컴포넌트를 업데이트하는 문서 기여를 하게 되었다.\n문서 관리에는 <a href=\"https://readthedocs.org/\">readthedocs</a>를 사용하고 있었고 Sphinx 빌드를 통해 문서를 확인할 수 있었다.</p>\n<p>사용하다보니 특히 EMR 관련 Hook과 Operator에 버그가 많았다.\n만일 JIRA에 이미 등록되어 있는 이슈가 아니라면 이슈를 새로 생성한 다음 PR을 추가해주어야 한다.</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1d0SNiE9qJza0CtmU8S2k8h4Q3iRPE8vN\"></p>\n<p>비슷한 이슈를 겪고 있는 사람들이 있어서 좀 신기했다.\n그리고 <strong>아주 작은 수정이라도 테스트 케이스를 추가</strong>해야 한다는 사실을 알게 되었다.</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1Re-gmGnEOlB8hxPhAkbjYQpQ-6kOzm6j\"></p>\n<p>양식만 잘 지키면 커미터들은 정말 친절하다. 내가 파악하지 못한 부분까지 알려주고, 코드 리뷰도 받을 수 있다.\n다른 PR을 참고하면서 많이 배울 수 있었다.</p>\n<br>\n<h2 id=\"클라우드-인프라-테스트-방법\" style=\"position:relative;\"><a href=\"#%ED%81%B4%EB%9D%BC%EC%9A%B0%EB%93%9C-%EC%9D%B8%ED%94%84%EB%9D%BC-%ED%85%8C%EC%8A%A4%ED%8A%B8-%EB%B0%A9%EB%B2%95\" aria-label=\"클라우드 인프라 테스트 방법 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>클라우드 인프라 테스트 방법</h2>\n<p>AWS는 기본적으로 클라우드 환경이다.\n따라서 과금문제로 인해 실제로 추가, 변경한 오퍼레이터가 잘 동작하는지 매번 확인해보기가 힘들다.\nAirflow에서는 AWS 서비스를 Mocking 하기 위해 <a href=\"https://github.com/spulec/moto\">moto</a> 라는 라이브러를 활용해서 테스트를 작성한다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token decorator annotation punctuation\">@mock_s3</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">test_my_model_save</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\"># Create Bucket so that test can run</span>\n    conn <span class=\"token operator\">=</span> boto3<span class=\"token punctuation\">.</span>resource<span class=\"token punctuation\">(</span><span class=\"token string\">'s3'</span><span class=\"token punctuation\">,</span> region_name<span class=\"token operator\">=</span><span class=\"token string\">'us-east-1'</span><span class=\"token punctuation\">)</span>\n    conn<span class=\"token punctuation\">.</span>create_bucket<span class=\"token punctuation\">(</span>Bucket<span class=\"token operator\">=</span><span class=\"token string\">'mybucket'</span><span class=\"token punctuation\">)</span>\n    model_instance <span class=\"token operator\">=</span> MyModel<span class=\"token punctuation\">(</span><span class=\"token string\">'steve'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'is awesome'</span><span class=\"token punctuation\">)</span>\n    model_instance<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    body <span class=\"token operator\">=</span> conn<span class=\"token punctuation\">.</span>Object<span class=\"token punctuation\">(</span><span class=\"token string\">'mybucket'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'steve'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token string\">'Body'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>decode<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">assert</span> body <span class=\"token operator\">==</span> <span class=\"token string\">'is awesome'</span></code></pre></div>\n<p>위와 같이 moto에서 미리 정의한 mock object를 decorator를 사용하여 쉽게 활용할 수 있다.\n하지만 AWS에서 공식으로 지원하는 라이브러리가 아니다보니 업데이트가 늦어지기도 한다.\n이런 이유로 인해 unittest의 mock으로 작성된 테스트 코드도 많이 있다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">TestEmrAddStepsOperator</span><span class=\"token punctuation\">(</span>unittest<span class=\"token punctuation\">.</span>TestCase<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\"># When</span>\n    _config <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">{</span>\n        <span class=\"token string\">'Name'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'test_step'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'ActionOnFailure'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'CONTINUE'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'HadoopJarStep'</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token string\">'Jar'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'command-runner.jar'</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">'Args'</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span>\n                <span class=\"token string\">'/usr/lib/spark/bin/run-example'</span>\n            <span class=\"token punctuation\">]</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">]</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">setUp</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        configuration<span class=\"token punctuation\">.</span>load_test_config<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\"># Mock out the emr_client (moto has incorrect response)</span>\n        self<span class=\"token punctuation\">.</span>emr_client_mock <span class=\"token operator\">=</span> MagicMock<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>operator <span class=\"token operator\">=</span> EmrAddStepsOperator<span class=\"token punctuation\">(</span>\n            task_id<span class=\"token operator\">=</span><span class=\"token string\">'test_task'</span><span class=\"token punctuation\">,</span>\n            job_flow_id<span class=\"token operator\">=</span><span class=\"token string\">'j-8989898989'</span><span class=\"token punctuation\">,</span>\n            aws_conn_id<span class=\"token operator\">=</span><span class=\"token string\">'aws_default'</span><span class=\"token punctuation\">,</span>\n            steps<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>_config\n        <span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">test_init</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>assertEqual<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>operator<span class=\"token punctuation\">.</span>aws_conn_id<span class=\"token punctuation\">,</span> <span class=\"token string\">'aws_default'</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>assertEqual<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>operator<span class=\"token punctuation\">.</span>emr_conn_id<span class=\"token punctuation\">,</span> <span class=\"token string\">'emr_default'</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">test_render_template</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        ti <span class=\"token operator\">=</span> TaskInstance<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>operator<span class=\"token punctuation\">,</span> DEFAULT_DATE<span class=\"token punctuation\">)</span>\n        ti<span class=\"token punctuation\">.</span>render_templates<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n        expected_args <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">{</span>\n            <span class=\"token string\">'Name'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'test_step'</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">'ActionOnFailure'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'CONTINUE'</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">'HadoopJarStep'</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n                <span class=\"token string\">'Jar'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'command-runner.jar'</span><span class=\"token punctuation\">,</span>\n                <span class=\"token string\">'Args'</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span>\n                    <span class=\"token string\">'/usr/lib/spark/bin/run-example'</span>\n                <span class=\"token punctuation\">]</span>\n            <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">]</span>\n\n        self<span class=\"token punctuation\">.</span>assertListEqual<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>operator<span class=\"token punctuation\">.</span>steps<span class=\"token punctuation\">,</span> expected_args<span class=\"token punctuation\">)</span>\n\n\n<span class=\"token keyword\">if</span> __name__ <span class=\"token operator\">==</span> <span class=\"token string\">'__main__'</span><span class=\"token punctuation\">:</span>\n    unittest<span class=\"token punctuation\">.</span>main<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>unittest로 작성된 테스트 케이스는 API로 주고 받는 json을 직접 정의해줘야 하는 번거로움이 있다.\n테스트 케이스를 작성하고 난 다음 바로 PR을 추가하는 것보다 로컬 CI를 미리 돌려보는게 좋다.</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1MEOqsKocQTV8y5y_y2xrpIppkw2ndOvT\"></p>\n<p>TravisCI는 오픈소스인 경우 무료로 사용할 수 있으며, yml 파일에 미리 정의되어 있으니 참고하면 된다. 로컬에서 CI가 통과되고 나면 PR을 추가해도 좋다.\n작업이 길어지면서 커밋이 여러 개로 늘어나는 경우, <strong>commit을 squash</strong> 해주는 것이 좋다.\n(나중에 문제가 생겼을 때 쉽게 rebase 하기 위함)</p>\n<br>\n<h2 id=\"잡다한-정리\" style=\"position:relative;\"><a href=\"#%EC%9E%A1%EB%8B%A4%ED%95%9C-%EC%A0%95%EB%A6%AC\" aria-label=\"잡다한 정리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>잡다한 정리</h2>\n<ul>\n<li><a href=\"https://issues.apache.org/jira/browse/AIRFLOW-713\">[AIRFLOW-713] EmrCreateJobFlowOperator and EmrAddStepsOperator attributes are not jinjafied</a></li>\n<li><a href=\"https://issues.apache.org/jira/browse/AIRFLOW-950\">[AIRFLOW-950] Missing AWS integrations on documentation::integrations</a></li>\n<li><a href=\"https://issues.apache.org/jira/browse/AIRFLOW-1453\">[AIRFLOW-1453] Add 'steps' into template_fields in EmrAddSteps</a></li>\n<li><a href=\"https://issues.apache.org/jira/browse/AIRFLOW-1436\">[AIRFLOW-1436, AIRFLOW-1475] EmrJobFlowSensor consideres Cancelled step as Successful</a></li>\n</ul>\n<p>그 동안 5개 정도의 버그를 해결했고 수정했던 AWS EMR 관련 버그들은 1.9 - 10 버전에 모두 반영 되었다.\n이외에도 Airflow에는 여전히 자잘한 버그가 많이 남아있다.\n(Docker로 운영했을 때 로그가 이상하게 나타난다거나, SubDag Deadlock 문제 등)\n당시에 블로그를 열심히 했다면 운영 관련해서 글을 남겼을텐데 하는 아쉬움이 남아있다.</p>\n<p>어쨋든 Airflow를 적용하고 난 뒤, 편히 새벽에 잠들 수 있게 되었다.\n지금은 머신러닝 파이프라인 관련 도구가 많이 나왔지만, Airflow도 충분히 해당 영역을 커버할 수 있다.</p>\n<p>그리고 오픈소스에 대해 다시 한번 생각해보게 되었다.\n많은 사람들이 참여하는 오픈소스이다 보니 당연히 버그나 이슈가 생길 수 있고,\n문제가 생겼을 때 고쳐달라고 강요하거나 기다리는 것보다 스스로 수정해서 기여하는 것이 올바른 태도가 아닌가 싶다.</p>","excerpt":"Apache Airflow는 코드를 통해 워크플로우를 관리하고 모니터링 할 수 있도록 도와주는 플랫폼이다.\nAirflow…"}}},{"id":"c548511f-3e1d-5c2e-a96f-b0e297f133e2","title":"Kafka Connect로 S3에 데이터를 저장해보자","slug":"kafka-connect","publishDate":"November 16, 2018","publishDateISO":"2018-11-16","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"e81fb246-b516-57b8-bf98-7771d7cfb4fc","childMarkdownRemark":{"id":"26d0807b-21d9-5de5-864e-e44c27cc2883","timeToRead":4,"html":"<p>Kafka에는 정말 유용한 컴포넌트들이 존재합니다.\n오늘은 그 중 하나인 Kafka-Connect에 대해 알아보고,\nConfluent에서 제공하는 Kafka-Connect-S3를 활용하여\nS3로 데이터를 저장하는 방법에 대해 정리해보려고 합니다.</p>\n<br>\n<h2 id=\"kafka-connect\" style=\"position:relative;\"><a href=\"#kafka-connect\" aria-label=\"kafka connect permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Kafka Connect</h2>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=172qcC4a0mgYnkeZHlH7HH4lar1dAebA3\" alt=\"kafka-connect\"></p>\n<p>우리는 서버로부터 생성되는 데이터를 실시간으로 Kafka에 보내기도 하고,\nKafka Topic에 쌓여있는 데이터를 실시간으로 RDBMS, Object Storage와 같은 시스템에 보내기도 합니다.\nKafka Connect는 위의 그림과 같이 다양한 시스템과 Kafka 사이의 연결을 도와주는 역할을 하는 컴포넌트입니다.\nSource System에서 Kafka로 들어가는 Connector를 Source Connect라 부르고,\nKafka에서 Target System으로 보내는 Connector를 Sink Connect라 부릅니다.</p>\n<p>Kafka Connect는 JSON, Avro, Protobuf 등의 다양한 직렬화 포멧을 지원하며\nKafka Schema Registry와 연동시켜 공통된 스키마 지정을 할 수도 있습니다.</p>\n<p>사실 Fluentd와 ELK Stack에서 사용하는 Logstash 등 서로 다른 시스템 간의 브릿지 역할을 하는 프레임워크들은 다양하게 존재합니다.\n하지만 Kafka Connect가 갖는 강점은 Kafka와 긴밀히 연동되어 있다는 점 입니다.</p>\n<p>Kafka Connect를 사용하지 않고 데이터를 실시간으로 전달하기 위해서는 Producer, Consumer API를 사용해야 합니다.\n이 과정에서 이미 처리되거나 실패한 데이터를 추적한다거나, 데이터 분산처리, 작업을 배포하는 등의 작업을 수행해야만 합니다.</p>\n<p>Kafka Connect는 앞의 모든 작업을 수행할 뿐만 아니라 connector task를 클러스터 전체에 자동으로 배포합니다.\n또한, Connect Worker 중에 하나가 실패하거나 Network partition이 발생하더라도 실행하던 작업을 나머지 Worker들에게 자동으로 재조정합니다.\nOffset을 자동으로 관리, 유지하기 때문에 재시작하더라도 중단 시점부터 다시 시작할 수 있고 (Exactly Once Delivery),\nHigh performance Kafka library로 작성되어 빠르며 불필요한 polling 작업을 수행하지 않습니다.\n무엇보다 코드 한 줄 없이 사용하기 편하다는 것도 큰 강점입니다.\n혹시 Kafka를 이미 중앙 집중형 로그 저장소로 사용하고 있다면 Kafka Connect를 고려해볼만 하다고 생각합니다.</p>\n<br>\n<h2 id=\"kafka-connect-s3\" style=\"position:relative;\"><a href=\"#kafka-connect-s3\" aria-label=\"kafka connect s3 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Kafka-Connect-S3</h2>\n<p>이 글에서는 Confluent로 Kafka를 설치하지 않은 경우를 예시로 들겠습니다.\n이미 confluent-hub를 설치하셨거나 Confluent로 Kafka를 설치하셨다면 공식문서를 따라가시면 됩니다.</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1R80lOarW9k1RGv2kYAYxNz_-q6wUsm28\" alt=\"aws-kafka-s3\"></p>\n<p>데이터 인프라가 AWS 환경에 구축되어 있다면 S3를 Cold Storage로 많이 사용하게 됩니다.\n최대한 단순하게 그림을 그려보면 위의 그림과 같은 아키텍쳐가 나오게 됩니다.\n여기에서는 Kafka에서 S3로 실시간 데이터를 저장하기 위해 Kafka-Connect-S3를 사용하게 됩니다.</p>\n<p>먼저 confluent에서 kafka-connect-s3를 다운받아 plugins 경로에 추가합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token function\">wget</span> https://api.hub.confluent.io/api/plugins/confluentinc/kafka-connect-s3/versions/4.1.1/archive\n$ <span class=\"token function\">unzip</span> archive\n$ <span class=\"token function\">mkdir</span> -p plugins/kafka-connect-s3\n$ <span class=\"token function\">cp</span> confluentinc-kafka-connect-s3-4.1.1/lib/* plugins/kafka-connect-s3/</code></pre></div>\n<p>이제 kafka config 경로에 <code class=\"language-text\">connect.properties</code>라는 이름으로 설정 파일을 추가합니다.\n<code class=\"language-text\">bootstrap.servers</code>와 <code class=\"language-text\">plugin.path</code> 경로는 상황에 맞게 수정하시면 됩니다.\n추가로 kafka 클러스터를 private network로 연결하고 싶다면 9093 포트를 사용해주시면 됩니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\"># Kafka broker IP addresses to connect to\nbootstrap.servers=localhost:9092\n\n# Path to directory containing the connector jar and dependencies\nplugin.path=/home/ec2-user/kafka/plugins\n\n# Converters to use to convert keys and values\nkey.converter=org.apache.kafka.connect.storage.StringConverter\nvalue.converter=org.apache.kafka.connect.storage.StringConverter\n\n# The internal converters Kafka Connect uses for storing offset and configuration data\ninternal.key.converter=org.apache.kafka.connect.json.JsonConverter\ninternal.value.converter=org.apache.kafka.connect.json.JsonConverter\ninternal.key.converter.schemas.enable=false\ninternal.value.converter.schemas.enable=false\noffset.storage.file.filename=/tmp/connect.offsets</code></pre></div>\n<br>\n<p>기존 클러스터에 Authentication credentials, encryption이 설정되어 있다면,\nconnect.properties에 관련 설정을 추가해주셔야 합니다.</p>\n<p>다음 S3에 데이터가 저장될 Bucket을 생성하고, AWS Credentials를 설정합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ pip <span class=\"token function\">install</span> awscli\n$ aws configure</code></pre></div>\n<p>sink connector 관련 설정 파일을 <code class=\"language-text\">s3-sink.properties</code>라는 이름으로 config 경로에 추가합니다.\ntopics와 s3.bucket.name의 이름은 맞게 수정해주셔야 합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">name=s3-sink\nconnector.class=io.confluent.connect.s3.S3SinkConnector\ntasks.max=1\ntopics=my-topic-name\ns3.region=ap-northeast-2\ns3.bucket.name=my-bucket-name\ns3.compression.type=gzip\ns3.part.size=5242880\nflush.size=3\nstorage.class=io.confluent.connect.s3.storage.S3Storage\nformat.class=io.confluent.connect.s3.format.json.JsonFormat\nschema.generator.class=io.confluent.connect.storage.hive.schema.DefaultSchemaGenerator\npartitioner.class=io.confluent.connect.storage.partitioner.TimeBasedPartitioner\npartition.duration.ms=3600000\npath.format=YYYY-MM-dd\nlocale=KR\ntimezone=UTC\nschema.compatibility=NONE</code></pre></div>\n<br>\n<p>이제 Kafka 설치 경로로 이동하고 Kafka-Connect를 실행시킵니다.\n여기에서는 standalone mode로 실행시켰지만, 경우에 따라 cluster mode로 실행하거나\ndocker container로 실행시켜도 됩니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">./bin/connect-standalone.sh connect.properties s3-sink.properties</code></pre></div>\n<p>이제 지정한 S3 Bucket의 topic/my-topic-name/2018-11-16 경로에 가시면\n지정한 설정 값에 따라 파일이 저장되는 것을 확인하실 수 있습니다.</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1bepmpAHi7kwUnqvGOwyq0i8jSMIhhMeU\"></p>\n<p>이미 Yahoo의 kafka-manager를 사용하고 계신 분들은 consumers 메뉴로 가시면\ntopic 마다 lag도 모니터링할 수 있습니다.</p>\n<br>\n<h2 id=\"kafka-connect-s3-configuration\" style=\"position:relative;\"><a href=\"#kafka-connect-s3-configuration\" aria-label=\"kafka connect s3 configuration permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Kafka-Connect-S3 Configuration</h2>\n<p>데이터 인프라에 맞게 수정해야할 옵션은 아래와 같습니다.</p>\n<ul>\n<li><strong>s3.part.size</strong>: S3의 multi part upload 사이즈를 지정</li>\n<li><strong>flush.size</strong>: file commit 시 저장할 record의 수 (파일 사이즈와 연관)</li>\n<li><strong>partitioner.class</strong>: partition 기준을 지정 (TimeBasedPartitioner는 시간을 기준으로 파티셔닝)</li>\n</ul>\n<p>이외에도 Avro Format과 Schema Registry를 사용하신다면 <code class=\"language-text\">format.class</code>, <code class=\"language-text\">schema.generator.class</code>를 수정해야 합니다.\n더 자세한 내용은 <a href=\"https://docs.confluent.io/5.0.0/connect/kafka-connect-s3/configuration_options.html#s3-configuration-options\">공식문서</a>에서 확인하시면 됩니다.</p>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<p>사실 Kafka는 이미 대부분의 데이터 파이프라인에서 활용하고 있다는 것이 강점이라고 생각합니다.\nETL 과정이 다양하고 복잡할 수록 새로운 프레임워크가 추가되고 아키텍쳐가 복잡해지기 마련인데,\nKafka의 다양한 컴포넌트들을 잘 활용하면 아키텍쳐를 단순화시킬 수도 있습니다.</p>\n<ul>\n<li><a href=\"https://www.confluent.io/blog/kafka-connect-deep-dive-converters-serialization-explained\">https://www.confluent.io/blog/kafka-connect-deep-dive-converters-serialization-explained</a></li>\n<li><a href=\"https://docs.confluent.io/5.0.0/connect/kafka-connect-s3/index.html\">https://docs.confluent.io/5.0.0/connect/kafka-connect-s3/index.html</a></li>\n</ul>","excerpt":"Kafka에는 정말 유용한 컴포넌트들이 존재합니다.\n오늘은 그 중 하나인 Kafka-Connect에 대해 알아보고,\nConfluent…"}}},{"id":"6e05249f-6d11-5fe8-9c0f-2ad22a78c83c","title":"Raft consensus algorithm","slug":"raft-consensus","publishDate":"September 01, 2018","publishDateISO":"2018-09-01","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"c603432b-0bfc-5d13-92ef-bb9f6b0614d0","childMarkdownRemark":{"id":"0ec7ec4f-c7ec-5944-902c-ba22c2a35bf8","timeToRead":2,"html":"<p>Consensus란 분산 시스템에서 노드 간의 상태를 공유하는 알고리즘을 말합니다.\n가장 유명한 알고리즘으로 Paxos가 있고, Zookeeper에서 사용하는 Zab이 있습니다.\nRaft는 이해하기 어려운 기존의 알고리즘과 달리 쉽게 이해하고 구현하기 위해 설계되었습니다.\n(PS. 이 글은 블록체인에서의 Consensus 알고리즘을 말하는 것이 아닙니다)</p>\n<br>\n<h2 id=\"what-is-consensus-problem\" style=\"position:relative;\"><a href=\"#what-is-consensus-problem\" aria-label=\"what is consensus problem permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>What is consensus problem</h2>\n<p>하나의 클라이언트와 서버가 있고 클라이언트가 서버에게 데이터를 전달한다고 가정해보겠습니다.\n서버는 하나의 노드로 이루어져있기 때문에 합의가 이루어지는건 아주 쉬운 문제입니다.\n(여기에서 말하는 합의는 공유된 상태라고 이해하시면 됩니다)</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1-KZIAy8UAFgLlUCHESjbOO7pgCVHByGS\" alt=\"con1\"></p>\n<p>만일 위 그림처럼 여러 노드로 이루어진 분산 서버에서 합의를 이루어내야한다면 어떻게 해야할까요?\n이러한 문제를 <strong>distributed consensus problem</strong> 이라고 합니다.</p>\n<br>\n<h2 id=\"raft-algorithm\" style=\"position:relative;\"><a href=\"#raft-algorithm\" aria-label=\"raft algorithm permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Raft Algorithm</h2>\n<p>Raft의 node는 <strong>Follower, Candidate, Leader</strong>라는 3가지 state를 가집니다.\n모든 노드는 처음에 Follower state를 가지고 시작합니다.\n만일 Follower가 Leader의 응답을 받지 못하면 Candidate 상태로 전환될 수 있습니다.</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1CiOwa7f7dv50HgqvF3Rm4MrWVQlQMRF4\" alt=\"election\"></p>\n<p>Candidate는 다른 노드들에게 투표를 요청하고 노드들은 투표 결과를 응답으로 전달합니다.\n노드 중 가장 많은 표를 얻은 노드는 Leader가 될 수 있습니다.\n이러한 프로세스를 <strong>Leader Election</strong> 이라고 부릅니다.</p>\n<br>\n<h2 id=\"leader-election\" style=\"position:relative;\"><a href=\"#leader-election\" aria-label=\"leader election permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Leader Election</h2>\n<p>Raft는 투표를 관리하기 위해 두 가지 timeout 설정을 가지고 있습니다.\n첫 번째는 <strong>Election timeout</strong> 입니다.\nElection timeout 이란, Follower에서 Candidate로 전환되기 위해 기다리는 시간을 의미합니다.\n일반적으로 Election timeout은 150ms에서 300ms 사이의 값으로 랜덤하게 설정됩니다.</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=18EJCDHGadTVHAtFEoXIms6OnB8hn8DTY\" alt=\"timeout\"></p>\n<ol>\n<li>Election timeout이 끝나면 Follower는 Candidate가 되고 Election term을 시작합니다.</li>\n<li>Candidate는 본인에게 투표를 하고 다른 노드들에게 투표 요청 메세지를 전달합니다.</li>\n<li>만일 메세지를 받는 노드가 해당 Election term에서 아직 투표를 하지 않았다면, 먼저 메세지를 전달해준 Candidate에게 투표합니다.</li>\n<li>투표를 마친 해당 노드는 Election timeout이 초기화 됩니다.</li>\n<li>가장 많은 표를 받은 노드가 Leader로 선정됩니다.</li>\n</ol>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=14gQt-B4NYslCtwca8xcATt9a2IVH7qqH\" alt=\"reelection\"></p>\n<ol>\n<li>선정 이후 Leader는 Append Entries 메세지를 Follower들에게 전송합니다.\n(이 메세지는 <strong>Heartbeat timeout</strong> 에 설정된 간격마다 보내게 됩니다)</li>\n<li>Follower들은 Append Entries 메세지를 받으면 Election timeout이 초기화되고 메세지에 대한 응답을 Leader에게 보냅니다.</li>\n<li>만일 Follower에게 Heartbeat가 도달하지 않으면 다시 Election term이 시작되고, Follower는 Candidate 상태로 전환됩니다.\n(위 그림은 노드A가 죽고 난 이후 노드B가 Leader로 선정되고 Heartbeat 메세지를 전달하는 예시입니다)</li>\n</ol>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1OtRVbaqBh-QmGg5JjDF4hxt4LFxK4oTP\" alt=\"same1\"></p>\n<ol>\n<li>만일 두 개의 노드가 동시에 Election term을 시작하고 메세지가 동시에 Follower에게 도달한다고 가정해보겠습니다.</li>\n<li>이러한 경우 노드A, 노드B는 2표씩 얻게 되고, 표가 동일하므로 해당 Election term에는 Leader가 선정되지 않습니다.</li>\n<li>Leader가 선정되지 않았으므로 Election timeout에 따라 새로운 Election term을 시작하게 됩니다.</li>\n</ol>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1o-llsn2rZop8u0jxzam8_K2hu-3n-nvD\" alt=\"same2\"></p>\n<br>\n<h2 id=\"log-replication\" style=\"position:relative;\"><a href=\"#log-replication\" aria-label=\"log replication permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Log Replication</h2>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=13PUDuWgR3bl8frAbiHhpkRieWuKrygVI\" alt=\"message\"></p>\n<p>Leader가 선정되고 난 이후, 시스템의 모든 변화는 Leader를 통해 이루어집니다.\n클라이언트는 Leader에게 데이터를 전달하고, Leader는 데이터의 복제하여 Follower에게 전달합니다.\n이 과정은 앞서 언급했던 <strong>Append Entries</strong> 메세지를 통해 이루어집니다.</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1RQVmzrOGOg0HZnZ8fO5dpZwoW7XVMd79\" alt=\"res\"></p>\n<p>Follower는 받은 데이터를 commit 하고 결과를 Leader에게 전달합니다.\nLeader는 Follow로부터 받은 결과를 Client에게 전달합니다.</p>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<p>정리하자면 분산 시스템은 fault-tolerence를 보장하기 위해 consensus algorithm을 사용하고 있고,\n분산 시스템을 다루는 프레임워크마다 Consensus 구현이 조금씩 다를 수 있습니다.\n그리고 원활한 Leader Election을 위해 클러스터 노드의 개수는 홀수로 구성하는 것이 좋습니다.</p>\n<p>Raft의 경우 Redis cluster에서 응용하여 사용하고 있고,\nElasticsearch cluster 또한 quorum-based consensus algorithm을 사용하고 있습니다.\n아래의 Raft 논문과 시각화 자료 링크를 보시면 더 쉽게 이해할 수 있습니다.</p>\n<ul>\n<li><a href=\"https://raft.github.io/raft.pdf\">https://raft.github.io/raft.pdf</a></li>\n<li><a href=\"http://thesecretlivesofdata.com/raft/\">http://thesecretlivesofdata.com/raft/</a></li>\n<li><a href=\"https://raft.github.io/\">https://raft.github.io/</a></li>\n</ul>\n<br>","excerpt":"Consensus란 분산 시스템에서 노드 간의 상태를 공유하는 알고리즘을 말합니다.\n가장 유명한 알고리즘으로 Paxos…"}}},{"id":"314dca06-efff-5b51-a3f2-609f2e02b3bb","title":"AWS에 Hadoop MR 어플리케이션 환경 구축하기","slug":"aws-hadoop","publishDate":"June 13, 2018","publishDateISO":"2018-06-13","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"85e2c430-57ba-5039-afc3-8ba29e23441f","childMarkdownRemark":{"id":"fa2082b2-a22e-59b9-a803-553e8dc09e59","timeToRead":4,"html":"<p>이번 학기에 하둡 프로그래밍 강의를 들으면서 정말 실습 환경의 개선이 필요하다는 생각이 들었습니다...\n나약한 실습 환경속에서 과제와 기말 프로젝트를 제출해야하는 후배들을 위해 AWS를 추천합니다!</p>\n<br>\n<h2 id=\"ec2-amazon-linux2에-기본-환경-구축\" style=\"position:relative;\"><a href=\"#ec2-amazon-linux2%EC%97%90-%EA%B8%B0%EB%B3%B8-%ED%99%98%EA%B2%BD-%EA%B5%AC%EC%B6%95\" aria-label=\"ec2 amazon linux2에 기본 환경 구축 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>EC2 Amazon Linux2에 기본 환경 구축</h2>\n<p>AWS에는 EMR이라는 클러스터 서비스가 있지만, 스터디 목적이라면 비용을 생각해서 사용하지 않겠습니다.\nAmazon Linux AMI는 EC2에서 편하게 사용할 수 있도록 지원하고 관리하는 리눅스 이미지입니다.\n만일 학생용 크레딧이 있다면 <strong>t2.medium</strong> 인스턴스를 추천합니다.</p>\n<p>먼저, JAVA JDK와 Hadoop 파일을 받겠습니다. 실습 환경은 자바 7, 하둡 1.2 버전입니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token function\">sudo</span> yum update -y\n$ <span class=\"token function\">sudo</span> yum <span class=\"token function\">install</span> -y java-1.7.0-openjdk-devel\n$ <span class=\"token function\">wget</span> https://archive.apache.org/dist/hadoop/core/hadoop-1.2.1/hadoop-1.2.1.tar.gz\n$ <span class=\"token function\">tar</span> xvfz hadoop-1.2.1</code></pre></div>\n<p>그리고 자바 프로젝트를 위해 Maven도 설치해줍니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token function\">wget</span> http://mirror.navercorp.com/apache/maven/maven-3/3.5.3/binaries/apache-maven-3.5.3-bin.tar.gz\n$ <span class=\"token function\">tar</span> xvfs apache-maven-3.5.3-bin.tar.gz\n$ <span class=\"token function\">mv</span> apache-maven-3.5.3/ apache-maven\n$ <span class=\"token function\">sudo</span> <span class=\"token function\">vi</span> /etc/profile.d/maven.sh\n\n<span class=\"token comment\"># Apache Maven Environment Variables</span>\n<span class=\"token comment\"># MAVEN_HOME for Maven 1 - M2_HOME for Maven 2</span>\n$ <span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">M2_HOME</span><span class=\"token operator\">=</span>/home/ec2-user/apache-maven\n$ <span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\"><span class=\"token environment constant\">PATH</span></span><span class=\"token operator\">=</span><span class=\"token variable\">${M2_HOME}</span>/bin:<span class=\"token variable\">${<span class=\"token environment constant\">PATH</span>}</span>\n\n$ <span class=\"token function\">chmod</span> +x maven.sh\n$ <span class=\"token builtin class-name\">source</span> /etc/profile.d/maven.sh</code></pre></div>\n<p>정상적으로 설치가 되었다면 아래의 명령어에 대한 결과가 나옵니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ java --version\n$ mvn --version</code></pre></div>\n<br>\n<h2 id=\"hadoop-환경-구축\" style=\"position:relative;\"><a href=\"#hadoop-%ED%99%98%EA%B2%BD-%EA%B5%AC%EC%B6%95\" aria-label=\"hadoop 환경 구축 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Hadoop 환경 구축</h2>\n<p>실습환경은 <strong>Pseudo-Distibuted</strong> 모드로 진행합니다.\n먼저 Password less SSH Login을 설정해주어야 합니다.\n그리고 편의를 위해 hadoop-1.2.1 폴더에 Symbolic link를 생성하겠습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token comment\"># ssh login setting</span>\n$ ssh-keygen -t rsa -P <span class=\"token string\">\"\"</span>\n$ <span class=\"token function\">cat</span> /home/ec2-user/.ssh/id_rsa.pub <span class=\"token operator\">>></span> /home/ec2-user/.ssh/authorized_keys\n\n<span class=\"token comment\"># symbolic link</span>\n$ <span class=\"token function\">ln</span> -s hadoop-1.2.1 hadoop</code></pre></div>\n<p>이제 HDFS와 MR 실행을 위해 설정파일을 수정해줍니다.\n먼저 <code class=\"language-text\">hadoop-env.sh</code>을 열어 <code class=\"language-text\">JAVA_HOME</code> 환경변수를 지정해줍니다.\n가상분산모드에서는 masters, slaves 파일을 수정할 필요가 없습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token builtin class-name\">cd</span> hadoop\n$ <span class=\"token function\">vi</span> conf/hadoop-env.sh\n\n<span class=\"token comment\"># set JAVA_HOME in this file, so that it is correctly defined on</span>\n<span class=\"token comment\"># remote nodes.</span>\n\n<span class=\"token comment\"># The java implementation to use. Required.</span>\n<span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">JAVA_HOME</span><span class=\"token operator\">=</span>/usr/lib/jvm/java-1.7.0\n\n<span class=\"token comment\"># Extra Java CLASSPATH elements.  Optional.</span>\n<span class=\"token comment\"># export HADOOP_CLASSPATH=</span></code></pre></div>\n<p>이제 <code class=\"language-text\">core-site.xml</code> 파일을 아래와 같이 수정해줍니다.\nHDFS 데이터 파일들은 홈 디렉토리의 hadoop-data 폴더에 저장하겠습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token function\">vi</span> conf/core-site.xml\n\n<span class=\"token operator\">&lt;</span>configuration<span class=\"token operator\">></span>\n    <span class=\"token operator\">&lt;</span>property<span class=\"token operator\">></span>\n        <span class=\"token operator\">&lt;</span>name<span class=\"token operator\">></span>fs.default.name<span class=\"token operator\">&lt;</span>/name<span class=\"token operator\">></span>\n        <span class=\"token operator\">&lt;</span>value<span class=\"token operator\">></span>hdfs://localhost:900<span class=\"token operator\"><span class=\"token file-descriptor important\">0</span>&lt;</span>/value<span class=\"token operator\">></span>\n    <span class=\"token operator\">&lt;</span>/property<span class=\"token operator\">></span>\n    <span class=\"token operator\">&lt;</span>property<span class=\"token operator\">></span>\n        <span class=\"token operator\">&lt;</span>name<span class=\"token operator\">></span>hadoop.tmp.dir<span class=\"token operator\">&lt;</span>/name<span class=\"token operator\">></span>\n        <span class=\"token operator\">&lt;</span>value<span class=\"token operator\">></span>/home/ec2-user/hadoop-data/<span class=\"token operator\">&lt;</span>/value<span class=\"token operator\">></span>\n    <span class=\"token operator\">&lt;</span>/property<span class=\"token operator\">></span>\n<span class=\"token operator\">&lt;</span>/configuration<span class=\"token operator\">></span></code></pre></div>\n<p><code class=\"language-text\">hdfs-site.xml</code> 파일도 수정해줍니다.\ndfs.replication 프로퍼티는 복제 개수를 의미합니다.\n일반적으로 복제 개수를 3으로 두는 것을 권장하지만,\n실습에서는 Fully-Distributed 모드가 아니기 때문에 1로 설정하겠습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token function\">vi</span> conf/hdfs-site.xml\n\n<span class=\"token operator\">&lt;</span>configuration<span class=\"token operator\">></span>\n    <span class=\"token operator\">&lt;</span>property<span class=\"token operator\">></span>\n        <span class=\"token operator\">&lt;</span>name<span class=\"token operator\">></span>dfs.replication<span class=\"token operator\">&lt;</span>/name<span class=\"token operator\">></span>\n        <span class=\"token operator\">&lt;</span>value<span class=\"token operator\">></span><span class=\"token operator\"><span class=\"token file-descriptor important\">1</span>&lt;</span>/value<span class=\"token operator\">></span>\n    <span class=\"token operator\">&lt;</span>/property<span class=\"token operator\">></span>\n<span class=\"token operator\">&lt;</span>/configuration<span class=\"token operator\">></span></code></pre></div>\n<p><code class=\"language-text\">mapred-site.xml</code> 파일도 수정해줍니다.\nmapred.job.tracker 프로퍼티는 job tracker가 동작하는 서버를 말합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token function\">vi</span> conf/mapred-site.xml\n\n<span class=\"token operator\">&lt;</span>configuration<span class=\"token operator\">></span>\n    <span class=\"token operator\">&lt;</span>property<span class=\"token operator\">></span>\n        <span class=\"token operator\">&lt;</span>name<span class=\"token operator\">></span>mapred.job.tracker<span class=\"token operator\">&lt;</span>/name<span class=\"token operator\">></span>\n        <span class=\"token operator\">&lt;</span>value<span class=\"token operator\">></span>localhost:900<span class=\"token operator\"><span class=\"token file-descriptor important\">1</span>&lt;</span>/value<span class=\"token operator\">></span>\n    <span class=\"token operator\">&lt;</span>/property<span class=\"token operator\">></span>\n<span class=\"token operator\">&lt;</span>/configuration<span class=\"token operator\">></span></code></pre></div>\n<br>\n<h2 id=\"hadoop-mr\" style=\"position:relative;\"><a href=\"#hadoop-mr\" aria-label=\"hadoop mr permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Hadoop MR</h2>\n<p>이제 NameNode를 초기화하고 하둡과 관련된 모든 데몬을 실행합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">./bin/hadoop namenode-format\n./bin/start-all.sh</code></pre></div>\n<p>jps를 통해 자바 프로세스가 제대로 실행되었는지 확인할 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ jps\n3368 TaskTracker\n2991 DataNode\n3241 JobTracker\n3480 Jps\n2872 NameNode\n3139 SecondaryNameNode</code></pre></div>\n<p>HDFS 웹 인터페이스 주소는 <a href=\"http://localhost:50070\">http://localhost:50070</a> 이며,\nMapReduce 웹 인터페이스 주소는 <a href=\"http://localhost:50030\">http://localhost:50030</a> 입니다.\n들어가시면 아래와 같은 화면이 나타납니다.</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=15OIYCbnc1cy93jJgqX1y8a5vfpCBkpqM\"></p>\n<p>이제 기본으로 설치되어 있는 WordCount 예제를 실행시켜보겠습니다.\n먼저 WordCount 예제의 input 데이터를 HDFS에 업로드하고 jar 파일과 output 경로를 지정해줍니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ ./bin/hadoop fs -put conf/hadoop-env.sh ./hadoop-env.sh\n$ ./bin/hadoop jar hadoop-examples-1.2.1.jar wordcount hadoop-env.sh output</code></pre></div>\n<p>HDFS에 write한 결과는 HDFS의 output 경로에서 확인하실 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ ./bin/hadoop fs -ls output\n$ ./bin/hadoop fs -cat output/part-r-00000</code></pre></div>\n<br>\n<h2 id=\"intellij\" style=\"position:relative;\"><a href=\"#intellij\" aria-label=\"intellij permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>IntelliJ</h2>\n<p>이번엔 예제가 아니라 Hadoop MR 어플리케이션 프로젝트를 새로 생성해보겠습니다.\nIntelliJ에서 JAVA, maven 프로젝트를 생성하시면 됩니다.</p>\n<p>그리고 pom.xml은 아래와 같이 수정해줍니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"xml\"><pre class=\"language-xml\"><code class=\"language-xml\"><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>groupId</span><span class=\"token punctuation\">></span></span>org.swalloow.hadoop<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>groupId</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>artifactId</span><span class=\"token punctuation\">></span></span>hadoop<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>artifactId</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>version</span><span class=\"token punctuation\">></span></span>1.0-SNAPSHOT<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>version</span><span class=\"token punctuation\">></span></span>\n\n<span class=\"token comment\">&lt;!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-core --></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>dependencies</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>dependency</span><span class=\"token punctuation\">></span></span>\n        <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>groupId</span><span class=\"token punctuation\">></span></span>org.apache.hadoop<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>groupId</span><span class=\"token punctuation\">></span></span>\n        <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>artifactId</span><span class=\"token punctuation\">></span></span>hadoop-core<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>artifactId</span><span class=\"token punctuation\">></span></span>\n        <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>version</span><span class=\"token punctuation\">></span></span>1.2.1<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>version</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>dependency</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>dependencies</span><span class=\"token punctuation\">></span></span></code></pre></div>\n<p>Mapper와 Reducer 클래스를 수정한 다음, <code class=\"language-text\">mvn packages</code> 명령어를 통해 jar 파일을 생성합니다.\n그리고 input 파일을 이전과 동일하게 HDFS에 추가하고 생성한 jar 파일을 통해 MR job을 실행시키시면 됩니다.</p>\n<p>아래 링크는 코인 거래 데이터를 입력받아 이동평균선(SMA) 추세를 계산해주는 간단한 예시 프로젝트입니다. 템플릿은 자유롭게 참고하셔도 됩니다!</p>\n<p><a href=\"https://github.com/Swalloow/hadoop-mr-project\">https://github.com/Swalloow/hadoop-mr-project</a></p>\n<br>","excerpt":"…"}}},{"id":"8d868e76-473f-5075-bfa6-fef3751eb0d8","title":"Data Science inconvenient truth","slug":"data-science-inconvenient-truth","publishDate":"April 01, 2018","publishDateISO":"2018-04-01","heroImage":{"id":"434fa86e-ac5b-52f4-8bd1-6ac1432526e2","title":"cover-datascience","fluid":{"aspectRatio":1.5,"src":"//images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&h=1200&q=50 1800w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&h=1200&q=50&fm=webp 1800w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"9ac3e892-037b-56dd-823b-b494ff739acd","childMarkdownRemark":{"id":"ee66eb82-0a50-5b28-8ce7-83a5921f67eb","timeToRead":1,"html":"<h2 id=\"데이터과학의-불편한-진실\" style=\"position:relative;\"><a href=\"#%EB%8D%B0%EC%9D%B4%ED%84%B0%EA%B3%BC%ED%95%99%EC%9D%98-%EB%B6%88%ED%8E%B8%ED%95%9C-%EC%A7%84%EC%8B%A4\" aria-label=\"데이터과학의 불편한 진실 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>데이터과학의 불편한 진실</h2>\n<ul>\n<li>Data is never clean (데이터는 절대 깨끗하지 않다)</li>\n<li>You will spend most of your time cleaning and preparing data (당신은 분석의 대부분의 시간을 전처리 단계에서 보내게 될 것이다)</li>\n<li>95% of tasks do not require deep learning (95% 일은 Deep Learning을 필요로 하지 않는다)</li>\n<li>In 90% of cases generalized linear regression will do the trick (실제 분석의 90%는 GLM으로 해결된다 )</li>\n<li>Big Data is just a tool (빅 데이터는 단지 도구일 뿐이다)</li>\n<li>You should embrace the Bayesian approach (당신은 베이지안 접근을 포용해야 한다)</li>\n<li>No one cares how you did it (사용자 입장에서는 네가 어떤 방법을 사용했는가는 중요하지 않다) </li>\n<li>Academia and business are two different worlds (학계와 산업계는 서로 다른 세계이다)</li>\n<li>Presentation is key - be a master of Power Point (프리젠테이션이 핵심이다: PowerPoint의 마스터가 되라)</li>\n<li>All models are false, but some are useful (모든 모델은 틀렸다, 하지만 몇몇은 유용하다)</li>\n<li>There is no fully automated Data Science. You need to get your hands dirty (완전 자동화된 데이터 과학같은 것은 없다. 인간이 개입되어야 할 부분이 있다)</li>\n</ul>\n<br>\n<p>Ref: <a href=\"https://www.kdnuggets.com/2015/05/data-science-inconvenient-truth.html\">https://www.kdnuggets.com/2015/05/data-science-inconvenient-truth.html</a></p>","excerpt":"데이터과학의 불편한 진실 Data is never clean (데이터는 절대 깨끗하지 않다) You will spend most of your…"}}},{"id":"ae1bd687-b1b2-535f-a826-8e600505d3df","title":"제플린 노트북 자동 실행 스크립트 만들기","slug":"zeppelin-bootstrap","publishDate":"September 13, 2017","publishDateISO":"2017-09-13","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"a29a76e7-6151-5f0f-8eb3-1c75a8fb8f5a","childMarkdownRemark":{"id":"1107c2c0-8dc1-5eca-a038-7c07e481d047","timeToRead":1,"html":"<p>제플린 노트북을 사용하다보면 가끔 제플린 어플리케이션을 재시작해야 하는 경우가 있습니다.\n이 때, view 또는 udf 등록을 위해 처음 실행시켜야 하는 노트북이 있다면 참 번거롭습니다.\n하지만 <strong>Zeppelin Notebook API</strong> 사용한다면 이를 쉽게 자동화 할 수 있습니다.</p>\n<br>\n<h2 id=\"zeppelin-notebook-api\" style=\"position:relative;\"><a href=\"#zeppelin-notebook-api\" aria-label=\"zeppelin notebook api permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Zeppelin Notebook API</h2>\n<p>제플린은 노트북 자동실행을 위한 REST API를 제공합니다.\n하지만 제플린에 인증이 걸려있다면, 인증을 거쳐야만 API를 사용할 수 있습니다.\n따라서, 먼저 curl로 세션 값을 받고 해당 노트북 아이디를 호출하시면 됩니다.</p>\n<p>노트북 아이디는 해당 노트 URL의 가장 마지막 값 입니다. (ex 2AZPHY918)\n아래의 스크립트는 아이디가 user, 패스워드가 1234인 경우를 예시로 들었습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">#!/bin/sh\nsudo /usr/lib/zeppelin/bin/zeppelin-daemon.sh stop\nsleep 3\nsudo /usr/lib/zeppelin/bin/zeppelin-daemon.sh start\n\nsleep 15\n\nSESSION=&quot;`curl -i --data &#39;userName=user&amp;password=1234)&#39; -X POST http://zeppelin-url.com:8890/api/login | grep &#39;Set-Cookie: JSESSIONID=&#39; | cut -d &#39;:&#39; -f2 |  tail -1 | cut -d &#39;;&#39; -f1`&quot;\necho $SESSION\ncurl -i -b ${SESSION} -X POST http://zeppelin-url.com:8890/api/notebook/job/NOTEBOOK_ID</code></pre></div>\n<p>Notebook API를 활용하면 노트북 실행 뿐만 아니라, Cron이나 노트북 권한 설정도 자동화할 수 있습니다.\n자세한 내용은 아래의 공식문서에서 확인하실 수 있습니다.</p>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<ul>\n<li><a href=\"https://zeppelin.apache.org/docs/0.7.3/rest-api/rest-notebook.html\">https://zeppelin.apache.org/docs/0.7.3/rest-api/rest-notebook.html</a></li>\n</ul>\n<br>","excerpt":"제플린 노트북을 사용하다보면 가끔 제플린 어플리케이션을 재시작해야 하는 경우가 있습니다.\n이 때, view 또는 udf…"}}},{"id":"ca419fc7-c4a8-5527-8671-c1e508769568","title":"Spark의 Shuffling 이해하기","slug":"spark-shuffling","publishDate":"August 25, 2017","publishDateISO":"2017-08-25","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"2a8f6e13-331a-57ae-9646-63d4ef59b0a6","childMarkdownRemark":{"id":"232124a0-9bf3-5161-8345-9ff38e52cee0","timeToRead":2,"html":"<p>효율적인 Spark Application을 개발하기 위해 <strong>Shuffling</strong> 은 상당히 중요한 개념입니다.\n이에 대해 간단히 정리해보았습니다.</p>\n<br>\n<h2 id=\"spark-architecture-shuffle\" style=\"position:relative;\"><a href=\"#spark-architecture-shuffle\" aria-label=\"spark architecture shuffle permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Spark Architecture: Shuffle</h2>\n<p><img src=\"/assets/images/shuffle.png\"></p>\n<p>Shuffle을 설명하기 전에 한 가지 예시를 들어보겠습니다.\n테이블에 전화 통화 기록 목록이 있고 매일 발생한 통화량을 계산한다고 가정 해보겠습니다.\n“날짜”를 키로 설정하고 각 레코드에 대해 값으로 “1”을 지정한 다음, 각 키의 값을 합산하여 결과 값을 계산할 수 있을 것 입니다.</p>\n<p>만일 데이터가 여러 클러스터에 저장되어 있다면 어떻게 해야 동일한 키의 값을 합산할 수 있을까요?\n이를 위한 유일한 방법은 같은 키의 모든 값을 동일한 시스템에 두는 것입니다. 그런 다음 이 값들을 합치면 됩니다.</p>\n<br>\n<h2 id=\"narrow-and-wide-transformation\" style=\"position:relative;\"><a href=\"#narrow-and-wide-transformation\" aria-label=\"narrow and wide transformation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Narrow and Wide Transformation</h2>\n<p><img src=\"/assets/images/narrow_and_wide.png\"></p>\n<p>몇 가지 사례를 통해 더 자세히 알아보겠습니다.\n만일 데이터가 이미 키 값으로 파티셔닝 되어 있고 키 값에 대해 변화를 주고 싶다면, 좌측의 그림처럼 수행하게 됩니다.\n<code class=\"language-text\">filter(), sample(), map(), flatMap()</code> 등의 transformation이 이에 해당하며, 이 경우 Shuffle이 필요 없습니다.\n이를 <strong>Narrow Transformation</strong> 이라고 합니다.</p>\n<p>반면, 서로 다른 파티션으로부터 특정한 값을 기준으로 추출하고 싶은 경우, 그 값을 기준으로 Shuffle이 발생하게 됩니다.\n<code class=\"language-text\">groupByKey(), reduceByKey()</code> 등이 이에 해당하며, 이를 <strong>Wide Transformation</strong> 이라고 합니다.</p>\n<br>\n<h2 id=\"shuffled-hashjoin\" style=\"position:relative;\"><a href=\"#shuffled-hashjoin\" aria-label=\"shuffled hashjoin permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Shuffled HashJoin</h2>\n<p><img src=\"/assets/images/shuffle_join.png\"></p>\n<p>두 개의 테이블을 <code class=\"language-text\">Join</code> 할 때에도 Shuffle 이 발생할 수 있습니다.\n위의 예시 처럼 두 테이블에서 키 값을 기준으로 Join 하게 되면, 동일한 키를 가진 데이터가 동일한 파티션으로 이동합니다.</p>\n<p>하지만 이 때, 셔플 되는 데이터의 양이 성능에 영향을 미칠 수 있습니다.\n만일 C의 데이터의 크기가 A보다 훨씬 크다면, C에 대한 작업으로 인해 전체의 수행시간이 오래 걸리게 될 것 입니다.</p>\n<br>\n<h2 id=\"broadcast-hashjoin\" style=\"position:relative;\"><a href=\"#broadcast-hashjoin\" aria-label=\"broadcast hashjoin permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Broadcast HashJoin</h2>\n<p><img src=\"/assets/images/broadcast_join.png\"></p>\n<p>이를 개선하기 위해 Spark에서는 <strong>Broadcast Join</strong> 을 제공합니다.\n이 경우 RDD 중 하나가 모든 파티션으로 브로드 캐스팅되며 복사됩니다.\n만일 RDD 중 하나가 다른 것에 비해 상당히 작다면 큰 RDD가 전혀 셔플 할 필요가 없습니다.\n작은 RDD 만 모든 작업자 서버에 복사해야 하므로 Broadcast Join은 전체적으로 네트워크 트래픽을 줄여주는 효과가 있습니다.</p>\n<p>Spark 1.2에서는 <code class=\"language-text\">spark.sql.autoBroadcastJoinThreshold</code> 값을 설정해주어야 했지만,\n2.0 이후 버전의 경우 Spark SQL이 알아서 최적화 잘 해줍니다.</p>\n<br>\n<h2 id=\"spark-shuffle-properties\" style=\"position:relative;\"><a href=\"#spark-shuffle-properties\" aria-label=\"spark shuffle properties permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Spark Shuffle Properties</h2>\n<ul>\n<li><code class=\"language-text\">spark.shuffle.compress</code>: 엔진이 shuffle 출력을 압축할지 여부를 지정</li>\n<li><code class=\"language-text\">spark.shuffle.spill.compress</code>: 중간 shuffle spill 파일을 압축할지 여부를 지정</li>\n</ul>\n<p>Shuffle에는 위의 두 가지 중요한 Spark Property 가 있습니다.</p>\n<p>둘 다 기본적으로 값이 “true”이며, <code class=\"language-text\">spark.io.compression.codec</code> 압축 코덱을 기본으로합니다.\n그리고 위에서 설명한 것처럼 Spark에는 여러 가지 셔플 구현이 있습니다.\n특정 구현에서 사용되는 Shuffle은 <code class=\"language-text\">spark.shuffle.manager</code> 값에 의해 결정됩니다.\n가능한 옵션은 <strong>hash, sort, tungsten-sort</strong> 이며, “sort” 옵션은 기본적으로 Spark 1.2.0부터 시작합니다.</p>\n<p>이외에도 Spark Shuffle 관련된 Property는 아래의 공식문서에서 확인하실 수 있습니다.\n<a href=\"https://spark.apache.org/docs/latest/configuration.html#shuffle-behavior\">https://spark.apache.org/docs/latest/configuration.html#shuffle-behavior</a></p>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<ul>\n<li><a href=\"https://0x0fff.com/spark-architecture-shuffle\">https://0x0fff.com/spark-architecture-shuffle</a></li>\n<li><a href=\"https://www.slideshare.net/databricks/strata-sj-everyday-im-shuffling-tips-for-writing-better-spark-programs\">https://www.slideshare.net/databricks/strata-sj-everyday-im-shuffling-tips-for-writing-better-spark-programs</a></li>\n</ul>\n<br>","excerpt":"효율적인 Spark Application을 개발하기 위해 Shuffling…"}}},{"id":"346030b5-8193-5161-9bea-951b3f0146ac","title":"Spark groupByKey vs reduceByKey","slug":"spark-reduceByKey-groupByKey","publishDate":"August 22, 2017","publishDateISO":"2017-08-22","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"037fcf8d-17a3-5fd2-8b52-271bc7f8836f","childMarkdownRemark":{"id":"5103dbd1-1b3c-5d75-8c16-3f900b1d0d8f","timeToRead":1,"html":"<p>Spark Application 성능 개선을 위한 <code class=\"language-text\">groupByKey, reduceBykey</code>에 대해 알아보겠습니다.</p>\n<br>\n<h2 id=\"groupbykey-vs-reducebykey\" style=\"position:relative;\"><a href=\"#groupbykey-vs-reducebykey\" aria-label=\"groupbykey vs reducebykey permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>groupByKey vs reduceBykey</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># reduceByKey</span>\nspark<span class=\"token punctuation\">.</span>textFile<span class=\"token punctuation\">(</span><span class=\"token string\">\"hdfs://...\"</span><span class=\"token punctuation\">)</span>\n <span class=\"token punctuation\">.</span>flatMap<span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> line<span class=\"token punctuation\">:</span> line<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n <span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> word<span class=\"token punctuation\">:</span> <span class=\"token punctuation\">(</span>word<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n <span class=\"token punctuation\">.</span>reduceByKey<span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> a<span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">:</span> a <span class=\"token operator\">+</span> b<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># groupByKey</span>\nspark<span class=\"token punctuation\">.</span>textFile<span class=\"token punctuation\">(</span><span class=\"token string\">\"hdfs://...\"</span><span class=\"token punctuation\">)</span>\n <span class=\"token punctuation\">.</span>flatMap<span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> line<span class=\"token punctuation\">:</span> line<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n <span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> word<span class=\"token punctuation\">:</span> <span class=\"token punctuation\">(</span>word<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n <span class=\"token punctuation\">.</span>groupByKey<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n <span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> <span class=\"token punctuation\">(</span>w<span class=\"token punctuation\">,</span> counts<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">(</span>w<span class=\"token punctuation\">,</span> <span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>counts<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>가장 흔히 알고 있는 word count 예제를 예로 들어보겠습니다.\n위의 예시는 reduceByKey를 사용했으며, 아래의 예시는 groupByKey를 사용했습니다.\n둘의 결과는 같지만 성능은 확인히 차이가 납니다.</p>\n<p>먼저 위의 코드에서 <code class=\"language-text\">flatMap, map</code> 까지는 동일한 노드에서 실행이 됩니다.\n하지만 reducer 부분에서는 모든 동일한 단어 쌍을 같은 노드로 이동시켜야 하기 때문에 <strong>Shuffle</strong> 이 발생합니다.</p>\n<p><img src=\"/assets/images/reduceByKey.png\"></p>\n<p>우선 reduceByKey의 경우, 먼저 각 노드에서 중간 집계를 진행하고 이에 대한 결과를 동일한 키 값으로 전송합니다.</p>\n<p><img src=\"/assets/images/groupByKey.png\"></p>\n<p>반면, groupByKey는 각 노드에 있는 데이터에 대해 바로 Shuffle 과정을 거치게 되고 결과를 내보냅니다.\n따라서 groupByKey는 네트워크를 통해 전송되는 데이터의 양이 많아질 뿐만 아니라, <strong>Out of disk</strong> 문제가 발생할 수도 있습니다.</p>\n<p>Shuffle은 기본적으로 비용이 큰 연산입니다.\ngroupByKey는 reduceByKey로 대체될 수 있기 때문에 많은 문서에서 이를 권장하고 있습니다.</p>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<ul>\n<li><a href=\"https://www.slideshare.net/databricks/strata-sj-everyday-im-shuffling-tips-for-writing-better-spark-programs\">https://www.slideshare.net/databricks/strata-sj-everyday-im-shuffling-tips-for-writing-better-spark-programs</a></li>\n</ul>\n<br>","excerpt":"Spark Application 성능 개선을 위한 에 대해 알아보겠습니다. groupByKey vs reduceBykey…"}}},{"id":"ae3d06e8-e30e-5942-b118-b3e930d67172","title":"Hive Metastore 구축 관련 문제와 해결과정","slug":"hive-metastore-issue","publishDate":"August 11, 2017","publishDateISO":"2017-08-11","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"8ff6b231-b785-52d0-8bed-8d7b851c2c78","childMarkdownRemark":{"id":"ce6997a5-dcfe-5d66-ad3b-4c121fa5b2f8","timeToRead":2,"html":"<p>최근 Hive Metastore를 구축하면서 겪은 이슈와 해결과정을 기록해두려고 합니다.\n사용 환경은 Spark 2.1.1, Hive 2.1.1 입니다.</p>\n<br>\n<h2 id=\"hive-partition\" style=\"position:relative;\"><a href=\"#hive-partition\" aria-label=\"hive partition permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Hive Partition</h2>\n<div class=\"gatsby-highlight\" data-language=\"sql\"><pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">CREATE</span> EXTERNAL <span class=\"token keyword\">TABLE</span> table_name <span class=\"token punctuation\">(</span>\ncol1 STRING<span class=\"token punctuation\">,</span>\ncol2 STRING\n<span class=\"token punctuation\">)</span>\nPARTITIONED <span class=\"token keyword\">BY</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">key</span> STRING<span class=\"token punctuation\">)</span>\nSTORED <span class=\"token keyword\">AS</span> PARQUET\nLOCATION <span class=\"token string\">'location'</span><span class=\"token punctuation\">;</span></code></pre></div>\n<p>Hive에서 보통 위와 같은 쿼리로 테이블을 생성합니다.\nMetastore는 말 그대로 외부에 있는 테이블의 정보(스키마, 파티션 등)를 저장하는 개념입니다.\n따라서 <strong>EXTERNAL TABLE</strong> 로 생성하지 않은 상태에서 테이블을 DROP 시키면 다 날아가게 됩니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"sql\"><pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">ALTER</span> <span class=\"token keyword\">TABLE</span> table_name\n<span class=\"token keyword\">ADD</span> <span class=\"token keyword\">PARTITION</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">key</span><span class=\"token operator\">=</span><span class=\"token string\">'2017-08-11'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code></pre></div>\n<p>도중에 Partition key를 추가하고 싶을 때는 위와 같은 쿼리를 통해 추가할 수 있습니다.\n그러나, 추가한 정보가 바로 반영이 안될 때가 있습니다.</p>\n<p>이 경우에는 <code class=\"language-text\">MSCK REPAIR TABLE table_name;</code> 쿼리로 해결할 수 있습니다.\nMSCK는 Metastore Check의 약자라고 합니다.</p>\n<br>\n<h2 id=\"hive-metastore-parquet\" style=\"position:relative;\"><a href=\"#hive-metastore-parquet\" aria-label=\"hive metastore parquet permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Hive Metastore, Parquet</h2>\n<p>먼저 겪었던 문제에 대해 설명드리자면 Hive Metastore에 분명히 테이블이 들어가있고,\nHue에서는 잘 보이는데 Zeppelin에서는 모든 데이터에 null 값이 찍혀있었습니다.</p>\n<p>우선 Spark으로 Hive를 사용하는 방식이 2.0 버전 이후 부터 조금 변경되었습니다.\n이전에는 HiveContext를 사용했다면, 이제 SparkSession에서 <code class=\"language-text\">.enableHiveSupport()</code> 추가만 하면 됩니다.\n제플린에서는 SparkSession이 spark이라는 변수로 제공되는데,\n이 경우 interpreter에 <code class=\"language-text\">zeppelin.spark.useHiveContext=true</code>를 추가해서 사용할 수 있습니다.</p>\n<p>다시 문제로 돌아와서 좀 더 확인해보니 컬럼명에 대문자가 들어가면 모든 값이 null로 출력되고 있었습니다.\nSpark 공식문서에 이와 관련된 내용이 잘 나와있습니다.</p>\n<p>Spark SQL에서 Hive metastore로 데이터를 불러오는 경우, 성능 상의 이슈로 SerDe 대신 Spark SQL의 <strong>MetastoreParquet</strong> 를 사용합니다.\n이때 주의사항으로 Hive는 대소문자를 구분하지 않지만, Parquet는 구분합니다. (Hive is case insensitive, while Parquet is not)</p>\n<p>이를 위해 Spark 2.1.1 버전부터 새로운 Spark Properties가 추가되었습니다.</p>\n<p>따라서, Zeppelin interpreter에 아래의 설정 값을 추가해주시면 해결됩니다.\n<code class=\"language-text\">spark.sql.hive.caseSensitiveInferenceMode = INFER_AND_SAVE</code></p>\n<br>\n<h2 id=\"hive-tblproperties\" style=\"position:relative;\"><a href=\"#hive-tblproperties\" aria-label=\"hive tblproperties permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Hive TBLPROPERTIES</h2>\n<p>위에서 말한대로 Spark Properties를 추가하면,\nHive metastore의 parameter에 <code class=\"language-text\">spark.sql.sources.schema.part</code>가 생기게 됩니다.</p>\n<p>여기에서 \"field: name\"에 대소문자가 잘 구분되는 경우, 문제가 없지만 간혹 소문자로 들어오는 경우가 있습니다.\n이 경우에는 아래의 쿼리를 통해 Hive parameter를 수정해주시면 됩니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"sql\"><pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">ALTER</span> <span class=\"token keyword\">TABLE</span> table_name <span class=\"token keyword\">SET</span> TBLPROPERTIES <span class=\"token punctuation\">(</span><span class=\"token string\">\"spark.sql.sources.schema.part.0\"</span> <span class=\"token operator\">=</span> <span class=\"token string\">\"fix this line\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code></pre></div>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<ul>\n<li><a href=\"https://spark.apache.org/docs/latest/sql-programming-guide.html#hive-metastore-parquet-table-conversion\">https://spark.apache.org/docs/latest/sql-programming-guide.html#hive-metastore-parquet-table-conversion</a></li>\n<li><a href=\"http://spark.apache.org/docs/latest/sql-programming-guide.html#upgrading-from-spark-sql-21-to-22\">http://spark.apache.org/docs/latest/sql-programming-guide.html#upgrading-from-spark-sql-21-to-22</a></li>\n</ul>\n<br>","excerpt":"최근 Hive Metastore를 구축하면서 겪은 이슈와 해결과정을 기록해두려고 합니다.\n사용 환경은 Spark 2.1.1, Hive 2.1.…"}}},{"id":"521ef7ff-15d1-5f53-b269-e5e9a75838d1","title":"Spark DataFrame을 MySQL에 저장하는 방법","slug":"spark-df-mysql","publishDate":"July 17, 2017","publishDateISO":"2017-07-17","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"11db5a37-d4e3-5555-90b2-7f2f8aae6d79","childMarkdownRemark":{"id":"02bdf521-be03-59df-87f6-df899fda1460","timeToRead":1,"html":"<p>Spark에서 MySQL에 접근하고 DataFrame을 read, write 하는 방법에 대해 정리해보았습니다.\n참고로 저는 Spark 2.1.0 버전을 사용 중 입니다.</p>\n<br>\n<h2 id=\"mysql-jdbc-driver\" style=\"position:relative;\"><a href=\"#mysql-jdbc-driver\" aria-label=\"mysql jdbc driver permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>MySQL JDBC Driver</h2>\n<p>JDBC를 통해 접근하기 때문에 드라이버가 필요합니다.\n만일 SBT를 사용하신다면, build.sbt에 maven의 <code class=\"language-text\">mysql-connector-java</code> 를 추가하시면 됩니다.</p>\n<p>직접 jar 파일을 사용해야하는 상황이라면, 다음 링크를 통해 다운받으시면 됩니다.\n<a href=\"https://dev.mysql.com/downloads/connector/j/\">https://dev.mysql.com/downloads/connector/j/</a></p>\n<p>그리고 받으신 jar 파일을 -jars 옵션으로 추가해주셔야 합니다.</p>\n<p><code class=\"language-text\">–jars /home/example/jars/mysql-connector-java-5.1.26.jar</code></p>\n<p>마지막으로 spark-submit 을 사용하신다면, --packages 옵션을 추가해주시면 됩니다.</p>\n<p><code class=\"language-text\">--packages mysql:mysql-connector-java:5.1.39</code></p>\n<br>\n<h2 id=\"spark-dataframe-mysql\" style=\"position:relative;\"><a href=\"#spark-dataframe-mysql\" aria-label=\"spark dataframe mysql permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Spark DataFrame MySQL</h2>\n<p>Spark의 DataFrame은 read, write 함수를 통해 쉽게 데이터를 가져오거나 저장할 수 있습니다.\n아래 예시는 Scala 언어로 작성했습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"scala\"><pre class=\"language-scala\"><code class=\"language-scala\"><span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>sql</span><span class=\"token punctuation\">.</span>SaveMode\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">java<span class=\"token punctuation\">.</span>util</span><span class=\"token punctuation\">.</span>Properties\n\n<span class=\"token keyword\">val</span> tempDF <span class=\"token operator\">=</span> List<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"1\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"2017-06-01\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"2017-06-03\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>toDF<span class=\"token punctuation\">(</span><span class=\"token string\">\"id\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"start\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"end\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">val</span> properties <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> Properties<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nproperties<span class=\"token punctuation\">.</span>put<span class=\"token punctuation\">(</span><span class=\"token string\">\"user\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"userId\"</span><span class=\"token punctuation\">)</span>\nproperties<span class=\"token punctuation\">.</span>put<span class=\"token punctuation\">(</span><span class=\"token string\">\"password\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"password\"</span><span class=\"token punctuation\">)</span>\ntempDF<span class=\"token punctuation\">.</span>write<span class=\"token punctuation\">.</span>mode<span class=\"token punctuation\">(</span>SaveMode<span class=\"token punctuation\">.</span>Append<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>jdbc<span class=\"token punctuation\">(</span><span class=\"token string\">\"jdbc:mysql://url/database\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"table\"</span><span class=\"token punctuation\">,</span> properties<span class=\"token punctuation\">)</span></code></pre></div>\n<p>위 예제에서는 Properties를 통해 설정값을 넣어주었습니다.\n유저 정보나 주소는 맞게 변경해주시면 됩니다.</p>\n<p>mode 라는 것이 있는데 <code class=\"language-text\">SaveMode.Append</code>는 기존의 테이블에 추가하는 방식이고\n<code class=\"language-text\">SaveMode.Overwrite</code>의 경우 기존의 테이블을 새로운 데이터로 대체하는 방식입니다.</p>\n<br>","excerpt":"Spark에서 MySQL에 접근하고 DataFrame을 read, write 하는 방법에 대해 정리해보았습니다.\n참고로 저는 Spark 2.…"}}},{"id":"17cb7e89-7826-5409-9b13-766bb5f1bc0c","title":"Spark 2.2.0 릴리즈 업데이트 정리","slug":"spark22","publishDate":"July 14, 2017","publishDateISO":"2017-07-14","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"fc24bdaa-b9ce-57d9-9c46-64c73c8f6553","childMarkdownRemark":{"id":"6296bebe-9af9-58d6-95b9-2a9c9c039b50","timeToRead":2,"html":"<p>7월 11일 약 2개월 만에 Spark 2.2.0이 릴리즈 되었습니다.\n어떤 변경 사항들이 있었는지 릴리즈 노트를 통해 간략하게 정리해보았습니다.</p>\n<br>\n<h2 id=\"pypi-를-통한-pyspark-설치\" style=\"position:relative;\"><a href=\"#pypi-%EB%A5%BC-%ED%86%B5%ED%95%9C-pyspark-%EC%84%A4%EC%B9%98\" aria-label=\"pypi 를 통한 pyspark 설치 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>pypi 를 통한 PySpark 설치</h2>\n<p>드디어 PySpark이 <code class=\"language-text\">pip</code>을 지원하게 되었습니다.\n<code class=\"language-text\">pip install pyspark</code> 명령어를 통해 쉽게 설치 가능합니다.\n설치된 버전은 Spark 2.2.0 버전 입니다.</p>\n<p><img src=\"/assets/images/pyspark-install.png\"></p>\n<p><code class=\"language-text\">numpy, pandas</code> 파이썬 패키지에 dependency가 있으며,\n자세한 사항은 <a href=\"https://pypi.python.org/pypi/pyspark\">pypi 패키지 링크</a>를 통해 확인하실 수 있습니다.\n이번 업데이트를 통해 standalone cluster에서 누구나 쉽게 사용해 볼 수 있을 듯 합니다.</p>\n<br>\n<h2 id=\"structured-streaming\" style=\"position:relative;\"><a href=\"#structured-streaming\" aria-label=\"structured streaming permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Structured Streaming</h2>\n<p>이번 버전부터 Structured Streaming이 새로 추가 되었습니다.\nStructured Streaming은 스트리밍 어플리케이션을 더 빠르고 쉽게 개발하기 위해 만들어진 패키지입니다.</p>\n<p>Spark Streaming이 내부적으로 RDD API를 지원하는 반면, Structured Streaming은 DataFrame, Dataset API를 지원합니다.\n언어는 Scala, Java, Python 모두 지원하며, <code class=\"language-text\">readStream</code> 이라는 메서드를 통해 다양한 저장소로부터 데이터를 읽을 수 있습니다.\n특히 이번 업데이트를 통해 Apache Kafka 스트리밍 지원이 추가되었습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># Subscribe to 1 topic</span>\ndf <span class=\"token operator\">=</span> spark \\\n  <span class=\"token punctuation\">.</span>readStream \\\n  <span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"kafka\"</span><span class=\"token punctuation\">)</span> \\\n  <span class=\"token punctuation\">.</span>option<span class=\"token punctuation\">(</span><span class=\"token string\">\"kafka.bootstrap.servers\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"host1:port1,host2:port2\"</span><span class=\"token punctuation\">)</span> \\\n  <span class=\"token punctuation\">.</span>option<span class=\"token punctuation\">(</span><span class=\"token string\">\"subscribe\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"topic1\"</span><span class=\"token punctuation\">)</span> \\\n  <span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\ndf<span class=\"token punctuation\">.</span>selectExpr<span class=\"token punctuation\">(</span><span class=\"token string\">\"CAST(key AS STRING)\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"CAST(value AS STRING)\"</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>Structured Streaming에 대한 자세한 내용은 <a href=\"http://spark.apache.org/docs/2.2.0/structured-streaming-programming-guide.html\">http://spark.apache.org/docs/2.2.0/structured-streaming-programming-guide.html</a> 에서 확인하실 수 있습니다.</p>\n<br>\n<h2 id=\"mllib\" style=\"position:relative;\"><a href=\"#mllib\" aria-label=\"mllib permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>MLlib</h2>\n<p>예상했던 대로 MLlib에도 많은 변화가 생겼습니다.\nRDD-based MLlib이 아니라 DataFrame-based MLlib을 확인하시면 됩니다.</p>\n<ul>\n<li>기존에 scala API만 지원하던 모델들에 <code class=\"language-text\">python, R API</code>가 추가되었습니다.</li>\n<li>지원이 추가된 모델은 <strong>Gradient Boosted Trees, Bisecting K-Means, LSH, Distributed PCA, SVD</strong> 입니다.</li>\n<li>DataFreame-based MLlib에 새로운 모델이 추가되었습니다.</li>\n<li>추가된 모델은 <strong>LinearSVC (Linear SVM Classifier), ChiSquare test, Correlation,\nImputer feature transformer, Tweedie distribution, FPGrowth frequent pattern mining, AssociationRules</strong> 입니다.</li>\n</ul>\n<br>\n<h2 id=\"sparkr\" style=\"position:relative;\"><a href=\"#sparkr\" aria-label=\"sparkr permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>SparkR</h2>\n<p>이번 업데이트를 통해 SparkR에서 Spark SQL API가 확대되었습니다.</p>\n<ul>\n<li>R API에 Structured Streaming, Catalog가 추가되었습니다.</li>\n<li>to<em>json, from</em>json 메서드가 추가되었습니다.</li>\n<li>Coalesce, DataFrame checkpointing, Multi-column approxQuantile 기능이 추가되었습니다.</li>\n</ul>\n<br>\n<h2 id=\"graphx\" style=\"position:relative;\"><a href=\"#graphx\" aria-label=\"graphx permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>GraphX</h2>\n<p>GraphX는 버그 수정, 최적화 업데이트가 추가되었습니다.\n이번 Structured Steaming이 메인에 추가된 것으로 보아,\n추후에 DataFrame, DataSet API 기반의 GraphFrame이 추가될 수도 있다고 예상합니다.</p>\n<ul>\n<li>PageRank, vertexRDD/EdgeRDD checkpoint 버그를 수정했습니다.</li>\n<li>PageRank, Pregel API가 개선되었습니다.</li>\n</ul>\n<br>\n<h2 id=\"core-and-sparksql-deprecations\" style=\"position:relative;\"><a href=\"#core-and-sparksql-deprecations\" aria-label=\"core and sparksql deprecations permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Core and SparkSQL, Deprecations</h2>\n<p>마지막으로 Core, SparkSQL 그리고 Deprecation 업데이트 입니다.\n전체 업데이트 및 기타 자세한 내용은 맨 아래의 링크를 참고하시면 됩니다.</p>\n<ul>\n<li>Python 2.6, Java 7, Hadoop 2.5 지원이 종료되었습니다.</li>\n<li><code class=\"language-text\">ALTER TABLE table_name ADD COLUMNS</code> 구문이 추가되었습니다.</li>\n<li>Cost-Based Optimizer 성능이 개선되었습니다.</li>\n<li>CSV, JSON 포멧의 File listing/IO 성능이 개선되었습니다.</li>\n</ul>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<ul>\n<li><a href=\"http://spark.apache.org/releases/spark-release-2-2-0.html\">http://spark.apache.org/releases/spark-release-2-2-0.html</a></li>\n</ul>\n<br>","excerpt":"7월 11일 약 2개월 만에 Spark 2.2.…"}}},{"id":"23238ff5-8f3e-5b04-951c-d1971d69b5a2","title":"AWS EMR step을 이용한 Spark Batch 작업","slug":"emr-step","publishDate":"July 02, 2017","publishDateISO":"2017-07-02","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"9b14c883-75a8-5767-9605-b31d2fc92488","childMarkdownRemark":{"id":"d4d37967-d3d8-5a21-9dab-b655511c629a","timeToRead":1,"html":"<p>AWS EMR은 특정 작업을 등록할 수 있는 <strong>step</strong> 이라는 기능을 제공합니다.\n예를 들어 매일 새벽에 클러스터에서 돌려야하는 Batch 작업이 있다면 step과 스케줄러를 통해 쉽게 해결할 수 있습니다.</p>\n<br>\n<h2 id=\"emr-step\" style=\"position:relative;\"><a href=\"#emr-step\" aria-label=\"emr step permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>EMR Step</h2>\n<p>Step은 AWS console 내에서 추가해도 되지만, AWS-Cli를 이용해서 등록해보도록 하겠습니다.\nAWS-Cli로 등록하면 이후에 스크립트로 활용할 수도 있다는 편리함이 있습니다.</p>\n<p>AWS EMR step을 등록하는 방법은 아래와 같습니다.\n가독성을 위해 줄바꿈, 띄어쓰기를 했지만 실제로 등록할 때는 전부 붙이셔야 합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ aws emr add-steps\n    --cluster-id <span class=\"token variable\">$CLUSTERID</span>,\n    --steps <span class=\"token assign-left variable\">Name</span><span class=\"token operator\">=</span><span class=\"token variable\">$JOBNAME</span>,\n    <span class=\"token assign-left variable\">Jar</span><span class=\"token operator\">=</span><span class=\"token variable\">$JARFILE</span>,\n    <span class=\"token assign-left variable\">Args</span><span class=\"token operator\">=</span><span class=\"token punctuation\">[</span>\n        /usr/lib/spark/bin/spark-submit,\n        --deploy-mode,client,\n        --properties-file,/etc/spark/conf/spark-defaults.conf,\n        --conf,spark.yarn.executor.memoryOverhead<span class=\"token operator\">=</span><span class=\"token number\">2048</span>,\n        --conf,spark.executor.memory<span class=\"token operator\">=</span>4g,\n        --packages,<span class=\"token variable\">$SPARK_PACKAGES</span>\n    <span class=\"token punctuation\">]</span>,\n    <span class=\"token assign-left variable\">ActionOnFailure</span><span class=\"token operator\">=</span><span class=\"token variable\">${ACTION_ON_FAIL}</span>'</code></pre></div>\n<p>Spark 작업 실행은 <code class=\"language-text\">Spark-submit</code>을 이용하여 클라이언트에 배포하는 형식입니다.\n이를 위해 jar 파일이 클라이언트의 로컬 경로에 포함되어 있어야 합니다.\nActionOnFailure를 통해 실패 시 Terminate, Stop 등의 옵션을 지정할 수 있습니다.</p>\n<p>만약 등록한 작업을 취소하고 싶다면, <code class=\"language-text\">cancel-steps</code>를 이용하시면 됩니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ aws emr cancel-steps <span class=\"token punctuation\">..</span>.</code></pre></div>\n<p>Spark 작업이 주기적으로 실행되어야 한다면,\n가장 간단한 방법은 위의 EMR step 등록 스크립트를 crontab으로 등록하는 것 입니다.\n만약 작업이 다양하고 복잡하다면, <strong>AWS Data Pipeline</strong> 이라는 제품을 고려해보는 것도 방법입니다.\n<a href=\"https://aws.amazon.com/ko/datapipeline/details/\">https://aws.amazon.com/ko/datapipeline/details/</a></p>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<ul>\n<li><a href=\"http://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-spark-submit-step.html\">http://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-spark-submit-step.html</a></li>\n<li><a href=\"http://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-work-with-steps.html\">http://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-work-with-steps.html</a></li>\n</ul>\n<br>","excerpt":"AWS EMR은 특정 작업을 등록할 수 있는 step 이라는 기능을 제공합니다.\n예를 들어 매일 새벽에 클러스터에서 돌려야하는 Batch…"}}},{"id":"0d2128fb-e03c-513c-a13e-65512e32e50f","title":"AWS 환경에서 Cloudera Manager 설치하기","slug":"cloudera-install","publishDate":"June 23, 2017","publishDateISO":"2017-06-23","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"cdc4d71a-e492-55c0-b955-f40f79e66e7d","childMarkdownRemark":{"id":"2e871a94-f412-52b4-a05e-d7e994b02bcc","timeToRead":1,"html":"<p>클라우데라 매니저는 하둡 에코시스템을 쉽게 설치하고 관리할 수 있도록 도와주는 도구입니다.\n이를 이용하여 AWS EC2 인스턴스에 하둡 클러스터를 설치하고 실행시키는 방법에 대해 정리해보았습니다.\n내 노트북에 가상머신 여러 개를 띄우기 힘든 경우에 좋은 대안이 될 수 있습니다.</p>\n<br>\n<h2 id=\"cloudera-manager\" style=\"position:relative;\"><a href=\"#cloudera-manager\" aria-label=\"cloudera manager permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Cloudera Manager</h2>\n<p>클라우데라는 데이터 인프라 관련 솔루션과 컨설팅을 하는 하둡 전문 기업입니다.\n하둡의 창시자 \"더그 커팅\"도 클라우데라의 수석 아키텍트로 일하고 있습니다.\nImpala, Hue 등 여러 오픈소스도 개발하고 있으며,\n오픈소스 하둡 프로젝트로부터 사람들이 쉽게 설치할 수 있도록 배포판(CDH)을 만들어서 제공해줍니다.\nCloudera Manager에는 유료, 무료버전이 있는데 여기에서는 무료버전(Express)을 설치하겠습니다.</p>\n<br>\n<h2 id=\"install\" style=\"position:relative;\"><a href=\"#install\" aria-label=\"install permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Install</h2>\n<p><img src=\"https://hadoopabcd.files.wordpress.com/2015/01/2.png?w=1378&#x26;h=510\"></p>\n<p>설치는 AWS EC2 m4.large / CentOS / 8GiB 에서 진행하였습니다.\n프리티어인 t2.micro 의 경우 내려가거나 설치가 안될 수 있기 때문에 제외하고 아무거나 쓰셔도 상관없습니다.</p>\n<p><img src=\"https://hadoopabcd.files.wordpress.com/2015/01/3.png\"></p>\n<p>클러스터의 수에 따라 인스턴스를 생성해줍니다. 그리고 Elastic IP로 public IP를 할당시켜줍니다.\nCloudera Manager는 기본으로 7180 포트를 사용하기 때문에 Inbound에서 열어주어야 합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ yum <span class=\"token function\">install</span> <span class=\"token function\">wget</span>\n$ <span class=\"token function\">wget</span> http://archive.cloudera.com/cm4/installer/latest/cloudera-manager-installer.bin\n$ <span class=\"token function\">chmod</span> +x cloudera-manager-installer.bin\n$ ./cloudera-manager-installer.bin</code></pre></div>\n<p>먼저 JDK를 설치한 다음, 위의 명령어를 통해 cloudera-manager-installer를 설치하고 실행시켜줍니다.</p>\n<p><img src=\"/assets/images/cloudera-login.png\"></p>\n<p>설치가 완료되고 나서, <code class=\"language-text\">localhost:7180</code>으로 접속하면 다음과 같은 로그인 화면이 나타납니다.\n초기 유저 아이디와 패스워드는 admin 입니다. 이후에는 본인이 원하는 환경에 맞추어 설치를 진행하면 됩니다.</p>\n<br>\n<h2 id=\"trouble-shooting\" style=\"position:relative;\"><a href=\"#trouble-shooting\" aria-label=\"trouble shooting permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Trouble Shooting</h2>\n<p><img src=\"/assets/images/error.png\" alt=\"Error1\"></p>\n<p><code class=\"language-text\">Fatal Error: SELinux is enabled. It must be disabled to install and use this product.</code>\n보안 관련된 문제인데 <code class=\"language-text\">vi /etc/selinux/config</code>로 들어가서 SELinux를 해제시켜주면 해결 됩니다.</p>\n<br>\n<p><img src=\"/assets/images/fail.png\" alt=\"Error2\"></p>\n<p>CDH를 설치하기 위해 <code class=\"language-text\">sudo vi /etc/ssh/sshd_config</code>에 들어가\n임시로 루트 계정의 SSH 접속을 허용해주어야 합니다.\n설치후에는 다시 잠금 설정해주셔도 됩니다.</p>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<ul>\n<li><a href=\"http://www.cloudera.com/documentation/manager/5-1-x/Cloudera-Manager-Installation-Guide/cm5ig_install_on_ec2.html\">http://www.cloudera.com/documentation/manager/5-1-x/Cloudera-Manager-Installation-Guide/cm5ig<em>install</em>on_ec2.html</a></li>\n</ul>\n<br>","excerpt":"클라우데라 매니저는 하둡 에코시스템을 쉽게 설치하고 관리할 수 있도록 도와주는 도구입니다.\n이를 이용하여 AWS EC…"}}},{"id":"5fb2b1b6-0c88-5b33-b094-05fdd281005c","title":"Spark의 Random Sampling에 대하여","slug":"spark-sampling","publishDate":"June 20, 2017","publishDateISO":"2017-06-20","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"d005037c-e152-5d2c-9817-eeee932c5e09","childMarkdownRemark":{"id":"e5acac9d-9bd0-5a16-aae3-05e8929d391e","timeToRead":1,"html":"<p>데이터를 분석하다보면 임의의 샘플을 추출해야 하는 상황이 생깁니다.\n그래서 이번에는 Spark에서 랜덤 샘플링을 하는 방법에 대해 정리해보았습니다.</p>\n<br>\n<h2 id=\"sample\" style=\"position:relative;\"><a href=\"#sample\" aria-label=\"sample permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Sample()</h2>\n<p>Spark RDD API 에는 다양한 sampling 메서드가 존재합니다.\n그 중에서 가장 기본이 되는 <code class=\"language-text\">sample()</code>에 대해 먼저 알아보겠습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># sample(boolean withReplacement, double fraction, long seed)</span>\nval rdd <span class=\"token operator\">=</span> sc<span class=\"token punctuation\">.</span>parallelize<span class=\"token punctuation\">(</span><span class=\"token number\">1</span> to <span class=\"token number\">10000</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span>\nrdd<span class=\"token punctuation\">.</span>sample<span class=\"token punctuation\">(</span>false<span class=\"token punctuation\">,</span> <span class=\"token number\">0.1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>count</code></pre></div>\n<p>첫 번째 인자는 추출 방식을 결정합니다. <strong>True면 복원추출, False면 비복원추출</strong> 을 실행합니다.\n여기에서 말하는 복원추출이란, 한 번 뽑은 것을 다시 뽑을 수 있게 하는 방법을 말합니다.\n세 번째 인자로 시드 변수를 지정할 수 있습니다.\n시드란, 컴퓨터가 난수를 일정하게 생성하지 않도록 변화를 주는 값을 말합니다.</p>\n<br>\n<h2 id=\"takesample\" style=\"position:relative;\"><a href=\"#takesample\" aria-label=\"takesample permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>takeSample()</h2>\n<p>takeSample()도 랜덤 샘플링을 지원하는 메서드지만, 위와 조금 다른 점이 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># takeSample(boolean withReplacement, int num, long seed)</span>\nval rdd <span class=\"token operator\">=</span> sc<span class=\"token punctuation\">.</span>parallelize<span class=\"token punctuation\">(</span><span class=\"token number\">1</span> to <span class=\"token number\">1000</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span>\nrdd<span class=\"token punctuation\">.</span>takeSample<span class=\"token punctuation\">(</span>false<span class=\"token punctuation\">,</span> <span class=\"token number\">100</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p><code class=\"language-text\">takeSample()</code>은 두 번째 인자를 지정하여 몇 개를 추출할 것인지 정할 수 있습니다.\n하지만, 결과 값이 RDD가 아닌 리스트나 배열이기 때문에 <strong>메모리에 주의</strong> 해야 합니다.\n정리하자면, 크기를 정해놓고 샘플을 추출하고자 한다면 takeSample() 메서드가 적합하고\n메모리를 생각해서 작은 값을 추출할 때 사용하는 것이 좋습니다.</p>\n<p>이외에도 <code class=\"language-text\">sampleByKey, sampleByKeyExtract</code> 메서드가 존재합니다.</p>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<ul>\n<li><a href=\"https://spark.apache.org/docs/1.6.2/api/java/org/apache/spark/rdd/RDD.html\">https://spark.apache.org/docs/1.6.2/api/java/org/apache/spark/rdd/RDD.html</a></li>\n</ul>\n<br>","excerpt":"데이터를 분석하다보면 임의의 샘플을 추출해야 하는 상황이 생깁니다.\n그래서 이번에는 Spark…"}}},{"id":"dea745a4-cb4c-53c1-9a2b-eb9a44e5b9d0","title":"Spark의 Temporary View에 대하여","slug":"spark-temp-view","publishDate":"June 16, 2017","publishDateISO":"2017-06-16","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"6da21b62-c3d6-5a04-bbe7-be693d5a5ff7","childMarkdownRemark":{"id":"3a3f8a1d-10e8-576e-98d6-87748b4bdbed","timeToRead":2,"html":"<p>SQL의 View 처럼 Spark에서도 View를 지원합니다.\n이 포스팅에서는 Spark 2.1.0 부터 생긴 <code class=\"language-text\">Spark Global Temporary View</code>와\n기존의 <code class=\"language-text\">TempView</code>가 어떤 차이가 있는지 그리고 어떻게 사용해야하는지 알아보곘습니다.</p>\n<br>\n<h2 id=\"spark-temporary-view\" style=\"position:relative;\"><a href=\"#spark-temporary-view\" aria-label=\"spark temporary view permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Spark Temporary View</h2>\n<p>공식문서를 보면 Spark의 Temporary View는 Session-Scope 입니다.\n무슨 말이냐 하면, View의 생명주기가 세션에 달려있다는 뜻 입니다.\n(여기에서 말하는 세션은 SparkSession 입니다)\n그리고, 세션이 종료되면 자동으로 View 테이블이 Drop 됩니다.</p>\n<br>\n<h2 id=\"createorreplacetempview\" style=\"position:relative;\"><a href=\"#createorreplacetempview\" aria-label=\"createorreplacetempview permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>CreateOrReplaceTempView</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">df <span class=\"token operator\">=</span> spark<span class=\"token punctuation\">.</span>sql<span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>cache<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span> df<span class=\"token punctuation\">.</span>count<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\ndf<span class=\"token punctuation\">.</span>CreateOrReplaceTempView<span class=\"token punctuation\">(</span><span class=\"token string\">\"TempView\"</span><span class=\"token punctuation\">)</span>\ndf<span class=\"token punctuation\">.</span>dropTempView<span class=\"token punctuation\">(</span><span class=\"token string\">\"TempView\"</span><span class=\"token punctuation\">)</span>\ndf<span class=\"token punctuation\">.</span>unpersist<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>먼저 기존에 사용하던 TempView를 보겠습니다.\n위의 예시는 PySpark 코드입니다.\n세 번째 줄의 <code class=\"language-text\">createOrReplaceTempView</code>가 View를 생성하는 함수인데,\nSpark은 Lazy evaluation이기 때문에 아직 실행 되기 이전 입니다.\n이후 두 번째 줄에서 count() 함수를 실행하면 생성되며,\nTempView라는 이름으로 메모리에 두고 사용할 수 있게 됩니다.\n다 사용한 다음에는 꼭 <code class=\"language-text\">unpersist</code> 함수로 할당된 메모리를 해제시켜줘야 합니다.</p>\n<p>위와 다르게 Temp View에 대한 명령만 내리고 마지막에 한번에 처리해도 되지만,\n여러 개로 쪼개서 명령을 내리는 것이 상대적으로 빠르다고 합니다.</p>\n<br>\n<h2 id=\"global-temporary-view\" style=\"position:relative;\"><a href=\"#global-temporary-view\" aria-label=\"global temporary view permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Global Temporary View</h2>\n<div class=\"gatsby-highlight\" data-language=\"sql\"><pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">CREATE</span> <span class=\"token keyword\">GLOBAL</span> <span class=\"token keyword\">TEMPORARY</span> <span class=\"token keyword\">VIEW</span> temp_view <span class=\"token keyword\">AS</span> <span class=\"token keyword\">SELECT</span> a<span class=\"token punctuation\">,</span> b <span class=\"token keyword\">FROM</span> tbl\n<span class=\"token keyword\">SELECT</span> <span class=\"token operator\">*</span> <span class=\"token keyword\">FROM</span> global_temp<span class=\"token punctuation\">.</span>temp_view\n<span class=\"token keyword\">DROP</span> <span class=\"token keyword\">VIEW</span> global_temp<span class=\"token punctuation\">.</span>temp_view</code></pre></div>\n<p>위의 예시는 Spark SQL 코드입니다.\nGlobal Temporary View는 Spark 2.1.0에서 처음 소개되었으며, <code class=\"language-text\">GLOBAL TEMPORARY VIEW</code> 라는 키워드로 생성합니다.\n그렇게 선언하고 나면 일종의 임시 테이블로 접근할 수 있습니다.\n삭제할 때는 <code class=\"language-text\">DROP VIEW</code> 라는 키워드로 삭제합니다.</p>\n<p>하지만 Global Temporary View는 조금 위험합니다.\n이 View는 말 그대로 전역적인 상태로 남기 위해 시스템의 임시 데이터베이스로 연결됩니다.\n그래서 접근할 때, <code class=\"language-text\">global_temp</code>로 접근하게 됩니다.</p>\n<p>결론부터 말하자면 Global Temporary View는 모든 세션에서 공유 가능하며,\nSpark 어플리케이션이 종료되기 전까지 살아있게 됩니다.\n제 경우 Master 노드의 하드디스크에 저장되어 있었습니다.\n이렇게 되면 일단 IO로 인해 로딩속도가 상당히 느려지고,\n만일 View의 크기가 메모리 용량을 넘어갔더라면 Master가 내려갈 수도 있는 상황입니다.\n이와 같은 이유로 Global Temporary View는 신중히 사용하는 것이 좋습니다.</p>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<ul>\n<li><a href=\"https://spark.apache.org/docs/2.1.1/api/java/org/apache/spark/sql/catalog/Catalog.html\">https://spark.apache.org/docs/2.1.1/api/java/org/apache/spark/sql/catalog/Catalog.html</a></li>\n<li><a href=\"https://spark.apache.org/docs/latest/sql-programming-guide.html#global-temporary-view\">https://spark.apache.org/docs/latest/sql-programming-guide.html#global-temporary-view</a></li>\n</ul>\n<br>","excerpt":"SQL의 View 처럼 Spark에서도 View를 지원합니다.\n이 포스팅에서는 Spark 2.1.…"}}},{"id":"879c5edc-af79-5354-a513-399c005b86ee","title":"Jupyter에서 Scala로 Spark 사용하는 방법","slug":"jupyter-spark","publishDate":"March 22, 2017","publishDateISO":"2017-03-22","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"f064af50-3130-58c7-bd5e-49ce84d97e59","childMarkdownRemark":{"id":"fb7d0e8a-5f23-5f32-a248-cecdc727f5dd","timeToRead":2,"html":"<p>이 글은 평소에 <strong>Jupyter Notebook</strong> 에 익숙해져있는 분들께 유용할 듯 합니다.\nZeppelin Notebook을 설정하는 방법은 <a href=\"http://swalloow.github.io/spark-zeppelin-install\">이전 포스팅</a>을 참고하시면 됩니다.</p>\n<br>\n<h2 id=\"apache-toree\" style=\"position:relative;\"><a href=\"#apache-toree\" aria-label=\"apache toree permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Apache Toree</h2>\n<p><img src=\"/assets/images/jupyter-toree.png\" alt=\"Jupyter-Toree\"></p>\n<p><strong>Apache Toree</strong> 는 Jupyter 커널을 통해 Spark에 접속하도록 해주는 아파치 오픈소스 프로젝트입니다.\n기존의 IPython Notebook은 파이썬에 제한되어 있었지만\nJupyter Kernel을 통해 다른 언어까지 확장 가능하도록 바뀌었습니다 (왼쪽 그림 참조).</p>\n<p>여기에서 더 나아가 Apache Toree는 <strong>Toree Kernel</strong> 을 통해 바로 Spark Driver에 연결함으로써,\nJupyter에서 Scala 언어로 Spark Driver/Context를 사용할 수 있게 만들었습니다.</p>\n<p>Toree가 Zeppelin과 다른 점은 <strong>Jupyter protocol</strong> 을 사용할 수 있다는 점 입니다.\n이미 수많은 생태계가 구축되어 있는 Jupyter에서 Spark가 잘 돌아간다면 굳이 Zeppelin을 쓸 필요가 있을까요 (<em>시각화가 어마어마한 강점이긴 합니다</em>).</p>\n<p>GitHub : <a href=\"https://github.com/apache/incubator-toree\">https://github.com/apache/incubator-toree</a></p>\n<br>\n<h2 id=\"jupyter-notebook에-toree-설치하기\" style=\"position:relative;\"><a href=\"#jupyter-notebook%EC%97%90-toree-%EC%84%A4%EC%B9%98%ED%95%98%EA%B8%B0\" aria-label=\"jupyter notebook에 toree 설치하기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Jupyter Notebook에 Toree 설치하기</h2>\n<p>Jupyter 노트북 커널 설정하는 방법은 <a href=\"http://swalloow.github.io/jupyter-notebook-kernel\">Jupyter Notebook 다중커널 설정하기</a>를,\nScala와 Spark을 설치하는 방법은 <a href=\"http://swalloow.github.io/spark-zeppelin-install\">OS X에서 Homebrew로 Spark, Zeppelin 설치하기</a>를 참고하시기 바랍니다.</p>\n<p>Toree는 아직 pre 버전만 존재하기 때문에 <code class=\"language-text\">--pre</code> 옵션을 붙여주시거나 파이썬 패키지를 통해 설치해주시면 됩니다.\n설치가 완료되면 jupyter kernel에 toree kernel을 설치해주는 과정이 필요한데 명령어를 통해 이 과정을 자동으로 진행합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ pip <span class=\"token function\">install</span> https://dist.apache.org/repos/dist/dev/incubator/toree/0.2.0/snapshots/dev1/toree-pip/toree-0.2.0.dev1.tar.gz\n$ jupyter toree <span class=\"token function\">install</span></code></pre></div>\n<p>혹시 <code class=\"language-text\">FileNotFoundError: [Errno 2] No such file or directory: &#39;/usr/local/spark/python/lib&#39;</code>\n이런 오류가 난다면, Spark 경로 환경변수를 읽지 못하는 문제입니다. <strong>Homebrew</strong> 를 통해 설치하셨다면 다음과 같이 환경변수를 등록해주시면 됩니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">SPARK_HOME</span><span class=\"token operator\">=</span>/usr/local/Cellar/apache-spark/2.1.0/libexec</code></pre></div>\n<br>\n<h2 id=\"잘-동작하는지-테스트를-해보자\" style=\"position:relative;\"><a href=\"#%EC%9E%98-%EB%8F%99%EC%9E%91%ED%95%98%EB%8A%94%EC%A7%80-%ED%85%8C%EC%8A%A4%ED%8A%B8%EB%A5%BC-%ED%95%B4%EB%B3%B4%EC%9E%90\" aria-label=\"잘 동작하는지 테스트를 해보자 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>잘 동작하는지 테스트를 해보자</h2>\n<p><img src=\"/assets/images/toree-kernel.png\" alt=\"Toree-Kernel\"></p>\n<p>잘 설치되었다면 <code class=\"language-text\">new</code> 했을 때 <code class=\"language-text\">Apache-Toree Scala</code>가 보이실 겁니다.\n잘 동작하는지 간단한 WordCounter 예제를 실행시켜 보시면 잘 동작하는 것을 확인할 수 있습니다.</p>\n<p><img src=\"/assets/images/toree-tuto.png\" alt=\"Toree-Tuto\"></p>\n<br>\n<h2 id=\"docker를-통해-jupyter-설정하는-방법\" style=\"position:relative;\"><a href=\"#docker%EB%A5%BC-%ED%86%B5%ED%95%B4-jupyter-%EC%84%A4%EC%A0%95%ED%95%98%EB%8A%94-%EB%B0%A9%EB%B2%95\" aria-label=\"docker를 통해 jupyter 설정하는 방법 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Docker를 통해 Jupyter 설정하는 방법</h2>\n<p>나는 이 모든 것이 귀찮다! 라면 Docker를 통해 노트북을 실행시키면 됩니다.\n제가 Docker를 통해 Notebook을 사용하지 않는 이유는 딱 한 가지 입니다.\nSpark만 쓰고 싶었는데 기타 등등이 많이 설치되어 있어서 컨테이너 메모리가 무려 <strong>4기가</strong> 나 됩니다...\n그래도 쓰겠다 싶으신 분들은 아래 링크를 참고하시면 됩니다.</p>\n<p><a href=\"https://hub.docker.com/r/jupyter/all-spark-notebook/\">https://hub.docker.com/r/jupyter/all-spark-notebook/</a></p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ docker pull jupyter/all-spark-notebook\n$ docker run -it --rm -p <span class=\"token number\">8888</span>:8888 jupyter/all-spark-notebook</code></pre></div>\n<p>이렇게 실행하고 8888번 포트로 접속하면 노트북을 실행할 수 있습니다.</p>\n<br>","excerpt":"이 글은 평소에 Jupyter Notebook 에 익숙해져있는 분들께 유용할 듯 합니다.\nZeppelin Notebook…"}}},{"id":"3bda34bf-e581-57bf-aa58-9130c0a3b6b1","title":"GFS, HDFS 그리고 MapReduce","slug":"map-reduce","publishDate":"March 14, 2017","publishDateISO":"2017-03-14","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"0c11f5f7-0e00-5786-9808-316f3c842c0f","childMarkdownRemark":{"id":"bbf8d9aa-58a2-57f0-98b1-ee6fd7837dbc","timeToRead":2,"html":"<p>데이터가 급속히 늘어나면서 기존의 방법으로 처리가 힘들어지자,\n빅데이터를 위한 대용량 분산 파일 시스템이 나타나기 시작했습니다.\n여기에서는 GFS, HDFS 그리고 Map Reduce 개념에 대해 정리해보려고 합니다.</p>\n<br>\n<h2 id=\"gfs-google-file-system\" style=\"position:relative;\"><a href=\"#gfs-google-file-system\" aria-label=\"gfs google file system permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>GFS (Google File System)</h2>\n<p>Google File System은 2003년 논문을 통해 소개되었습니다.\n이전에 구글에서 사용하던 파일 시스템은 Big File 이었는데,\n구글의 데이터가 급격히 늘어남에 따라 핵심 데이터 스토리지와 구글 검색 엔진을 위해\n최적화 된 파일 시스템이 필요하게 된 것 입니다.</p>\n<p><img src=\"/assets/images/GFS.png\" alt=\"Google File System\"></p>\n<p>GFS는 크게 하나의 master node와 여러 개의 slave node로 구성되어 있습니다.\n기능으로 보면 Master, Chunk Server, Client로 이루어져 있습니다.</p>\n<ul>\n<li><strong>Master</strong>: GFS 전체를 관리하고 통제하는 중앙 서버의 역할</li>\n<li><strong>Chunk Server</strong>: 물리적인 서버, 실제 입출력을 처리</li>\n<li><strong>Client</strong>: 파일 입출력을 요청하는 클라이언트 어플리케이션</li>\n</ul>\n<p>수행과정은 다음과 같습니다.\n먼저 Client가 Master에게 파일의 읽기, 쓰기를 요청하게 되면,\nMaster는 Client와 가까운 Chunk Server의 정보를 Client에게 전달합니다.\nClient는 전달받은 Chunk Server와 직접 통신하며 IO 작업을 수행하게 됩니다.</p>\n<p>GFS의 엄청난 강점은 <strong>Failuer Tolerance</strong> 입니다.\n다시 말해서, 물리적으로 서버 중 하나가 고장이 나도 정지하지 않고 잘 돌아가도록 설계되었습니다.\n예를 들어, Chunk Server 중 하나가 고장이 나면 Master는 고장나지 않은 Chunk Server의 정보를 전달하고\nMaster Server가 고장이 나면 다른 서버가 Master를 대체하게 됩니다.\n이러한 이유로 Chunk Server는 가격이 저렴한 범용 컴퓨터들로 구성할 수 있게 되었고, 클러스터 환경에서 잘 동작할 수 있게 되었습니다.</p>\n<br>\n<h2 id=\"mapreduce\" style=\"position:relative;\"><a href=\"#mapreduce\" aria-label=\"mapreduce permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>MapReduce</h2>\n<p>Map Reduce는 마찬가지로 2004년 구글의 논문(저자: 구글의 전설 제프 딘)을 통해 소개되었습니다.\n논문의 제목은 <strong>MapReduce: Simplified Data Processing on Large Clusters</strong> 입니다.\n즉, MapReduce는 말 그대로 대용량 분산 클러스터에서 데이터를 간단히 처리하는 방법입니다.</p>\n<p>그는 논문을 통해 2가지 Function을 제시하는데 바로 Map과 Reduce 입니다.\n논문에서 제시한 MapReduce의 예시 수도코드는 다음과 같습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span>String key<span class=\"token punctuation\">,</span> String value<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token operator\">//</span> key<span class=\"token punctuation\">:</span> document name\n    <span class=\"token operator\">//</span> value<span class=\"token punctuation\">:</span> document contents\n    <span class=\"token keyword\">for</span> each word w <span class=\"token keyword\">in</span> value<span class=\"token punctuation\">:</span>\n        EmitIntermediate<span class=\"token punctuation\">(</span>w<span class=\"token punctuation\">,</span> <span class=\"token string\">\"1\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token builtin\">reduce</span><span class=\"token punctuation\">(</span>String key<span class=\"token punctuation\">,</span> Iterator values<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token operator\">//</span> key<span class=\"token punctuation\">:</span> a word\n    <span class=\"token operator\">//</span> values<span class=\"token punctuation\">:</span> a <span class=\"token builtin\">list</span> of counts\n    <span class=\"token builtin\">int</span> result <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">for</span> each v <span class=\"token keyword\">in</span> values<span class=\"token punctuation\">:</span>\n        result <span class=\"token operator\">+=</span> ParseInt<span class=\"token punctuation\">(</span>v<span class=\"token punctuation\">)</span>\n    Emit<span class=\"token punctuation\">(</span>AsString<span class=\"token punctuation\">(</span>result<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>먼저 <strong>Map</strong> 함수는 어떤 key-value를 input으로 받아서 각 단어와 관련 발생 횟수를 출력합니다.\n그리고 <strong>Reduce</strong> 함수는 특정 단어에 대해 생성된 모든 카운트를 합산합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">map(k1, v1) -&gt; list(k2, v2)\nreduce(k2, list(v2)) -&gt; list(v2)</code></pre></div>\n<p><strong>Map</strong> 함수는 key-vale를 읽어서 필터링하거나 다른 값으로 변환시켜주며,\n<strong>Reduce</strong> 함수는 Map을 통해 출력된 리스트에\n새로운 key를 기준으로 Groupping하고 이를 Aggregation한 결과를 출력합니다.</p>\n<p><img src=\"/assets/images/mapreduce.png\" alt=\"MapReduce\"></p>\n<p>MapReduce는 여러 대의 컴퓨터에서 데이터를 처리하는 경우, 병렬처리를 하기 때문에 확장이 쉽습니다.\n스케줄러가 데이터를 분산 배치하면 worker에서 작업을 수행하고 각 중간 결과는 로컬 디스크에 저장되며,\n나중에 Reduce 연산을 할당받으면 중간 결과를 읽어와서 작업을 수행하고 마찬가지로 파일 시스템에 저장합니다.\n위의 그림과 같이 Master 노드에 모든 데이터를 받아서 처리하던 옛날 방식과 통신 처리면에서 확실히 줄어든 것을 알 수 있습니다.</p>\n<p>구글은 MapReduce를 URL 접근빈도, Web-Link Graph를 계산하는데 사용하였고,\n이를 통해 인덱싱, 정렬 등에서 엄청난 성능향상을 보여주었습니다.</p>\n<br>\n<h2 id=\"hdfs-hadoop-distributed-file-system\" style=\"position:relative;\"><a href=\"#hdfs-hadoop-distributed-file-system\" aria-label=\"hdfs hadoop distributed file system permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>HDFS (Hadoop Distributed File System)</h2>\n<p>Hadoop은 2006년 Doug Cutting과 Mike Cafarella가 개발한 분산처리 프레임워크입니다.\n이들은 구글의 GFS를 대체하기 위해 <strong>HDFS</strong> 와 <strong>MapReduce</strong> 를 구현하였습니다.</p>\n<p>GFS가 C++로 구현되었다면, Hadoop은 자바로 개발된 데다가 아파치 재단의 오픈소스로 넘어가면서 인기가 많아졌습니다.\nGFS를 구현한 결과물이기 때문에 크게 달라진 것은 없으나\n<strong>YARN, Hadoop Ecosystem</strong> 등 다른 장점으로 인해 많이 사용됩니다.</p>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<ul>\n<li><a href=\"http://xpgc.vicp.net/course/svt/TechDoc/storagepaper/gfs-sosp2003.pdf\">논문: The Google File System</a></li>\n<li><a href=\"https://static.googleusercontent.com/media/research.google.com/ko//archive/mapreduce-osdi04.pdf\">논문: MapReduce - Simplified Data Processing on Large Clusters</a></li>\n</ul>\n<br>","excerpt":"…"}}},{"id":"ec4cd801-966b-58d1-b29f-642aa46efc80","title":"OS X에서 Homebrew로 Spark, Zeppelin 설치하기","slug":"spark-zeppelin-install","publishDate":"March 13, 2017","publishDateISO":"2017-03-13","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"f45248c6-9caf-5a42-8dac-73586e202581","childMarkdownRemark":{"id":"1bb823f3-0f55-5944-a351-ca8c729d11bf","timeToRead":2,"html":"<blockquote>\n<p><strong>Apache Spark</strong> is a fast and general engine for large-scale data processing.\n<strong>Zeppelin</strong>, a web-based notebook that enables interactive data analytics.\nYou can make beautiful data-driven, interactive and collaborative documents with SQL, Scala and more.</p>\n</blockquote>\n<p>공식 문서에 나와있는 소개 글처럼 Spark는 대용량 데이터 처리를 위한 범용 엔진입니다.\n얼마 전까지는 <strong>범용적 목적의 분산 고성능 클러스터링 플랫폼</strong> 이라고 설명했는데 최근에 쉽게 다가가기 위해 바꾼듯 합니다.</p>\n<p>그리고 Zeppelin은 데이터 분석을 위한 웹 기반의 노트북입니다.\nZeppelin은 작년 말부터 Apache-Top Level project로 승격하면서 인기가 높아지고 있습니다.\nZeppelin이 Jupyter Notebook과 다른 점은 빅데이터 처리를 위해 Spark 등 다양한 아파치 프로젝트를 지원하고,\nJavascript 기반의 데이터 시각화가 내장되어 있어 편리합니다.</p>\n<br>\n<h2 id=\"spark-install\" style=\"position:relative;\"><a href=\"#spark-install\" aria-label=\"spark install permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Spark Install</h2>\n<p>Spark는 Scala로 구현되어 있지만 SDK를 통해 Java, Python API 또한 지원합니다.\n그리고 빅데이터 플랫폼으로 Hadoop, AWS S3, Cassandra 등 다양한 저장소를 지원합니다.\n만약 Hadoop이 필요없다면 홈페이지에서 Hadoop이 제외된 바이너리 파일로 설치하시면 됩니다.\n여기에서는 간단하게 OS X의 Homebrew를 통해 설치하도록 하겠습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ brew <span class=\"token function\">install</span> scala\n$ <span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">SCALA_HOME</span><span class=\"token operator\">=</span>/usr/local/bin/scala\n$ <span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\"><span class=\"token environment constant\">PATH</span></span><span class=\"token operator\">=</span><span class=\"token environment constant\">$PATH</span><span class=\"token builtin class-name\">:</span><span class=\"token variable\">$SCALA_HOME</span>/bin</code></pre></div>\n<p>먼저 스칼라를 설치하고 환경변수를 저장합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ brew <span class=\"token function\">install</span> apache-spark\n$ spark-shell</code></pre></div>\n<p>그리고 Spark을 설치한 다음, <code class=\"language-text\">spark-shell</code> 명령을 통해 실행시키면 됩니다.</p>\n<p><img src=\"/assets/images/spark-shell.png\" alt=\"spark-shell\"></p>\n<p><a href=\"http://172.30.105.117:4040\">http://172.30.105.117:4040</a> 주소로 접속하면 Spark UI를 확인할 수 있습니다.</p>\n<p><img src=\"/assets/images/spark-ui.png\" alt=\"spark-ui\"></p>\n<br>\n<h2 id=\"zeppelin-install\" style=\"position:relative;\"><a href=\"#zeppelin-install\" aria-label=\"zeppelin install permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Zeppelin Install</h2>\n<p>Zeppelin은 GitHub 저장소를 clone하여 설치하는 방법과 홈페이지에서 다운받는 방법이 있습니다.\n여기에서는 위와 마찬가지로 Homebrew를 통해 설치해보려 합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ brew <span class=\"token function\">install</span> apache-zeppelin\n$ /usr/local/Cellar/apache-zeppelin/0.7.0/bin/zeppelin-daemon.sh start\n$ /usr/local/Cellar/apache-zeppelin/0.7.0/bin/zeppelin-daemon.sh stop</code></pre></div>\n<p>brew 명령어로 apache-zeppelin을 설치하고\n스크립트를 실행하면 <a href=\"localhost:8080\">localhost:8080</a> 포트에서 Zeppelin을 사용할 수 있게 됩니다.\n명령어가 너무 길다보니 <code class=\"language-text\">~/.zshrc</code>에 등록해서 사용하면 좀 편리합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token function\">vi</span> ~/.zshrc\n$ <span class=\"token builtin class-name\">alias</span> zeppelin-start <span class=\"token operator\">=</span> <span class=\"token string\">\"/usr/.../bin/zeppelin-daemon.sh start\"</span>\n$ <span class=\"token builtin class-name\">alias</span> zeppelin-stop <span class=\"token operator\">=</span> <span class=\"token string\">\"/usr/.../bin/zeppelin-daemon.sh stop\"</span>\n$ <span class=\"token builtin class-name\">source</span> ~/.zshrc</code></pre></div>\n<p>위와 같이 alias로 등록해주면 앞으로 <code class=\"language-text\">zeppelin-start</code> 명령어를 통해 실행할 수 있게 됩니다.\n자세한 환경설정은 <a href=\"https://zeppelin.apache.org/\">Zeppelin 홈페이지</a>에서 확인하실 수 있습니다.</p>\n<br>","excerpt":"Apache Spark is a fast and general engine for large-scale data processing…"}}},{"id":"c83a7091-0a01-5886-876f-6a7e9d8cb6ca","title":"Pandas DataFrame을 병렬처리 하는 방법","slug":"pandas-parallel","publishDate":"February 27, 2017","publishDateISO":"2017-02-27","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"3a929e46-2df8-5ebb-a912-ab2e8ac6706f","childMarkdownRemark":{"id":"7f693de6-6997-5fe5-8cfc-b165faa35db3","timeToRead":1,"html":"<p>Scikit-learn의 모델들은 cython과 joblib으로 최적화 및 자동 병렬처리 되도록 설계되어 있지만,\nPandas는 여전히 내부적으로 병렬처리 기능을 지원하지 않습니다.</p>\n<p>하지만, 큰 규모의 DataFrame을 돌리다보면 전처리에도 시간이 많이 걸리게 됩니다.\n그런 경우에 병렬처리를 통해 속도를 개선할 수 있습니다.</p>\n<p>이 포스팅에서는 가장 간단한 CPU 프로세스 병렬처리를 다루도록 하겠습니다. 방법은 간단합니다.\n거대한 DataFrame을 CPU 코어 수 만큼 분할하고, 전처리 기능을 수행한 다음 다시 합치면 됩니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token keyword\">import</span> seaborn <span class=\"token keyword\">as</span> sns\n<span class=\"token keyword\">from</span> multiprocessing <span class=\"token keyword\">import</span> Pool\n\nnum_cores <span class=\"token operator\">=</span> <span class=\"token number\">4</span>\niris <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>DataFrame<span class=\"token punctuation\">(</span>sns<span class=\"token punctuation\">.</span>load_dataset<span class=\"token punctuation\">(</span><span class=\"token string\">'iris'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>예시로 iris 데이터를 사용하겠습니다.\ncpu 코어의 수는 <code class=\"language-text\">multiprocessing.cpu_count()</code> 함수를 통해서 얻으실 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">parallelize_dataframe</span><span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">,</span> func<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    df_split <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array_split<span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">,</span> num_cores<span class=\"token punctuation\">)</span>\n    pool <span class=\"token operator\">=</span> Pool<span class=\"token punctuation\">(</span>num_cores<span class=\"token punctuation\">)</span>\n    df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>concat<span class=\"token punctuation\">(</span>pool<span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span>func<span class=\"token punctuation\">,</span> df_split<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    pool<span class=\"token punctuation\">.</span>close<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    pool<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> df</code></pre></div>\n<p>parallelize_dataframe은 어떤 전처리 함수가 들어왔을 때 CPU 병렬처리를 도와주는 함수입니다.\nmultiprocessing.Pool을 이용하여 분할된 DataFrame에 함수를 적용시키고,\npd.concat()으로 다시 합치는 과정입니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">multiply_columns</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    data<span class=\"token punctuation\">[</span><span class=\"token string\">'length_of_word'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> data<span class=\"token punctuation\">[</span><span class=\"token string\">'species'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">apply</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> data</code></pre></div>\n<p>각 종 이름의 글자 수를 세는 전처리 함수를 예로 들어 속도차이를 확인해보겠습니다.\n결과는 아래와 같습니다.</p>\n<br>\n<p><img src=\"/assets/images/pandas-parallel.png\" alt=\"pandas-parrallel\"></p>\n<p>다른 방법으로 Pandas의 engine에 Dask를 사용하는 방법도 있습니다.\n<a href=\"http://dask.readthedocs.io/en/latest/\">http://dask.readthedocs.io/en/latest/</a></p>","excerpt":"Scikit-learn의 모델들은 cython과 joblib으로 최적화 및 자동 병렬처리 되도록 설계되어 있지만,\nPandas…"}}},{"id":"6c0b771c-38aa-5b9b-9f90-cf9fffe85421","title":"Pandas DataFrame을 MySQL에 저장하는 방법","slug":"dataframe-to-mysql","publishDate":"February 26, 2017","publishDateISO":"2017-02-26","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"e3b0fdda-5a39-5feb-b648-af85cc3e320a","childMarkdownRemark":{"id":"aa742a71-02df-5247-a8c3-37da2b1de659","timeToRead":1,"html":"<p>Pandas DataFrame을 MySQL에 저장하기 위해 먼저 커넥터가 필요합니다.\n파이썬3에서는 <code class=\"language-text\">MySQLdb</code>를 지원하지 않기 때문에, <code class=\"language-text\">pymysql</code>로 불러와야 합니다.\n꼭 pymysql이 아니어도 상관없지만, 사용해보면 <code class=\"language-text\">mysql-connector</code> 보다 빠르다는걸 체감할 수 있습니다. 먼저, 필요한 패키지를 설치해줍니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\"># python3\n$ pip install pymysql\n$ pip install sqlalchemy</code></pre></div>\n<br>\n<h2 id=\"sqlalchemy-pymysql-mysqldb\" style=\"position:relative;\"><a href=\"#sqlalchemy-pymysql-mysqldb\" aria-label=\"sqlalchemy pymysql mysqldb permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>SQLAlchemy, pymysql, MySQLdb</h2>\n<p><code class=\"language-text\">install_as_MySQLdb()</code> 함수를 통해 MySQLdb와 호환 가능합니다.\n이제 sqlalchemy를 통해 DB에 연결할 수 있습니다.\n주소에서 root, password는 DB에 맞게 변경해야 합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd\n<span class=\"token keyword\">from</span> sqlalchemy <span class=\"token keyword\">import</span> create_engine\n\n<span class=\"token comment\"># MySQL Connector using pymysql</span>\npymysql<span class=\"token punctuation\">.</span>install_as_MySQLdb<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">import</span> MySQLdb\n\nengine <span class=\"token operator\">=</span> create_engine<span class=\"token punctuation\">(</span><span class=\"token string\">\"mysql+mysqldb://root:\"</span><span class=\"token operator\">+</span><span class=\"token string\">\"password\"</span><span class=\"token operator\">+</span><span class=\"token string\">\"@localhost/db_name\"</span><span class=\"token punctuation\">,</span> encoding<span class=\"token operator\">=</span><span class=\"token string\">'utf-8'</span><span class=\"token punctuation\">)</span>\nconn <span class=\"token operator\">=</span> engine<span class=\"token punctuation\">.</span>connect<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<br>\n<h2 id=\"mysql에-저장하기\" style=\"position:relative;\"><a href=\"#mysql%EC%97%90-%EC%A0%80%EC%9E%A5%ED%95%98%EA%B8%B0\" aria-label=\"mysql에 저장하기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>MySQL에 저장하기</h2>\n<p>이제 DataFrame을 MySQL에 테이블 형태로 저장할 차례입니다.\n아래와 같이 pandas의 <code class=\"language-text\">to_sql()</code> 함수를 사용하여 저장하면 됩니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">df<span class=\"token punctuation\">.</span>to_sql<span class=\"token punctuation\">(</span>name<span class=\"token operator\">=</span>table<span class=\"token punctuation\">,</span> con<span class=\"token operator\">=</span>engine<span class=\"token punctuation\">,</span> if_exists<span class=\"token operator\">=</span><span class=\"token string\">'append'</span><span class=\"token punctuation\">)</span>\npython\n\n자주 사용할 수 있으니 함수로 따로 설정해주면 편합니다<span class=\"token punctuation\">.</span></code></pre></div>","excerpt":"Pandas DataFrame을 MySQL에 저장하기 위해 먼저 커넥터가 필요합니다.\n파이썬…"}}},{"id":"8396978b-cf43-57c1-8853-2a1fd69f9e6e","title":"Jupyter Notebook 외부접속 설정하기","slug":"jupyter-config","publishDate":"February 12, 2017","publishDateISO":"2017-02-12","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"7c18488e-799f-581d-afbd-cb16754e4b6e","childMarkdownRemark":{"id":"7403eebf-2776-50aa-a81a-b617b9334fbb","timeToRead":1,"html":"<p>이번 포스팅에서는 Jupyter Notebook을 환경구축하고 난 이후에 외부접속을 설정하는 과정에 대해 알아보겠습니다. 환경구축하는 방법에 대해서는 이전의 포스팅 <a href=\"https://swalloow.github.io/jupyter-notebook-kernel\">https://swalloow.github.io/jupyter-notebook-kernel</a> 을 참고해주시기 바랍니다.</p>\n<br>\n<h2 id=\"외부접속-허용하기\" style=\"position:relative;\"><a href=\"#%EC%99%B8%EB%B6%80%EC%A0%91%EC%86%8D-%ED%97%88%EC%9A%A9%ED%95%98%EA%B8%B0\" aria-label=\"외부접속 허용하기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>외부접속 허용하기</h2>\n<p>우선 <code class=\"language-text\">~/.jupyter/jupyter_notebook_config.py</code> 에 있는 Jupyter Notebook의 설정파일을 열어줍니다. 아마 모두 주석이 걸려있을텐데 필요한 부분만 수정해주시면 됩니다.</p>\n<ul>\n<li>실행경로 변경 : <code class=\"language-text\">c.NotebookApp.default_url = &#39;/tree&#39;</code></li>\n<li>외부접속 허용 : <code class=\"language-text\">c.NotebookApp.ip = &#39;0.0.0.0&#39;</code></li>\n<li>포트변경: <code class=\"language-text\">c.NotebookApp.port = 8888</code></li>\n</ul>\n<br>\n<h2 id=\"비밀번호-설정하기\" style=\"position:relative;\"><a href=\"#%EB%B9%84%EB%B0%80%EB%B2%88%ED%98%B8-%EC%84%A4%EC%A0%95%ED%95%98%EA%B8%B0\" aria-label=\"비밀번호 설정하기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>비밀번호 설정하기</h2>\n<p>비밀번호를 설정하면 url에 접속했을 때, 암호를 입력하는 화면이 나타나게 됩니다. Jupyter Notebook에서는 HASH 값을 통해 암호화된 비밀번호를 적용할 수 있습니다.</p>\n<p>먼저, 새로운 노트를 생성하고 다음의 스크립트를 작성합니다. 암호를 설정하는 칸이 나오고 결과 값이 주어지면 그대로 복사해서 <code class=\"language-text\">c.NotebookApp.password = u&#39;&#39;</code> 여기에 붙여넣기 하시면 됩니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> notebook<span class=\"token punctuation\">.</span>auth <span class=\"token keyword\">import</span> passwd<span class=\"token punctuation\">;</span>\npasswd<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>","excerpt":"이번 포스팅에서는 Jupyter Notebook…"}}},{"id":"ac4d21a5-d1d3-51f4-b301-ef5fe84a6eed","title":"DB 테이블을 DataFrame으로 읽어오는 방법","slug":"db-to-dataframe","publishDate":"January 14, 2017","publishDateISO":"2017-01-14","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"c2cd971c-bec9-5e5a-8704-02f3736f9caa","childMarkdownRemark":{"id":"cbaa2cc7-96ca-560a-86c9-be1cfe047b8e","timeToRead":1,"html":"<p>본 포스팅에서는 예시를 MySQL로 들지만 sqlalchemy의 커넥터만 변경해주면,\nMySQL 뿐만 아니라 모든 데이터베이스에 적용가능합니다.</p>\n<p>먼저 sqlalchemy가 설치되어 있지 않다면 설치해줍니다.\nsqlalchemy와 mysql을 연결하는 패키지가 필요합니다.</p>\n<p>파이썬2를 사용한다면 <code class=\"language-text\">mysql-python</code>, 3을 사용한다면 <code class=\"language-text\">pymysql</code>을 설치해주면 됩니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\"># python2\n$ pip install mysql-python\n$ pip install sqlalchemy\n\n# python3\n$ pip install pymysql\n$ pip install sqlalchemy</code></pre></div>\n<br>\n<p>이제 sqlalchemy를 통해 DB에 연결해보겠습니다.\n주소에서 root, password, table은 DB에 맞게 변경해야 합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd\n<span class=\"token keyword\">from</span> sqlalchemy <span class=\"token keyword\">import</span> create_engine\n\nengine <span class=\"token operator\">=</span> create_engine<span class=\"token punctuation\">(</span><span class=\"token string\">'mysql://root:password@localhost/table'</span><span class=\"token punctuation\">,</span> convert_unicode<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\nconn <span class=\"token operator\">=</span> engine<span class=\"token punctuation\">.</span>connect<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<br>\n<p>마지막으로 pandas를 통해 table을 읽어들일 차례입니다.\npandas의 <code class=\"language-text\">read_sql()</code> 은 0.19 버전부터 생겨났으며, sqlalchemy를 필수로 사용하도록 되어 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">data <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_sql_table<span class=\"token punctuation\">(</span><span class=\"token string\">'table_name'</span><span class=\"token punctuation\">,</span> conn<span class=\"token punctuation\">)</span>\ndata<span class=\"token punctuation\">.</span>head<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<br>\n<h2 id=\"mysql-dump-파일을-읽어오는-방법\" style=\"position:relative;\"><a href=\"#mysql-dump-%ED%8C%8C%EC%9D%BC%EC%9D%84-%EC%9D%BD%EC%96%B4%EC%98%A4%EB%8A%94-%EB%B0%A9%EB%B2%95\" aria-label=\"mysql dump 파일을 읽어오는 방법 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>MySQL dump 파일을 읽어오는 방법</h2>\n<p>추가로 외부로부터 데이터를 넘겨받을 때 DB dump 파일 (.sql) 을 넘겨받는 경우가 있습니다.\n데이터베이스 전체를 받은 dump 파일이라면, 커멘드에 다음과 같이 입력합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\"># root, database, data.sql은 알아서 수정\n$ mysqldump -u root -p database &gt; data.sql</code></pre></div>\n<br>\n<p>특정 테이블만 받고 싶다면, 커멘드에 다음과 같이 입력합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\"># root, table, database, data.sql은 알아서 수정\n$ mysqldump -u root -p database table &gt; data.sql</code></pre></div>\n<br>\n<p>위와 같은 과정이 끝나면, 나의 MySQL 계정에 데이터가 저장된 것을 확인할 수 있습니다.\n이후에는 앞에서 설명한대로 pandas를 통해 DataFrame으로 변환하면 됩니다.</p>","excerpt":"본 포스팅에서는 예시를 MySQL로 들지만 sqlalchemy의 커넥터만 변경해주면,\nMySQL…"}}},{"id":"2b717c14-f760-515c-ab04-78976e855c7d","title":"Jupyter Notebook 다중커널 설정하기","slug":"jupyter-notebook-kernel","publishDate":"January 28, 2017","publishDateISO":"2017-01-28","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"474c97da-c421-5a28-804e-a766dbdf66d6","childMarkdownRemark":{"id":"d9e323c4-1b1e-5b95-adfa-3b23e2ba4c60","timeToRead":5,"html":"<p>Jupyer Notebook은 웹 기반의 대화형 노트북 지원으로 수식, 표, 그림 등을 표현하기 쉬운 개발 환경입니다.\n코딩과 문서화(Markdown)까지 한 화면에서 가능하며 커널 확장을 통해 다양한 파이썬 버전 뿐만 아니라 여러 언어를 지원합니다.</p>\n<p>이제 파이썬을 처음 설치한다고 가정하고 맥 OS에서 간단하게 jupyter 환경설정하는 방법을 소개해드리고자 합니다.</p>\n<br>\n<h2 id=\"pyenv-설치하기\" style=\"position:relative;\"><a href=\"#pyenv-%EC%84%A4%EC%B9%98%ED%95%98%EA%B8%B0\" aria-label=\"pyenv 설치하기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>pyenv 설치하기</h2>\n<h3 id=\"1-homebrew를-통해-pyenv를-설치\" style=\"position:relative;\"><a href=\"#1-homebrew%EB%A5%BC-%ED%86%B5%ED%95%B4-pyenv%EB%A5%BC-%EC%84%A4%EC%B9%98\" aria-label=\"1 homebrew를 통해 pyenv를 설치 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. Homebrew를 통해 pyenv를 설치</h3>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ brew install pyenv</code></pre></div>\n<br>\n<h3 id=\"2-pyenv-init을-bashrc에-추가-zsh를-사용하는-경우-zshrc\" style=\"position:relative;\"><a href=\"#2-pyenv-init%EC%9D%84-bashrc%EC%97%90-%EC%B6%94%EA%B0%80-zsh%EB%A5%BC-%EC%82%AC%EC%9A%A9%ED%95%98%EB%8A%94-%EA%B2%BD%EC%9A%B0-zshrc\" aria-label=\"2 pyenv init을 bashrc에 추가 zsh를 사용하는 경우 zshrc permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. pyenv init을 ~/.bashrc에 추가 (zsh를 사용하는 경우 ~/.zshrc)</h3>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ echo &#39;eval &quot;$(pyenv init -)&quot;&#39; &gt;&gt; ~/.bashrc</code></pre></div>\n<br>\n<h3 id=\"3-pyenv-사용해보기\" style=\"position:relative;\"><a href=\"#3-pyenv-%EC%82%AC%EC%9A%A9%ED%95%B4%EB%B3%B4%EA%B8%B0\" aria-label=\"3 pyenv 사용해보기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. pyenv 사용해보기</h3>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ pyenv versions\nsystem (set by /Users/USERNAME/.pyenv/version)</code></pre></div>\n<br>\n<h3 id=\"4-pyenv-명령어-정리\" style=\"position:relative;\"><a href=\"#4-pyenv-%EB%AA%85%EB%A0%B9%EC%96%B4-%EC%A0%95%EB%A6%AC\" aria-label=\"4 pyenv 명령어 정리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4. pyenv 명령어 정리</h3>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ pyenv install &lt;version&gt;\n$ pyenv uninstall &lt;version&gt;\n$ pyenv install -list\n$ pyenv shell &lt;version&gt;\n$ pyenv activate &lt;environment&gt;\n$ pyenv deactivate &lt;environment&gt;</code></pre></div>\n<br>\n<h2 id=\"pyenv-virtualenv-설치하기\" style=\"position:relative;\"><a href=\"#pyenv-virtualenv-%EC%84%A4%EC%B9%98%ED%95%98%EA%B8%B0\" aria-label=\"pyenv virtualenv 설치하기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>pyenv-virtualenv 설치하기</h2>\n<h3 id=\"1-homebrew를-통해-pyenv-virtualenv를-설치\" style=\"position:relative;\"><a href=\"#1-homebrew%EB%A5%BC-%ED%86%B5%ED%95%B4-pyenv-virtualenv%EB%A5%BC-%EC%84%A4%EC%B9%98\" aria-label=\"1 homebrew를 통해 pyenv virtualenv를 설치 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. Homebrew를 통해 pyenv-virtualenv를 설치</h3>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ brew install pyenv-virtualenv</code></pre></div>\n<br>\n<h3 id=\"2-virtualenv-init을-bashrc에-추가-zsh를-사용하는-경우-zshrc\" style=\"position:relative;\"><a href=\"#2-virtualenv-init%EC%9D%84-bashrc%EC%97%90-%EC%B6%94%EA%B0%80-zsh%EB%A5%BC-%EC%82%AC%EC%9A%A9%ED%95%98%EB%8A%94-%EA%B2%BD%EC%9A%B0-zshrc\" aria-label=\"2 virtualenv init을 bashrc에 추가 zsh를 사용하는 경우 zshrc permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. virtualenv init을 ~/.bashrc에 추가 (zsh를 사용하는 경우 ~/.zshrc)</h3>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ echo &#39;eval &quot;$(pyenv virtualenv-init -)&quot;&#39; &gt;&gt; ~/.bashrc</code></pre></div>\n<br>\n<h3 id=\"2-pyenv-virtualenv-사용해보기\" style=\"position:relative;\"><a href=\"#2-pyenv-virtualenv-%EC%82%AC%EC%9A%A9%ED%95%B4%EB%B3%B4%EA%B8%B0\" aria-label=\"2 pyenv virtualenv 사용해보기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. pyenv-virtualenv 사용해보기</h3>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\"># pyenv virtualenv [python version] [myname]\n$ pyenv virtualenv 2.7.11 python2\n$ pyenv virtualenv 3.5.1 python3</code></pre></div>\n<br>\n<h3 id=\"2-virtualenv-명령어-정리\" style=\"position:relative;\"><a href=\"#2-virtualenv-%EB%AA%85%EB%A0%B9%EC%96%B4-%EC%A0%95%EB%A6%AC\" aria-label=\"2 virtualenv 명령어 정리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. virtualenv 명령어 정리</h3>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ pyenv virtualenv versions\n$ pyenv virtualenv [python version] [myname]\n$ pyenv shell [myname]</code></pre></div>\n<br>\n<h3 id=\"jupyter-notebook-설치\" style=\"position:relative;\"><a href=\"#jupyter-notebook-%EC%84%A4%EC%B9%98\" aria-label=\"jupyter notebook 설치 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Jupyter Notebook 설치</h3>\n<p>이제 방금 설치했던 파이썬 2와 3 버전의 환경에 python, notebook, jupyter를 설치할 차례입니다.\n따라서 방금 설치한 환경을 각각 activate한 다음에 아래와 같은 명령어를 실행시켜야 합니다.</p>\n<br>\n<h3 id=\"1-pip-install-python2-python3-각각-실행\" style=\"position:relative;\"><a href=\"#1-pip-install-python2-python3-%EA%B0%81%EA%B0%81-%EC%8B%A4%ED%96%89\" aria-label=\"1 pip install python2 python3 각각 실행 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. pip install (python2, python3 각각 실행)</h3>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ pip install ipython\n$ pip install notebook\n$ pip install jupyter</code></pre></div>\n<br>\n<h3 id=\"2-초기-jupyter-configuration-파일-생성-마찬가지로-각각-실행\" style=\"position:relative;\"><a href=\"#2-%EC%B4%88%EA%B8%B0-jupyter-configuration-%ED%8C%8C%EC%9D%BC-%EC%83%9D%EC%84%B1-%EB%A7%88%EC%B0%AC%EA%B0%80%EC%A7%80%EB%A1%9C-%EA%B0%81%EA%B0%81-%EC%8B%A4%ED%96%89\" aria-label=\"2 초기 jupyter configuration 파일 생성 마찬가지로 각각 실행 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. 초기 Jupyter configuration 파일 생성 (마찬가지로 각각 실행)</h3>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ jupyter notebook --generate-config\nInstalled kernelspec python3 in /Users/username/Library/Jupyter/kernels/python3</code></pre></div>\n<br>\n<h3 id=\"3-생성된-jupyternotebookconfigpy-설정-원하는-경우에만-커스텀-설정\" style=\"position:relative;\"><a href=\"#3-%EC%83%9D%EC%84%B1%EB%90%9C-jupyternotebookconfigpy-%EC%84%A4%EC%A0%95-%EC%9B%90%ED%95%98%EB%8A%94-%EA%B2%BD%EC%9A%B0%EC%97%90%EB%A7%8C-%EC%BB%A4%EC%8A%A4%ED%85%80-%EC%84%A4%EC%A0%95\" aria-label=\"3 생성된 jupyternotebookconfigpy 설정 원하는 경우에만 커스텀 설정 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. 생성된 jupyter<em>notebook</em>config.py 설정 (원하는 경우에만 커스텀 설정)</h3>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ vi /Users/username/Library/Jupyter/kernels/python3/jupyter_notebook_config.py\n\n$ c.NotebookApp.ip = &#39;127.0.0.1&#39;\n$ c.NotebookApp.open_browser = False\n$ c.NotebookApp.port = 8888\n$ c.NotebookApp.password = [SHA password]</code></pre></div>\n<br>\n<h3 id=\"4-ipykernel-설정-마찬가지로-각각-실행\" style=\"position:relative;\"><a href=\"#4-ipykernel-%EC%84%A4%EC%A0%95-%EB%A7%88%EC%B0%AC%EA%B0%80%EC%A7%80%EB%A1%9C-%EA%B0%81%EA%B0%81-%EC%8B%A4%ED%96%89\" aria-label=\"4 ipykernel 설정 마찬가지로 각각 실행 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4. ipykernel 설정 (마찬가지로 각각 실행)</h3>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ pyenv shell python2\n$ python -m ipykernel install --user\nInstalled kernelspec python2 in /home/seen/.local/share/jupyter/kernels/python2</code></pre></div>\n<br>\n<h3 id=\"5-kerneljson-확인-원하는-경우에만-커스텀-설정\" style=\"position:relative;\"><a href=\"#5-kerneljson-%ED%99%95%EC%9D%B8-%EC%9B%90%ED%95%98%EB%8A%94-%EA%B2%BD%EC%9A%B0%EC%97%90%EB%A7%8C-%EC%BB%A4%EC%8A%A4%ED%85%80-%EC%84%A4%EC%A0%95\" aria-label=\"5 kerneljson 확인 원하는 경우에만 커스텀 설정 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>5. kernel.json 확인 (원하는 경우에만 커스텀 설정)</h3>\n<div class=\"gatsby-highlight\" data-language=\"json\"><pre class=\"language-json\"><code class=\"language-json\">$ vi /home/seen/.local/share/jupyter/kernels/python<span class=\"token number\">2</span>/kernel.json\n<span class=\"token punctuation\">{</span>\n  <span class=\"token property\">\"display_name\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"Python 2\"</span><span class=\"token punctuation\">,</span>\n  <span class=\"token property\">\"language\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"python\"</span><span class=\"token punctuation\">,</span>\n  <span class=\"token property\">\"argv\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span>\n    <span class=\"token string\">\"/home/seen/.pyenv/versions/py27/bin/python\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"-m\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"ipykernel\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"-f\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"{connection_file}\"</span>\n    <span class=\"token punctuation\">]</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code></pre></div>\n<br>\n<h3 id=\"6-jupyter-notebook을-실행\" style=\"position:relative;\"><a href=\"#6-jupyter-notebook%EC%9D%84-%EC%8B%A4%ED%96%89\" aria-label=\"6 jupyter notebook을 실행 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>6. jupyter notebook을 실행</h3>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ jupyter notebook\n\n# background running\n$ nohup jupyter notebook &amp;\n\n# kill process\n$ ps -a\n37788 ttys000 0:00:00 ...python (노트북을 실행한 프로세스)\n$ kill 37788</code></pre></div>\n<br>\n<h3 id=\"정리\" style=\"position:relative;\"><a href=\"#%EC%A0%95%EB%A6%AC\" aria-label=\"정리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>정리</h3>\n<p>윈도우10 에서 아주 고생했던 환경설정이 맥 OS에서는 아주 간편하게 됩니다…\n잘 안되거나 오류가 생기시면 댓글로 알려주시면 감사하겠습니다!</p>\n<br>\n<h3 id=\"참고링크\" style=\"position:relative;\"><a href=\"#%EC%B0%B8%EA%B3%A0%EB%A7%81%ED%81%AC\" aria-label=\"참고링크 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>참고링크</h3>\n<ul>\n<li><a href=\"https://github.com/yyuu/pyenv\">https://github.com/yyuu/pyenv</a></li>\n<li><a href=\"https://github.com/yyuu/pyenv-virtualenv\">https://github.com/yyuu/pyenv-virtualenv</a></li>\n</ul>","excerpt":"Jupyer Notebook…"}}}]}},"pageContext":{"slug":"dataengineering","basePath":"","paginationPath":"/tag/dataengineering","pageNumber":0,"humanPageNumber":1,"skip":0,"limit":6,"numberOfPages":6,"previousPagePath":"","nextPagePath":"/tag/dataengineering/2"}}}