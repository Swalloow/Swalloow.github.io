{"componentChunkName":"component---src-templates-tag-js","path":"/tag/datascience","result":{"data":{"contentfulTag":{"title":"DataScience","id":"82931dd3-d22b-528e-8a9b-ddbb200bb401","slug":"datascience","post":[{"id":"b6f97b31-bd09-5915-81f9-4ad527909181","title":"Bagging과 Boosting 그리고 Stacking","slug":"bagging-boosting","publishDate":"July 19, 2017","publishDateISO":"2017-07-19","heroImage":{"title":"cover-datascience","gatsbyImageData":{"images":{"sources":[{"srcSet":"https://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=450&h=300&q=50&fm=webp 450w,\nhttps://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=900&h=600&q=50&fm=webp 900w,\nhttps://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&h=1200&q=50&fm=webp 1800w","sizes":"(min-width: 1800px) 1800px, 100vw","type":"image/webp"}],"fallback":{"src":"https://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&h=1200&fl=progressive&q=50&fm=jpg","srcSet":"https://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=450&h=300&fl=progressive&q=50&fm=jpg 450w,\nhttps://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=900&h=600&fl=progressive&q=50&fm=jpg 900w,\nhttps://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&h=1200&fl=progressive&q=50&fm=jpg 1800w","sizes":"(min-width: 1800px) 1800px, 100vw"}},"layout":"constrained","width":1800,"height":1200,"placeholder":{"fallback":"data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wAARCAANABQDASIAAhEBAxEB/8QAGQAAAgMBAAAAAAAAAAAAAAAAAAQCAwUG/8QAIBAAAgEEAQUAAAAAAAAAAAAAAQIAAwQRIRIFEzFCkf/EABQBAQAAAAAAAAAAAAAAAAAAAAH/xAAWEQEBAQAAAAAAAAAAAAAAAAABABH/2gAMAwEAAhEDEQA/AK2EUrvxZQfJOplUeoXt4xHeWkMeqSS8jcKtSrUqHOcs2vggpIN0JGSdQiZvnXRUGENJxv/Z"}},"ogimg":{"src":"https://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&q=50"}},"body":{"childMarkdownRemark":{"timeToRead":2,"html":"<p>오늘은 머신러닝 성능을 최대로 끌어올릴 수 있는 앙상블 기법에 대해 정리해보았습니다.</p>\n<br>\n<h2 id=\"ensemble-hybrid-method\" style=\"position:relative;\"><a href=\"#ensemble-hybrid-method\" aria-label=\"ensemble hybrid method permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Ensemble, Hybrid Method</h2>\n<p>앙상블 기법은 동일한 학습 알고리즘을 사용해서 여러 모델을 학습하는 개념입니다.\nWeak learner를 결합한다면, Single learner보다 더 나은 성능을 얻을 수 있다는 아이디어입니다.\n<strong>Bagging</strong> 과 <strong>Boosting</strong> 이 이에 해당합니다.</p>\n<p>동일한 학습 알고리즘을 사용하는 방법을 앙상블이라고 한다면,\n서로 다른 모델을 결합하여 새로운 모델을 만들어내는 방법도 있습니다.\n대표적으로 <strong>Stacking</strong> 이 있으며, 최근 Kaggle 에서 많이 소개된 바 있습니다.</p>\n<br>\n<h2 id=\"bagging\" style=\"position:relative;\"><a href=\"#bagging\" aria-label=\"bagging permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Bagging</h2>\n<p>Bagging은 샘플을 여러 번 뽑아 각 모델을 학습시켜 결과를 <strong>집계(Aggregating)</strong> 하는 방법입니다. 아래의 그림을 통해 자세히 알아보겠습니다.</p>\n<p><span\n        class=\"gatsby-resp-image-wrapper\"\n        style=\"position: relative; display: block; ; max-width: 650px; margin-left: auto; margin-right: auto;\"\n      >\n        <span\n          class=\"gatsby-resp-image-background-image\"\n          style=\"padding-bottom: 67.3768308921438%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACgAAAAbCAIAAACBclo5AAAE9ElEQVRIx71WS4tc1Rb+1tr7nFOvLrsTbbua1pCrQntRMlAIRogDNQ4E8UIG93c4E/wPDq8DQSd3dJEMLkhsCHcQBTWCxJEvtH2QpB9Jd6qqT+1z9uNzUJV0VaKhW8lds71Ye3/rtde3hCQOLINRuDGorcr4SJLA8tGmuaU5uNhDWX/14+5bF64eydWIJNIndHN9++zfHnyguL/AKvLcw425wpCwBgLpu0j8GTkccEwc1MmIuJCamQowrBP+D8CtwrStGkE7UwCJeKht7OELDEAO1VwEYqQKfKRREQEIY+QvRUwiTjkhQLrLJQFEQAhAAAKhMCZy7NRts1lPVEXuEXFMEIEISEAggA80KhMUuTP28WMhIrMTv8d3Y0JmJukZXyVxdzUsgLquSVY+5VZVkee5956JzqciUxHJ87yua5BjeIHYLHPOjW8VmapqkefOuUTUPjUyVWOyLBs5lwgfJjaNRmMfOMZ47ty569evE6IiKcUzZ85cunTp5s2biVCBqrz00ssXL150zo2HRlEUp0+fXltbCyEkAkzz8/OnTp06f/78uOOYYq/XO3HixNramjEmETH4lZWVs2fPyq2sWxHp9/siYo0RkZ2dvvd+MBioqhEBMBgMxpq8KMaXhsNhCKGqqk6nAyClVFVVCMF73+12AYQQnHPee+99q9USkaqSsixnUk2yruuyLJvNlqvczX6fpHMuxFgUxagsy7IkWZajEGKW58PhQICxxtjMGjMY9FutFsnhcJjnhRqzu7uzaC3Jfn+Q54Wq7uzcaDabJG9HLCTX19ddVem4CQS9Xm97e7uuvSARqqq93tLGxkYIQaKjaVhrl5aWtrav05fQjKJ5li0sLGxuboEJsaJtNIqi2+1ubm0JACZCG41ieXl5qj1vy+anjHuclo2PyXpG88uHZNw/XrtItzljEPf460czmtDn1ue8S3SKetZRDaeqkND/AfVUYVINv4dY72vCCN7N/JJQI5Qzn7oaYPDTPSdXKqENYMqVWMI0Z79wBMwfH39XmRArmOadwDHxv9+4KsGoJGCvSi88kn+54SMgIiRd4OmV/NMr3piJPRNPLucXfq6bmQDwkZng5HJ24Wc/lwuBKrCbydMP2f/9WndzJaT06Wgh/3iyIVNdjY+uhV88j1hRwbejtHrEfHg17CTOWSFxtebqgvnPFa+CthVPVIGPzZsPNsK8RcuKi+gIHp83/77mV3JtWfQDj+ey1Nb3robHG9o02PL8e0Nf5/40tQAi8YXjkzkSURICePKy4/EMNSdZGyX8EHgsYRjxsAWAK4HfeDyR44rns00h8KXHZkqPWlkPfCQTAp97lky9TL6quVrMjH6rihcXzVNz2s3FRYJY7JhXl7KTLnUyKQMzlcW2+eeyHXq2M9nz7FhZ6pg3j+U+sZnJXs2FhizPmX8dzwAURvY8e21d6Zr3j+eZIjey69JKR6cntpBM5OQL494UKbhFGbibNaaGw5giiH1NTLxjL5t0dToAKcuEIUCgSmjoPkkfhNPvIKjDLQK733+//dlnYm0ijApJtXbllTNZZ+7+rj7D9fXNd981R4+yLKXdRghpNFp8/tR9B4ZqsbrafeaZ0O8zRsY4+u47Eb3vyx6977/zjr7xBusaIn5jo758GfwzC66kdND9VERufP315iefiLWTTktJrD322mtFt8tDwv8GnTAxXRy6lLMAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n        >\n          <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;\"\n        alt=\"boosting\"\n        title=\"\"\n        src=\"https://images.ctfassets.net/tushy4jlcik7/2Qi9V8VS1XzgWdLT3UiSpk/fe2d857d275ee85b2122f350bc18c718/boosting.png\"\n        srcset=\"https://images.ctfassets.net/tushy4jlcik7/2Qi9V8VS1XzgWdLT3UiSpk/fe2d857d275ee85b2122f350bc18c718/boosting.png?w=188 188w,\nhttps://images.ctfassets.net/tushy4jlcik7/2Qi9V8VS1XzgWdLT3UiSpk/fe2d857d275ee85b2122f350bc18c718/boosting.png?w=376 376w,\nhttps://images.ctfassets.net/tushy4jlcik7/2Qi9V8VS1XzgWdLT3UiSpk/fe2d857d275ee85b2122f350bc18c718/boosting.png?w=751 751w\"\n        sizes=\"(max-width: 650px) 100vw, 650px\"\n        loading=\"lazy\"\n      />\n        </span>\n      </span></p>\n<p>먼저 대상 데이터로부터 복원 랜덤 샘플링을 합니다.\n이렇게 추출한 데이터가 일종의 표본 집단이 됩니다.\n이제 여기에 동일한 모델을 학습시킵니다.\n그리고 학습된 모델의 예측변수들을 집계하여 그 결과로 모델을 생성해냅니다.</p>\n<p>이러한 방식을 <strong>Bootstrap Aggregating</strong> 이라고 부릅니다.</p>\n<p>이렇게 하는 이유는 \"알고리즘의 안정성과 정확성을 향상시키기 위해서\" 입니다.\n대부분 학습에서 나타나는 오류는 다음과 같습니다.</p>\n<ol>\n<li>높은 bias로 인한 Underfitting</li>\n<li>높은 Variance로 인한 Overfitting</li>\n</ol>\n<p>앙상블 기법은 이러한 오류를 최소화하는데 도움이 됩니다.\n특히 Bagging은 각 샘플에서 나타난 결과를 일종의 중간값으로 맞추어 주기 때문에,\nOverfitting을 피할 수 있습니다.</p>\n<p>일반적으로 Categorical Data인 경우, 투표 방식 (Voting)으로 집계하며\nContinuous Data인 경우, 평균 (Average)으로 집계합니다.</p>\n<p>대표적인 Bagging 알고리즘으로 <code class=\"language-text\">RandomForest</code> 모델이 있습니다.\n원래 단일 DecisionTree 모델은 boundary가 discrete 한 모양일 수 밖에 없지만,\nRandomForest는 여러 트리 모델을 결합하여 이를 넘어설 수 있게 되었습니다.</p>\n<p>결과는 아래와 같습니다.</p>\n<p><span\n        class=\"gatsby-resp-image-wrapper\"\n        style=\"position: relative; display: block; ; max-width: 650px; margin-left: auto; margin-right: auto;\"\n      >\n        <span\n          class=\"gatsby-resp-image-background-image\"\n          style=\"padding-bottom: 110.00000000000001%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wAARCAAsACgDAREAAhEBAxEB/8QAGgAAAgMBAQAAAAAAAAAAAAAABAUAAgMGCf/EAC0QAAIBAwMCAwgDAQAAAAAAAAECAwAEEQUSITFRBhSREyIjQWFxgaEVMkLh/8QAGAEBAQEBAQAAAAAAAAAAAAAAAAMBAgT/xAAfEQEBAAICAgMBAAAAAAAAAAABAAIxESEDEiJBUWH/2gAMAwEAAhEDEQA/APSyS8uYXuTOjCMGQlhJzw52gD7YrSlkHdS2u7qdGKfFj9oqho5CcpjnJ7k4o24dPJZTau0TR+4FdlKhDKcBsgDP4INSd3txFFjJ7ieO4XbC0kRWPZ8QgDIJY8nn89qqXnd91NLvvM3ywMNyBmy6yE9OB8/pVEQuZjfeHbXUJGeQvuPY4x3H5qfNjiPdhY+HjYidRLiOQ5CwqFwc9ec1m7QMXkhLrQLU3KwRPJHM6E5ePeABgcdPp6VFzxMzx/bV9st8zGXQ0ubaOGV5HCKFycDOM49M1cfXVwvPdhaeGfJX8NxDclVQYKFAS2Tk5P8Azit9nVk9rmQmqSSxadcPACZQh2460kqutZeK8h3bY2DsmGPVcZ57cgUk5s5mnt0dwAx6gdKS3pKUljdNGsDCV9iuCufuKxQ3aC6uXvrNP5C0t4FEtpMkpuLtnX4TADZlf9ZyfSpPk+QGq54hwyyXhOODjf73/J7osQtrcw+c82ynOdoXaO2KoZDqiibmNdXNKSE1WOSXTrhYm2OUOCf3+qSS3OqyxyqTKWIkYYRSQBg+vNJPNPkaWzjZm3kj+3ekiaSlJVdA6MrDKkYIpIAaDa4bPtGJXaCZDlfsflSRNjYxadbiGIuUBz77lj+6SIpL/9k='); background-size: cover; display: block;\"\n        >\n          <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;\"\n        alt=\"agg result\"\n        title=\"\"\n        src=\"https://images.ctfassets.net/tushy4jlcik7/24IAgyNrQgeMlBCt81CroN/3d82eca18a1289219478efdbd24fbe2f/agg_result.png\"\n        srcset=\"https://images.ctfassets.net/tushy4jlcik7/24IAgyNrQgeMlBCt81CroN/3d82eca18a1289219478efdbd24fbe2f/agg_result.png?w=240 240w,\nhttps://images.ctfassets.net/tushy4jlcik7/24IAgyNrQgeMlBCt81CroN/3d82eca18a1289219478efdbd24fbe2f/agg_result.png?w=480 480w,\nhttps://images.ctfassets.net/tushy4jlcik7/24IAgyNrQgeMlBCt81CroN/3d82eca18a1289219478efdbd24fbe2f/agg_result.png?w=960 960w\"\n        sizes=\"(max-width: 650px) 100vw, 650px\"\n        loading=\"lazy\"\n      />\n        </span>\n      </span></p>\n<br>\n<h2 id=\"boosting\" style=\"position:relative;\"><a href=\"#boosting\" aria-label=\"boosting permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Boosting</h2>\n<p>Bagging이 일반적인 모델을 만드는데 집중되어있다면,\nBoosting은 맞추기 어려운 문제를 맞추는데 초점이 맞춰져 있습니다.</p>\n<p>수학 문제를 푸는데 9번 문제가 엄청 어려워서 계속 틀렸다고 가정해보겠습니다.\nBoosting 방식은 9번 문제에 가중치를 부여해서 9번 문제를 잘 맞춘 모델을 최종 모델로 선정합니다.\n아래 그림을 통해 자세히 알아보겠습니다.</p>\n<p><img src=\"https://quantdare.com/wp-content/uploads/2016/04/bb3.png\" alt=\"\"></p>\n<p>Boosting도 Bagging과 동일하게 복원 랜덤 샘플링을 하지만, 가중치를 부여한다는 차이점이 있습니다.\nBagging이 병렬로 학습하는 반면, Boosting은 순차적으로 학습시킵니다.\n학습이 끝나면 나온 결과에 따라 가중치가 재분배됩니다.</p>\n<p>오답에 대해 높은 가중치를 부여하고, 정답에 대해 낮은 가중치를 부여하기 때문에\n오답에 더욱 집중할 수 있게 되는 것 입니다.\nBoosting 기법의 경우, 정확도가 높게 나타납니다.\n하지만, 그만큼 Outlier에 취약하기도 합니다.</p>\n<p>AdaBoost, XGBoost, GradientBoost 등 다양한 모델이 있습니다.\n그 중에서도 XGBoost 모델은 강력한 성능을 보여줍니다. 최근 대부분의 Kaggle 대회 우승 알고리즘이기도 합니다.</p>\n<br>\n<h2 id=\"stacking\" style=\"position:relative;\"><a href=\"#stacking\" aria-label=\"stacking permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Stacking</h2>\n<p><strong>Meta Modeling</strong> 이라고 불리기도 하는 이 방법은 위의 2가지 방식과는 조금 다릅니다.\n“Two heads are better than one” 이라는 아이디어에서 출발합니다.</p>\n<p>Stacking은 서로 다른 모델들을 조합해서 최고의 성능을 내는 모델을 생성합니다.\n여기에서 사용되는 모델은 SVM, RandomForest, KNN 등 다양한 알고리즘을 사용할 수 있습니다.\n이러한 조합을 통해 서로의 장점은 취하고 약점을 보완할 수 있게 되는 것 입니다.</p>\n<p>Stacking은 이미 느끼셨겠지만 필요한 연산량이 어마어마합니다.\n적용해보고 싶다면 아래의 StackNet을 사용하는 방법을 추천합니다.</p>\n<p><a href=\"https://github.com/kaz-Anova/StackNet\">https://github.com/kaz-Anova/StackNet</a></p>\n<p>문제에 따라 정확도를 요구하기도 하지만, 안정성을 요구하기도 합니다.\n따라서, 주어진 문제에 적절한 모델을 선택하는 것이 중요합니다.</p>\n<br>","excerpt":"오늘은 머신러닝 성능을 최대로 끌어올릴 수 있는 앙상블 기법에 대해 정리해보았습니다. Ensemble, Hybrid Method…"}}},{"id":"8428f581-63b4-5beb-a64e-19bd4128b369","title":"머신러닝을 시작하기 위한 기초 지식 (1)","slug":"pyml-intro1","publishDate":"February 05, 2017","publishDateISO":"2017-02-05","heroImage":{"title":"cover-datascience","gatsbyImageData":{"images":{"sources":[{"srcSet":"https://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=450&h=300&q=50&fm=webp 450w,\nhttps://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=900&h=600&q=50&fm=webp 900w,\nhttps://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&h=1200&q=50&fm=webp 1800w","sizes":"(min-width: 1800px) 1800px, 100vw","type":"image/webp"}],"fallback":{"src":"https://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&h=1200&fl=progressive&q=50&fm=jpg","srcSet":"https://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=450&h=300&fl=progressive&q=50&fm=jpg 450w,\nhttps://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=900&h=600&fl=progressive&q=50&fm=jpg 900w,\nhttps://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&h=1200&fl=progressive&q=50&fm=jpg 1800w","sizes":"(min-width: 1800px) 1800px, 100vw"}},"layout":"constrained","width":1800,"height":1200,"placeholder":{"fallback":"data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wAARCAANABQDASIAAhEBAxEB/8QAGQAAAgMBAAAAAAAAAAAAAAAAAAQCAwUG/8QAIBAAAgEEAQUAAAAAAAAAAAAAAQIAAwQRIRIFEzFCkf/EABQBAQAAAAAAAAAAAAAAAAAAAAH/xAAWEQEBAQAAAAAAAAAAAAAAAAABABH/2gAMAwEAAhEDEQA/AK2EUrvxZQfJOplUeoXt4xHeWkMeqSS8jcKtSrUqHOcs2vggpIN0JGSdQiZvnXRUGENJxv/Z"}},"ogimg":{"src":"https://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&q=50"}},"body":{"childMarkdownRemark":{"timeToRead":3,"html":"<p>이 글의 목차나 그림은 <strong>Sebastian Rashka - Python Machine Learning</strong> 을 참고하였습니다.</p>\n<p>사실 기계학습, 인공지능에 대한 연구는 예전부터 존재했지만 발전이 없었으며 소수에 연구원들에 의한 주제였기에 대중화 될 수 없었습니다. 하지만 풍부한 데이터의 확보, 컴퓨팅 성능향상, 오픈소스 라이브러리로 인해 많은 개발자들이 인공지능 연구에 참여하게 되었습니다.</p>\n<p>이 글에서는 기계학습에 대한 간략한 소개와 데이터 분석 시스템을 어떻게 디자인해야 되는지, 마지막으로 파이썬을 이용한 데이터 분석에 대해 소개해드리겠습니다.</p>\n<br>\n<p><span\n        class=\"gatsby-resp-image-wrapper\"\n        style=\"position: relative; display: block; ; max-width: 650px; margin-left: auto; margin-right: auto;\"\n      >\n        <span\n          class=\"gatsby-resp-image-background-image\"\n          style=\"padding-bottom: 71.53075822603721%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,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'); background-size: cover; display: block;\"\n        >\n          <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;\"\n        alt=\"ml-diagram\"\n        title=\"\"\n        src=\"https://images.ctfassets.net/tushy4jlcik7/4Yh3afQOHK8NuIlkJYIiHv/279d8487606d3dabeeed7e32a66d44dc/ml-diagram.png\"\n        srcset=\"https://images.ctfassets.net/tushy4jlcik7/4Yh3afQOHK8NuIlkJYIiHv/279d8487606d3dabeeed7e32a66d44dc/ml-diagram.png?w=350 350w,\nhttps://images.ctfassets.net/tushy4jlcik7/4Yh3afQOHK8NuIlkJYIiHv/279d8487606d3dabeeed7e32a66d44dc/ml-diagram.png?w=699 699w,\nhttps://images.ctfassets.net/tushy4jlcik7/4Yh3afQOHK8NuIlkJYIiHv/279d8487606d3dabeeed7e32a66d44dc/ml-diagram.png?w=1398 1398w\"\n        sizes=\"(max-width: 650px) 100vw, 650px\"\n        loading=\"lazy\"\n      />\n        </span>\n      </span></p>\n<p>요즘에는 머신러닝을 크게 3가지 분야로 나누어 볼 수 있습니다. 흔히 알고있는 <strong>지도학습(Supervised Learning)</strong> 과 <strong>비지도학습(Unsupervised Learning)</strong> 이 있으며, 마지막으로 알파고에 적용되었던 <strong>강화학습(Reinforcement Learning)</strong> 이 있습니다. 이제 세 가지 다른 알고리즘 간의 근본적인 차이점에 대해 알아보고, 실제로 어떤 문제에 적용되는지 알아보겠습니다.</p>\n<br>\n<h2 id=\"supervised-learning\" style=\"position:relative;\"><a href=\"#supervised-learning\" aria-label=\"supervised learning permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Supervised Learning</h2>\n<p>지도학습과 비지도학습의 궁극적인 목표는 모두 과거, 현재의 데이터로부터 미래를 예측하는 것이라 할 수 있습니다. 다만, 두 가지 방법의 차이점은 라벨링 된 데이터인지 아닌지에 따라 결정됩니다.</p>\n<p>만일 내가 가지고 있는 데이터가 라벨링 되어 있다면 지도학습이라고 볼 수 있습니다. 여기에서 라벨링 된 데이터(Labeled data)란 데이터에 대한 답이 주어져 있는 것 (평가가 되어 있는 것) 을 말합니다.</p>\n<p><span\n        class=\"gatsby-resp-image-wrapper\"\n        style=\"position: relative; display: block; ; max-width: 650px; margin-left: auto; margin-right: auto;\"\n      >\n        <span\n          class=\"gatsby-resp-image-background-image\"\n          style=\"padding-bottom: 58.066808813077465%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACgAAAAXCAMAAABODP0nAAAB1FBMVEX////09PTh4eHw8PD9/f319fX6+vr7+/v39/f5+fn8/Pzq6ury8vLt7e3p6enf39+CgoKpqamysrK9vb21tbW3t7e6urqvrq7f3t7S0tK8vLy0tLOwsK/Dw8O2tra4uLjg4OClpaWurq65ubnAwMDt7Oza2dnY2NjW1tbR0dHs7Ozu7u7z8/Pv7+/09PP7+/ru7u3u7e329vbx8fHl5eXPz8/m5ubLy8vr6+vz8/Lx8fDw8O/n5+f8/P7S1+HO1N7R1+DL0NvU2eLQ1uDM0t3U2eH+/v/s7vLJz9rL0dzR1uDM0dz4+fr8/f3+/v7w8vbu8PTs7/Pq7fH19/n7/P3t7/Pq7PHv8fTw8vX9/f73+PnO1N3d3d3k5OPk5OTb29vd3dzf397b2trV1dXa2tr29/nGzNf9/v7o6Ojc3Nz4+Pj09vj3+PrIztjx8/bx8vXFy9b6+/vZ2dn09ffK0Nr6+vvi4uLh5On+///e3t7X19f09vn2+Prz9Pf09fjx8/Xz9Pbw8vTt7/Hu7/Hu7/Ly9Pbp7fHw8fPz9ff09vf19vj8/P3Q1d7V1dbj4+PU1NTW1tfz9PTw8PHU1NXZ2drIztnd3Nzp6ei9xdK+xtLDytXi5eo1ZslwAAACNklEQVQYGY3B6UPSYAAH4N9we8erbGSKaYfRyYKhtRFRkd2Yla/asqyIZaHIZhfYUrSigzIr7T7/2ZAmfOhDPQ/+H+dp4oUmjojEy4uECoIoNrf4iEgk2UuJiDr/utb1be2Bjg2dXRs3bd7SHdjaFtzWvr27o7t1RyCwc9fukLJHQhWRwuGIGu2J9O4N75M03Rfbr6nxA4mDarSHO3SYk1tiSQ5rjvQdPXb8xMlTp1Oo6z8zcLZv4Nx5uAYBBjY0PHJheHhkCDUGeODi6KXLY/2jV/DH1WuMqNHOtN9zPWPeGL+Z7pIBg/ikW9nx8RgaJiZzwJRi5s2oSC1qWRoFbIBvCgezU2iYvp0DLCmRlJtRZwMgmt/fIqgMrjuTDABR8xk0GDwRVS6Yz6fTPFx37zEAIpcJo8G4r0YUMyvHC3GsKc7kAEa8iQgajAc+STHNuGOGInAVH84CjOqZuZLD4DIAXtC0XqJxFK7U/MKjscdPyk+fPX9RLlfsmpeVV4sVo/J6cWnBsGveoPiWES5RMgvvlp3QyvsPWGUT9aNS+vR5xeGxpvglB/BCNPv1GxgRUbMEMEv1OJRHXXGGASC+UjAeicI1D4BYMZmhYeL7IBijVJeSywm47Fkwi3ryOhrKP1LEJylKLB+amwoVTB5VdgoQm3U5IugCxwkMVWM/cwDv1SjVLGJpXqyyU2CW1wn55blQOu+IqCr+SuEv07MA5bLOcsEfx7+IJCkLqq7hH5jGFUoi6n4Dcrd5GnBH6WQAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n        >\n          <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;\"\n        alt=\"learning-diagram\"\n        title=\"\"\n        src=\"https://images.ctfassets.net/tushy4jlcik7/6CfHYlS5Hn6qCPdiaXfuID/80297adb97a019a52056b7a2f670ad4a/learning-diagram.png\"\n        srcset=\"https://images.ctfassets.net/tushy4jlcik7/6CfHYlS5Hn6qCPdiaXfuID/80297adb97a019a52056b7a2f670ad4a/learning-diagram.png?w=352 352w,\nhttps://images.ctfassets.net/tushy4jlcik7/6CfHYlS5Hn6qCPdiaXfuID/80297adb97a019a52056b7a2f670ad4a/learning-diagram.png?w=704 704w,\nhttps://images.ctfassets.net/tushy4jlcik7/6CfHYlS5Hn6qCPdiaXfuID/80297adb97a019a52056b7a2f670ad4a/learning-diagram.png?w=1407 1407w\"\n        sizes=\"(max-width: 650px) 100vw, 650px\"\n        loading=\"lazy\"\n      />\n        </span>\n      </span></p>\n<br>\n<h3 id=\"classification\" style=\"position:relative;\"><a href=\"#classification\" aria-label=\"classification permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Classification</h3>\n<p>지도학습은 Classification과 Regression으로 나누어집니다. 먼저, Classification은 주어진 데이터를 정해진 카테고리에 따라 분류하는 문제를 말합니다. 최근에 많이 사용되는 이미지 분류도 Classification 문제 중에 하나입니다.</p>\n<p>예를 들어, 이메일이 스팸메일인지 아닌지를 예측한다고 하면 이메일은 스팸메일 / 정상적인 메일로 라벨링 될 수 있을 것입니다. 비슷한 예시로 암을 예측한다고 가정했을 때 이 종양이 악성종양인지 / 아닌지로 구분할 수 있습니다. 이처럼 맞다 / 아니다로 구분되는 문제를 <strong>Binary Classification</strong> 이라고 부릅니다.</p>\n<p>분류 문제가 모두 맞다 / 아니다로 구분되지는 않습니다. 예를 들어, 공부시간에 따른 전공 Pass / Fail 을 예측한다고 하면 이는 Binary Classifiaction 으로 볼 수 있습니다. 반면에, 수능 공부시간에 따른 전공 학점을 A / B / C / D / F 으로 예측하는 경우도 있습니다. 이러한 분류를 <strong>Multi-label Classification</strong> 이라고 합니다.</p>\n<br>\n<h3 id=\"regression\" style=\"position:relative;\"><a href=\"#regression\" aria-label=\"regression permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Regression</h3>\n<p>다음으로 Regression은 연속된 값을 예측하는 문제를 말합니다. 주로 어떤 패턴이나 트렌드, 경향을 예측할 때 사용됩니다. Coursera에서는 Regression을 설명할 때 항상 집의 크기에 따른 매매가격을 예로 듭니다. 아까와 유사한 예를 들자면, 공부시간에 따른 전공 시험 점수를 예측하는 문제를 예로 들 수 있습니다.</p>\n<br>\n<h2 id=\"unsupervised-learning\" style=\"position:relative;\"><a href=\"#unsupervised-learning\" aria-label=\"unsupervised learning permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Unsupervised Learning</h2>\n<p>비지도학습은 앞에서 언급한 것 처럼 라벨링이 되어 있지 않은 데이터로부터 미래를 예측하는 학습방법입니다. 평가되어 있지 않은 데이터로부터 숨어있는 패턴이나 형태를 찾아야 하기 때문에 당연히 더 어렵습니다. 비지도학습도 데이터가 분리되어 있는지 (Categorial data) 연속적인지 (Continuous data)로 나누어 생각할 수 있습니다.</p>\n<p>대표적으로 클러스터링 (Clustering) 이 있습니다. 실제로는 그 데이터의 label이나 category가 무엇인지 알 수 없는 경우가 많기 때문에 이러한 방법이 중요하다고 볼 수 있습니다. 이외에도 차원축소(Dimentionality Reduction), Hidden Markov Model 등이 있습니다.</p>\n<br>\n<h2 id=\"reinforcement-learning\" style=\"position:relative;\"><a href=\"#reinforcement-learning\" aria-label=\"reinforcement learning permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reinforcement Learning</h2>\n<p><span\n        class=\"gatsby-resp-image-wrapper\"\n        style=\"position: relative; display: block; ; max-width: 434px; margin-left: auto; margin-right: auto;\"\n      >\n        <span\n          class=\"gatsby-resp-image-background-image\"\n          style=\"padding-bottom: 40.322580645161295%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACgAAAAQCAQAAADO3vUmAAADE0lEQVQ4y2NgwAWYSzlr+DuSrS30TdSBUBOMdUwyg7rMGAgDZ8XCpNqY8tgCMCyMLYzOKgiZW54yPZCBoVmqQ2uiSJfoVIl5SseZC+Vnu9mwFnKUI0P2MmY0A1Us4pwWSvQrtAJhi0IzEFdrRrlmmk72Y2DoCOzp62pv7umobCtcIhCl0NhYmVyVUg2HVSnlWe1x55lQDJQ2Y9CeqrLUbaP1Rus51s3WLdYtNvElRVlTgxgYegUn60yMr9QukSqVYmDMlZ/hwcAewRnLGQeGsZwhnJ5irRmbWNEN1OnVL5QBMhnBkImByZ+jTqg3qsmywbzevMGi3qzRrAkIG337jTBCjLc1ZTmqgQymDDrdutXK8wUa+CYIzBMv44AI90j06fRp92n3avdBoE6XSjkrunkcvC0pDMBQNGYEcuaEzo9YGZHgy6DdqdMVuKh2ds3Mypn5RVIMpADeluy5wQuSJ8S1BzJ0hc9OXJWXGsSg1aEzy221ZZXQDPEJQlEspBnYlrsub0XABAdwkvJk2eua4sGg3a3brb5DjIEcwNuStS30gAKcf4nDwZpBp08vWxJZVSarLpcBlykYmiFBUy4dLieuWqRkwgwMw0nsMchpURgYKX26+RIMDDN5UlnmSqxlncDV5mdhp2Gta6NrowPEejb6QKgHhmrWMa71VgjdLMBYXooaVfLAZNNvUGqcJjXNdJL1/JC1cd3OAfbAKGPD7kd9TlsHJC5Xa8paVANlgAZO46/WK9Huc+4J6XdvsMh0VLHOlmyLmGAx3XC1yxSrZsMukzaLXstpVhOtJzuU8Ub650UlF05wn+Q6ybUzoKtgD2rmU7cI9aqTr1AoVJhs2G2xuWJT4hQXcwt3mbzYhoipBZMKWjN6SiZnNKTX5k+e2J7bk9InEOyT4ReZnGuea5ZrlmPeqoTmhXDZoojK0IrQsrCuyMKcitSmhNK0ABeQZxhYs9l82RLY+/nKWflYFdh6+BnYJnMFsGvaEJkCVklN5gTRurzl0c7m9qY2pham5kBoDMSWQLaRCZBtEuaQ54NdPwDEa/Ef3YoFDgAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n        >\n          <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;\"\n        alt=\"agent-environment\"\n        title=\"\"\n        src=\"https://images.ctfassets.net/tushy4jlcik7/2cqCzTkr5rgjgClwWBNJK8/96047e15630bdf1819bcd52ae6794cb0/agent-environment.png\"\n        srcset=\"https://images.ctfassets.net/tushy4jlcik7/2cqCzTkr5rgjgClwWBNJK8/96047e15630bdf1819bcd52ae6794cb0/agent-environment.png?w=109 109w,\nhttps://images.ctfassets.net/tushy4jlcik7/2cqCzTkr5rgjgClwWBNJK8/96047e15630bdf1819bcd52ae6794cb0/agent-environment.png?w=217 217w,\nhttps://images.ctfassets.net/tushy4jlcik7/2cqCzTkr5rgjgClwWBNJK8/96047e15630bdf1819bcd52ae6794cb0/agent-environment.png?w=434 434w\"\n        sizes=\"(max-width: 434px) 100vw, 434px\"\n        loading=\"lazy\"\n      />\n        </span>\n      </span></p>\n<p>마지막으로 강화학습은 앞서 말했던 학습방법과는 조금 다른 개념입니다. 데이터가 정답이 있는 것도 아니며, 심지어 주어진 데이터가 없을 수도 있습니다. 강화학습이란, 자신이 한 행동에 대한 \"보상\"을 알 수 있어서 그로부터 학습하는 것을 말합니다.</p>\n<p>예를 들면, 아이가 걷는 것을 배우는 것처럼 어떻게 행동할 줄 모르지만 환경과 상호작용하면서 걷는 법을 알아가는 것과 같은 학습 방법을 강화학습이라고 합니다.</p>\n<p><img src=\"https://dnddnjs.gitbooks.io/rl/content/90-6.png\" alt=\"atari\"></p>\n<p>보통 아타리 게임 인공지능을 많이 예시로 드는데, 여기에서 학습 대상 (agent) 은 움직이면서 적을 물리치는 존재입니다. 이 학습 대상은 움직이면서 적을 물리치면 보상 (reward) 을 받게 됩니다. 이러한 과정을 스스로 반복 학습 (Trial and Error) 하면서 점수를 최대화하는 것이 목표입니다.</p>\n<br>\n<h2 id=\"how\" style=\"position:relative;\"><a href=\"#how\" aria-label=\"how permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>How?</h2>\n<p>처음에는 공부를 시작하기에 막막한데 다행히 아주 좋은 강의와 자료들이 많이 있습니다.</p>\n<h3 id=\"machine-learning--deep-learning\" style=\"position:relative;\"><a href=\"#machine-learning--deep-learning\" aria-label=\"machine learning  deep learning permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Machine Learning / Deep Learning</h3>\n<ul>\n<li>Coursera - Andrew Ng : <a href=\"https://www.coursera.org/learn/machine-learning\">https://www.coursera.org/learn/machine-learning</a></li>\n<li>모두의 딥러닝 : <a href=\"https://hunkim.github.io/ml/\">https://hunkim.github.io/ml/</a></li>\n<li>CS231n : <a href=\"http://cs231n.stanford.edu/\">http://cs231n.stanford.edu/</a></li>\n</ul>\n<br>\n<h3 id=\"reinforcement-learning-1\" style=\"position:relative;\"><a href=\"#reinforcement-learning-1\" aria-label=\"reinforcement learning 1 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reinforcement Learning</h3>\n<ul>\n<li>모두의 연구소 깃북 : <a href=\"https://dnddnjs.gitbooks.io/rl/content/\">https://dnddnjs.gitbooks.io/rl/content/</a></li>\n<li>Deep Mind - David Silver : <a href=\"https://www.youtube.com/watch?v=2pWv7GOvuf0\">https://www.youtube.com/watch?v=2pWv7GOvuf0</a></li>\n</ul>\n<br>","excerpt":"이 글의 목차나 그림은 Sebastian Rashka - Python Machine Learning…"}}},{"id":"3ccd38eb-d100-5c4e-b130-ac92a8966ac8","title":"머신러닝을 시작하기 위한 기초 지식 (2)","slug":"pyml-intro2","publishDate":"February 08, 2017","publishDateISO":"2017-02-08","heroImage":{"title":"cover-datascience","gatsbyImageData":{"images":{"sources":[{"srcSet":"https://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=450&h=300&q=50&fm=webp 450w,\nhttps://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=900&h=600&q=50&fm=webp 900w,\nhttps://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&h=1200&q=50&fm=webp 1800w","sizes":"(min-width: 1800px) 1800px, 100vw","type":"image/webp"}],"fallback":{"src":"https://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&h=1200&fl=progressive&q=50&fm=jpg","srcSet":"https://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=450&h=300&fl=progressive&q=50&fm=jpg 450w,\nhttps://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=900&h=600&fl=progressive&q=50&fm=jpg 900w,\nhttps://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&h=1200&fl=progressive&q=50&fm=jpg 1800w","sizes":"(min-width: 1800px) 1800px, 100vw"}},"layout":"constrained","width":1800,"height":1200,"placeholder":{"fallback":"data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wAARCAANABQDASIAAhEBAxEB/8QAGQAAAgMBAAAAAAAAAAAAAAAAAAQCAwUG/8QAIBAAAgEEAQUAAAAAAAAAAAAAAQIAAwQRIRIFEzFCkf/EABQBAQAAAAAAAAAAAAAAAAAAAAH/xAAWEQEBAQAAAAAAAAAAAAAAAAABABH/2gAMAwEAAhEDEQA/AK2EUrvxZQfJOplUeoXt4xHeWkMeqSS8jcKtSrUqHOcs2vggpIN0JGSdQiZvnXRUGENJxv/Z"}},"ogimg":{"src":"https://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&q=50"}},"body":{"childMarkdownRemark":{"timeToRead":2,"html":"<p>이번 포스팅에서는 데이터를 분석하기 위한 과정에 대해 하나하나 간단히 알아보겠습니다.\n일반적으로 어떠한 데이터로부터 어떠한 가치를 창출하고자 할 때, 다음과 같이 <strong>[전처리 - 모델링 - 평가 - 예측]</strong> 프로세스를 따르게 됩니다.</p>\n<p><span\n        class=\"gatsby-resp-image-wrapper\"\n        style=\"position: relative; display: block; ; max-width: 650px; margin-left: auto; margin-right: auto;\"\n      >\n        <span\n          class=\"gatsby-resp-image-background-image\"\n          style=\"padding-bottom: 66.5924276169265%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,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'); background-size: cover; display: block;\"\n        >\n          <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;\"\n        alt=\"process\"\n        title=\"\"\n        src=\"https://images.ctfassets.net/tushy4jlcik7/dTT8eucBtcpZOtgU4Osmd/bb92e32157028dd4fe3a8487dd5567ee/process.png\"\n        srcset=\"https://images.ctfassets.net/tushy4jlcik7/dTT8eucBtcpZOtgU4Osmd/bb92e32157028dd4fe3a8487dd5567ee/process.png?w=225 225w,\nhttps://images.ctfassets.net/tushy4jlcik7/dTT8eucBtcpZOtgU4Osmd/bb92e32157028dd4fe3a8487dd5567ee/process.png?w=449 449w,\nhttps://images.ctfassets.net/tushy4jlcik7/dTT8eucBtcpZOtgU4Osmd/bb92e32157028dd4fe3a8487dd5567ee/process.png?w=898 898w\"\n        sizes=\"(max-width: 650px) 100vw, 650px\"\n        loading=\"lazy\"\n      />\n        </span>\n      </span></p>\n<br>\n<h2 id=\"preprocessing\" style=\"position:relative;\"><a href=\"#preprocessing\" aria-label=\"preprocessing permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Preprocessing</h2>\n<p>전처리 과정은 <strong>Preprocessing</strong> 또는 <strong>Data Cleaning</strong> / <strong>Wrangling</strong> /  <strong>Munging</strong> 과 같이 다양한 용어로 불립니다. 이 과정에서 어떤 일을 하는지 한마디로 요약하자면 비정형 데이터를 정형화시키는 작업을 합니다. 대부분의 우리가 수집한 데이터는 쓰레기의 집합에 가깝습니다. 따라서, 원하는 형태에 맞게 수정 / 변환해주는 작업이 필요한 것입니다.</p>\n<p>비정형 데이터를 가치있는 데이터로 변환하기 이전에, 먼저 어떻게 생겼는지 확인해보는 것이 좋습니다. 실제 Kaggle에 가보면 많은 사이언티스트들이 데이터를 시각화해놓은 스크립트를 많이 볼 수 있습니다. 이러한 과정을 통해 모델링 이전에 인사이트를 얻게 된다면, 이후에 많은 시간을 절약할 수 있게 됩니다.</p>\n<p>대충 확인했다면 이제 데이터를 정형화시키는 작업을 진행합니다. 이 단계는 데이터에 따라 다르겠지만 약간 노가다 작업이 많이 들어갑니다. 텍스트 날짜 데이터를 datetime 객체로 변환하고 날짜별로 정리한다던지, Null 데이터를 적절한 값으로 채우거나 버리는 작업이 이에 해당합니다.</p>\n<p>만일 텍스트 데이터를 분석해야 한다면, 상황에 따라 다음과 같은 과정이 필요할 것입니다. 이 부분에 대해서는 나중에 자세히 다루겠습니다.</p>\n<ul>\n<li>Stopword 제거</li>\n<li>한글 형태소 분석</li>\n<li>개체명 인식</li>\n<li>One-Hot Encoding</li>\n<li>Word Embedding</li>\n<li>그 밖에 여러가지</li>\n</ul>\n<p>데이터가 어느정도 깨끗해지고 나면 Training Dataset과 Test Dataset을 나누어 줘야 합니다. Training Dataset으로 학습하고 나면, 모델이 그 데이터에 최적화 되어 있기 때문에 학습에 사용하지 않은 데이터로 나누어주는 것이 좋습니다. Coursera 강의를 보면 일반적으로 Training Dataset을 70%, Test Dataset을 30%로 나누는게 적당하다고 말합니다.</p>\n<br>\n<h2 id=\"modeling\" style=\"position:relative;\"><a href=\"#modeling\" aria-label=\"modeling permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Modeling</h2>\n<p>모델링 과정은 적절한 Learning Algorithm을 선택하여 Training Dataset을 넣고 학습하는 과정입니다. 먼저 Model Selection 같은 경우, 분석하고자 하는 과정이 Classification인지, Regression인지 등 여러 경우와 데이터에 따라 적절한 모델을 선택하면 됩니다. 이 과정에서 통계적 지식이 조금 요구됩니다.</p>\n<p>이렇게 모델을 만들고 나서 바로 Test Dataset 과 비교하는 것이 아니라, <strong>Cross-Validation</strong> 과정을 거치게 됩니다. Cross-Validation은 학습에 사용된 Training Dataset 중 일부분을 나누어 검증하는 데 사용하는 것을 말합니다. 왜 중간에 검증 과정이 필요한가 하면, 우리가 가지고 있는 데이터는 전체 데이터 중 일부를 샘플링 한 데이터이기 때문에 신뢰도가 100%일 수 없습니다. 따라서, Cross-Validation은 통계적으로 신뢰도를 높이기 위한 과정입니다. 대표적인 방법으로 <strong>K-Fold</strong>와 <strong>Bootstrap</strong>이 있습니다.</p>\n<p>그리고 모델의 성능을 높이기 위한 방법으로 <strong>Hyperparameter Optimization</strong> 이 있습니다. Parameter Tuning 이라고 부르기도 합니다. 간단히 말해서 모델에 들어가는 파라메터들을 최적의 값으로 튜닝하는 것입니다. 딥러닝의 경우 뉴럴넷을 통해 알아서 최적화 되지만, 머신러닝 알고리즘의 경우 결과 값을 확인하여 최적화하는 경우가 많습니다. 대표적으로 <strong>Grid Search</strong>, <strong>Random Search</strong> 등의 방법이 있습니다.</p>\n<br>\n<h2 id=\"evaluation--prediction\" style=\"position:relative;\"><a href=\"#evaluation--prediction\" aria-label=\"evaluation  prediction permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Evaluation &#x26; Prediction</h2>\n<p>마지막은 모델을 평가하고 결과를 예측하는 과정입니다. 모델을 평가한다는 것은 말 그대로 이 모델이 좋은지 별로인지, 너무 Training Dataset 에만 최적화 된 것은 아닌지 등을 평가하는 작업을 말합니다. 일반적으로 모델 평가에는 <strong>performance matrix</strong> 나 <strong>loss function</strong> 이 사용됩니다. Log Loss, F1 Score, RMSE 등의 값들이 이에 해당합니다.</p>\n<br>\n<h2 id=\"python-library\" style=\"position:relative;\"><a href=\"#python-library\" aria-label=\"python library permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Python Library</h2>\n<p>다행히 파이썬에는 일련의 과정에 필요한 패키지들이 다양하게 제공됩니다. 그 중에서 제가 자주 쓰는 라이브러리를 간단히 정리해보았습니다.</p>\n<h3 id=\"data-analysis\" style=\"position:relative;\"><a href=\"#data-analysis\" aria-label=\"data analysis permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Data Analysis</h3>\n<ul>\n<li>Numpy, Pandas</li>\n<li>Scikit-learn, Scipy</li>\n<li>Gensim, NLTK</li>\n<li>TensorFlow</li>\n</ul>\n<h3 id=\"data-visualization\" style=\"position:relative;\"><a href=\"#data-visualization\" aria-label=\"data visualization permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Data Visualization</h3>\n<ul>\n<li>Matplotlib, Seaborn</li>\n<li>Chart.js, HighChart.js, D3.js</li>\n</ul>","excerpt":"…"}}},{"id":"06ab8a86-5c79-565e-8a20-7665fe5adee3","title":"DecisionTree와 RandomForest에 대하여","slug":"decision-randomforest","publishDate":"February 10, 2017","publishDateISO":"2017-02-10","heroImage":{"title":"cover-datascience","gatsbyImageData":{"images":{"sources":[{"srcSet":"https://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=450&h=300&q=50&fm=webp 450w,\nhttps://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=900&h=600&q=50&fm=webp 900w,\nhttps://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&h=1200&q=50&fm=webp 1800w","sizes":"(min-width: 1800px) 1800px, 100vw","type":"image/webp"}],"fallback":{"src":"https://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&h=1200&fl=progressive&q=50&fm=jpg","srcSet":"https://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=450&h=300&fl=progressive&q=50&fm=jpg 450w,\nhttps://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=900&h=600&fl=progressive&q=50&fm=jpg 900w,\nhttps://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&h=1200&fl=progressive&q=50&fm=jpg 1800w","sizes":"(min-width: 1800px) 1800px, 100vw"}},"layout":"constrained","width":1800,"height":1200,"placeholder":{"fallback":"data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wAARCAANABQDASIAAhEBAxEB/8QAGQAAAgMBAAAAAAAAAAAAAAAAAAQCAwUG/8QAIBAAAgEEAQUAAAAAAAAAAAAAAQIAAwQRIRIFEzFCkf/EABQBAQAAAAAAAAAAAAAAAAAAAAH/xAAWEQEBAQAAAAAAAAAAAAAAAAABABH/2gAMAwEAAhEDEQA/AK2EUrvxZQfJOplUeoXt4xHeWkMeqSS8jcKtSrUqHOcs2vggpIN0JGSdQiZvnXRUGENJxv/Z"}},"ogimg":{"src":"https://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&q=50"}},"body":{"childMarkdownRemark":{"timeToRead":3,"html":"<h3 id=\"의사결정트리decisiontree\" style=\"position:relative;\"><a href=\"#%EC%9D%98%EC%82%AC%EA%B2%B0%EC%A0%95%ED%8A%B8%EB%A6%ACdecisiontree\" aria-label=\"의사결정트리decisiontree permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>의사결정트리 (DecisionTree)</h3>\n<p>의사결정나무는 다양한 의사결정 경로와 결과를 나타내는데 트리 구조를 사용합니다. 보통 어렸을 때의 스무고개 놀이를 예로 드는 경우가 많습니다.</p>\n<p><img src=\"http://cfile3.uf.tistory.com/image/2720193757A374DF33F327\" alt=\"img\"></p>\n<br>\n<p>위의 그림은 타이타닉 생존자를 찾는 의사결정트리 모델입니다. 첫번째 뿌리 노드를 보면 성별 &#x3C;= 0.5 라고 되어있는데 이는 남자냐? 여자냐? 라고 질문하는 것과 같습니다.</p>\n<p>최종적으로, 모든 승객에 대한 분류(Classification)를 통해 생존확률을 예측할 수 있게 됩니다.</p>\n<p>이처럼, 숫자형 결과를 반환하는 것을 <strong>회귀나무(Regression Tree)</strong> 라고 하며, 범주형 결과를 반환하는 것을 <strong>분류나무(Classification Tree)</strong> 라고 합니다. 의사결정트리를 만들기 위해서는 먼저 어떤 질문을 할 것인지, 어떤 순서로 질문을 할 것인지 정해야 합니다.</p>\n<p>가장 좋은 방법은 예측하려는 대상에 대해 가장 많은 정보를 담고 있는 질문을 고르는 것이 좋습니다. 이러한 '얼마만큼의 정보를 담고 있는가'를 엔트로피(entropy) 라고 합니다. 엔트로피는 보통 데이터의 불확실성(?)을 나타내며, 결국 엔트로피가 클 수록 데이터 정보가 잘 분포되어 있기 때문에 좋은 지표라고 예상할 수 있습니다.</p>\n<p>그림과 같이 의사결정트리는 이해하고 해석하기 쉽다는 장점이 있습니다. 또한 예측할 때 사용하는 프로세스가 명백하며, 숫자형 / 범주형 데이터를 동시에 다룰 수 있습니다. 그리고 특정 변수의 값이 누락되어도 사용할 수 있습니다.</p>\n<p>하지만 최적의 의사결정트리를 찾는 것이 정말 어려운 문제입니다. (어떤 것들을 조건(Feature)으로 넣어야 할지, 깊이(Depth)는 얼마로 정해야 할지…) 그리고 의사결정트리의 단점은 새로운 데이터에 대한 일반화 성능이 좋지 않게 오버피팅(Overfitting)되기 쉽다는 것입니다.</p>\n<p>잠깐 오버피팅에 대해 설명하자면, 오버피팅이란 Supervised Learning에서 과거의 학습한 데이터에 대해서는 잘 예측하지만 새로 들어온 데이터에 대해서 성능이 떨어지는 경우를 말합니다. 즉, 학습 데이터에 지나치게 최적화되어 일반화가 어렵다는 말입니다. 이러한 오버피팅을 방지할 수 있는 대표적인 방법 중 하나가 바로 앙상블 기법을 적용한 <strong>랜덤포레스트(Random Forest)</strong> 입니다.</p>\n<br>\n<h3 id=\"랜덤포레스트-randomforest\" style=\"position:relative;\"><a href=\"#%EB%9E%9C%EB%8D%A4%ED%8F%AC%EB%A0%88%EC%8A%A4%ED%8A%B8-randomforest\" aria-label=\"랜덤포레스트 randomforest permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>랜덤포레스트 (RandomForest)</h3>\n<p>랜덤포레스트는 위에서 말한 것과 같이 의사결정트리를 이용해 만들어진 알고리즘입니다.</p>\n<blockquote>\n<p>랜덤포레스트는 분류, 회귀 분석 등에 사용되는 앙상블 학습 방법의 일종으로, </p>\n<p>훈련 과정에서 구성한 다수의 결정 트리로부터 분류 또는 평균 예측치를 출력함으로써 동작한다.</p>\n</blockquote>\n<br>\n<p>즉, 랜덤포레스트란 여러 개의 의사결정트리를 만들고, 투표를 시켜 다수결로 결과를 결정하는 방법입니다.</p>\n<br>\n<p><img src=\"http://cfile24.uf.tistory.com/image/2325343B57A37515289AD9\" alt=\"img\"></p>\n<p>위의 그림은 고작 몇 십개의 트리노드가 있지만 실제로는 수 백개에서 수 만개까지 노드가 생성될 수 있습니다. 이렇게 여러 개의 트리를 통해 투표를 해서 오버피팅이 생길 경우에 대비할 수 있습니다.</p>\n<p>그런데 보통 구축한 트리에는 랜덤성이 없는데 어떻게하면 랜덤하게 트리를 얻을 수 있나? 라는 의문이 듭니다. 랜덤포레스트에서는 데이터를 bootstrap 해서 포레스트를 구성합니다.</p>\n<p>bootstrap aggregating 또는 begging 이라고 하는데, 전체 데이터를 전부 이용해서 학습시키는 것이 아니라 샘플의 결과물을 각 트리의 입력 값으로 넣어 학습하는 방식입니다. 이렇게 하면 각 트리가 서로 다른 데이터로 구축되기 때문에 랜덤성이 생기게 됩니다. 그리고 파티션을 나눌 때 변수에 랜덤성을 부여합니다. 즉, 남아있는 모든 변수 중에서 최적의 변수를 선택하는 것이 아니라 변수 중 일부만 선택하고 그 일부 중에서 최적의 변수를 선택하는 것입니다.</p>\n<p>이러한 방식을 <strong>앙상블 기법(ensemble learning)</strong> 이라고 합니다. 랜덤포레스트는 아주 인기가 많고 자주 사용되는 알고리즘 중 하나입니다. 샘플링되지 않은 데이터를 테스트 데이터로 이용할 수 있기 때문에 데이터 전체를 학습에 사용할 수 있으며, 의사결정트리에 비해 일반화도 적용될 수 있습니다.</p>\n<p>하지만 실제로 테스트 해보면 꼭 모든 경우에 뛰어나다고 할 수는 없습니다. (예를 들면 데이터 셋이 비교적 적은 경우)</p>\n<br>\n<h2 id=\"실제로-사용해보자\" style=\"position:relative;\"><a href=\"#%EC%8B%A4%EC%A0%9C%EB%A1%9C-%EC%82%AC%EC%9A%A9%ED%95%B4%EB%B3%B4%EC%9E%90\" aria-label=\"실제로 사용해보자 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>실제로 사용해보자</h2>\n<p>이렇게 이론을 공부하고 나면 실제로 적용해보는 예측모델을 만들고 싶어집니다.\n정말 고맙게도 파이썬의 scikit-learn에 다양한 트리 모델이 구현되어 있습니다.\n다른 앙상블 모델 뿐만 아니라 RandomForest까지 제공합니다.</p>\n<p>공식 레퍼런스는 아래의 링크를 참조</p>\n<p><a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html</a></p>\n<br>\n<p><span\n        class=\"gatsby-resp-image-wrapper\"\n        style=\"position: relative; display: block; ; max-width: 650px; margin-left: auto; margin-right: auto;\"\n      >\n        <span\n          class=\"gatsby-resp-image-background-image\"\n          style=\"padding-bottom: 25.989445910290236%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,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'); background-size: cover; display: block;\"\n        >\n          <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;\"\n        alt=\"decisiontree load\"\n        title=\"\"\n        src=\"https://images.ctfassets.net/tushy4jlcik7/h2zq985L28nU1Hmtvlsvf/63608d954a2b558c86f66c980129eb1a/decisiontree_load.png\"\n        srcset=\"https://images.ctfassets.net/tushy4jlcik7/h2zq985L28nU1Hmtvlsvf/63608d954a2b558c86f66c980129eb1a/decisiontree_load.png?w=379 379w,\nhttps://images.ctfassets.net/tushy4jlcik7/h2zq985L28nU1Hmtvlsvf/63608d954a2b558c86f66c980129eb1a/decisiontree_load.png?w=758 758w,\nhttps://images.ctfassets.net/tushy4jlcik7/h2zq985L28nU1Hmtvlsvf/63608d954a2b558c86f66c980129eb1a/decisiontree_load.png?w=1516 1516w\"\n        sizes=\"(max-width: 650px) 100vw, 650px\"\n        loading=\"lazy\"\n      />\n        </span>\n      </span></p>\n<p>방법은 간단합니다. sklearn.tree에 있는 model 을 import 합니다.\nskikit-learn의 모델들은 대부분 파라메터로 X, y 값을 넣는다는 공통점이 있습니다.\n여기서 X는 input 또는 feature가 되고, y는 output이 됩니다.</p>\n<br>\n<p><img src=\"/assets/images/decisiontree_fit.png\" alt=\"decisiontree_fit\"></p>\n<p>model.fit(X, y)를 하면 모델에 대한 정보가 출력됩니다. 최초에 모델을 로드할 때 random_state 값만 조정했기 때문에 전부 다 default 값이 적용된 걸 볼 수 있습니다.</p>\n<p>RandomForest나 DecisionTree 같은 경우에는 max_depth, n_estimator에 따라 결과 값이 달라집니다. 데이터에 따라 다르지만, 보통 100-150 사이의 값 중에 성능이 가장 잘 나오는 값으로 결정합니다.</p>\n<p>Kaggle Titanic에 적용한 스크립트는 아래의 링크를 참조하시면 됩니다.</p>\n<p><a href=\"https://github.com/Swalloow/Kaggle/blob/master/Titanic%20Survivors/Titanic%20Tree%20Modeling.ipynb\">https://github.com/Swalloow/Kaggle/blob/master/Titanic%20Survivors/Titanic%20Tree%20Modeling.ipynb</a></p>","excerpt":"의사결정트리 (DecisionTree…"}}},{"id":"9160ad92-4b57-5842-ab2e-5ee3b2c9070c","title":"Deep Learning Programming Style: Symbolic, Imperative","slug":"deep-learning-style","publishDate":"January 05, 2018","publishDateISO":"2018-01-05","heroImage":{"title":"cover-datascience","gatsbyImageData":{"images":{"sources":[{"srcSet":"https://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=450&h=300&q=50&fm=webp 450w,\nhttps://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=900&h=600&q=50&fm=webp 900w,\nhttps://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&h=1200&q=50&fm=webp 1800w","sizes":"(min-width: 1800px) 1800px, 100vw","type":"image/webp"}],"fallback":{"src":"https://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&h=1200&fl=progressive&q=50&fm=jpg","srcSet":"https://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=450&h=300&fl=progressive&q=50&fm=jpg 450w,\nhttps://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=900&h=600&fl=progressive&q=50&fm=jpg 900w,\nhttps://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&h=1200&fl=progressive&q=50&fm=jpg 1800w","sizes":"(min-width: 1800px) 1800px, 100vw"}},"layout":"constrained","width":1800,"height":1200,"placeholder":{"fallback":"data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wAARCAANABQDASIAAhEBAxEB/8QAGQAAAgMBAAAAAAAAAAAAAAAAAAQCAwUG/8QAIBAAAgEEAQUAAAAAAAAAAAAAAQIAAwQRIRIFEzFCkf/EABQBAQAAAAAAAAAAAAAAAAAAAAH/xAAWEQEBAQAAAAAAAAAAAAAAAAABABH/2gAMAwEAAhEDEQA/AK2EUrvxZQfJOplUeoXt4xHeWkMeqSS8jcKtSrUqHOcs2vggpIN0JGSdQiZvnXRUGENJxv/Z"}},"ogimg":{"src":"https://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&q=50"}},"body":{"childMarkdownRemark":{"timeToRead":5,"html":"<p>TensorFlow 1.5 버전부터 <a href=\"https://github.com/tensorflow/tensorflow/tree/r1.5/tensorflow/contrib/eager\">Eager Execution</a> 이라는 기능이 추가되었습니다.\n다시 말해서 <code class=\"language-text\">imperative programming style</code>을 지원한다고 적혀있는데, 기존의 방식과 어떤 차이가 있는지 알아보겠습니다.\nMXNet의 <a href=\"https://mxnet.incubator.apache.org/architecture/program_model.html\">Deep Learning Programming Style</a> 문서를 번역한 내용입니다.</p>\n<br>\n<h2 id=\"deep-learning-programming-style\" style=\"position:relative;\"><a href=\"#deep-learning-programming-style\" aria-label=\"deep learning programming style permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Deep Learning Programming Style</h2>\n<p>우리는 항상 <strong>성능과 최적화</strong>에 대한 고민을 합니다. 하지만 그 이전에 잘 동작하는 코드인지 여부가 중요합니다. 이제는 다양한 딥러닝 라이브러리들이 존재하지만 각자 프로그래밍 방식에 대해 다른 접근 방식을 가지고 있기 때문에 학습하는 것도 힘들며, 이를 이용하여 명확하고 직관적인 deep learning 코드를 작성하는 것도 어렵습니다.</p>\n<p>이 문서에서는 가장 중요한 두 가지 디자인 패턴에 집중하려고 합니다.</p>\n<ol>\n<li>\n<p>Whether to embrace the symbolic or imperative paradigm for mathematical computation.</p>\n</li>\n<li>\n<p>Whether to build networks with bigger (more abstract) or more atomic operations.</p>\n</li>\n</ol>\n<hr>\n<h2 id=\"symbolic-vs-imperative-programs\" style=\"position:relative;\"><a href=\"#symbolic-vs-imperative-programs\" aria-label=\"symbolic vs imperative programs permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Symbolic vs. Imperative Programs</h2>\n<p>만일 당신이 파이썬 또는 C++ 개발자라면, 이미 <code class=\"language-text\">Imperative program</code>과 친숙할 것 입니다.\nImperative style program들은 바로 연산을 수행합니다. 대부분의 파이썬 코드들이 imperative 한 형태를 보여주는데, 예를 들면 아래와 같은 Numpy 코드를 말합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\na <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>ones<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span>\nb <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>ones<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token number\">2</span>\nc <span class=\"token operator\">=</span> b <span class=\"token operator\">*</span> a\nd <span class=\"token operator\">=</span> c <span class=\"token operator\">+</span> <span class=\"token number\">1</span></code></pre></div>\n<p>프로그램이 <code class=\"language-text\">c = b * a</code>를 수행하도록 명령을 내리면, 실제로 연산이 실행됩니다.</p>\n<p>반면에 <code class=\"language-text\">Symbolic program</code>은 조금 다릅니다. Symbolic-style program에서는 먼저 function (potentially complex) 을 정의합니다. <strong>function을 정의했다고 해서 실제 연산이 수행되는 것은 아닙니다.</strong> 우리는 그저 placeholder 값에 function을 정의한 것 뿐 입니다. 이 과정 이후에 function을 컴파일 할 수 있으며, 실제 입력 값을 통해 이를 평가하게 됩니다. 아래는 위에서 언급했던 imperative 코드를 symbolic style로 변환한 예제입니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">A <span class=\"token operator\">=</span> Variable<span class=\"token punctuation\">(</span><span class=\"token string\">'A'</span><span class=\"token punctuation\">)</span>\nB <span class=\"token operator\">=</span> Variable<span class=\"token punctuation\">(</span><span class=\"token string\">'B'</span><span class=\"token punctuation\">)</span>\nC <span class=\"token operator\">=</span> B <span class=\"token operator\">*</span> A\nD <span class=\"token operator\">=</span> C <span class=\"token operator\">+</span> Constant<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># compiles the function</span>\nf <span class=\"token operator\">=</span> <span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span>D<span class=\"token punctuation\">)</span>\nd <span class=\"token operator\">=</span> f<span class=\"token punctuation\">(</span>A<span class=\"token operator\">=</span>np<span class=\"token punctuation\">.</span>ones<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> B<span class=\"token operator\">=</span>np<span class=\"token punctuation\">.</span>ones<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token operator\">*</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>보시다시피 symbolic 버전에서는 <code class=\"language-text\">C = B * A</code>가 수행되는 시점에 실제로 연산이 일어나지 않습니다. 대신에 이 operation은 연산 과정을 표현하는 <strong>computation graph (aka. symbolic graph)</strong> 를 생성합니다. 예를 들면, D의 연산을 위해 아래와 같은 computation graph가 생성됩니다.</p>\n<p><span\n        class=\"gatsby-resp-image-wrapper\"\n        style=\"position: relative; display: block; ; max-width: 217px; margin-left: auto; margin-right: auto;\"\n      >\n        <span\n          class=\"gatsby-resp-image-background-image\"\n          style=\"padding-bottom: 61.29032258064516%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACgAAAAZCAMAAAB0BpxXAAABHVBMVEX////+/v78/PzR0dHHx8fPz8+IiIj19fX9/f20tLSvr6/U1NXr6+u4uLj6+vr09vf6/P318vHjzsPhzMDy7+318/Hk0MXy7uzZvKvbcwDccwDVtJ/Zvq7bdADVsZv+///z8O/izcHizMDg29nw8fHo6Oju7u739/je29ngy8DjzcDy7uv7+/vz8/Pw8PDd3d3k5OTs7e3p6er9/v7V1dXa2try8vLx8fH39/fm5ubj4+Ph4eHe3t7g4ODLy8vp6eni4N7d2dj29vXb29vS0tLf39/Gv7xaAABTAACmmJLn5+fU0tGsn5mrnJbc2NbExMTq6urn5+j5+vr09PT5+fm9vb34+Pjv7+/s7OzGxsbIyMj29vbJycnU1NTNzc1luk9gAAABGElEQVQYGaXBB1eCUACA0e+h5quUhk3bA1uuBqShUdmkYWWpzf//M9Kso8AxPKd76ULgoQQEXsEQboG+MB6yf0DBSYYGI3iIaFSlJ0PDuI2MxsZwG5+ITeIyNR2fwW12Lj6/gNPi0vLKqqRJS9Cytr6xucW3pEqHlJaWQCZLk9je2eXXno6Doe0LWnJ5g7YDExdDMyQgElqSDoUiHsahGYkELZySR8cntMlACRKnmn6Gy/nF5RVtRV0FmTUzNk7y+ub2jjazfE+DYN8SgMKP9MMjToZCS8VWeHq2aKraNbrL5VX0CiDrlspfVDtHQyWfwocwi1TydYkv6yXzWsOH9oYo2dkCPmS0bBC2rSo+lHc9Q08+Pqv8xxdGnh/5ZhMmIgAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n        >\n          <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;\"\n        alt=\"comp graph\"\n        title=\"\"\n        src=\"https://images.ctfassets.net/tushy4jlcik7/6ZV7X7VsuVZ1iQ8bnLAcm2/d1fa256c4b9a76bec671424aa08d1e55/comp_graph.png\"\n        srcset=\"https://images.ctfassets.net/tushy4jlcik7/6ZV7X7VsuVZ1iQ8bnLAcm2/d1fa256c4b9a76bec671424aa08d1e55/comp_graph.png?w=54 54w,\nhttps://images.ctfassets.net/tushy4jlcik7/6ZV7X7VsuVZ1iQ8bnLAcm2/d1fa256c4b9a76bec671424aa08d1e55/comp_graph.png?w=109 109w,\nhttps://images.ctfassets.net/tushy4jlcik7/6ZV7X7VsuVZ1iQ8bnLAcm2/d1fa256c4b9a76bec671424aa08d1e55/comp_graph.png?w=217 217w\"\n        sizes=\"(max-width: 217px) 100vw, 217px\"\n        loading=\"lazy\"\n      />\n        </span>\n      </span></p>\n<p>대부분의 symbolic-style 프로그램들은 명시적으로든 암시적으로든 컴파일 단계를 포함합니다. 이를 통해 computation graph를 언제든 호출할 수 있는 함수로 변환시켜줍니다. 위의 예제에서도 실제 연산은 코드의 마지막 줄에서만 수행됩니다. 이를 통해 얻을 수 있는 점은 computation graph를 작성하는 단계와 실행하는 단계를 명확히 분리할 수 있다는 것 입니다. Neural Network에서도 우리는 전체 모델을 단일 computation graph로 정의합니다.</p>\n<p><code class=\"language-text\">Torch</code>, <code class=\"language-text\">Chiner</code> 그리고 <code class=\"language-text\">Minerva</code>와 같은 딥러닝 라이브러리들은 imperative style을 사용하고 있습니다. symbolic-style을 사용하는 딥러닝 라이브러리로는 <code class=\"language-text\">Theano</code>, <code class=\"language-text\">CGT</code> 그리고 <code class=\"language-text\">TensorFlow</code>가 있습니다. 그리고 <code class=\"language-text\">CXXNet</code> 이나 <code class=\"language-text\">Caffe</code>와 같은 라이브러리들은 설정파일에 의존하는 방식으로 symbolic style을 지원합니다. (ex. Caffe의 prototxt)\n이제 두 가지 딥러닝 프로그래밍 방식에 대해 이해했으니, 각 방식의 장점에 대해 알아보겠습니다.</p>\n<hr>\n<h2 id=\"imperative-programs-tend-to-be-more-flexible\" style=\"position:relative;\"><a href=\"#imperative-programs-tend-to-be-more-flexible\" aria-label=\"imperative programs tend to be more flexible permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Imperative Programs Tend to be More Flexible</h2>\n<p>imperative program은 프로그래밍 언어의 flow와 상당히 잘 맞아들어가며 유연하게 동작하는 것 처럼 보입니다. 그렇다면 왜 수 많은 딥러닝 라이브러리들이 symbolic 패러다임을 선택할까요? 가장 큰 이유는 <strong>메모리 사용량과 속도 측면에서의 효율성</strong> 때문입니다. 위에서 언급했던 예제로 돌아가 천천히 설명드리겠습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">a <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>ones<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span>\nb <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>ones<span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token number\">2</span>\nc <span class=\"token operator\">=</span> b <span class=\"token operator\">*</span> a\nd <span class=\"token operator\">=</span> c <span class=\"token operator\">+</span> <span class=\"token number\">1</span></code></pre></div>\n<p><span\n        class=\"gatsby-resp-image-wrapper\"\n        style=\"position: relative; display: block; ; max-width: 217px; margin-left: auto; margin-right: auto;\"\n      >\n        <span\n          class=\"gatsby-resp-image-background-image\"\n          style=\"padding-bottom: 61.29032258064516%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACgAAAAZCAMAAAB0BpxXAAABHVBMVEX////+/v78/PzR0dHHx8fPz8+IiIj19fX9/f20tLSvr6/U1NXr6+u4uLj6+vr09vf6/P318vHjzsPhzMDy7+318/Hk0MXy7uzZvKvbcwDccwDVtJ/Zvq7bdADVsZv+///z8O/izcHizMDg29nw8fHo6Oju7u739/je29ngy8DjzcDy7uv7+/vz8/Pw8PDd3d3k5OTs7e3p6er9/v7V1dXa2try8vLx8fH39/fm5ubj4+Ph4eHe3t7g4ODLy8vp6eni4N7d2dj29vXb29vS0tLf39/Gv7xaAABTAACmmJLn5+fU0tGsn5mrnJbc2NbExMTq6urn5+j5+vr09PT5+fm9vb34+Pjv7+/s7OzGxsbIyMj29vbJycnU1NTNzc1luk9gAAABGElEQVQYGaXBB1eCUACA0e+h5quUhk3bA1uuBqShUdmkYWWpzf//M9Kso8AxPKd76ULgoQQEXsEQboG+MB6yf0DBSYYGI3iIaFSlJ0PDuI2MxsZwG5+ITeIyNR2fwW12Lj6/gNPi0vLKqqRJS9Cytr6xucW3pEqHlJaWQCZLk9je2eXXno6Doe0LWnJ5g7YDExdDMyQgElqSDoUiHsahGYkELZySR8cntMlACRKnmn6Gy/nF5RVtRV0FmTUzNk7y+ub2jjazfE+DYN8SgMKP9MMjToZCS8VWeHq2aKraNbrL5VX0CiDrlspfVDtHQyWfwocwi1TydYkv6yXzWsOH9oYo2dkCPmS0bBC2rSo+lHc9Q08+Pqv8xxdGnh/5ZhMmIgAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n        >\n          <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;\"\n        alt=\"comp graph\"\n        title=\"\"\n        src=\"https://images.ctfassets.net/tushy4jlcik7/6ZV7X7VsuVZ1iQ8bnLAcm2/d1fa256c4b9a76bec671424aa08d1e55/comp_graph.png\"\n        srcset=\"https://images.ctfassets.net/tushy4jlcik7/6ZV7X7VsuVZ1iQ8bnLAcm2/d1fa256c4b9a76bec671424aa08d1e55/comp_graph.png?w=54 54w,\nhttps://images.ctfassets.net/tushy4jlcik7/6ZV7X7VsuVZ1iQ8bnLAcm2/d1fa256c4b9a76bec671424aa08d1e55/comp_graph.png?w=109 109w,\nhttps://images.ctfassets.net/tushy4jlcik7/6ZV7X7VsuVZ1iQ8bnLAcm2/d1fa256c4b9a76bec671424aa08d1e55/comp_graph.png?w=217 217w\"\n        sizes=\"(max-width: 217px) 100vw, 217px\"\n        loading=\"lazy\"\n      />\n        </span>\n      </span></p>\n<p>주어진 array의 각 셀이 8 바이트의 메모리를 소모한다고 가정해보겠습니다. 콘솔에서 위의 프로그램을 실행하면 메모리가 얼마나 소모될까요?</p>\n<p>imperative program에서는 각 라인마다 메모리 할당이 요구됩니다. 사이즈가 10인 array가 4개 할당되므로 <code class=\"language-text\">4 * 10 * 8 = 320 bytes</code>의 메모리가 요구됩니다.\n반면 computation graph에서는 궁극적으로 d가 필요하다는 것을 알고 있기 때문에, 즉시 값을 메모리에 할당하는 대신에 <strong>메모리를 재사용</strong>할 수 있습니다. 예를 들어 b를 위해 할당된 공간에 c를 저장하도록 재사용하고, c를 위해 할당된 공간에 다시 d를 저장하도록 한다면 결국 요구되는 메모리는 <code class=\"language-text\">2 * 10 * 8 = 160 bytes</code> 절반으로 줄어들게 됩니다.</p>\n<p><span\n        class=\"gatsby-resp-image-wrapper\"\n        style=\"position: relative; display: block; ; max-width: 531px; margin-left: auto; margin-right: auto;\"\n      >\n        <span\n          class=\"gatsby-resp-image-background-image\"\n          style=\"padding-bottom: 26.365348399246706%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACgAAAALCAMAAAA6GD/HAAAA3lBMVEX////b3Nzt7u7s7Oz19vbj5OT3+Pjx8vP4+frp6en19PPj4uH39vb+/v7+/f3qzLzu2s7v3tTlyrr8/Pz9/f38+vrjxLLz5+Hx8vLl5eb///7r1svx4tv29vbx8fH9+/r59fP39/f5+fn7+/v4+Pj49PL9/Pvu7u718e/18vH4+vr+///6+vr08/Pz8/Pv7+/p6Ofm4+Hr6+v8+/rjspLnybjOx8Sgi4L29fTn5+fh3t3MxMHt7e319fX48u/28/H29/fv7u3p5uX09PTh4eHl5eXw8PDk5OTy8vLc3NxsPQGAAAAAzklEQVQYGQXBhyLDUAAAwCM1imc1toSXlKKRULOkVs3//yF3AAAAADOzAEkHMDcPAAALiwDdJcDyCgAQYHVtHSFgY7NHytb2DgDY3YP9g0NkOY6OY1H2lZ2TU+kAgLNzcDFEdQnEuhlEcHWtyPM8H1U3t3dDiAH3D49QjdOkmwoMn57TmLRtO554eX2bT+lTxfePACESYlYrsoAQQqhAL8ZpEvslAJA30woAoB11P9tJ00yzmAKKQf1VAQDIv0PZ/HR/67zuAbK/AAAAAPgHjVAVFm5W+N4AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n        >\n          <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;\"\n        alt=\"comp graph fold\"\n        title=\"\"\n        src=\"https://images.ctfassets.net/tushy4jlcik7/598GTPa6qN31Q1lgoA0u5A/3802633e211b5ccf00df3a4a3e11561c/comp_graph_fold.png\"\n        srcset=\"https://images.ctfassets.net/tushy4jlcik7/598GTPa6qN31Q1lgoA0u5A/3802633e211b5ccf00df3a4a3e11561c/comp_graph_fold.png?w=133 133w,\nhttps://images.ctfassets.net/tushy4jlcik7/598GTPa6qN31Q1lgoA0u5A/3802633e211b5ccf00df3a4a3e11561c/comp_graph_fold.png?w=266 266w,\nhttps://images.ctfassets.net/tushy4jlcik7/598GTPa6qN31Q1lgoA0u5A/3802633e211b5ccf00df3a4a3e11561c/comp_graph_fold.png?w=531 531w\"\n        sizes=\"(max-width: 531px) 100vw, 531px\"\n        loading=\"lazy\"\n      />\n        </span>\n      </span></p>\n<p>Symbolic program은 사실 이보다 더 엄격합니다. 우리가 D에 대한 컴파일을 호출하면, 시스템은 오직 d 값이 필요하다는 사실만 인지합니다. 따라서 위와 같은 경우, 즉시 연산에 의해 c는 존재하지 않는 값으로 취급합니다.</p>\n<p>symbolic program이 안전하게 메모리를 재사용함으로 인해 우리가 얻는 장점은 분명 있습니다. 하지만, 나중에 우리가 c에 대해 접근해야하는 경우가 생긴다면 난감해집니다. 따라서 imperative program은 모든 가능한 경우의 수에 접근해야 할 때 더 좋은 대안이 될 수 있습니다. 대표적으로 파이썬 콘솔에서 imperative 버전의 코드를 실행시킨다면, 미래에 발생할 수 있는 변수를 중간 과정을 통해 미리 검사할 수 있습니다.</p>\n<p>Symbolic program은 <code class=\"language-text\">operation folding</code> 최적화도 수행해줍니다. 다시 위의 예시를 살펴보면 곱셈과 합 연산이 하나의 operation으로 합쳐지는 것을 그래프를 통해 확인할 수 있습니다. 만일 연산이 GPU 프로세서에 의해 실행된다면, 두 개가 아닌 하나의 GPU 커널만 실행될 것 입니다. 실제로 이는 CXXNet, Caffe와 같은 라이브러리에서 연산을 수행하는 방식입니다. Operation folding 방식은 계산 효율을 향상시켜줍니다.</p>\n<p>아시다시피 imperative program에서는 중간 값이 나중에 참조될 수 있기 때문에 operation folding 방식을 수행할 수 없습니다. 반면, computation graph에서는 전체 계산 그래프를 얻을 수 있고 어떤 값을 필요로하는지 알 수 있기 때문에 operation folding이 가능합니다.</p>\n<hr>\n<h2 id=\"case-study-backprop-and-autodiff\" style=\"position:relative;\"><a href=\"#case-study-backprop-and-autodiff\" aria-label=\"case study backprop and autodiff permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Case Study: Backprop and AutoDiff</h2>\n<p>이제 <code class=\"language-text\">auto differentiation</code>이나 <code class=\"language-text\">backpropagation</code>과 같은 문제를 통해 두 가지 프로그래밍 모델을 비교해보겠습니다. (chaining rule이 어떻게 동작하는지 보여주겠다)\n미분은 모델을 훈련시키는 메커니즘이기 때문에 딥러닝에 있어 정말 중요합니다. 우선 대부분의 딥러닝 모델에서 loss function을 정의하는데 이는 모델이 예측한 값이 실제 값과 얼마나 멀리 떨어져 있는지를 말합니다. 그리고 나서 훈련 데이터를 모델에게 전달하고, 각 step에서 모델의 parameter를 업데이트하여 loss를 최소화합니다. 즉, parameter가 업데이트 하는 방향은 loss function 결과에 의해 결정됩니다.</p>\n<p><span\n        class=\"gatsby-resp-image-wrapper\"\n        style=\"position: relative; display: block; ; max-width: 650px; margin-left: auto; margin-right: auto;\"\n      >\n        <span\n          class=\"gatsby-resp-image-background-image\"\n          style=\"padding-bottom: 19.351230425055927%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACgAAAAICAMAAAC8jE1pAAAA21BMVEX////6+vr9/f35+fny8vL29/f09PTw8PD+/Pz8/Pz7+/v+/v719fb4+Pnx8fH39vb39/fw7+/w4uL49vb+///38O3z8e/z8/Pu5N/48/Hy6+f28O328/Hy7u349PPw5uL4+Pj6+fnz6Oj9+/v69fX37u7s7Oz19fXu7u77/Pz5+vr09PX8+ff6+Pf29vb6+Pb+/Pvy8fH69fP28vD8+/v6+/v17+/57+/09fX9/v778fH07+/9/f7l4uH7+/rv7+/o5uX29fXr6+vv8PD79fX18vL8/Pv4+fnp6ekyqqdMAAAAx0lEQVQYGWXB6ToDMRiA0TeZNp8k1cYau6hlxjbWWkspyv1fkZEfeDiHf5SGotU2osmmrHPKQ8cD7YLMTUO3B2Fmds7Mky0sShQFS8vAyirZ2rr3G5spqa3+Nju7e6Gs9g8OpRuBo+OiVien9gyv0vlFCuFS97QfFIOr6xvlzO3dvUhNw5oYhriHRyWjYSdWFp6e8TKOL4bG65spg/V8cZI0mdI+lW4C2OgKReNdRi0xmoYXY/lWj8mqWmn+0PxSR7Lqo0r8+ARIKxAlIDu3kQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n        >\n          <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;\"\n        alt=\"comp graph backward\"\n        title=\"\"\n        src=\"https://images.ctfassets.net/tushy4jlcik7/2FrO5jXr2mwezBIpgjU5Ea/d7b2f97fa259ae6ea6312f3df957dd9c/comp_graph_backward.png\"\n        srcset=\"https://images.ctfassets.net/tushy4jlcik7/2FrO5jXr2mwezBIpgjU5Ea/d7b2f97fa259ae6ea6312f3df957dd9c/comp_graph_backward.png?w=224 224w,\nhttps://images.ctfassets.net/tushy4jlcik7/2FrO5jXr2mwezBIpgjU5Ea/d7b2f97fa259ae6ea6312f3df957dd9c/comp_graph_backward.png?w=447 447w,\nhttps://images.ctfassets.net/tushy4jlcik7/2FrO5jXr2mwezBIpgjU5Ea/d7b2f97fa259ae6ea6312f3df957dd9c/comp_graph_backward.png?w=894 894w\"\n        sizes=\"(max-width: 650px) 100vw, 650px\"\n        loading=\"lazy\"\n      />\n        </span>\n      </span></p>\n<p>imperative와 symbolic 방식 모두 <code class=\"language-text\">gradient</code> 계산을 수행할 수 있습니다. 먼저 아래의 파이썬 코드를 통해 imperative program이 어떻게 automatic differentiation을 수행하는지 알아보겠습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">array</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">object</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    Simple Array object that support autodiff.\n    \"\"\"</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> value<span class=\"token punctuation\">,</span> name<span class=\"token operator\">=</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>value <span class=\"token operator\">=</span> value\n        <span class=\"token keyword\">if</span> name<span class=\"token punctuation\">:</span>\n            self<span class=\"token punctuation\">.</span>grad <span class=\"token operator\">=</span> <span class=\"token keyword\">lambda</span> g <span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>name <span class=\"token punctuation\">:</span> g<span class=\"token punctuation\">}</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__add__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> other<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">assert</span> <span class=\"token builtin\">isinstance</span><span class=\"token punctuation\">(</span>other<span class=\"token punctuation\">,</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">)</span>\n        ret <span class=\"token operator\">=</span> array<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>value <span class=\"token operator\">+</span> other<span class=\"token punctuation\">)</span>\n        ret<span class=\"token punctuation\">.</span>grad <span class=\"token operator\">=</span> <span class=\"token keyword\">lambda</span> g <span class=\"token punctuation\">:</span> self<span class=\"token punctuation\">.</span>grad<span class=\"token punctuation\">(</span>g<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> ret\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__mul__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> other<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">assert</span> <span class=\"token builtin\">isinstance</span><span class=\"token punctuation\">(</span>other<span class=\"token punctuation\">,</span> array<span class=\"token punctuation\">)</span>\n        ret <span class=\"token operator\">=</span> array<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>value <span class=\"token operator\">*</span> other<span class=\"token punctuation\">.</span>value<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">def</span> <span class=\"token function\">grad</span><span class=\"token punctuation\">(</span>g<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            x <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>grad<span class=\"token punctuation\">(</span>g <span class=\"token operator\">*</span> other<span class=\"token punctuation\">.</span>value<span class=\"token punctuation\">)</span>\n            x<span class=\"token punctuation\">.</span>update<span class=\"token punctuation\">(</span>other<span class=\"token punctuation\">.</span>grad<span class=\"token punctuation\">(</span>g <span class=\"token operator\">*</span> self<span class=\"token punctuation\">.</span>value<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">return</span> x\n        ret<span class=\"token punctuation\">.</span>grad <span class=\"token operator\">=</span> grad\n        <span class=\"token keyword\">return</span> ret\n\n<span class=\"token comment\"># some examples</span>\na <span class=\"token operator\">=</span> array<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'a'</span><span class=\"token punctuation\">)</span>\nb <span class=\"token operator\">=</span> array<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'b'</span><span class=\"token punctuation\">)</span>\nc <span class=\"token operator\">=</span> b <span class=\"token operator\">*</span> a\nd <span class=\"token operator\">=</span> c <span class=\"token operator\">+</span> <span class=\"token number\">1</span>\n<span class=\"token keyword\">print</span> d<span class=\"token punctuation\">.</span>value\n<span class=\"token keyword\">print</span> d<span class=\"token punctuation\">.</span>grad<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># Results</span>\n<span class=\"token comment\"># 3</span>\n<span class=\"token comment\"># {'a': 2, 'b': 1}</span></code></pre></div>\n<hr>\n<h2 id=\"model-checkpoints\" style=\"position:relative;\"><a href=\"#model-checkpoints\" aria-label=\"model checkpoints permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Model Checkpoints</h2>\n<p>모델을 저장하고 다시 불러오는 일 또한 중요합니다. 보통 Neural Network 모델을 저장한다는 것은 네트워크의 구조, 설정 값 그리고 weight 값의 저장을 의미합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">A <span class=\"token operator\">=</span> Variable<span class=\"token punctuation\">(</span><span class=\"token string\">'A'</span><span class=\"token punctuation\">)</span>\nB <span class=\"token operator\">=</span> Variable<span class=\"token punctuation\">(</span><span class=\"token string\">'B'</span><span class=\"token punctuation\">)</span>\nC <span class=\"token operator\">=</span> B <span class=\"token operator\">*</span> A\nD <span class=\"token operator\">=</span> C <span class=\"token operator\">+</span> Constant<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n\nD<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span><span class=\"token string\">'mygraph'</span><span class=\"token punctuation\">)</span>\nD2 <span class=\"token operator\">=</span> load<span class=\"token punctuation\">(</span><span class=\"token string\">'mygraph'</span><span class=\"token punctuation\">)</span>\nf <span class=\"token operator\">=</span> <span class=\"token builtin\">compile</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>D2<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># more operations</span>\n<span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span></code></pre></div>\n<p>설정 값을 체크하는 일은 symbolic program이 더 유리 합니다. symbolic 구조에서는 실제 연산을 수행할 필요가 없기 때문에 computation graph를 그대로 serialize 하면 됩니다.\n반면에 Imperative program은 연산 할 때 실행되기 때문에 코드 자체를 설정 파일로 저장하거나 그 위에 또 다른 레이어를 구성해야합니다.</p>\n<hr>\n<h2 id=\"parameter-updates\" style=\"position:relative;\"><a href=\"#parameter-updates\" aria-label=\"parameter updates permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Parameter Updates</h2>\n<p>computation graph의 경우 연산과정은 쉽게 설명할 수 있지만 parameter 업데이트에 대해서는 명확하지 못합니다. parameter update는 기본적으로 값의 변경(mutation)을 요구하기 때문에 computation graph의 개념과 맞지 않습니다. 따라서 대부분의 symbolic program들은 persistent state를 갱신하기 위해 special update 구문을 사용하고 있습니다.</p>\n<p>반면에 imperative style에서는 parameter 업데이트를 작성하는 것이 쉽습니다. 특히 서로 연관된 여러 업데이트가 필요할 때 더욱 그렇습니다. Symbolic program의 경우 업데이트 문은 사용자가 호출 할 때 실행됩니다. 이런 점에서 대부분의 symbolic deep learning 라이브러리는 parameter 업데이트에 대해 gradient 연산을 수행하면서 업데이트를 수행하는 imperative style로 다시 돌아갑니다.</p>\n<hr>\n<h2 id=\"there-is-no-strict-boundary\" style=\"position:relative;\"><a href=\"#there-is-no-strict-boundary\" aria-label=\"there is no strict boundary permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>There Is No Strict Boundary</h2>\n<p>두 가지 프로그래밍 스타일을 비교해서, 하나만 사용하라는 말이 아닙니다. 명령형 프로그램을 상징형 프로그램처럼 만들거나 그 반대도 가능합니다. 예를 들면, Python으로 JIT (just-in-time) 컴파일러를 작성하여 명령형 Python 프로그램을 컴파일 할 수 있습니다. 하지만 두 가지 아키텍쳐를 이해하는 것은 수 많은 딥러닝 라이브러리의 추상화와 그 차이를 이해하는데 도움이 됩니다. <strong>결국, 우리는 프로그래밍 스타일 간에 명확한 경계선이 없다고 결론을 내릴 수 있습니다.</strong></p>\n<br>","excerpt":"TensorFlow 1.5 버전부터 Eager Execution…"}}},{"id":"976a40c0-463b-5a5b-918a-bb7adeb7a48e","title":"Structuring Your TensorFlow Models","slug":"structuring-tf","publishDate":"April 20, 2018","publishDateISO":"2018-04-20","heroImage":{"title":"cover-datascience","gatsbyImageData":{"images":{"sources":[{"srcSet":"https://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=450&h=300&q=50&fm=webp 450w,\nhttps://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=900&h=600&q=50&fm=webp 900w,\nhttps://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&h=1200&q=50&fm=webp 1800w","sizes":"(min-width: 1800px) 1800px, 100vw","type":"image/webp"}],"fallback":{"src":"https://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&h=1200&fl=progressive&q=50&fm=jpg","srcSet":"https://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=450&h=300&fl=progressive&q=50&fm=jpg 450w,\nhttps://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=900&h=600&fl=progressive&q=50&fm=jpg 900w,\nhttps://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&h=1200&fl=progressive&q=50&fm=jpg 1800w","sizes":"(min-width: 1800px) 1800px, 100vw"}},"layout":"constrained","width":1800,"height":1200,"placeholder":{"fallback":"data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wAARCAANABQDASIAAhEBAxEB/8QAGQAAAgMBAAAAAAAAAAAAAAAAAAQCAwUG/8QAIBAAAgEEAQUAAAAAAAAAAAAAAQIAAwQRIRIFEzFCkf/EABQBAQAAAAAAAAAAAAAAAAAAAAH/xAAWEQEBAQAAAAAAAAAAAAAAAAABABH/2gAMAwEAAhEDEQA/AK2EUrvxZQfJOplUeoXt4xHeWkMeqSS8jcKtSrUqHOcs2vggpIN0JGSdQiZvnXRUGENJxv/Z"}},"ogimg":{"src":"https://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&q=50"}},"body":{"childMarkdownRemark":{"timeToRead":4,"html":"<p>이 글은 저자의 허락을 받아 번역한 글 입니다. <a href=\"https://danijar.com/structuring-your-tensorflow-models/\">원문 링크</a></p>\n<p>TensorFlow에서 모델을 정의하다보면 어느새 많은 양의 코드가 생성된 경험이 있을 것 입니다. 어떻게 하면 가독성과 재사용성이 높은 코드로 구성할 수 있을까요? 여기에서 실제 동작하는 예시 코드를 확인하실 수 있습니다. <a href=\"https://gist.github.com/danijar/8663d3bbfd586bffecf6a0094cd116f2\">Gist Link</a></p>\n<br>\n<h2 id=\"defining-the-compute-graph\" style=\"position:relative;\"><a href=\"#defining-the-compute-graph\" aria-label=\"defining the compute graph permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Defining the Compute Graph</h2>\n<p>모델 당 하나의 클래스부터 시작하는 것이 좋습니다. 그 클래스의 인터페이스는 무엇인가요? 일반적으로 모델은 input data와 target placeholder를 연결하며 training, evaluation 그리고 inference 관련 함수를 제공합니다.</p>\n<script src=\"https://gist.github.com/Swalloow/c90dea8bce9ceee147851656f48fac9f.js\"></script>\n<p>위의 코드가 기본적으로 TensorFlow codebase에서 모델이 정의되는 방식입니다. 그러나 여기에도 몇 가지 문제가 있습니다. 가장 중요한 문제는 전체 그래프가 단일 함수 생성자로 정의된다는 점 입니다. 이렇게 되면 가독성이 떨어지며 재사용이 어렵습니다.</p>\n<br>\n<h2 id=\"using-properties\" style=\"position:relative;\"><a href=\"#using-properties\" aria-label=\"using properties permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Using Properties</h2>\n<p>함수가 호출 될 때마다 그래프는 확장되기 때문에 함수로 분할하는 것만으로는 부족합니다. 따라서 함수를 처음 호출하는 시점에 operation들이 그래프에 추가되도록 해야합니다. 이러한 방식을 기본적으로 <strong>lazy-loading</strong>이라고 합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">Model</span><span class=\"token punctuation\">:</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> data<span class=\"token punctuation\">,</span> target<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        data_size <span class=\"token operator\">=</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">.</span>get_shape<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n        target_size <span class=\"token operator\">=</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>target<span class=\"token punctuation\">.</span>get_shape<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n        weight <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>Variable<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>truncated_normal<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>data_size<span class=\"token punctuation\">,</span> target_size<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        bias <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>Variable<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>constant<span class=\"token punctuation\">(</span><span class=\"token number\">0.1</span><span class=\"token punctuation\">,</span> shape<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span>target_size<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        incoming <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>matmul<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">,</span> weight<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> bias\n        self<span class=\"token punctuation\">.</span>_prediction <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>softmax<span class=\"token punctuation\">(</span>incoming<span class=\"token punctuation\">)</span>\n        cross_entropy <span class=\"token operator\">=</span> <span class=\"token operator\">-</span>tf<span class=\"token punctuation\">.</span>reduce_sum<span class=\"token punctuation\">(</span>target<span class=\"token punctuation\">,</span> tf<span class=\"token punctuation\">.</span>log<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>_prediction<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>_optimize <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">.</span>RMSPropOptimizer<span class=\"token punctuation\">(</span><span class=\"token number\">0.03</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>minimize<span class=\"token punctuation\">(</span>cross_entropy<span class=\"token punctuation\">)</span>\n        mistakes <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>not_equal<span class=\"token punctuation\">(</span>\n            tf<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>target<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> tf<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>_prediction<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>_error <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>reduce_mean<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>cast<span class=\"token punctuation\">(</span>mistakes<span class=\"token punctuation\">,</span> tf<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token decorator annotation punctuation\">@property</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">prediction</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>_prediction\n\n    <span class=\"token decorator annotation punctuation\">@property</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">optimize</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>_optimize\n\n    <span class=\"token decorator annotation punctuation\">@property</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">error</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>_error</code></pre></div>\n<p>위의 방식이 첫 번째 예제보다 훨씬 좋습니다. 이제 코드는 독립적인 함수로 구성되어 있습니다. 그러나 아직 코드는 lazy-loading으로 인해 약간 복잡해보입니다. 이를 어떻게 개선 할 수 있는지 보도록 하겠습니다.</p>\n<br>\n<h2 id=\"lazy-property-decorator\" style=\"position:relative;\"><a href=\"#lazy-property-decorator\" aria-label=\"lazy property decorator permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Lazy Property Decorator</h2>\n<p>파이썬은 아주 유연한 언어입니다. 이제 마지막 예제에서 중복 코드를 제거하는 방법을 보여드리겠습니다. 우리는 <code class=\"language-text\">@property</code>처럼 동작하지만 한번만 함수를 평가하는 decorator를 사용할 것입니다. decorator는 함수(접두사를 앞에 붙임)의 이름을 따서 멤버에 결과를 저장하고 나중에 호출되는 시점에 해당 값을 반환합니다. custom decorator를 아직 사용해본적이 없다면, <a href=\"http://blog.apcelent.com/python-decorator-tutorial-with-example.html\">이 가이드</a>를 참고하시면 됩니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">Model</span><span class=\"token punctuation\">:</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> data<span class=\"token punctuation\">,</span> target<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>data <span class=\"token operator\">=</span> data\n        self<span class=\"token punctuation\">.</span>target <span class=\"token operator\">=</span> target\n        self<span class=\"token punctuation\">.</span>_prediction <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span>\n        self<span class=\"token punctuation\">.</span>_optimize <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span>\n        self<span class=\"token punctuation\">.</span>_error <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span>\n\n    <span class=\"token decorator annotation punctuation\">@property</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">prediction</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> self<span class=\"token punctuation\">.</span>_prediction<span class=\"token punctuation\">:</span>\n            data_size <span class=\"token operator\">=</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">.</span>get_shape<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n            target_size <span class=\"token operator\">=</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>target<span class=\"token punctuation\">.</span>get_shape<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n            weight <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>Variable<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>truncated_normal<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>data_size<span class=\"token punctuation\">,</span> target_size<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n            bias <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>Variable<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>constant<span class=\"token punctuation\">(</span><span class=\"token number\">0.1</span><span class=\"token punctuation\">,</span> shape<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span>target_size<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n            incoming <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>matmul<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">,</span> weight<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> bias\n            self<span class=\"token punctuation\">.</span>_prediction <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>softmax<span class=\"token punctuation\">(</span>incoming<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>_prediction\n\n    <span class=\"token decorator annotation punctuation\">@property</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">optimize</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> self<span class=\"token punctuation\">.</span>_optimize<span class=\"token punctuation\">:</span>\n            cross_entropy <span class=\"token operator\">=</span> <span class=\"token operator\">-</span>tf<span class=\"token punctuation\">.</span>reduce_sum<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>target<span class=\"token punctuation\">,</span> tf<span class=\"token punctuation\">.</span>log<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>prediction<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n            optimizer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">.</span>RMSPropOptimizer<span class=\"token punctuation\">(</span><span class=\"token number\">0.03</span><span class=\"token punctuation\">)</span>\n            self<span class=\"token punctuation\">.</span>_optimize <span class=\"token operator\">=</span> optimizer<span class=\"token punctuation\">.</span>minimize<span class=\"token punctuation\">(</span>cross_entropy<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>_optimize\n\n    <span class=\"token decorator annotation punctuation\">@property</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">error</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> self<span class=\"token punctuation\">.</span>_error<span class=\"token punctuation\">:</span>\n            mistakes <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>not_equal<span class=\"token punctuation\">(</span>\n                tf<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>target<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> tf<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>prediction<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n            self<span class=\"token punctuation\">.</span>_error <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>reduce_mean<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>cast<span class=\"token punctuation\">(</span>mistakes<span class=\"token punctuation\">,</span> tf<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>_error</code></pre></div>\n<p>위의 decorator를 사용해서 예시 코드는 아래와 같이 간결해졌습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> functools\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">lazy_property</span><span class=\"token punctuation\">(</span>function<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    attribute <span class=\"token operator\">=</span> <span class=\"token string\">'_cache_'</span> <span class=\"token operator\">+</span> function<span class=\"token punctuation\">.</span>__name__\n\n    <span class=\"token decorator annotation punctuation\">@property</span>\n    <span class=\"token decorator annotation punctuation\">@functools<span class=\"token punctuation\">.</span>wraps</span><span class=\"token punctuation\">(</span>function<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">decorator</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> <span class=\"token builtin\">hasattr</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> attribute<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            <span class=\"token builtin\">setattr</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> attribute<span class=\"token punctuation\">,</span> function<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> <span class=\"token builtin\">getattr</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> attribute<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">return</span> decorator</code></pre></div>\n<p>생성자에서 property를 언급했다는 부분이 중요합니다. 이렇게 구성한다면 <code class=\"language-text\">tf.initialize_variables()</code>를 실행할 때 전체 그래프가 정의됩니다.</p>\n<br>\n<h2 id=\"organizing-the-graph-with-scopes\" style=\"position:relative;\"><a href=\"#organizing-the-graph-with-scopes\" aria-label=\"organizing the graph with scopes permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Organizing the Graph with Scopes</h2>\n<p>이제 코드에서 모델을 정의하는 부분은 깔끔해졌지만, 그래프의 연산 부분은 여전히 복잡합니다. 만일 <a href=\"https://www.tensorflow.org/programmers_guide/graph_viz\">그래프를 시각화</a>한다면, 서로 연결되어 있는 노드가 많이 나타날 것 입니다. 이를 해결하기 위한 방법은 <code class=\"language-text\">tf.name_scope('name')</code> 또는 <code class=\"language-text\">tf.variable_scope('name')</code>을 사용하여 각 함수의 내용을 래핑하는 것 입니다. 이렇게 하면 노드들은 그래프 상에서 그룹화되어 있을 것 입니다. 우리는 이전에 만들었던 decorator를 이용하여 이를 자동으로 적용시켜보겠습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">Model</span><span class=\"token punctuation\">:</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> data<span class=\"token punctuation\">,</span> target<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>data <span class=\"token operator\">=</span> data\n        self<span class=\"token punctuation\">.</span>target <span class=\"token operator\">=</span> target\n        self<span class=\"token punctuation\">.</span>prediction\n        self<span class=\"token punctuation\">.</span>optimize\n        self<span class=\"token punctuation\">.</span>error\n\n    <span class=\"token decorator annotation punctuation\">@lazy_property</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">prediction</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        data_size <span class=\"token operator\">=</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">.</span>get_shape<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n        target_size <span class=\"token operator\">=</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>target<span class=\"token punctuation\">.</span>get_shape<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n        weight <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>Variable<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>truncated_normal<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>data_size<span class=\"token punctuation\">,</span> target_size<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        bias <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>Variable<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>constant<span class=\"token punctuation\">(</span><span class=\"token number\">0.1</span><span class=\"token punctuation\">,</span> shape<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span>target_size<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        incoming <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>matmul<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">,</span> weight<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> bias\n        <span class=\"token keyword\">return</span> tf<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>softmax<span class=\"token punctuation\">(</span>incoming<span class=\"token punctuation\">)</span>\n\n    <span class=\"token decorator annotation punctuation\">@lazy_property</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">optimize</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        cross_entropy <span class=\"token operator\">=</span> <span class=\"token operator\">-</span>tf<span class=\"token punctuation\">.</span>reduce_sum<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>target<span class=\"token punctuation\">,</span> tf<span class=\"token punctuation\">.</span>log<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>prediction<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        optimizer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">.</span>RMSPropOptimizer<span class=\"token punctuation\">(</span><span class=\"token number\">0.03</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> optimizer<span class=\"token punctuation\">.</span>minimize<span class=\"token punctuation\">(</span>cross_entropy<span class=\"token punctuation\">)</span>\n\n    <span class=\"token decorator annotation punctuation\">@lazy_property</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">error</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        mistakes <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>not_equal<span class=\"token punctuation\">(</span>\n            tf<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>target<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> tf<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>prediction<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> tf<span class=\"token punctuation\">.</span>reduce_mean<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>cast<span class=\"token punctuation\">(</span>mistakes<span class=\"token punctuation\">,</span> tf<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>lazy caching 이외에도 TensorFlow의 기능을 포함시키므로 decorator에 새로운 이름을 지정했습니다. 그 외의 나머지 부분은 이전과 동일합니다.</p>\n<p>이제 <code class=\"language-text\">@define_scope</code> decorator를 통해 <code class=\"language-text\">tf.variable_scope()</code>에 인자를 전달할 수 있습니다. 예를 들어 해당 scope에 default initializer를 정의할 수 있습니다. 이 부분이 더 궁금하다면 <a href=\"https://gist.github.com/danijar/8663d3bbfd586bffecf6a0094cd116f2\">전체 예제 코드</a>를 확인해보시면 됩니다.</p>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<p><a href=\"https://danijar.com/structuring-your-tensorflow-models/\">https://danijar.com/structuring-your-tensorflow-models/</a></p>\n<br>","excerpt":"이 글은 저자의 허락을 받아 번역한 글 입니다. 원문 링크 TensorFlow…"}}}]}},"pageContext":{"slug":"datascience","basePath":"","paginationPath":"/tag/datascience","pageNumber":0,"humanPageNumber":1,"skip":0,"limit":6,"numberOfPages":1,"previousPagePath":"","nextPagePath":""}},"staticQueryHashes":["1946181227","2744905544","3732430097"]}