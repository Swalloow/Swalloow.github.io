{"componentChunkName":"component---src-templates-post-js","path":"/map-reduce/","result":{"data":{"contentfulPost":{"id":"3bda34bf-e581-57bf-aa58-9130c0a3b6b1","title":"GFS, HDFS 그리고 MapReduce","slug":"map-reduce","metaDescription":null,"publishDate":"March 14, 2017","publishDateISO":"2017-03-14","tags":[{"title":"DataEngineering","id":"6d3fb203-7cdf-53d7-be6f-12ba3e82d74d","slug":"dataengineering"}],"heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"0c11f5f7-0e00-5786-9808-316f3c842c0f","childMarkdownRemark":{"id":"bbf8d9aa-58a2-57f0-98b1-ee6fd7837dbc","timeToRead":2,"html":"<p>데이터가 급속히 늘어나면서 기존의 방법으로 처리가 힘들어지자,\n빅데이터를 위한 대용량 분산 파일 시스템이 나타나기 시작했습니다.\n여기에서는 GFS, HDFS 그리고 Map Reduce 개념에 대해 정리해보려고 합니다.</p>\n<br>\n<h2 id=\"gfs-google-file-system\" style=\"position:relative;\"><a href=\"#gfs-google-file-system\" aria-label=\"gfs google file system permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>GFS (Google File System)</h2>\n<p>Google File System은 2003년 논문을 통해 소개되었습니다.\n이전에 구글에서 사용하던 파일 시스템은 Big File 이었는데,\n구글의 데이터가 급격히 늘어남에 따라 핵심 데이터 스토리지와 구글 검색 엔진을 위해\n최적화 된 파일 시스템이 필요하게 된 것 입니다.</p>\n<p><img src=\"/assets/images/GFS.png\" alt=\"Google File System\"></p>\n<p>GFS는 크게 하나의 master node와 여러 개의 slave node로 구성되어 있습니다.\n기능으로 보면 Master, Chunk Server, Client로 이루어져 있습니다.</p>\n<ul>\n<li><strong>Master</strong>: GFS 전체를 관리하고 통제하는 중앙 서버의 역할</li>\n<li><strong>Chunk Server</strong>: 물리적인 서버, 실제 입출력을 처리</li>\n<li><strong>Client</strong>: 파일 입출력을 요청하는 클라이언트 어플리케이션</li>\n</ul>\n<p>수행과정은 다음과 같습니다.\n먼저 Client가 Master에게 파일의 읽기, 쓰기를 요청하게 되면,\nMaster는 Client와 가까운 Chunk Server의 정보를 Client에게 전달합니다.\nClient는 전달받은 Chunk Server와 직접 통신하며 IO 작업을 수행하게 됩니다.</p>\n<p>GFS의 엄청난 강점은 <strong>Failuer Tolerance</strong> 입니다.\n다시 말해서, 물리적으로 서버 중 하나가 고장이 나도 정지하지 않고 잘 돌아가도록 설계되었습니다.\n예를 들어, Chunk Server 중 하나가 고장이 나면 Master는 고장나지 않은 Chunk Server의 정보를 전달하고\nMaster Server가 고장이 나면 다른 서버가 Master를 대체하게 됩니다.\n이러한 이유로 Chunk Server는 가격이 저렴한 범용 컴퓨터들로 구성할 수 있게 되었고, 클러스터 환경에서 잘 동작할 수 있게 되었습니다.</p>\n<br>\n<h2 id=\"mapreduce\" style=\"position:relative;\"><a href=\"#mapreduce\" aria-label=\"mapreduce permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>MapReduce</h2>\n<p>Map Reduce는 마찬가지로 2004년 구글의 논문(저자: 구글의 전설 제프 딘)을 통해 소개되었습니다.\n논문의 제목은 <strong>MapReduce: Simplified Data Processing on Large Clusters</strong> 입니다.\n즉, MapReduce는 말 그대로 대용량 분산 클러스터에서 데이터를 간단히 처리하는 방법입니다.</p>\n<p>그는 논문을 통해 2가지 Function을 제시하는데 바로 Map과 Reduce 입니다.\n논문에서 제시한 MapReduce의 예시 수도코드는 다음과 같습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span>String key<span class=\"token punctuation\">,</span> String value<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token operator\">//</span> key<span class=\"token punctuation\">:</span> document name\n    <span class=\"token operator\">//</span> value<span class=\"token punctuation\">:</span> document contents\n    <span class=\"token keyword\">for</span> each word w <span class=\"token keyword\">in</span> value<span class=\"token punctuation\">:</span>\n        EmitIntermediate<span class=\"token punctuation\">(</span>w<span class=\"token punctuation\">,</span> <span class=\"token string\">\"1\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token builtin\">reduce</span><span class=\"token punctuation\">(</span>String key<span class=\"token punctuation\">,</span> Iterator values<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token operator\">//</span> key<span class=\"token punctuation\">:</span> a word\n    <span class=\"token operator\">//</span> values<span class=\"token punctuation\">:</span> a <span class=\"token builtin\">list</span> of counts\n    <span class=\"token builtin\">int</span> result <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">for</span> each v <span class=\"token keyword\">in</span> values<span class=\"token punctuation\">:</span>\n        result <span class=\"token operator\">+=</span> ParseInt<span class=\"token punctuation\">(</span>v<span class=\"token punctuation\">)</span>\n    Emit<span class=\"token punctuation\">(</span>AsString<span class=\"token punctuation\">(</span>result<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>먼저 <strong>Map</strong> 함수는 어떤 key-value를 input으로 받아서 각 단어와 관련 발생 횟수를 출력합니다.\n그리고 <strong>Reduce</strong> 함수는 특정 단어에 대해 생성된 모든 카운트를 합산합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">map(k1, v1) -&gt; list(k2, v2)\nreduce(k2, list(v2)) -&gt; list(v2)</code></pre></div>\n<p><strong>Map</strong> 함수는 key-vale를 읽어서 필터링하거나 다른 값으로 변환시켜주며,\n<strong>Reduce</strong> 함수는 Map을 통해 출력된 리스트에\n새로운 key를 기준으로 Groupping하고 이를 Aggregation한 결과를 출력합니다.</p>\n<p><img src=\"/assets/images/mapreduce.png\" alt=\"MapReduce\"></p>\n<p>MapReduce는 여러 대의 컴퓨터에서 데이터를 처리하는 경우, 병렬처리를 하기 때문에 확장이 쉽습니다.\n스케줄러가 데이터를 분산 배치하면 worker에서 작업을 수행하고 각 중간 결과는 로컬 디스크에 저장되며,\n나중에 Reduce 연산을 할당받으면 중간 결과를 읽어와서 작업을 수행하고 마찬가지로 파일 시스템에 저장합니다.\n위의 그림과 같이 Master 노드에 모든 데이터를 받아서 처리하던 옛날 방식과 통신 처리면에서 확실히 줄어든 것을 알 수 있습니다.</p>\n<p>구글은 MapReduce를 URL 접근빈도, Web-Link Graph를 계산하는데 사용하였고,\n이를 통해 인덱싱, 정렬 등에서 엄청난 성능향상을 보여주었습니다.</p>\n<br>\n<h2 id=\"hdfs-hadoop-distributed-file-system\" style=\"position:relative;\"><a href=\"#hdfs-hadoop-distributed-file-system\" aria-label=\"hdfs hadoop distributed file system permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>HDFS (Hadoop Distributed File System)</h2>\n<p>Hadoop은 2006년 Doug Cutting과 Mike Cafarella가 개발한 분산처리 프레임워크입니다.\n이들은 구글의 GFS를 대체하기 위해 <strong>HDFS</strong> 와 <strong>MapReduce</strong> 를 구현하였습니다.</p>\n<p>GFS가 C++로 구현되었다면, Hadoop은 자바로 개발된 데다가 아파치 재단의 오픈소스로 넘어가면서 인기가 많아졌습니다.\nGFS를 구현한 결과물이기 때문에 크게 달라진 것은 없으나\n<strong>YARN, Hadoop Ecosystem</strong> 등 다른 장점으로 인해 많이 사용됩니다.</p>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<ul>\n<li><a href=\"http://xpgc.vicp.net/course/svt/TechDoc/storagepaper/gfs-sosp2003.pdf\">논문: The Google File System</a></li>\n<li><a href=\"https://static.googleusercontent.com/media/research.google.com/ko//archive/mapreduce-osdi04.pdf\">논문: MapReduce - Simplified Data Processing on Large Clusters</a></li>\n</ul>\n<br>","excerpt":"데이터가 급속히 늘어나면서 기존의 방법으로 처리가 힘들어지자,\n빅데이터를 위한 대용량 분산 파일 시스템이 나타나기 시작했습니다.\n여기에서는 GFS, HDFS 그리고 Map Reduce 개념에 대해 정리해보려고 합니다. GFS (Google File System) Google File System은 2003년 논문을 통해 소개되었습니다.\n이전에 구글에서 사용하던 파일 시스템은 Big File 이었는데,\n구글의 데이터가 급격히 늘어남에 따라 핵심 데이터 스토리지와 구글 검색 엔진을 위해\n최적화 된 파일 시스템이 필요하게 된 것 입니다. Google File System…"}}}},"pageContext":{"slug":"map-reduce","basePath":"","prev":{"slug":"scala-for-bigdata","publishDate":"2017-03-17"},"next":{"slug":"spark-zeppelin-install","publishDate":"2017-03-13"}}}}