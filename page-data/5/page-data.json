{"componentChunkName":"component---src-templates-posts-js","path":"/5","result":{"data":{"allContentfulPost":{"edges":[{"node":{"title":"Amazon EKS에 Kubeflow 구축하기","id":"c41958b4-0f03-5549-94c4-2e19fa5fcc89","slug":"eks-kubeflow","publishDate":"March 10, 2019","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"46a42260-b4aa-51d5-aa64-b7247af33731","childMarkdownRemark":{"id":"fef60629-38e4-5c67-8b2f-f654ddcbf758","timeToRead":3,"html":"<p>AWS EKS는 Fully managed K8S 서비스 입니다. 이번 글에서는 EKS 환경에 Kubeflow를 구축하는 방법에 대해 정리해보겠습니다.</p>\n<ul>\n<li><a href=\"http://swalloow.github.io/why-kubeflow\">Why kubeflow in your Infrastructure</a></li>\n<li><a href=\"http://swalloow.github.io/eks-kubeflow\">Amazon EKS에 Kubeflow 구축하기</a></li>\n<li>Kubeflow의 ModelDB</li>\n<li>Kubeflow의 Hyper parameter Tuning (Katib)</li>\n</ul>\n<br>\n<h2 id=\"기본-환경-설치\" style=\"position:relative;\"><a href=\"#%EA%B8%B0%EB%B3%B8-%ED%99%98%EA%B2%BD-%EC%84%A4%EC%B9%98\" aria-label=\"기본 환경 설치 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>기본 환경 설치</h2>\n<p>Kubeflow를 설치하기 이전에 AWS CLI, Docker가 설치되어 있어야 합니다.\nEKS에서는 최근에 GPU 인스턴스인 P2, P3에 대한 지원을 제공하고 있습니다.\n이를 사용하기 위해 AWS Marketplace에서 <a href=\"https://aws.amazon.com/marketplace/pp/B07GRHFXGM\">EKS-optimized AMI with GPU Support</a>를 구독해주어야 합니다.</p>\n<p>EKS는 Web UI 또는 eksctl이라는 cli 도구를 사용해서 클러스터를 구성할 수 있습니다.\neksctl은 kubectl이나 kops와 유사한 명령어를 제공합니다.\n자세한 내용은 <a href=\"https://aws.amazon.com/ko/blogs/opensource/eksctl-eks-cluster-one-command/\">https://aws.amazon.com/ko/blogs/opensource/eksctl-eks-cluster-one-command/</a> 에서 참고하시면 됩니다.</p>\n<br>\n<h2 id=\"eks-클러스터-생성\" style=\"position:relative;\"><a href=\"#eks-%ED%81%B4%EB%9F%AC%EC%8A%A4%ED%84%B0-%EC%83%9D%EC%84%B1\" aria-label=\"eks 클러스터 생성 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>EKS 클러스터 생성</h2>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token comment\"># install eksctl</span>\n$ brew tap weaveworks/tap\n$ brew <span class=\"token function\">install</span> weaveworks/tap/eksctl\n\n<span class=\"token comment\"># create cluster</span>\n$ eksctl create cluster eks-cpu <span class=\"token punctuation\">\\</span>\n--node-type<span class=\"token operator\">=</span>c4.xlarge <span class=\"token punctuation\">\\</span>\n--timeout<span class=\"token operator\">=</span>40m <span class=\"token punctuation\">\\</span>\n--nodes<span class=\"token operator\">=</span><span class=\"token number\">2</span> <span class=\"token punctuation\">\\</span>\n--region<span class=\"token operator\">=</span>ap-northeast-2\n\n<span class=\"token comment\"># NVIDIA driver plugin</span>\nkubectl apply -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v1.11/nvidia-device-plugin.yml\nkubectl get nodes <span class=\"token string\">\"-o=custom-columns=NAME:.metadata.name,MEMORY:.status.allocatable.memory,CPU:.status.allocatable.cpu,GPU:.status.allocatable.nvidia\\.com/gpu\"</span></code></pre></div>\n<ul>\n<li>먼저 Homebrew로 <code class=\"language-text\">eksctl</code>을 설치합니다. 이후 아래의 명령어를 통해 c4 인스턴스 기반의 EKS 클러스터를 생성하고 Memory, CPU, GPU 정보를 확인해줍니다.</li>\n<li>GPU 인스턴스로 클러스터를 생성하고 싶다면 생성하기 이전에 EC2 Limit 페이지에서 p2 또는 p3 인스턴스의 limit을 확인해야 합니다. 0으로 되어있다면 <code class=\"language-text\">Request limit Increase</code>가 필요합니다.</li>\n<li>GPU-enabled worker를 가지는 EKS 클러스터를 생성한다면 NVIDIA driver plugin을 활성화시키는 과정이 필요합니다.</li>\n<li>Create cluster에서 <code class=\"language-text\">AccessDenied</code> 오류가 발생하는 경우, 사용할 IAM 유저를 생성하고 EKS 관련 permission과 <code class=\"language-text\">AWSCloudFormationReadOnlyAccess</code>를 추가해주어야 합니다. EKS는 현재 기준 1.11 버전을 default로 사용하고 있습니다.</li>\n</ul>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1y10f8hW0KFZGSn7WLFne_aqUV4YjPQqJ\" alt=\"eks\"></p>\n<p>EKS 메뉴에 가보시면 EC2 인스턴스, 네트워크 설정이 완료된 것을 확인하실 수 있습니다.\nAWS CloudFormation에서 cluster와 node-group에 대한 stack이 생성됩니다.</p>\n<p>K8S 대시보드는 <a href=\"https://docs.aws.amazon.com/ko_kr/eks/latest/userguide/dashboard-tutorial.html\">AWS EKS 공식 문서</a>를 참고하여 띄울 수 있습니다.</p>\n<br>\n<h2 id=\"ksonnet을-이용한-kubeflow-설치\" style=\"position:relative;\"><a href=\"#ksonnet%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-kubeflow-%EC%84%A4%EC%B9%98\" aria-label=\"ksonnet을 이용한 kubeflow 설치 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>ksonnet을 이용한 KubeFlow 설치</h2>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token comment\"># install ksonnet</span>\n$ brew <span class=\"token function\">install</span> ksonnet/tap/ks\n$ ks version\nksonnet version: <span class=\"token number\">0.13</span>.1\njsonnet version: v0.11.2\nclient-go version: kubernetes-1.10.4\n\n<span class=\"token comment\"># install kubeflow</span>\n$ <span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">KUBEFLOW_TAG</span><span class=\"token operator\">=</span>v0.4.1\n$ <span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">KUBEFLOW_SRC</span><span class=\"token operator\">=</span>/tmp/kubeflow_src\n$ <span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">KFAPP</span><span class=\"token operator\">=</span>eks-kubeflow\n\n$ <span class=\"token function\">mkdir</span> <span class=\"token variable\">${KUBEFLOW_SRC}</span> <span class=\"token operator\">&amp;&amp;</span> <span class=\"token builtin class-name\">cd</span> <span class=\"token variable\">${KUBEFLOW_SRC}</span>\n$ <span class=\"token function\">curl</span> https://raw.githubusercontent.com/kubeflow/kubeflow/<span class=\"token variable\">${KUBEFLOW_TAG}</span>/scripts/download.sh <span class=\"token operator\">|</span> <span class=\"token function\">bash</span>\n\n$ <span class=\"token function\">sh</span> <span class=\"token variable\">${KUBEFLOW_SRC}</span>/scripts/kfctl.sh init <span class=\"token variable\">${KFAPP}</span> --platform none\n$ <span class=\"token builtin class-name\">cd</span> <span class=\"token variable\">${KFAPP}</span>\n$ <span class=\"token function\">sh</span> <span class=\"token variable\">${KUBEFLOW_SRC}</span>/scripts/kfctl.sh generate k8s\n$ <span class=\"token function\">sh</span> <span class=\"token variable\">${KUBEFLOW_SRC}</span>/scripts/kfctl.sh apply k8s</code></pre></div>\n<p>ksonnet으로 KubeFlow를 설치하기 이전에 먼저 Homebrew로 ksonnet을 설치합니다.</p>\n<br>\n<h2 id=\"kubeflow\" style=\"position:relative;\"><a href=\"#kubeflow\" aria-label=\"kubeflow permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>KubeFlow</h2>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1W9rnEB-Bn5IZjLOymYXNxMPNclyY4eJn\" alt=\"kubeflow-pods\">\n<img src=\"http://drive.google.com/uc?export=view&#x26;id=15IWqbbib_vhB_k4FlUK_K39ERUbkVHr0\" alt=\"kubeflow-pvc\"></p>\n<p>KubeFlow를 설치하고 나면 Pods, Deployment, Service, ConfigMap 등 모든 컴포넌트들이 자동으로 배포됩니다. default로 PVC는 EBS gp2 볼륨이 설정된 것을 확인하실 수 있습니다.</p>\n<p>EKS에서는 IAM 기반의 RBAC 인증을 사용합니다.\n아래의 명령어를 통해 EKS의 JupyterHub를 로컬의 8080 포트로 포워딩해서 접속하실 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ kubectl port-forward svc/jupyter-lb -n kubeflow <span class=\"token number\">8080</span>:80</code></pre></div>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1XNiADQX6faiejXKz3OlpwYMhqZQ6xPoz\" alt=\"kubeflow-jupyterhub\"></p>\n<p>위와 같이 설치하고 난 이후에 KubeFlow 문서의 git summerization 튜토리얼을 그대로 따라하실 수 있습니다. 모든 컴포넌트가 자동으로 배포되다 보니 생략하고 넘어가는 경우가 많은데 production 환경에서 사용하려면 각 설정 YAML 파일을 내 환경에 맞도록 수정할 필요가 있습니다. 삭제는 아래의 명령어를 통해 실행시키면 됩니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token builtin class-name\">cd</span> <span class=\"token variable\">${KUBEFLOW_SRC}</span>/<span class=\"token variable\">${KFAPP}</span>\n$ <span class=\"token function\">sh</span> <span class=\"token variable\">${KUBEFLOW_SRC}</span>/scripts/kfctl.sh delete k8s</code></pre></div>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<ul>\n<li><a href=\"https://aws.amazon.com/ko/blogs/opensource/kubeflow-amazon-eks/\">https://aws.amazon.com/ko/blogs/opensource/kubeflow-amazon-eks/</a></li>\n<li><a href=\"https://github.com/aws-samples/machine-learning-using-k8s/blob/master/kubeflow.md\">https://github.com/aws-samples/machine-learning-using-k8s/blob/master/kubeflow.md</a></li>\n<li><a href=\"https://eksctl.io/\">https://eksctl.io/</a></li>\n</ul>\n<br>","excerpt":"AWS EKS는 Fully managed K8S 서비스 입니다. 이번 글에서는 EKS 환경에 Kubeflow…"}}}},{"node":{"title":"Why Kubeflow in your Infrastructure?","id":"b8091786-4329-5d05-802b-b6b069b38702","slug":"why-kubeflow","publishDate":"March 09, 2019","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"9ea4a340-b124-57db-977d-2a8c3a1a9cdf","childMarkdownRemark":{"id":"a056a78c-da2c-502e-8b6d-1656d874de89","timeToRead":2,"html":"<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1JO_ek8Dyr-i5-uvjd4NpzMKBqL6PICDV\" alt=\"Hidden Technical Dept in Machine Learning Systems\"></p>\n<p>실제 ML을 서비스에 적용시키는 일은 위 그림에 나타난 바와 같이 ML 모델링 보다 이외의 작업들이 많이 필요합니다. 특히 서비스의 여러 기능에 ML을 적용시키려 하는 경우, 이러한 파이프라인이 복잡해지고 유지보수가 힘든 방향으로 가는 경우가 많습니다. 이러한 이유로 규모있는 IT 서비스 회사들은 공통의 ML 플랫폼을 구축하곤 합니다.</p>\n<p>앞으로 소개하려는 Kubeflow는 Kubernetes를 기반으로 하는 오픈소스 ML Toolkit 입니다. 아직 버전이 낮아 production 환경에서 사용하는 곳이 많지 않지만 미리 알아두면 좋을 것 같아 컴포넌트들을 하나씩 분석해보려 합니다.</p>\n<ul>\n<li><a href=\"http://swalloow.github.io/why-kubeflow\">Why kubeflow in your Infrastructure</a></li>\n<li><a href=\"http://swalloow.github.io/eks-kubeflow\">Amazon EKS에 Kubeflow 구축하기</a></li>\n<li>Kubeflow의 ModelDB</li>\n<li>Kubeflow의 Hyper parameter Tuning (Katib)</li>\n</ul>\n<br>\n<h2 id=\"why-kubeflow\" style=\"position:relative;\"><a href=\"#why-kubeflow\" aria-label=\"why kubeflow permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Why Kubeflow?</h2>\n<p>이미 기존의 인프라를 기반으로 자동화된 ML Workflow가 구축되어 있다면, 굳이 Kubeflow로 옮길 필요는 없습니다. 하지만 아래와 같은 상황을 가진 팀이라면 Kubeflow는 좋은 선택지가 될 수 있습니다.</p>\n<ul>\n<li>이미 Kubernetes 기반의 인프라를 사용하고 있으며, ML 인프라를 구축하려는 경우</li>\n<li>서비스를 On-premise, Multi-cloud 환경에 배포해야 하는 경우</li>\n<li>Scalable ML이 필수적이며, 기존의 여러 ML 서비스를 쉽게 배포하고 리소스 관리 비용을 줄이려는 경우</li>\n<li>Research Engineer, Data Scientist 를 위한 인프라 관리의 복잡성을 최소화하고 일관된 인터페이스를 제공하여 몇 번의 클릭만으로 설정을 쉽게 하고 싶은 경우</li>\n</ul>\n<br>\n<h2 id=\"consistency-in-infrastructure\" style=\"position:relative;\"><a href=\"#consistency-in-infrastructure\" aria-label=\"consistency in infrastructure permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Consistency in Infrastructure</h2>\n<p>Kubeflow는 Kubernetes 기반의 인프라가 가지는 장점을 그대로 가지고 있습니다. 각 서비스에 대한 Monitoring, Health Check, Replication 등의 기본 요구사항을 갖추고 있으며 쉬운 배포 환경을 제공합니다. 이외에도 아래와 같은 usecase에서 활용될 수 있습니다.</p>\n<ul>\n<li>Research Engineer들이 인프라가 아닌 모델링에만 집중할 수 있는 환경을 제공할 수 있습니다. 모두가 Docker 기반의 추상화된 환경에서 연구를 할 수 있으며, 동일한 데이터, 연구 결과를 공유할 수 있습니다. 가상화된 GPU 환경에서 모델을 분산 학습시킬 수 있으며, TensorFlow, PyTorch, MXNet 등 다양한 프레임워크 환경을 지원할 수 있습니다.</li>\n<li>Kubeflow는 end-to-end를 제공하기 때문에 ML 프로젝트를 production에 반영하는 과정이 단순해집니다. 지속적인 데이터 파이프라인을 구축하여 <strong>argo</strong>를 통해 모델을 업데이트 하고, <strong>seldon</strong>을 통해 production 환경을 테스트해 볼 수 있습니다.</li>\n<li><strong>Katib</strong>을 통해 Hyper parameter tuning 과정을 쉽게 자동화 할 수 있습니다. <strong>Katib</strong>에서 제공하는 인터페이스를 통해 여러 어플리케이션으로 확장시킬 수 있으며, 튜닝 결과를 지속적으로 기록하고 공유할 수 있습니다.</li>\n</ul>\n<br>\n<h2 id=\"resource-utilization-by-the-training--serving-modules\" style=\"position:relative;\"><a href=\"#resource-utilization-by-the-training--serving-modules\" aria-label=\"resource utilization by the training  serving modules permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Resource utilization by the Training / Serving modules</h2>\n<p>테스트 환경을 쉽게 구축할 수 있으며, 클라우드 비용을 최적화시킬 수 있습니다. K8S 클러스터는 동일한 인스턴스에 여러 Pod을 실행시킬 수 있습니다. 따라서, 사용하는 리소스를 팀 또는 프로젝트 단위로 namespace를 분리시켜 리소스 사용량을 모니터링 할 수 있습니다.</p>\n<p>일반적인 클라우드 인프라 환경을 서비스 라이프사이클과 연계되어 있지 않기 때문에 training job이 끝난 이후에도 인스턴스가 켜져 있기 때문에 그에 대한 비용을 지불해야 합니다. 하지만 Kubeflow를 사용하는 경우, 사용량에 따라 클러스터를 auto scaling 한다거나 spot instance로 training job을 실행시킬 수 있습니다.</p>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<ul>\n<li><a href=\"https://medium.com/kubeflow/why-kubeflow-in-your-infrastructure-56b8fabf1f3e\">https://medium.com/kubeflow/why-kubeflow-in-your-infrastructure-56b8fabf1f3e</a></li>\n</ul>","excerpt":"Hidden Technical Dept in Machine Learning Systems 실제 ML…"}}}},{"node":{"title":"KOPS로 AWS에 Kubernetes 클러스터 구축하기","id":"22782f34-788f-5197-a6f7-35b71f4da0c9","slug":"aws-kops","publishDate":"February 10, 2019","heroImage":{"id":"f36c235f-3e3e-517d-bd80-697bc6183072","title":"cover-devops","fluid":{"aspectRatio":1.5,"src":"//images.ctfassets.net/tushy4jlcik7/7KaSTt3mdmrYq2ZK1RiJku/dafd981ff3686217ac151b562e8b1412/cover_devops.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7KaSTt3mdmrYq2ZK1RiJku/dafd981ff3686217ac151b562e8b1412/cover_devops.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7KaSTt3mdmrYq2ZK1RiJku/dafd981ff3686217ac151b562e8b1412/cover_devops.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7KaSTt3mdmrYq2ZK1RiJku/dafd981ff3686217ac151b562e8b1412/cover_devops.jpg?w=1080&h=720&q=50 1080w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7KaSTt3mdmrYq2ZK1RiJku/dafd981ff3686217ac151b562e8b1412/cover_devops.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7KaSTt3mdmrYq2ZK1RiJku/dafd981ff3686217ac151b562e8b1412/cover_devops.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7KaSTt3mdmrYq2ZK1RiJku/dafd981ff3686217ac151b562e8b1412/cover_devops.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7KaSTt3mdmrYq2ZK1RiJku/dafd981ff3686217ac151b562e8b1412/cover_devops.jpg?w=1080&h=720&q=50&fm=webp 1080w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7KaSTt3mdmrYq2ZK1RiJku/dafd981ff3686217ac151b562e8b1412/cover_devops.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"39b3b781-063c-5008-81ca-6b2620548d99","childMarkdownRemark":{"id":"861450a3-c3ca-512b-9d61-4eb1dfeea051","timeToRead":4,"html":"<p>Kubernetes 클러스터를 구성하는 방법은 여러 가지가 있습니다.\n그 중에서 kubeadam은 온프레미스 환경에서 많이 사용하고 kops는 클라우드 환경에서 많이 사용하고 있습니다. 이번 글에서는 kops로 AWS EC2에 Kubernetes 클러스터 구축하는 방법에 대해 정리해보겠습니다.</p>\n<br>\n<h2 id=\"kops-kubectl-awscli-설치-linux\" style=\"position:relative;\"><a href=\"#kops-kubectl-awscli-%EC%84%A4%EC%B9%98-linux\" aria-label=\"kops kubectl awscli 설치 linux permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>kops, kubectl, awscli 설치 (Linux)</h2>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token comment\"># kops 설치</span>\n<span class=\"token function\">wget</span> -O kops https://github.com/kubernetes/kops/releases/download/<span class=\"token variable\"><span class=\"token variable\">$(</span><span class=\"token function\">curl</span> -s https://api.github.com/repos/kubernetes/kops/releases/latest <span class=\"token operator\">|</span> <span class=\"token function\">grep</span> tag_name <span class=\"token operator\">|</span> <span class=\"token function\">cut</span> -d <span class=\"token string\">'\"'</span> -f <span class=\"token number\">4</span><span class=\"token variable\">)</span></span>/kops-linux-amd64\n<span class=\"token function\">chmod</span> +x ./kops\n<span class=\"token function\">sudo</span> <span class=\"token function\">mv</span> ./kops /usr/local/bin/\n\n<span class=\"token comment\"># kubectl 설치</span>\n<span class=\"token function\">wget</span> -O kubectl https://storage.googleapis.com/kubernetes-release/release/<span class=\"token variable\"><span class=\"token variable\">$(</span><span class=\"token function\">curl</span> -s https://storage.googleapis.com/kubernetes-release/release/stable.txt<span class=\"token variable\">)</span></span>/bin/linux/amd64/kubectl\n<span class=\"token function\">chmod</span> +x ./kubectl\n<span class=\"token function\">sudo</span> <span class=\"token function\">mv</span> ./kubectl /usr/local/bin/kubectl\n\n<span class=\"token comment\"># aws-cli 설치 (amazon linux라면 불필요)</span>\npip <span class=\"token function\">install</span> awscli</code></pre></div>\n<br>\n<h2 id=\"iam-user-설정\" style=\"position:relative;\"><a href=\"#iam-user-%EC%84%A4%EC%A0%95\" aria-label=\"iam user 설정 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>IAM User 설정</h2>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token comment\"># 아래의 권한이 필요</span>\nAmazonEC2FullAccess\nAmazonRoute53FullAccess\nAmazonS3FullAccess\nIAMFullAccess\nAmazonVPCFullAccess</code></pre></div>\n<br>\n<h2 id=\"aws-cli로-iam-계정-생성\" style=\"position:relative;\"><a href=\"#aws-cli%EB%A1%9C-iam-%EA%B3%84%EC%A0%95-%EC%83%9D%EC%84%B1\" aria-label=\"aws cli로 iam 계정 생성 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>aws-cli로 IAM 계정 생성</h2>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">aws iam create-group --group-name kops\n\naws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonEC2FullAccess --group-name kops\naws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonRoute53FullAccess --group-name kops\naws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonS3FullAccess --group-name kops\naws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/IAMFullAccess --group-name kops\naws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonVPCFullAccess --group-name kops\n\naws iam create-user --user-name kops\naws iam add-user-to-group --user-name kops --group-name kops\naws iam create-access-key --user-name kops\n\naws configure   <span class=\"token comment\"># AccessKeyID와 SecretAccessKey 등록</span></code></pre></div>\n<br>\n<h2 id=\"dns-cluster-state-storage-설정\" style=\"position:relative;\"><a href=\"#dns-cluster-state-storage-%EC%84%A4%EC%A0%95\" aria-label=\"dns cluster state storage 설정 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>DNS, Cluster State storage 설정</h2>\n<ul>\n<li>kops 1.6.2 버전 이상이라면 DNS 설정은 옵션 (gossip-based cluster)</li>\n<li>Cluster Configuration Storage로 S3를 사용 (Bucket 미리 생성해야 함)</li>\n<li>S3 default bucket encryption을 사용할 수 있음</li>\n<li>default encryption 설정이 안되어 있다면 kops에서 AES256 encryption</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token comment\"># Create Bucket</span>\naws s3api create-bucket <span class=\"token punctuation\">\\</span>\n    --bucket prefix-example-com-state-store <span class=\"token punctuation\">\\</span>\n    --region ap-northeast-2\n\n<span class=\"token comment\"># S3 versioning</span>\naws s3api put-bucket-versioning <span class=\"token punctuation\">\\</span>\n    --bucket prefix-example-com-state-store <span class=\"token punctuation\">\\</span>\n    --versioning-configuration <span class=\"token assign-left variable\">Status</span><span class=\"token operator\">=</span>Enabled</code></pre></div>\n<br>\n<h2 id=\"kubernetes-cluster-생성\" style=\"position:relative;\"><a href=\"#kubernetes-cluster-%EC%83%9D%EC%84%B1\" aria-label=\"kubernetes cluster 생성 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Kubernetes Cluster 생성</h2>\n<ul>\n<li>kops를 통해 생성된 인스턴스는 자동으로 Auto Scaling 그룹에 들어감</li>\n<li><code class=\"language-text\">kops create</code>: cluster configuration을 생성, SSH-Key가 필요</li>\n<li><code class=\"language-text\">kops edit</code>: cluster configuation을 수정</li>\n<li><code class=\"language-text\">kops update</code>: Build 단계, kubernetes component를 모두 설치하고 나면 ready 상태로 전환</li>\n<li><code class=\"language-text\">kops delete</code>: cluster 제거, --yes (구성요소까지 전부 삭제)</li>\n<li><code class=\"language-text\">kops rolling-update</code>: downtime이 없는 rolling-update 실행</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token comment\"># Environment</span>\n<span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">NAME</span><span class=\"token operator\">=</span>myfirstcluster.example.com  <span class=\"token comment\"># DNS가 설정되어 있는 경우</span>\n<span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">NAME</span><span class=\"token operator\">=</span>myfirstcluster.k8s.local    <span class=\"token comment\"># DNS가 설정되어 있지 않은 경우</span>\n<span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">KOPS_STATE_STORE</span><span class=\"token operator\">=</span>s3://prefix-example-com-state-store\n\n<span class=\"token comment\"># Seoul region</span>\naws ec2 describe-availability-zones --region ap-northeast-2\nkops create cluster --zones ap-northeast-2 <span class=\"token variable\">${NAME}</span>\nkops edit cluster <span class=\"token variable\">${NAME}</span>\nkops update cluster <span class=\"token variable\">${NAME}</span> --yes\nkops validate cluster\n\n<span class=\"token comment\"># Kubectl</span>\nkubectl get nodes\nkubectl cluster-info\nkubectl -n kube-system get po   <span class=\"token comment\"># system pod</span>\n\n<span class=\"token comment\"># Dashboard</span>\nkops get secrets admin -oplaintext\nkubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml\n\n<span class=\"token comment\"># Access https://&lt;kubernetes-master-hostname>/ui</span>\nkops get secrets admin --type secret -oplaintext\n\n<span class=\"token comment\"># Stop cluster</span>\n<span class=\"token comment\"># Change minSize, MaxSize to 0</span>\nkops get ig\nkops edit ig nodes\nkops edit ig master</code></pre></div>\n<br>\n<h2 id=\"advanced\" style=\"position:relative;\"><a href=\"#advanced\" aria-label=\"advanced permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Advanced</h2>\n<ul>\n<li>Network topology를 설정할 수 있음 (public, private)</li>\n<li>Private: VPC내의 private subnet으로 생성</li>\n<li>Public: VPC내의 public subnet으로 생성 (routed to Internet Gateway)</li>\n<li>Multiple zone, HA Master를 구성할 수 있음 (--master-zones=us-east-1b,us-east-1c,us-east-1d)</li>\n<li>Instance Group을 지정 가능 (<a href=\"https://github.com/kubernetes/kops/blob/master/docs/instance_groups.md\">https://github.com/kubernetes/kops/blob/master/docs/instance_groups.md</a>)</li>\n<li>AMI를 지정가능, CoreOS AMI</li>\n<li>Container Network Interface (CNI) 지정 가능 (<a href=\"https://kubernetes.io/docs/concepts/cluster-administration/networking/\">https://kubernetes.io/docs/concepts/cluster-administration/networking/</a>)</li>\n<li>Authorization (<a href=\"https://kubernetes.io/docs/reference/access-authn-authz/authorization/\">https://kubernetes.io/docs/reference/access-authn-authz/authorization/</a>)</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token comment\"># SSH Key</span>\nssh-keygen -t rsa -f <span class=\"token variable\">$NAME</span>.key -N <span class=\"token string\">''</span>\n<span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">PUBKEY</span><span class=\"token operator\">=</span><span class=\"token string\">\"<span class=\"token variable\">$NAME</span>.key.pub\"</span>\n\n<span class=\"token comment\"># CoreOS Image</span>\n<span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">IMAGE</span><span class=\"token operator\">=</span><span class=\"token variable\"><span class=\"token variable\">$(</span><span class=\"token function\">curl</span> -s https://coreos.com/dist/aws/aws-stable.json<span class=\"token operator\">|</span><span class=\"token function\">sed</span> <span class=\"token string\">'s/-/_/g'</span><span class=\"token operator\">|</span>jq <span class=\"token string\">'.'</span>$REGION<span class=\"token string\">'.hvm'</span><span class=\"token operator\">|</span><span class=\"token function\">sed</span> <span class=\"token string\">'s/_/-/g'</span> <span class=\"token operator\">|</span> <span class=\"token function\">sed</span> <span class=\"token string\">'s/<span class=\"token entity\" title=\"\\&quot;\">\\\"</span>//g'</span><span class=\"token variable\">)</span></span>\n\n<span class=\"token comment\"># Create Cluster</span>\nkops create cluster --kubernetes-version<span class=\"token operator\">=</span><span class=\"token number\">1.12</span>.1 <span class=\"token punctuation\">\\</span>\n    --ssh-public-key <span class=\"token variable\">$PUBKEY</span> <span class=\"token punctuation\">\\</span>\n    --networking flannel <span class=\"token punctuation\">\\</span>\n    --api-loadbalancer-type public <span class=\"token punctuation\">\\</span>\n    --admin-access <span class=\"token number\">0.0</span>.0.0/0 <span class=\"token punctuation\">\\</span>\n    --authorization RBAC <span class=\"token punctuation\">\\</span>\n    --zones ap-northeast-2 <span class=\"token punctuation\">\\</span>\n    --master-zones ap-northeast-2 <span class=\"token punctuation\">\\</span>\n    --master-size t2.medium <span class=\"token punctuation\">\\</span>\n    --node-size t2.medium <span class=\"token punctuation\">\\</span>\n    --image <span class=\"token variable\">$IMAGE</span> <span class=\"token punctuation\">\\</span>\n    --node-count <span class=\"token number\">3</span> <span class=\"token punctuation\">\\</span>\n    --cloud aws <span class=\"token punctuation\">\\</span>\n    --bastion <span class=\"token punctuation\">\\</span>\n    --name <span class=\"token variable\">$NAME</span> <span class=\"token punctuation\">\\</span>\n    --yes</code></pre></div>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<ul>\n<li><a href=\"https://github.com/kubernetes/kops\">https://github.com/kubernetes/kops</a></li>\n<li><a href=\"https://kubernetes.io/ko/docs/setup/custom-cloud/kops/\">https://kubernetes.io/ko/docs/setup/custom-cloud/kops/</a></li>\n</ul>\n<br>","excerpt":"Kubernetes 클러스터를 구성하는 방법은 여러 가지가 있습니다.\n그 중에서 kubeadam은 온프레미스 환경에서 많이 사용하고 kops…"}}}},{"node":{"title":"분산 컨테이너 환경에서의 디자인 패턴 (1)","id":"9307407d-64a7-50d7-a261-07a48ec192cb","slug":"container-patterns","publishDate":"January 26, 2019","heroImage":{"id":"1563c3af-a4e8-5db4-acb2-9bfd9fdb294d","title":"cover-develop","fluid":{"aspectRatio":1.5,"src":"//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=1800&h=1200&q=50 1800w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=1800&h=1200&q=50&fm=webp 1800w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"3a9720a9-32ed-51fb-9835-f2d0e7f319d0","childMarkdownRemark":{"id":"5240b6d3-d24e-55e9-be93-71350bb375bb","timeToRead":3,"html":"<p>구글 클라우드 팀이 Kubernetes와 같은 Container Orchestration 기술을 개발하면서 겪은\n분산 컨테이너 환경에서의 디자인 패턴에 대해 정리한 내용입니다.\n분산 어플리케이션을 컨테이너 환경으로 옮기려는 분들에게 많은 도움이 될 듯 합니다.</p>\n<ul>\n<li><a href=\"http://swalloow.github.io/container-patterns\">분산 컨테이너 환경에서의 디자인 패턴 1. Single-Node Patterns</a></li>\n<li><a href=\"http://swalloow.github.io/container-patterns2\">분산 컨테이너 환경에서의 디자인 패턴 2. Multi-Node Serving Patterns</a></li>\n<li><a href=\"http://swalloow.github.io/container-patterns3\">분산 컨테이너 환경에서의 디자인 패턴 3. Batch Computational Patterns</a></li>\n</ul>\n<br>\n<h2 id=\"modular-container-design\" style=\"position:relative;\"><a href=\"#modular-container-design\" aria-label=\"modular container design permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Modular Container Design</h2>\n<p>최근 많은 개발 환경이 Docker 기반의 컨테이너 환경으로 옮겨가고 있습니다.\n그 중에서는 복잡한 의존성에서 벗어나 독립적으로 운영하고 싶어서 옮기는 경우가 많습니다.</p>\n<p>하지만 분산 컨테이너 환경은 아주 복잡하게 연결되어 있어서 운영하기 힘듭니다.\n복잡한 연결을 쉽게 이해하려면 이 문제가 어디에 해당하는지 경계를 잘 정의하는 것이 중요합니다.\n이렇게 <strong>경계를 정의하고 분류하는 것을 모듈화</strong>라고 부릅니다.</p>\n<p>우리는 과거부터 효율적인 코드를 작성하기 위해 절차지향 프로그래밍에서 객체지향 프로그래밍으로 변화해왔습니다.\n객체지향 프로그래밍의 클래스는 경계를 정의한다는 측면에서 컨테이너 환경과 유사한 면이 있습니다.</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1KTN3XFpFugvI6OXqnJdvc0LBUjW0HfbV\" alt=\"modular\"></p>\n<p>과거 모놀리틱 아키텍쳐에서는 왼쪽 그림과 같은 구조로 설계되어 왔습니다.\n우리가 기여하거나 자주 수정하는 코드가 있는 반면, 코어 모듈이나 공통에 해당하는 부분은 잘 변하지 않습니다.</p>\n<p>컨테이너 환경은 이와 조금 다릅니다.\n우선 <strong>컨테이너 환경에서 컨테이너는 하나의 어플리케이션이 아니라는 점</strong>을 이해하고 있어야 합니다.\n하나의 컨테이너는 객체지향 언어의 클래스 또는 함수와 유사합니다.\n오른쪽 그림처럼 작은 모듈 조각을 모으고 조립해서 다음 어플리케이션을 설계하는 형태가 되어야 합니다.</p>\n<br>\n<h2 id=\"benefit\" style=\"position:relative;\"><a href=\"#benefit\" aria-label=\"benefit permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Benefit</h2>\n<p>위와 같은 컨테이너 환경을 구성했을 때 가지는 장점은 아래와 같습니다.</p>\n<ul>\n<li>이미 만들어 놓은 컨테이너를 재사용할 수 있고 사용하기 쉬움</li>\n<li>컨테이너 경계에 따라 팀의 역할을 분리시킬 수 있음</li>\n<li>분리되어 있기 때문에 각 모듈에 대해 더 깊게 이해할 수 있음</li>\n<li>각 모듈에 대해 작은 수정사항을 빠르게 업데이트할 수 있음</li>\n<li>흔히 얘기하는 관심사의 분리를 만족시킬 수 있음 (Seperate concerns)</li>\n</ul>\n<br>\n<h2 id=\"requirements\" style=\"position:relative;\"><a href=\"#requirements\" aria-label=\"requirements permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Requirements</h2>\n<p>위와 같은 컨테이너 환경을 구성하기 위해 필요한 요소는 아래와 같습니다.</p>\n<ul>\n<li>공통된 네임스페이스 (PID, IPC, 네트워크 등), 마치 localhost 처럼 사용할 수 있도록 하나의 컨테이너가 다른 컨테이너의 프로세스를 컨트롤 할 수 있어야 합니다.</li>\n<li>공유할 수 있는 파일 시스템, Kubernetes의 PV, PVC에 내한 내용을 떠올리면 이해하기 쉽습니다.</li>\n<li>어플리케이션을 구성할 때 노드의 분리도 고려되어야 합니다. 예시로 WordPress-MySQL 어플리케이션을 배포한다고 가정했을 때, WordPress가 배포된 노드와 MySQL 노드의 위치가 달라야 합니다. 그리고 WordPress, MySQL에 각각에 대한 Scale-out도 고려되어야 합니다.</li>\n<li>컨테이너가 런타임 시점에 파라메터로 설정 값을 받을 수 있도록 설계되어야 합니다. 그리고 각 이미지에 대한 문서화도 필요합니다.\n특히 여러 컨테이너에서 공통으로 사용하는 라이브러리의 경우 필요</li>\n</ul>\n<br>\n<h2 id=\"sidecar-pattern\" style=\"position:relative;\"><a href=\"#sidecar-pattern\" aria-label=\"sidecar pattern permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Sidecar Pattern</h2>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1zkTfbZgsYUlylN6kGVXDjCqfZGVTo5jF\"></p>\n<p>이제부터 자주 사용되는 세 가지 디자인 패턴을 소개드리려고 합니다.\n먼저 첫 번째는 사이드 카 패턴입니다.\n<strong>사이드 카 패턴은 이전에 사용되던 컨테이너의 기능을 확장시키고 싶을 때</strong> 유용하게 사용됩니다.\n여기서 이전에 사용되던 컨테이너란 잘 변하지 않으며 같은 작업을 반복하는 어플리케이션을 말합니다.</p>\n<p>위 그림의 예시에서 이전에 사용되던 컨테이너는 왼쪽의 node.js 어플리케이션 입니다.\nnode.js 어플리케이션은 단순히 파일 시스템에 접근하여 어떤 작업을 수행하는 일만 합니다.\n만일 파일 시스템에 대해 git 동기화 기능을 추가하고 싶다면, 오른쪽 컨테이너처럼 확장시킬 수 있습니다.\nnode.js 어플리케이션은 사이드 카 컨테이너가 어떤 작업을 수행하는지 고려할 필요가 없습니다.\n사이드 카 컨테이너 역시 어떤 어플리케이션이 이 파일을 서빙하는지 고려할 필요가 없습니다.\n앞서 말한 것처럼 관심사의 분리를 만족시키며, 컨테이너를 관리하는 팀을 분리시킬 수 있습니다.\n또한 사이드 카 컨테이너를 다른 어플리케이션에서 재사용할 수 있고, 더 다양한 기능으로 확장시킬 수 있습니다.</p>\n<br>\n<h2 id=\"ambassador-pattern\" style=\"position:relative;\"><a href=\"#ambassador-pattern\" aria-label=\"ambassador pattern permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Ambassador Pattern</h2>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1pzXLY74nqBfNti5cPd-zSw0kGPEh2CUK\"></p>\n<p>다음은 엠베서더 패턴입니다.\n<strong>엠베서더 패턴은 어플리케이션을 대신하여 외부의 네트워크 또는 요청을 처리해야할 때</strong> 유용하게 사용됩니다.</p>\n<p>위 그림의 예시에서 어플리케이션은 PHP 앱이고 Memcache를 사용한 지속적인 해싱이 필요하다고 가정해보겠습니다.\n그리고 Memcache 사용을 위해 <a href=\"https://github.com/twitter/twemproxy\">twemproxy</a>라는 라이브러리를 가져와야 합니다.\n위 그림처럼 어플리케이션과 twemproxy 컨테이너를 분리시킨다면,\ntwemproxy 컨테이너는 외부에 있는 Memcache 샤드를 관리하고 통신하는 역할을 수행할 수 있습니다.\n기존에 있던 어플리케이션 컨테이너는 twemproxy 컨테이너와 같은 네임스페이스에 존재하지만, 외부의 통신에 대해서는 관여할 필요가 없습니다.\n역시 마찬가지로 관심사의 분리를 만족시키며, 재사용될 수 있고, 다양한 기능으로 확장시킬 수 있습니다.</p>\n<br>\n<h2 id=\"adapter-pattern\" style=\"position:relative;\"><a href=\"#adapter-pattern\" aria-label=\"adapter pattern permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Adapter Pattern</h2>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1Vpp_gVNarlAql_eGKkBJ2ojntRkAYzQL\"></p>\n<p>다음은 어댑터 패턴입니다.\n<strong>어댑터 패턴은 추상화된 레이어가 필요할 때</strong> 유용하게 사용됩니다.</p>\n<p>대표적인 예시로 위 그림과 같은 모니터링 에이전트가 있습니다.\n일반적으로 Redis, Memcache, MySQL 등 다양한 컴포넌트에 모니터링이 필요합니다.\n모놀리틱 구조로 설계되었다면, 새로운 컴포넌트에 대한 지원이 필요할때마다 변경이 필요합니다.\n하지만 분리되어 있는 공통 인터페이스가 존재한다면, 새로운 컴포넌트를 쉽게 추가할 수 있습니다.\n특히 오픈소스 진영에서는 많은 사람들이 다양한 컴포넌트를 사용하기 때문에 많이 활용됩니다.</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1doLkvd4eNSQvCtw0KT1ipw2EVA0uTXJP\"></p>\n<p>많이 사용하는 prometheus exporter도 이와 같은 패턴으로 설계되어 있습니다.\nexporter는 모니터링 시스템과 쉽게 결합할 수 있습니다.\n그리고 exporter와 memcache, redis는 결합해서 하나의 컨테이너로 배포하는 형태입니다.\nredis-exporter에 코드 변경이 이루어지더라도 memcache-exporter는 변경될 필요가 없습니다.</p>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<p>이외에도 Replication, Micro service Load Balancer에 사용되는 다양한 패턴이 존재합니다.\n분산 컨테이너 환경에서 어플리케이션을 개발하는 일은 레고 블럭을 조립하는 것과 비슷합니다.\n더 자세한 내용이 궁금하신 분은 아래 링크를 확인하시면 됩니다.</p>\n<ul>\n<li><a href=\"https://www.youtube.com/watch?v=Ph3t8jIt894\">DockerCon - Container patterns for modular distributed system design</a></li>\n<li><a href=\"https://static.googleusercontent.com/media/research.google.com/ko//pubs/archive/45406.pdf\">GooglePaper - Design patterns for container-based distributed systems</a></li>\n</ul>\n<br>","excerpt":"구글 클라우드 팀이 Kubernetes와 같은 Container Orchestration…"}}}},{"node":{"title":"Apache Airflow에 기여하면서 배운 점들","id":"50a917d3-58d2-56fb-b3c1-101b359f2f8a","slug":"airflow-contrib","publishDate":"December 08, 2018","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"a216f939-c13e-5c9e-bf73-f38e51932651","childMarkdownRemark":{"id":"188eab1d-542f-5ef1-b928-da67dfe8eee5","timeToRead":4,"html":"<p>Apache Airflow는 코드를 통해 워크플로우를 관리하고 모니터링 할 수 있도록 도와주는 플랫폼이다.\nAirflow 프로젝트에 대한 설명은 다른 글에서도 많이 다루기 때문에 생략하고\n이 글에서는 처음으로 아파치 프로젝트에 기여해본 경험을 정리해보려 한다.</p>\n<br>\n<h2 id=\"기여하게-된-배경\" style=\"position:relative;\"><a href=\"#%EA%B8%B0%EC%97%AC%ED%95%98%EA%B2%8C-%EB%90%9C-%EB%B0%B0%EA%B2%BD\" aria-label=\"기여하게 된 배경 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>기여하게 된 배경</h2>\n<p>당시에 관리하던 데이터 인프라에는 의존성이 얽혀있는 배치 작업이 상당히 많았다.\n여기에서 의존성이 얽혀있다는 말은 A 작업과 B 작업이 성공적으로 끝나고 난 뒤 C 작업을 해야하는 경우를 말한다.\n또한 각 작업들은 서로 다른 시간에 스케줄링 되어야 했고, 작업이 실패하는 경우 재시도 또는 특정 로직을 실행시킬 수 있어야 했다.</p>\n<p>처음에는 단순한 구조이다 보니 스크립트로 관리했지만 점차 늘어나는 운영 이슈에 대응하기 위해 Airflow를 활용하기로 결정했다.\n하지만 운영하다 보니 AWS 관련 컴포넌트들의 여러 버그를 발견하게 되었고 이를 수정하기 위해 PR을 추가했었다.</p>\n<br>\n<h2 id=\"아파치-프로젝트-pr-프로세스\" style=\"position:relative;\"><a href=\"#%EC%95%84%ED%8C%8C%EC%B9%98-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-pr-%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4\" aria-label=\"아파치 프로젝트 pr 프로세스 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>아파치 프로젝트 PR 프로세스</h2>\n<p>아파치 프로젝트는 이슈 관리 도구로 JIRA를 사용한다. CI 도구는 프로젝트마다 다른 편인데 Airflow의 경우 TravisCI를 사용한다.\n모든 프로젝트에는 처음 프로젝트에 기여하려는 개발자를 위해 <strong>CONTRIBUTING.md</strong> 라는 문서를 제공한다.\n문서에는 개발 및 테스트 환경을 어떻게 구축해야하는지, 지켜야할 규칙, PR 가이드라인 등에 대해 설명되어 있다.\n그리고 PR template를 준수해야 하는데 잘 모르겠다면, 이전 PR들을 확인하고 비슷한 양식으로 작성하면 된다.</p>\n<p>내가 처음 접했던 Airflow 문서에는 AWS 관련 Hook, Operator도 반영되어 있지 않았다.\n그래서 첫 PR로 AWS, GCP 관련 컴포넌트를 업데이트하는 문서 기여를 하게 되었다.\n문서 관리에는 <a href=\"https://readthedocs.org/\">readthedocs</a>를 사용하고 있었고 Sphinx 빌드를 통해 문서를 확인할 수 있었다.</p>\n<p>사용하다보니 특히 EMR 관련 Hook과 Operator에 버그가 많았다.\n만일 JIRA에 이미 등록되어 있는 이슈가 아니라면 이슈를 새로 생성한 다음 PR을 추가해주어야 한다.</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1d0SNiE9qJza0CtmU8S2k8h4Q3iRPE8vN\"></p>\n<p>비슷한 이슈를 겪고 있는 사람들이 있어서 좀 신기했다.\n그리고 <strong>아주 작은 수정이라도 테스트 케이스를 추가</strong>해야 한다는 사실을 알게 되었다.</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1Re-gmGnEOlB8hxPhAkbjYQpQ-6kOzm6j\"></p>\n<p>양식만 잘 지키면 커미터들은 정말 친절하다. 내가 파악하지 못한 부분까지 알려주고, 코드 리뷰도 받을 수 있다.\n다른 PR을 참고하면서 많이 배울 수 있었다.</p>\n<br>\n<h2 id=\"클라우드-인프라-테스트-방법\" style=\"position:relative;\"><a href=\"#%ED%81%B4%EB%9D%BC%EC%9A%B0%EB%93%9C-%EC%9D%B8%ED%94%84%EB%9D%BC-%ED%85%8C%EC%8A%A4%ED%8A%B8-%EB%B0%A9%EB%B2%95\" aria-label=\"클라우드 인프라 테스트 방법 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>클라우드 인프라 테스트 방법</h2>\n<p>AWS는 기본적으로 클라우드 환경이다.\n따라서 과금문제로 인해 실제로 추가, 변경한 오퍼레이터가 잘 동작하는지 매번 확인해보기가 힘들다.\nAirflow에서는 AWS 서비스를 Mocking 하기 위해 <a href=\"https://github.com/spulec/moto\">moto</a> 라는 라이브러를 활용해서 테스트를 작성한다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token decorator annotation punctuation\">@mock_s3</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">test_my_model_save</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\"># Create Bucket so that test can run</span>\n    conn <span class=\"token operator\">=</span> boto3<span class=\"token punctuation\">.</span>resource<span class=\"token punctuation\">(</span><span class=\"token string\">'s3'</span><span class=\"token punctuation\">,</span> region_name<span class=\"token operator\">=</span><span class=\"token string\">'us-east-1'</span><span class=\"token punctuation\">)</span>\n    conn<span class=\"token punctuation\">.</span>create_bucket<span class=\"token punctuation\">(</span>Bucket<span class=\"token operator\">=</span><span class=\"token string\">'mybucket'</span><span class=\"token punctuation\">)</span>\n    model_instance <span class=\"token operator\">=</span> MyModel<span class=\"token punctuation\">(</span><span class=\"token string\">'steve'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'is awesome'</span><span class=\"token punctuation\">)</span>\n    model_instance<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    body <span class=\"token operator\">=</span> conn<span class=\"token punctuation\">.</span>Object<span class=\"token punctuation\">(</span><span class=\"token string\">'mybucket'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'steve'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token string\">'Body'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>decode<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">assert</span> body <span class=\"token operator\">==</span> <span class=\"token string\">'is awesome'</span></code></pre></div>\n<p>위와 같이 moto에서 미리 정의한 mock object를 decorator를 사용하여 쉽게 활용할 수 있다.\n하지만 AWS에서 공식으로 지원하는 라이브러리가 아니다보니 업데이트가 늦어지기도 한다.\n이런 이유로 인해 unittest의 mock으로 작성된 테스트 코드도 많이 있다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">TestEmrAddStepsOperator</span><span class=\"token punctuation\">(</span>unittest<span class=\"token punctuation\">.</span>TestCase<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\"># When</span>\n    _config <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">{</span>\n        <span class=\"token string\">'Name'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'test_step'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'ActionOnFailure'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'CONTINUE'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'HadoopJarStep'</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token string\">'Jar'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'command-runner.jar'</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">'Args'</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span>\n                <span class=\"token string\">'/usr/lib/spark/bin/run-example'</span>\n            <span class=\"token punctuation\">]</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">]</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">setUp</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        configuration<span class=\"token punctuation\">.</span>load_test_config<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\"># Mock out the emr_client (moto has incorrect response)</span>\n        self<span class=\"token punctuation\">.</span>emr_client_mock <span class=\"token operator\">=</span> MagicMock<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>operator <span class=\"token operator\">=</span> EmrAddStepsOperator<span class=\"token punctuation\">(</span>\n            task_id<span class=\"token operator\">=</span><span class=\"token string\">'test_task'</span><span class=\"token punctuation\">,</span>\n            job_flow_id<span class=\"token operator\">=</span><span class=\"token string\">'j-8989898989'</span><span class=\"token punctuation\">,</span>\n            aws_conn_id<span class=\"token operator\">=</span><span class=\"token string\">'aws_default'</span><span class=\"token punctuation\">,</span>\n            steps<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>_config\n        <span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">test_init</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>assertEqual<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>operator<span class=\"token punctuation\">.</span>aws_conn_id<span class=\"token punctuation\">,</span> <span class=\"token string\">'aws_default'</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>assertEqual<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>operator<span class=\"token punctuation\">.</span>emr_conn_id<span class=\"token punctuation\">,</span> <span class=\"token string\">'emr_default'</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">test_render_template</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        ti <span class=\"token operator\">=</span> TaskInstance<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>operator<span class=\"token punctuation\">,</span> DEFAULT_DATE<span class=\"token punctuation\">)</span>\n        ti<span class=\"token punctuation\">.</span>render_templates<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n        expected_args <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">{</span>\n            <span class=\"token string\">'Name'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'test_step'</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">'ActionOnFailure'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'CONTINUE'</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">'HadoopJarStep'</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n                <span class=\"token string\">'Jar'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'command-runner.jar'</span><span class=\"token punctuation\">,</span>\n                <span class=\"token string\">'Args'</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span>\n                    <span class=\"token string\">'/usr/lib/spark/bin/run-example'</span>\n                <span class=\"token punctuation\">]</span>\n            <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">]</span>\n\n        self<span class=\"token punctuation\">.</span>assertListEqual<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>operator<span class=\"token punctuation\">.</span>steps<span class=\"token punctuation\">,</span> expected_args<span class=\"token punctuation\">)</span>\n\n\n<span class=\"token keyword\">if</span> __name__ <span class=\"token operator\">==</span> <span class=\"token string\">'__main__'</span><span class=\"token punctuation\">:</span>\n    unittest<span class=\"token punctuation\">.</span>main<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>unittest로 작성된 테스트 케이스는 API로 주고 받는 json을 직접 정의해줘야 하는 번거로움이 있다.\n테스트 케이스를 작성하고 난 다음 바로 PR을 추가하는 것보다 로컬 CI를 미리 돌려보는게 좋다.</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1MEOqsKocQTV8y5y_y2xrpIppkw2ndOvT\"></p>\n<p>TravisCI는 오픈소스인 경우 무료로 사용할 수 있으며, yml 파일에 미리 정의되어 있으니 참고하면 된다. 로컬에서 CI가 통과되고 나면 PR을 추가해도 좋다.\n작업이 길어지면서 커밋이 여러 개로 늘어나는 경우, <strong>commit을 squash</strong> 해주는 것이 좋다.\n(나중에 문제가 생겼을 때 쉽게 rebase 하기 위함)</p>\n<br>\n<h2 id=\"잡다한-정리\" style=\"position:relative;\"><a href=\"#%EC%9E%A1%EB%8B%A4%ED%95%9C-%EC%A0%95%EB%A6%AC\" aria-label=\"잡다한 정리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>잡다한 정리</h2>\n<ul>\n<li><a href=\"https://issues.apache.org/jira/browse/AIRFLOW-713\">[AIRFLOW-713] EmrCreateJobFlowOperator and EmrAddStepsOperator attributes are not jinjafied</a></li>\n<li><a href=\"https://issues.apache.org/jira/browse/AIRFLOW-950\">[AIRFLOW-950] Missing AWS integrations on documentation::integrations</a></li>\n<li><a href=\"https://issues.apache.org/jira/browse/AIRFLOW-1453\">[AIRFLOW-1453] Add 'steps' into template_fields in EmrAddSteps</a></li>\n<li><a href=\"https://issues.apache.org/jira/browse/AIRFLOW-1436\">[AIRFLOW-1436, AIRFLOW-1475] EmrJobFlowSensor consideres Cancelled step as Successful</a></li>\n</ul>\n<p>그 동안 5개 정도의 버그를 해결했고 수정했던 AWS EMR 관련 버그들은 1.9 - 10 버전에 모두 반영 되었다.\n이외에도 Airflow에는 여전히 자잘한 버그가 많이 남아있다.\n(Docker로 운영했을 때 로그가 이상하게 나타난다거나, SubDag Deadlock 문제 등)\n당시에 블로그를 열심히 했다면 운영 관련해서 글을 남겼을텐데 하는 아쉬움이 남아있다.</p>\n<p>어쨋든 Airflow를 적용하고 난 뒤, 편히 새벽에 잠들 수 있게 되었다.\n지금은 머신러닝 파이프라인 관련 도구가 많이 나왔지만, Airflow도 충분히 해당 영역을 커버할 수 있다.</p>\n<p>그리고 오픈소스에 대해 다시 한번 생각해보게 되었다.\n많은 사람들이 참여하는 오픈소스이다 보니 당연히 버그나 이슈가 생길 수 있고,\n문제가 생겼을 때 고쳐달라고 강요하거나 기다리는 것보다 스스로 수정해서 기여하는 것이 올바른 태도가 아닌가 싶다.</p>","excerpt":"Apache Airflow는 코드를 통해 워크플로우를 관리하고 모니터링 할 수 있도록 도와주는 플랫폼이다.\nAirflow…"}}}},{"node":{"title":"Kafka Connect로 S3에 데이터를 저장해보자","id":"c548511f-3e1d-5c2e-a96f-b0e297f133e2","slug":"kafka-connect","publishDate":"November 16, 2018","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"e81fb246-b516-57b8-bf98-7771d7cfb4fc","childMarkdownRemark":{"id":"26d0807b-21d9-5de5-864e-e44c27cc2883","timeToRead":4,"html":"<p>Kafka에는 정말 유용한 컴포넌트들이 존재합니다.\n오늘은 그 중 하나인 Kafka-Connect에 대해 알아보고,\nConfluent에서 제공하는 Kafka-Connect-S3를 활용하여\nS3로 데이터를 저장하는 방법에 대해 정리해보려고 합니다.</p>\n<br>\n<h2 id=\"kafka-connect\" style=\"position:relative;\"><a href=\"#kafka-connect\" aria-label=\"kafka connect permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Kafka Connect</h2>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=172qcC4a0mgYnkeZHlH7HH4lar1dAebA3\" alt=\"kafka-connect\"></p>\n<p>우리는 서버로부터 생성되는 데이터를 실시간으로 Kafka에 보내기도 하고,\nKafka Topic에 쌓여있는 데이터를 실시간으로 RDBMS, Object Storage와 같은 시스템에 보내기도 합니다.\nKafka Connect는 위의 그림과 같이 다양한 시스템과 Kafka 사이의 연결을 도와주는 역할을 하는 컴포넌트입니다.\nSource System에서 Kafka로 들어가는 Connector를 Source Connect라 부르고,\nKafka에서 Target System으로 보내는 Connector를 Sink Connect라 부릅니다.</p>\n<p>Kafka Connect는 JSON, Avro, Protobuf 등의 다양한 직렬화 포멧을 지원하며\nKafka Schema Registry와 연동시켜 공통된 스키마 지정을 할 수도 있습니다.</p>\n<p>사실 Fluentd와 ELK Stack에서 사용하는 Logstash 등 서로 다른 시스템 간의 브릿지 역할을 하는 프레임워크들은 다양하게 존재합니다.\n하지만 Kafka Connect가 갖는 강점은 Kafka와 긴밀히 연동되어 있다는 점 입니다.</p>\n<p>Kafka Connect를 사용하지 않고 데이터를 실시간으로 전달하기 위해서는 Producer, Consumer API를 사용해야 합니다.\n이 과정에서 이미 처리되거나 실패한 데이터를 추적한다거나, 데이터 분산처리, 작업을 배포하는 등의 작업을 수행해야만 합니다.</p>\n<p>Kafka Connect는 앞의 모든 작업을 수행할 뿐만 아니라 connector task를 클러스터 전체에 자동으로 배포합니다.\n또한, Connect Worker 중에 하나가 실패하거나 Network partition이 발생하더라도 실행하던 작업을 나머지 Worker들에게 자동으로 재조정합니다.\nOffset을 자동으로 관리, 유지하기 때문에 재시작하더라도 중단 시점부터 다시 시작할 수 있고 (Exactly Once Delivery),\nHigh performance Kafka library로 작성되어 빠르며 불필요한 polling 작업을 수행하지 않습니다.\n무엇보다 코드 한 줄 없이 사용하기 편하다는 것도 큰 강점입니다.\n혹시 Kafka를 이미 중앙 집중형 로그 저장소로 사용하고 있다면 Kafka Connect를 고려해볼만 하다고 생각합니다.</p>\n<br>\n<h2 id=\"kafka-connect-s3\" style=\"position:relative;\"><a href=\"#kafka-connect-s3\" aria-label=\"kafka connect s3 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Kafka-Connect-S3</h2>\n<p>이 글에서는 Confluent로 Kafka를 설치하지 않은 경우를 예시로 들겠습니다.\n이미 confluent-hub를 설치하셨거나 Confluent로 Kafka를 설치하셨다면 공식문서를 따라가시면 됩니다.</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1R80lOarW9k1RGv2kYAYxNz_-q6wUsm28\" alt=\"aws-kafka-s3\"></p>\n<p>데이터 인프라가 AWS 환경에 구축되어 있다면 S3를 Cold Storage로 많이 사용하게 됩니다.\n최대한 단순하게 그림을 그려보면 위의 그림과 같은 아키텍쳐가 나오게 됩니다.\n여기에서는 Kafka에서 S3로 실시간 데이터를 저장하기 위해 Kafka-Connect-S3를 사용하게 됩니다.</p>\n<p>먼저 confluent에서 kafka-connect-s3를 다운받아 plugins 경로에 추가합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token function\">wget</span> https://api.hub.confluent.io/api/plugins/confluentinc/kafka-connect-s3/versions/4.1.1/archive\n$ <span class=\"token function\">unzip</span> archive\n$ <span class=\"token function\">mkdir</span> -p plugins/kafka-connect-s3\n$ <span class=\"token function\">cp</span> confluentinc-kafka-connect-s3-4.1.1/lib/* plugins/kafka-connect-s3/</code></pre></div>\n<p>이제 kafka config 경로에 <code class=\"language-text\">connect.properties</code>라는 이름으로 설정 파일을 추가합니다.\n<code class=\"language-text\">bootstrap.servers</code>와 <code class=\"language-text\">plugin.path</code> 경로는 상황에 맞게 수정하시면 됩니다.\n추가로 kafka 클러스터를 private network로 연결하고 싶다면 9093 포트를 사용해주시면 됩니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\"># Kafka broker IP addresses to connect to\nbootstrap.servers=localhost:9092\n\n# Path to directory containing the connector jar and dependencies\nplugin.path=/home/ec2-user/kafka/plugins\n\n# Converters to use to convert keys and values\nkey.converter=org.apache.kafka.connect.storage.StringConverter\nvalue.converter=org.apache.kafka.connect.storage.StringConverter\n\n# The internal converters Kafka Connect uses for storing offset and configuration data\ninternal.key.converter=org.apache.kafka.connect.json.JsonConverter\ninternal.value.converter=org.apache.kafka.connect.json.JsonConverter\ninternal.key.converter.schemas.enable=false\ninternal.value.converter.schemas.enable=false\noffset.storage.file.filename=/tmp/connect.offsets</code></pre></div>\n<br>\n<p>기존 클러스터에 Authentication credentials, encryption이 설정되어 있다면,\nconnect.properties에 관련 설정을 추가해주셔야 합니다.</p>\n<p>다음 S3에 데이터가 저장될 Bucket을 생성하고, AWS Credentials를 설정합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ pip <span class=\"token function\">install</span> awscli\n$ aws configure</code></pre></div>\n<p>sink connector 관련 설정 파일을 <code class=\"language-text\">s3-sink.properties</code>라는 이름으로 config 경로에 추가합니다.\ntopics와 s3.bucket.name의 이름은 맞게 수정해주셔야 합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">name=s3-sink\nconnector.class=io.confluent.connect.s3.S3SinkConnector\ntasks.max=1\ntopics=my-topic-name\ns3.region=ap-northeast-2\ns3.bucket.name=my-bucket-name\ns3.compression.type=gzip\ns3.part.size=5242880\nflush.size=3\nstorage.class=io.confluent.connect.s3.storage.S3Storage\nformat.class=io.confluent.connect.s3.format.json.JsonFormat\nschema.generator.class=io.confluent.connect.storage.hive.schema.DefaultSchemaGenerator\npartitioner.class=io.confluent.connect.storage.partitioner.TimeBasedPartitioner\npartition.duration.ms=3600000\npath.format=YYYY-MM-dd\nlocale=KR\ntimezone=UTC\nschema.compatibility=NONE</code></pre></div>\n<br>\n<p>이제 Kafka 설치 경로로 이동하고 Kafka-Connect를 실행시킵니다.\n여기에서는 standalone mode로 실행시켰지만, 경우에 따라 cluster mode로 실행하거나\ndocker container로 실행시켜도 됩니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">./bin/connect-standalone.sh connect.properties s3-sink.properties</code></pre></div>\n<p>이제 지정한 S3 Bucket의 topic/my-topic-name/2018-11-16 경로에 가시면\n지정한 설정 값에 따라 파일이 저장되는 것을 확인하실 수 있습니다.</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1bepmpAHi7kwUnqvGOwyq0i8jSMIhhMeU\"></p>\n<p>이미 Yahoo의 kafka-manager를 사용하고 계신 분들은 consumers 메뉴로 가시면\ntopic 마다 lag도 모니터링할 수 있습니다.</p>\n<br>\n<h2 id=\"kafka-connect-s3-configuration\" style=\"position:relative;\"><a href=\"#kafka-connect-s3-configuration\" aria-label=\"kafka connect s3 configuration permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Kafka-Connect-S3 Configuration</h2>\n<p>데이터 인프라에 맞게 수정해야할 옵션은 아래와 같습니다.</p>\n<ul>\n<li><strong>s3.part.size</strong>: S3의 multi part upload 사이즈를 지정</li>\n<li><strong>flush.size</strong>: file commit 시 저장할 record의 수 (파일 사이즈와 연관)</li>\n<li><strong>partitioner.class</strong>: partition 기준을 지정 (TimeBasedPartitioner는 시간을 기준으로 파티셔닝)</li>\n</ul>\n<p>이외에도 Avro Format과 Schema Registry를 사용하신다면 <code class=\"language-text\">format.class</code>, <code class=\"language-text\">schema.generator.class</code>를 수정해야 합니다.\n더 자세한 내용은 <a href=\"https://docs.confluent.io/5.0.0/connect/kafka-connect-s3/configuration_options.html#s3-configuration-options\">공식문서</a>에서 확인하시면 됩니다.</p>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<p>사실 Kafka는 이미 대부분의 데이터 파이프라인에서 활용하고 있다는 것이 강점이라고 생각합니다.\nETL 과정이 다양하고 복잡할 수록 새로운 프레임워크가 추가되고 아키텍쳐가 복잡해지기 마련인데,\nKafka의 다양한 컴포넌트들을 잘 활용하면 아키텍쳐를 단순화시킬 수도 있습니다.</p>\n<ul>\n<li><a href=\"https://www.confluent.io/blog/kafka-connect-deep-dive-converters-serialization-explained\">https://www.confluent.io/blog/kafka-connect-deep-dive-converters-serialization-explained</a></li>\n<li><a href=\"https://docs.confluent.io/5.0.0/connect/kafka-connect-s3/index.html\">https://docs.confluent.io/5.0.0/connect/kafka-connect-s3/index.html</a></li>\n</ul>","excerpt":"Kafka에는 정말 유용한 컴포넌트들이 존재합니다.\n오늘은 그 중 하나인 Kafka-Connect에 대해 알아보고,\nConfluent…"}}}}]}},"pageContext":{"basePath":"","paginationPath":"","pageNumber":4,"humanPageNumber":5,"skip":25,"limit":6,"numberOfPages":16,"previousPagePath":"/4","nextPagePath":"/6"}}}