{"componentChunkName":"component---src-templates-posts-js","path":"/5","result":{"data":{"allContentfulPost":{"edges":[{"node":{"title":"Open Infra Days 2019 후기","id":"861cfb94-32ad-584a-b524-ff3f3f1f1883","slug":"openinfra","publishDate":"July 20, 2019","heroImage":{"id":"1faaada3-e12b-5548-8532-08b7c04dc7eb","title":"cover-personal","fluid":{"aspectRatio":1.694915254237288,"src":"//images.ctfassets.net/tushy4jlcik7/3ltdJp06NzCExAWz9OF8Ak/d8ca530c80e7c79a7bd7e4c396c0ae00/cover_personal.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/3ltdJp06NzCExAWz9OF8Ak/d8ca530c80e7c79a7bd7e4c396c0ae00/cover_personal.jpg?w=450&h=266&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/3ltdJp06NzCExAWz9OF8Ak/d8ca530c80e7c79a7bd7e4c396c0ae00/cover_personal.jpg?w=900&h=531&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/3ltdJp06NzCExAWz9OF8Ak/d8ca530c80e7c79a7bd7e4c396c0ae00/cover_personal.jpg?w=1400&h=826&q=50 1400w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/3ltdJp06NzCExAWz9OF8Ak/d8ca530c80e7c79a7bd7e4c396c0ae00/cover_personal.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/3ltdJp06NzCExAWz9OF8Ak/d8ca530c80e7c79a7bd7e4c396c0ae00/cover_personal.jpg?w=450&h=266&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/3ltdJp06NzCExAWz9OF8Ak/d8ca530c80e7c79a7bd7e4c396c0ae00/cover_personal.jpg?w=900&h=531&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/3ltdJp06NzCExAWz9OF8Ak/d8ca530c80e7c79a7bd7e4c396c0ae00/cover_personal.jpg?w=1400&h=826&q=50&fm=webp 1400w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/3ltdJp06NzCExAWz9OF8Ak/d8ca530c80e7c79a7bd7e4c396c0ae00/cover_personal.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"2cb0611e-2304-59aa-9e9e-33e66b24004a","childMarkdownRemark":{"id":"6d6b40fc-069f-5368-84b9-91a48d436fe4","timeToRead":4,"html":"<p>19일부터 진행했던 <a href=\"https://openinfradays.kr/#schedule\">Open Infra Days 2019</a>에 참여하면서\n배운 점들을 간단히 정리해보고자 한다. 해외의 CNCF 컨퍼런스처럼 사람들의 관심이 높아지고 있다는걸 느낄 수 있었다.\n그리고 돈 많은 후원사가 많아서 그런지 먹거리와 경품이 풍성했다. 하지만 내 번호는 한번도 당첨되지 않았다.</p>\n<p>내가 들었던 세션들은 주로 Kubernetes Scheduler, Controller, Kubernetes 기반의 ML Workflow에 대한 내용이었다.</p>\n<br>\n<h2 id=\"kubernetes-scheduler-deep-dive\" style=\"position:relative;\"><a href=\"#kubernetes-scheduler-deep-dive\" aria-label=\"kubernetes scheduler deep dive permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>kubernetes scheduler deep dive</h2>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1yIIsllw24U7pTsytGg38t1OapYsLo0UT\"></p>\n<ul>\n<li>kube default 스케줄러가 어떻게 동작하는지, custom 스케줄러를 어떻게 적용시킬 수 있는지에 대한 내용</li>\n<li>어려운 내용을 단계 별로 도식화하여 쉽게 설명해주셔서 좋았음</li>\n<li><a href=\"https://drive.google.com/file/d/1bqkUrXOEUvNZxf0iXghlPZ5DSJhRZ85t/view?fbclid=IwAR34JIei_4nzEgZfZkk8knwLQN-ldyRI5t1x-VQN9dVSq4b1CjAcZQ_LTpk\">발표자료 링크</a></li>\n</ul>\n<br>\n<h2 id=\"kubernetes에서-kafka와-flink를-사용하여-실시간-스트리밍-구현하기\" style=\"position:relative;\"><a href=\"#kubernetes%EC%97%90%EC%84%9C-kafka%EC%99%80-flink%EB%A5%BC-%EC%82%AC%EC%9A%A9%ED%95%98%EC%97%AC-%EC%8B%A4%EC%8B%9C%EA%B0%84-%EC%8A%A4%ED%8A%B8%EB%A6%AC%EB%B0%8D-%EA%B5%AC%ED%98%84%ED%95%98%EA%B8%B0\" aria-label=\"kubernetes에서 kafka와 flink를 사용하여 실시간 스트리밍 구현하기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Kubernetes에서 kafka와 flink를 사용하여 실시간 스트리밍 구현하기</h2>\n<ul>\n<li>주로 적용하면서 겪었던 문제들에 대한 내용을 공유</li>\n<li>kafka, flink의 state가 크게 증가하는 경우 이슈 발생 가능 (retension으로 정리)</li>\n<li><a href=\"https://www.slideshare.net/secret/xLiHQcuZoRWhZd?fbclid=IwAR34j570PitRo3lwwDpU1LvJ5CI5MmsJky3pYXE5PVRyY29J5XBmqXKQt3I\">발표자료 링크</a></li>\n<li><a href=\"https://github.com/protess/k3a-f3k-k8s\">핸즈온 링크</a></li>\n</ul>\n<br>\n<h2 id=\"line에서-kubernetes를-쓰는-방법-배운-것들\" style=\"position:relative;\"><a href=\"#line%EC%97%90%EC%84%9C-kubernetes%EB%A5%BC-%EC%93%B0%EB%8A%94-%EB%B0%A9%EB%B2%95-%EB%B0%B0%EC%9A%B4-%EA%B2%83%EB%93%A4\" aria-label=\"line에서 kubernetes를 쓰는 방법 배운 것들 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>LINE에서 Kubernetes를 쓰는 방법, 배운 것들</h2>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1RXRMOZYuyVSOvXGcZwFb9l5yTiW5I_aX\"></p>\n<ul>\n<li>사내 프라이빗 클라우드 Verda에 Kubernetes 기반의 서비스를 올리면서 겪은 이슈</li>\n<li>Kubernetes as a Service를 개발하면서 겪은 이슈</li>\n<li>Kube Custom Controller를 구현하는 방법</li>\n</ul>\n<br>\n<h2 id=\"카카오-t택시를-통해-살펴보는-카카오의-kubernetes-as-a-service\" style=\"position:relative;\"><a href=\"#%EC%B9%B4%EC%B9%B4%EC%98%A4-t%ED%83%9D%EC%8B%9C%EB%A5%BC-%ED%86%B5%ED%95%B4-%EC%82%B4%ED%8E%B4%EB%B3%B4%EB%8A%94-%EC%B9%B4%EC%B9%B4%EC%98%A4%EC%9D%98-kubernetes-as-a-service\" aria-label=\"카카오 t택시를 통해 살펴보는 카카오의 kubernetes as a service permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>카카오 T택시를 통해 살펴보는 카카오의 kubernetes as a service</h2>\n<ul>\n<li>사내 프라이빗 클라우드에 Kubernetes as a Service 개발하면서 이슈 공유</li>\n<li>기존 LDAP 통합 인증을 위해 kubectl login plugin 개발</li>\n<li>In-House Custom DNS Controller 개발 과정 (Operator SDK 사용)</li>\n<li>카카오 T 택시를 Kubernetes 기반으로 마이그레이션 했던 과정 공유</li>\n</ul>\n<br>\n<h2 id=\"kakao-automatic-k8s-monitoring\" style=\"position:relative;\"><a href=\"#kakao-automatic-k8s-monitoring\" aria-label=\"kakao automatic k8s monitoring permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Kakao automatic k8s monitoring</h2>\n<ul>\n<li>카카오의 대용량 K8S 클러스터 모니터링 자동화 서비스 개발 공유</li>\n<li>pod, ingress, api-server, system 지표를 자동으로 수집, 알림, 모니터링</li>\n<li>자동으로 리소스 정리, 플러그인을 Helm으로 배포</li>\n<li>EFK + prometheus 기반으로 개발</li>\n<li>OOM 이슈 해결을 위한 불필요 메트릭 제거 (카디널리티 분석)</li>\n</ul>\n<br>\n<h2 id=\"efficient-job-scheduling-for-ml-workloads-in-kube-env\" style=\"position:relative;\"><a href=\"#efficient-job-scheduling-for-ml-workloads-in-kube-env\" aria-label=\"efficient job scheduling for ml workloads in kube env permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Efficient Job scheduling for ML workloads in kube env</h2>\n<ul>\n<li>삼성전자의 ML Workflow 플랫폼 개발하면서 겪은 이슈 공유</li>\n<li>kube default scheduler가 ML Workflow에 안맞는 이유 설명</li>\n<li>Kube 기반의 분산 DL 학습에서 병목이 가능한 지점들 설명</li>\n<li>kube-batch로 스케줄링 최적화하는 과정 (PodGroup을 기준으로 스케줄링)</li>\n<li>기타 ML Job에서 발생할 수 있는 이슈 (GPU Staggler, Locality...)</li>\n</ul>\n<br>\n<h2 id=\"대규모-gpu-기반-k8s-cluster를-활용한-ml-training-이슈\" style=\"position:relative;\"><a href=\"#%EB%8C%80%EA%B7%9C%EB%AA%A8-gpu-%EA%B8%B0%EB%B0%98-k8s-cluster%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-ml-training-%EC%9D%B4%EC%8A%88\" aria-label=\"대규모 gpu 기반 k8s cluster를 활용한 ml training 이슈 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>대규모 GPU 기반 k8s cluster를 활용한 ml training 이슈</h2>\n<ul>\n<li>삼성전자의 Kube 기반 GPU 클러스터를 운영하면서 겪은 이슈 공유</li>\n<li>CPU-GPU, GPU-GPU 간의 연결 파이프라인 (NVIDIA/DALI)</li>\n<li>GPGPU 간 데이터 복제 오버헤드 문제, CNI 이슈</li>\n<li>Processing 단계에서 Feeding Bottleneck 문제</li>\n</ul>\n<br>\n<h2 id=\"kubernetes를-활용하여-효율적인-ml-pipeline-만들기\" style=\"position:relative;\"><a href=\"#kubernetes%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%98%EC%97%AC-%ED%9A%A8%EC%9C%A8%EC%A0%81%EC%9D%B8-ml-pipeline-%EB%A7%8C%EB%93%A4%EA%B8%B0\" aria-label=\"kubernetes를 활용하여 효율적인 ml pipeline 만들기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>kubernetes를 활용하여 효율적인 ml pipeline 만들기</h2>\n<ul>\n<li>AWS 에서 ML 플랫폼 개발, 설계 단계에 대해 공유</li>\n<li>학습 데이터를 전달하기 위해 EC2 NFS 서버를 PV로 사용 (S3FS로 했다가 수정)</li>\n<li>Inference 서버는 TensorRT를 활용 (Sync, Async)</li>\n<li><a href=\"https://on-demand.gputechconf.com/gtc/2019/presentation/_/s9264-how-to-build-efficient-ml-pipelines-from-the-startup-perspective.pdf\">발표자료 링크</a></li>\n</ul>\n<br>\n<h2 id=\"정리하면서\" style=\"position:relative;\"><a href=\"#%EC%A0%95%EB%A6%AC%ED%95%98%EB%A9%B4%EC%84%9C\" aria-label=\"정리하면서 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>정리하면서</h2>\n<p>발표를 통해 Scheduler, Controller에 대한 내용을 더 잘 이해할 수 있었고, 기술 세션 뿐만 아니라 Kubernetes에 대한 생각과\n향후 개발 방향을 공유하는 발표도 많았던 점이 좋았다.</p>\n<p>여러 세션에서 공유했던 이슈들을 다시 보니 Ingreess/Egress, DNS Controller, RBAC에 대한 내용이 특히 많았다.\n사내에 적용하면서 당연히 마주하게 될 부분일테니 네트워크, 인증 관련 부분은 다시 공부해보려한다.</p>\n<br>","excerpt":"19일부터 진행했던 Open Infra Days 2019에 참여하면서\n배운 점들을 간단히 정리해보고자 한다. 해외의 CNCF…"}}}},{"node":{"title":"분산 컨테이너 환경에서의 디자인 패턴 (3)","id":"ef37ff49-0dda-5d61-af33-46098b19d6ab","slug":"container-patterns3","publishDate":"April 06, 2019","heroImage":{"id":"1563c3af-a4e8-5db4-acb2-9bfd9fdb294d","title":"cover-develop","fluid":{"aspectRatio":1.5,"src":"//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=1800&h=1200&q=50 1800w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=1800&h=1200&q=50&fm=webp 1800w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"31e2a29c-b7e9-5f6f-8198-cba9bbc26501","childMarkdownRemark":{"id":"64d104f3-19d3-5384-b65c-d6a20e35d9ef","timeToRead":3,"html":"<p>구글 클라우드 팀이 Kubernetes와 같은 Container Orchestration 기술을 개발하면서 겪은\n분산 컨테이너 환경에서의 디자인 패턴에 대해 정리한 내용입니다.\n지난 글에 이어서 배치 작업에 관련된 디자인 패턴에 대한 내용입니다.</p>\n<ul>\n<li><a href=\"http://swalloow.github.io/container-patterns\">분산 컨테이너 환경에서의 디자인 패턴 1. Single-Node Patterns</a></li>\n<li><a href=\"http://swalloow.github.io/container-patterns2\">분산 컨테이너 환경에서의 디자인 패턴 2. Multi-Node Serving Patterns</a></li>\n<li><a href=\"http://swalloow.github.io/container-patterns3\">분산 컨테이너 환경에서의 디자인 패턴 3. Batch Computational Patterns</a></li>\n</ul>\n<br>\n<h2 id=\"batch-computational-patterns\" style=\"position:relative;\"><a href=\"#batch-computational-patterns\" aria-label=\"batch computational patterns permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Batch Computational Patterns</h2>\n<p>앞서 설명했던 long-running computation 패턴과 달리 이번에는 일시적으로 돌아가는 Batch Computational 패턴에 대한 내용이다.\n배치 프로세스는 사용자 로그 데이터의 수집, 데이터 분석 또는 미디어 파일의 변환 등에 자주 사용된다.\n일반적으로 대용량 데이터의 처리 속도를 높이기 위해 병렬 처리를 사용한다는 특징이 있다.\n이에 대해 가장 유명한 패턴은 MapReduce 패턴이며 이미 많이 사용하고 있다.</p>\n<br>\n<h2 id=\"work-queue-systems\" style=\"position:relative;\"><a href=\"#work-queue-systems\" aria-label=\"work queue systems permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Work Queue Systems</h2>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1lgFxyQ5EfZ5IXTf4SPxZ1liOLuSq6-Z5\"></p>\n<p>배치 프로세싱의 가장 간단한 형태가 바로 Work Queue System 이다.\nQueue 형태의 작업 대기열이 있고 이를 관리해주는 컨테이너가 Worker에 작업을 분배해주는 형태이다.\n일반적으로 작업 대기열에서 각 작업은 일정 시간 내에 수행되어야 하며 처리량에 따라 Worker는 Scale-out 할 수 있어야 한다.\n작업이 지속적으로 지연된다면 큐에 작업이 계속 쌓이게 되고 이는 장애로 이어질 수 있다.</p>\n<br>\n<h2 id=\"source-worker-container-interface\" style=\"position:relative;\"><a href=\"#source-worker-container-interface\" aria-label=\"source worker container interface permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Source, Worker Container Interface</h2>\n<ul>\n<li>Source 컨테이너와 Worker 컨테이너에 대한 인터페이스가 필요</li>\n<li>작업 대기열 스트림을 제공하는 컨테이너와 실제로 작업을 처리하는 컨테이너를 분리</li>\n<li>Source 컨테이너가 Ambassador 역할을 수행 (Storage, Network, Kafka/Redis Queue에 대한 통신을 맡음)</li>\n<li>현재 대기열에 쌓인 작업 리스트, 작업에 대한 구체적인 정보를 알려주는 Work Queue API 구현 필요</li>\n<li>작업에 대한 설정 정보는 Kubernetes의 ConfigMap과 ConfigMapVolume을 활용해서 구현</li>\n<li>Worker 컨테이너는 Rolling Update, Dynamic Scaling 기능이 필요</li>\n<li>Work Queue, Worker Process에 대한 모니터링이 필요</li>\n</ul>\n<br>\n<h2 id=\"event-driven-batch-processing\" style=\"position:relative;\"><a href=\"#event-driven-batch-processing\" aria-label=\"event driven batch processing permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Event-Driven Batch Processing</h2>\n<p>앞서 설명한 작업 대기열 처리는 하나의 입력을 하나의 출력으로 변환할 때 많이 사용한다.\n하지만 단일 작업 이상을 처리해야 한다거나 단일 입력에서 여러 출력을 생성해야 하는 경우도 있다.\n이러한 경우 여러 작업 대기열을 연결하는 이벤트 스트림 방식을 통해 작업을 수행한다.\n이전 단계의 작업이 완료되면 이벤트가 발생하고 이벤트를 통해 다음 단계의 대기열로 이동하는 형태이다.</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1fOMS2fS1bVaKHobo225bRPD-2z8Zaoz0\"></p>\n<p>스트림 처리에 대한 여러 패턴이 존재하지만 위 그림은 그 중 하나인 Sharder에 대한 내용이다.\nSharder는 작업 큐 2개를 두고 만일 두 개의 큐가 모두 healthy 하다면, id 기준으로 작업을 분배한다.\n만일 어느 하나가 unhealthy 하다면, 새로운 큐를 생성해서 다른 한쪽으로 작업을 분배한다.\n이를 통해 단일 큐를 사용하는 것보다 안정적이고 작업을 분산처리할 수 있다.</p>\n<p>이외에도 Publisher/Subscriber, Merger, Splitter 등의 패턴이 있다.\nSpark의 DAG와 같은 그림을 떠올린다면 어떤 내용인지 바로 이해할 수 있을 것이다.\n처리 시간이 비교적 짧은 이벤트 기반의 배치 프로세싱은 앞서 소개했던 FaaS 패턴으로 구현할 수도 있다.\nAWS의 Lambda, Stream, Kinesis Firehose를 떠올리면 된다.</p>\n<br>\n<h2 id=\"coordinated-batch-processing\" style=\"position:relative;\"><a href=\"#coordinated-batch-processing\" aria-label=\"coordinated batch processing permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Coordinated Batch Processing</h2>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1o4P4CyxS-V3ZMHQc5J0M7BwCdp937Q0H\"></p>\n<p>처음에는 단일 대기열로 처리했지만 더 복잡한 배치 작업을 처리하기 위해 대기열을 분할하고 연결했다.\n하지만 최종 단계에서는 결국 원하는 결과를 생성하기 위해 여러 출력을 하나로 합쳐야 한다.\n합치는 작업은 여러 개의 작업 큐가 모두 종료되고 난 이후에 수행되어야 한다.\n이와 관련된 패턴으로 Join과 Reduce가 있다.\nJoin과 달리 Reducer의 경우 parallel 하게 시작할 수 있다는 차이가 있다.\ncount, sum, histogram을 추출하는 작업이 이에 해당한다.</p>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<p>책을 마무리할 무렵 Kubernetes Korea Group 세미나에서 책 저자의 발표를 들을 수 있었다.\n다른 컨퍼런스에서 진행했던 발표들과 내용이 유사했고 Azure Kuberentes Service에 대한 홍보가 짙었지만\n클라우드 네이티브와 최근 개발 환경의 변화에 대한 생각을 들을 수 있는 시간이었다.</p>\n<p>그동안 개발할 때 정형화 된 패턴을 공부하지 않았음에도 비슷한 형태로 설계된 경우를 많이 볼 수 있었다.\n하지만 패턴을 한번 정리하고 나면 더 명확하게 이해되고 현재 상황에 맞는 패턴을 적용할 수 있게 되는 것 같다.\n마틴 파울러의 리팩토링 책도 그렇고 이번 책 또한 그런 부분을 느낄 수 있었다.</p>\n<ul>\n<li><a href=\"https://static.googleusercontent.com/media/research.google.com/ko//pubs/archive/45406.pdf\">GooglePaper - Design patterns for container-based distributed systems</a></li>\n<li>Designing Distributed Systems: Brendan Burns</li>\n</ul>\n<br>","excerpt":"구글 클라우드 팀이 Kubernetes와 같은 Container Orchestration…"}}}},{"node":{"title":"분산 컨테이너 환경에서의 디자인 패턴 (2)","id":"9999dc4c-6bbd-5c01-97a3-8010120e36bd","slug":"container-patterns2","publishDate":"March 23, 2019","heroImage":{"id":"1563c3af-a4e8-5db4-acb2-9bfd9fdb294d","title":"cover-develop","fluid":{"aspectRatio":1.5,"src":"//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=1800&h=1200&q=50 1800w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=1800&h=1200&q=50&fm=webp 1800w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"a21a14e1-d7ca-543f-9244-b8931920bc87","childMarkdownRemark":{"id":"d872115b-cde5-5bbe-9963-57721d8da6b1","timeToRead":5,"html":"<p>구글 클라우드 팀이 Kubernetes와 같은 Container Orchestration 기술을 개발하면서 겪은\n분산 컨테이너 환경에서의 디자인 패턴에 대해 정리한 내용입니다.\n지난 글에 이어서 멀티 노드에 관련된 디자인 패턴에 대한 내용입니다.</p>\n<ul>\n<li><a href=\"http://swalloow.github.io/container-patterns\">분산 컨테이너 환경에서의 디자인 패턴 1. Single-Node Patterns</a></li>\n<li><a href=\"http://swalloow.github.io/container-patterns2\">분산 컨테이너 환경에서의 디자인 패턴 2. Multi-Node Serving Patterns</a></li>\n<li><a href=\"http://swalloow.github.io/container-patterns3\">분산 컨테이너 환경에서의 디자인 패턴 3. Batch Computational Patterns</a></li>\n</ul>\n<br>\n<h2 id=\"multi-node-serving-pattern\" style=\"position:relative;\"><a href=\"#multi-node-serving-pattern\" aria-label=\"multi node serving pattern permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Multi-Node Serving Pattern</h2>\n<p>지난 번에 소개했던 싱글 노드 패턴들은 컨테이너 간에 커플링이 강하다는 특징이 있다.\n반면 이번에 소개할 멀티 노드 패턴들은 컨테이너 간에 커플링이 약하다.\n서로 다른 노드 간에 네트워크 호출을 통해 통신이 이루어지며\n<strong>Parallel, Coordinate via loose synchronization</strong>에 대한 이슈가 존재한다.\n특히 어플리케이션이 MSA 아키텍쳐로 구성된 경우, 컨테이너 간의 커플링이 낮다보니 스케일링에 이점이 있다.\n하지만 여러 노드에서 복잡한 구조로 동작하다보니 디버깅이 어려울 수 있다.</p>\n<br>\n<h2 id=\"replicated-load-balanced-services\" style=\"position:relative;\"><a href=\"#replicated-load-balanced-services\" aria-label=\"replicated load balanced services permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Replicated Load-Balanced Services</h2>\n<p>LoadBalancer가 트래픽을 관리하는 패턴이다. 가장 간단하면서 잘 알려져 있다.\nstateless한 서비스의 경우, LoadBalancer + Replica 형태로 쉽게 구성할 수 있다.\n처리해야 하는 요청에 따라 Scale-Up, Down을 쉽게 구성할 수 있어야 한다.</p>\n<ul>\n<li>LoadBalancing 패턴은 서비스의 network layer에 해당 (TCP/IP)</li>\n<li>Caching Layer는 web 서비스에서 유저의 요청을 메모리에 캐싱하는 프록시</li>\n<li>Caches Server에서 유저의 요청을 캐싱하고 있기 때문에 2번 요청을 보내더라도 실제 서버에는 1번만 요청</li>\n</ul>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1vzxSQ-qTm3g4rg1tGrmKfnH7GGYGGfpO\"></p>\n<p>가장 간단하게 웹 서버와 캐시 서버를 구성하는 방법은 위 그림과 같이 앞서 배웠던 Sidecar를 활용하는 방법.\n이 방법은 간단하게 구현할 수 있지만 내 웹 서버와 동일한 레벨에 있기 때문에 각자 스케일링하기 어렵다.\nKubernetes의 Deployments와 Service로 동일한 환경을 쉽게 구성해볼 수 있다.</p>\n<br>\n<h2 id=\"shared-services\" style=\"position:relative;\"><a href=\"#shared-services\" aria-label=\"shared services permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Shared Services</h2>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1vzG4BnqfHFQ4IRhwmS9z7ZwsI4AZTtKZ\"></p>\n<p>위의 Load-Balanced Services가 stateless 하다면 shared service는 stateful.\nReplicated Service에서는 각 Pod에서 모두 동일한 요청을 처리하고,\nShared Service에서는 root가 routing 해주면서 서로 다른 요청을 처리한다.</p>\n<ul>\n<li>앞의 글에서 ambassador 패턴을 활용해 shared cache를 만드는 예제의 응용편</li>\n<li>요구사항: Cache Proxy에서 적절한 Cache Shard로 라우팅해주어야 한다</li>\n<li>cache hit, miss에 대한 처리 결과를 노드 사이에서 통신</li>\n<li>sharding은 single node에 들어갈 수 없을 정도의 데이터 사이즈가 있는 경우에 장점</li>\n<li>네트워크 latency와 데이터 등을 파악해서 적절한 아키텍쳐를 구성하는 것이 중요</li>\n</ul>\n<br>\n<h2 id=\"scatter-getter\" style=\"position:relative;\"><a href=\"#scatter-getter\" aria-label=\"scatter getter permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Scatter, Getter</h2>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1WpL_5H5auqYY6jmcvTnismPrdiLJL5CY\"></p>\n<p>scatter, getter 패턴은 스케일링, 분산처리에 유용한 패턴 중 하나이다.\n위에 언급했던 패턴들처럼 트리 구조로 되어 있고,\nroot 서버가 요청을 분산시키거나 여러 서버로부터 받아오는 구조.\n이 패턴은 분산처리에서 embarassingly parallel 문제를 해결하는 것과 동일하다.</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1XrL4vaLHARyNarjIhLWthC4dhCNpOMl7\"></p>\n<p><strong>Hands On: Distributed Document Search</strong></p>\n<p>모든 문서 파일로부터 cat, dog 단어가 모두 포함되어 있는지 검색하는 문제를 풀어야 한다고 가정해보자.\n왼쪽 그림과 같이 각 노드로부터 서로 다른 단어를 검색하고 결과를 내는 방법이 있다.\n하지만 document 하나의 사이즈가 아주 크다면? 하나의 노드에서 처리는 불가능하다.\n이 경우, 단어 기준이 아니라 document 기준으로 분산처리해야 한다. (MapReduce의 WordCount 예제와 동일)</p>\n<p>이 때 적절한 노드 개수를 선정하는 것이 중요하다. (컴퓨팅과 비용 사이의 문제)\n노드가 많아질수록 요청을 분산하고 수집하는데 오버헤드가 발생할 수 있다.\n위 경우 처리가 가장 오래걸리는 노드의 시간이 전체 처리 시간을 결정할 것이다. (straggler problem)\n이를 해결하기 위해 Erasure Coding을 통해 연산을 추정하는 방법도 있다.</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1DPFcq_ggveaUcw_kXdRlN4Ic-DqLMnud\"></p>\n<p><strong>Scaling Scatter/Gather for Reliability and Scale</strong></p>\n<p>항상 실패에 대한 대비가 되어 있어야 한다. (Fault Tolerance)\n앞서 설명한대로 단순히 샤드의 수를 늘리는 것은 적절하지 못한 방법이다.\n각 Shard가 Replica로 구성되어 있기 때문에 동시에 업그레이드도 가능할 수 있어야 한다.</p>\n<br>\n<h2 id=\"functions-and-event-driven-processing\" style=\"position:relative;\"><a href=\"#functions-and-event-driven-processing\" aria-label=\"functions and event driven processing permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Functions and Event-Driven Processing</h2>\n<p>방금 전까지는 long-running computation에 대한 패턴에 대해 소개했다면,\n이번에는 FaaS 기반의 일시적인 서비스에 대한 패턴에 대한 내용이다. (serverless computing)\n서버리스는 좋은 패턴이자 도구이지만 모든 어플리케이션에 무조건 적용하기 보다는\n장점과 단점을 잘 이해하고 적절한 경우에 사용하는 것이 좋다.</p>\n<ul>\n<li>함수 단위로 모듈화하고 바로 클라우드를 통해 서비스할 수 있다는 장점</li>\n<li>각 서비스가 완전히 독립적이어야 하고 상태를 스토리지에 저장해야 하기 때문에 운영이 복잡해질 수 있음</li>\n<li>함수 사이에 루프가 생기는 경우, 심각한 문제가 발생 (모니터링 필수적임)</li>\n<li>Event-Driven의 우선순위가 낮은 일시적인 작업을 처리할 때 유용함</li>\n<li>인메모리 수준의 빠른 처리가 필요한 경우, <strong>함수가 로드되는 오버헤드</strong>를 고려하면 부적합 할 수 있음</li>\n<li>가끔씩 수행되어야 하는 경우, 비용 측면에서 일반 인스턴스보다 저렴</li>\n<li>FaaS는 아주 간단한 Code Snippet으로 쉽게 구현할 수 있음</li>\n</ul>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1xgMYmBFb3538gT5gOv3XPAPt72qt9mIV\"></p>\n<p><strong>FaaS Decorator Pattern: Request or Response Transformation</strong></p>\n<p>Input이 들어왔을 때, transform 해서 output을 내는 패턴이다.\n이번에는 Kubernetes 기반의 serverless 플랫폼인 kubeless로 간단한 예제를 진행해보았다.\n설치와 실행은 아래와 같이 진행하면 된다.\n예제 코드와 이에 대한 자세한 설명은 <a href=\"https://github.com/Swalloow/KubeStudy/tree/master/faas\">https://github.com/Swalloow/KubeStudy/tree/master/faas</a> 에서 확인.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token comment\"># install kubeless, cli</span>\nkubectl create ns kubeless\nkubectl create -f https://github.com/kubeless/kubeless/releases/download/v1.0.3/kubeless-v1.0.3.yaml\n\n<span class=\"token function\">curl</span> -OL https://github.com/kubeless/kubeless/releases/download/v1.0.3/kubeless_darwin-amd64.zip\n<span class=\"token function\">unzip</span> kubeless_darwin-amd64.zip\n<span class=\"token function\">sudo</span> <span class=\"token function\">mv</span> bundles/kubeless_darwin-amd64/kubeless /usr/local/bin/\n\n<span class=\"token comment\"># install kubeless UI</span>\nkubectl create -f https://raw.githubusercontent.com/kubeless/kubeless-ui/master/k8s.yaml\nkubectl get svc ui -n kubeless\nkubectl port-forward svc/ui -n kubeless <span class=\"token number\">3000</span>:3000</code></pre></div>\n<p><strong>Hands On: Implementing Two-Factor Authentication</strong></p>\n<ul>\n<li>Random Code Generator를 비동기로 생성</li>\n<li>로그인 서비스에 코드를 등록</li>\n<li>사용자의 전화로 문자메세지를 전송</li>\n</ul>\n<p><strong>Hands On: Implementing a Pipeline for New-User Signup</strong></p>\n<ul>\n<li>이벤트 기반의 파이프라인 예제</li>\n<li>MSA는 long-running 인 반면, Event Pipeline은 async, short-running</li>\n<li>빌드, 배포 CI 도구가 좋은 예제 (각 단계의 이벤트가 발생하면 함수 실행)</li>\n<li>유저가 신규 가입하면, welcome 이메일 전송하는 예제</li>\n<li>A list of required actions (e.g., sending a welcome mail)</li>\n<li>A list of optional actions (e.g., subscribing the user to a mailing list)</li>\n</ul>\n<br>\n<h2 id=\"9-ownership-election\" style=\"position:relative;\"><a href=\"#9-ownership-election\" aria-label=\"9 ownership election permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>9. Ownership Election</h2>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1PN0T-kHQRzxm41D8JLKl9p3Z9rvlsYax\"></p>\n<p>분산 시스템에서는 Ownership을 결정하는 것이 중요하다. 리더가 여러 책임을 가지고 있다.\n마스터 노드에 장애가 발생하더라도 Election에 의해 새로운 마스터 노드를 선정할 수 있어야 한다.</p>\n<p><strong>Determining If You Even Need Master Election</strong></p>\n<ul>\n<li>노드가 안정적으로 영원히 돌아갈리가 없기 때문에 필요</li>\n<li>singleton container로 구현하는 방법도 있음</li>\n<li>컨테이너에 장애가 발생해도 재시작 가능</li>\n<li>health check를 구현했다면, hang에 걸려도 재시작</li>\n<li>노드에 장애가 발생하면 다른 노드로 이전</li>\n<li>하지만 이 방법은 uptime이 발생할 수 밖에 없음 (2초~5분 간 서비스 정지)</li>\n<li>노력하면 uptime을 일부 줄일 수 있겠지만 그 만큼 복잡성이 증가</li>\n</ul>\n<p><strong>The Basics of Master Election</strong></p>\n<p>가장 잘 알려진 Leader Election 알고리즘으로 Paxos와 Raft가 있다.\n자세한 내용은 이전에 작성한 <a href=\"http://swalloow.github.io/raft-consensus\">Raft Consensus</a> 글을 참고.</p>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<ul>\n<li><a href=\"https://static.googleusercontent.com/media/research.google.com/ko//pubs/archive/45406.pdf\">GooglePaper - Design patterns for container-based distributed systems</a></li>\n<li>Designing Distributed Systems: Brendan Burns</li>\n</ul>\n<br>","excerpt":"구글 클라우드 팀이 Kubernetes와 같은 Container Orchestration…"}}}},{"node":{"title":"Amazon EKS에 Kubeflow 구축하기","id":"c41958b4-0f03-5549-94c4-2e19fa5fcc89","slug":"eks-kubeflow","publishDate":"March 10, 2019","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"46a42260-b4aa-51d5-aa64-b7247af33731","childMarkdownRemark":{"id":"fef60629-38e4-5c67-8b2f-f654ddcbf758","timeToRead":3,"html":"<p>AWS EKS는 Fully managed K8S 서비스 입니다. 이번 글에서는 EKS 환경에 Kubeflow를 구축하는 방법에 대해 정리해보겠습니다.</p>\n<ul>\n<li><a href=\"http://swalloow.github.io/why-kubeflow\">Why kubeflow in your Infrastructure</a></li>\n<li><a href=\"http://swalloow.github.io/eks-kubeflow\">Amazon EKS에 Kubeflow 구축하기</a></li>\n<li>Kubeflow의 ModelDB</li>\n<li>Kubeflow의 Hyper parameter Tuning (Katib)</li>\n</ul>\n<br>\n<h2 id=\"기본-환경-설치\" style=\"position:relative;\"><a href=\"#%EA%B8%B0%EB%B3%B8-%ED%99%98%EA%B2%BD-%EC%84%A4%EC%B9%98\" aria-label=\"기본 환경 설치 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>기본 환경 설치</h2>\n<p>Kubeflow를 설치하기 이전에 AWS CLI, Docker가 설치되어 있어야 합니다.\nEKS에서는 최근에 GPU 인스턴스인 P2, P3에 대한 지원을 제공하고 있습니다.\n이를 사용하기 위해 AWS Marketplace에서 <a href=\"https://aws.amazon.com/marketplace/pp/B07GRHFXGM\">EKS-optimized AMI with GPU Support</a>를 구독해주어야 합니다.</p>\n<p>EKS는 Web UI 또는 eksctl이라는 cli 도구를 사용해서 클러스터를 구성할 수 있습니다.\neksctl은 kubectl이나 kops와 유사한 명령어를 제공합니다.\n자세한 내용은 <a href=\"https://aws.amazon.com/ko/blogs/opensource/eksctl-eks-cluster-one-command/\">https://aws.amazon.com/ko/blogs/opensource/eksctl-eks-cluster-one-command/</a> 에서 참고하시면 됩니다.</p>\n<br>\n<h2 id=\"eks-클러스터-생성\" style=\"position:relative;\"><a href=\"#eks-%ED%81%B4%EB%9F%AC%EC%8A%A4%ED%84%B0-%EC%83%9D%EC%84%B1\" aria-label=\"eks 클러스터 생성 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>EKS 클러스터 생성</h2>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token comment\"># install eksctl</span>\n$ brew tap weaveworks/tap\n$ brew <span class=\"token function\">install</span> weaveworks/tap/eksctl\n\n<span class=\"token comment\"># create cluster</span>\n$ eksctl create cluster eks-cpu <span class=\"token punctuation\">\\</span>\n--node-type<span class=\"token operator\">=</span>c4.xlarge <span class=\"token punctuation\">\\</span>\n--timeout<span class=\"token operator\">=</span>40m <span class=\"token punctuation\">\\</span>\n--nodes<span class=\"token operator\">=</span><span class=\"token number\">2</span> <span class=\"token punctuation\">\\</span>\n--region<span class=\"token operator\">=</span>ap-northeast-2\n\n<span class=\"token comment\"># NVIDIA driver plugin</span>\nkubectl apply -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v1.11/nvidia-device-plugin.yml\nkubectl get nodes <span class=\"token string\">\"-o=custom-columns=NAME:.metadata.name,MEMORY:.status.allocatable.memory,CPU:.status.allocatable.cpu,GPU:.status.allocatable.nvidia\\.com/gpu\"</span></code></pre></div>\n<ul>\n<li>먼저 Homebrew로 <code class=\"language-text\">eksctl</code>을 설치합니다. 이후 아래의 명령어를 통해 c4 인스턴스 기반의 EKS 클러스터를 생성하고 Memory, CPU, GPU 정보를 확인해줍니다.</li>\n<li>GPU 인스턴스로 클러스터를 생성하고 싶다면 생성하기 이전에 EC2 Limit 페이지에서 p2 또는 p3 인스턴스의 limit을 확인해야 합니다. 0으로 되어있다면 <code class=\"language-text\">Request limit Increase</code>가 필요합니다.</li>\n<li>GPU-enabled worker를 가지는 EKS 클러스터를 생성한다면 NVIDIA driver plugin을 활성화시키는 과정이 필요합니다.</li>\n<li>Create cluster에서 <code class=\"language-text\">AccessDenied</code> 오류가 발생하는 경우, 사용할 IAM 유저를 생성하고 EKS 관련 permission과 <code class=\"language-text\">AWSCloudFormationReadOnlyAccess</code>를 추가해주어야 합니다. EKS는 현재 기준 1.11 버전을 default로 사용하고 있습니다.</li>\n</ul>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1y10f8hW0KFZGSn7WLFne_aqUV4YjPQqJ\" alt=\"eks\"></p>\n<p>EKS 메뉴에 가보시면 EC2 인스턴스, 네트워크 설정이 완료된 것을 확인하실 수 있습니다.\nAWS CloudFormation에서 cluster와 node-group에 대한 stack이 생성됩니다.</p>\n<p>K8S 대시보드는 <a href=\"https://docs.aws.amazon.com/ko_kr/eks/latest/userguide/dashboard-tutorial.html\">AWS EKS 공식 문서</a>를 참고하여 띄울 수 있습니다.</p>\n<br>\n<h2 id=\"ksonnet을-이용한-kubeflow-설치\" style=\"position:relative;\"><a href=\"#ksonnet%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-kubeflow-%EC%84%A4%EC%B9%98\" aria-label=\"ksonnet을 이용한 kubeflow 설치 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>ksonnet을 이용한 KubeFlow 설치</h2>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token comment\"># install ksonnet</span>\n$ brew <span class=\"token function\">install</span> ksonnet/tap/ks\n$ ks version\nksonnet version: <span class=\"token number\">0.13</span>.1\njsonnet version: v0.11.2\nclient-go version: kubernetes-1.10.4\n\n<span class=\"token comment\"># install kubeflow</span>\n$ <span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">KUBEFLOW_TAG</span><span class=\"token operator\">=</span>v0.4.1\n$ <span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">KUBEFLOW_SRC</span><span class=\"token operator\">=</span>/tmp/kubeflow_src\n$ <span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">KFAPP</span><span class=\"token operator\">=</span>eks-kubeflow\n\n$ <span class=\"token function\">mkdir</span> <span class=\"token variable\">${KUBEFLOW_SRC}</span> <span class=\"token operator\">&amp;&amp;</span> <span class=\"token builtin class-name\">cd</span> <span class=\"token variable\">${KUBEFLOW_SRC}</span>\n$ <span class=\"token function\">curl</span> https://raw.githubusercontent.com/kubeflow/kubeflow/<span class=\"token variable\">${KUBEFLOW_TAG}</span>/scripts/download.sh <span class=\"token operator\">|</span> <span class=\"token function\">bash</span>\n\n$ <span class=\"token function\">sh</span> <span class=\"token variable\">${KUBEFLOW_SRC}</span>/scripts/kfctl.sh init <span class=\"token variable\">${KFAPP}</span> --platform none\n$ <span class=\"token builtin class-name\">cd</span> <span class=\"token variable\">${KFAPP}</span>\n$ <span class=\"token function\">sh</span> <span class=\"token variable\">${KUBEFLOW_SRC}</span>/scripts/kfctl.sh generate k8s\n$ <span class=\"token function\">sh</span> <span class=\"token variable\">${KUBEFLOW_SRC}</span>/scripts/kfctl.sh apply k8s</code></pre></div>\n<p>ksonnet으로 KubeFlow를 설치하기 이전에 먼저 Homebrew로 ksonnet을 설치합니다.</p>\n<br>\n<h2 id=\"kubeflow\" style=\"position:relative;\"><a href=\"#kubeflow\" aria-label=\"kubeflow permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>KubeFlow</h2>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1W9rnEB-Bn5IZjLOymYXNxMPNclyY4eJn\" alt=\"kubeflow-pods\">\n<img src=\"http://drive.google.com/uc?export=view&#x26;id=15IWqbbib_vhB_k4FlUK_K39ERUbkVHr0\" alt=\"kubeflow-pvc\"></p>\n<p>KubeFlow를 설치하고 나면 Pods, Deployment, Service, ConfigMap 등 모든 컴포넌트들이 자동으로 배포됩니다. default로 PVC는 EBS gp2 볼륨이 설정된 것을 확인하실 수 있습니다.</p>\n<p>EKS에서는 IAM 기반의 RBAC 인증을 사용합니다.\n아래의 명령어를 통해 EKS의 JupyterHub를 로컬의 8080 포트로 포워딩해서 접속하실 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ kubectl port-forward svc/jupyter-lb -n kubeflow <span class=\"token number\">8080</span>:80</code></pre></div>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1XNiADQX6faiejXKz3OlpwYMhqZQ6xPoz\" alt=\"kubeflow-jupyterhub\"></p>\n<p>위와 같이 설치하고 난 이후에 KubeFlow 문서의 git summerization 튜토리얼을 그대로 따라하실 수 있습니다. 모든 컴포넌트가 자동으로 배포되다 보니 생략하고 넘어가는 경우가 많은데 production 환경에서 사용하려면 각 설정 YAML 파일을 내 환경에 맞도록 수정할 필요가 있습니다. 삭제는 아래의 명령어를 통해 실행시키면 됩니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token builtin class-name\">cd</span> <span class=\"token variable\">${KUBEFLOW_SRC}</span>/<span class=\"token variable\">${KFAPP}</span>\n$ <span class=\"token function\">sh</span> <span class=\"token variable\">${KUBEFLOW_SRC}</span>/scripts/kfctl.sh delete k8s</code></pre></div>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<ul>\n<li><a href=\"https://aws.amazon.com/ko/blogs/opensource/kubeflow-amazon-eks/\">https://aws.amazon.com/ko/blogs/opensource/kubeflow-amazon-eks/</a></li>\n<li><a href=\"https://github.com/aws-samples/machine-learning-using-k8s/blob/master/kubeflow.md\">https://github.com/aws-samples/machine-learning-using-k8s/blob/master/kubeflow.md</a></li>\n<li><a href=\"https://eksctl.io/\">https://eksctl.io/</a></li>\n</ul>\n<br>","excerpt":"AWS EKS는 Fully managed K8S 서비스 입니다. 이번 글에서는 EKS 환경에 Kubeflow…"}}}},{"node":{"title":"Why Kubeflow in your Infrastructure?","id":"b8091786-4329-5d05-802b-b6b069b38702","slug":"why-kubeflow","publishDate":"March 09, 2019","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"9ea4a340-b124-57db-977d-2a8c3a1a9cdf","childMarkdownRemark":{"id":"a056a78c-da2c-502e-8b6d-1656d874de89","timeToRead":2,"html":"<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1JO_ek8Dyr-i5-uvjd4NpzMKBqL6PICDV\" alt=\"Hidden Technical Dept in Machine Learning Systems\"></p>\n<p>실제 ML을 서비스에 적용시키는 일은 위 그림에 나타난 바와 같이 ML 모델링 보다 이외의 작업들이 많이 필요합니다. 특히 서비스의 여러 기능에 ML을 적용시키려 하는 경우, 이러한 파이프라인이 복잡해지고 유지보수가 힘든 방향으로 가는 경우가 많습니다. 이러한 이유로 규모있는 IT 서비스 회사들은 공통의 ML 플랫폼을 구축하곤 합니다.</p>\n<p>앞으로 소개하려는 Kubeflow는 Kubernetes를 기반으로 하는 오픈소스 ML Toolkit 입니다. 아직 버전이 낮아 production 환경에서 사용하는 곳이 많지 않지만 미리 알아두면 좋을 것 같아 컴포넌트들을 하나씩 분석해보려 합니다.</p>\n<ul>\n<li><a href=\"http://swalloow.github.io/why-kubeflow\">Why kubeflow in your Infrastructure</a></li>\n<li><a href=\"http://swalloow.github.io/eks-kubeflow\">Amazon EKS에 Kubeflow 구축하기</a></li>\n<li>Kubeflow의 ModelDB</li>\n<li>Kubeflow의 Hyper parameter Tuning (Katib)</li>\n</ul>\n<br>\n<h2 id=\"why-kubeflow\" style=\"position:relative;\"><a href=\"#why-kubeflow\" aria-label=\"why kubeflow permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Why Kubeflow?</h2>\n<p>이미 기존의 인프라를 기반으로 자동화된 ML Workflow가 구축되어 있다면, 굳이 Kubeflow로 옮길 필요는 없습니다. 하지만 아래와 같은 상황을 가진 팀이라면 Kubeflow는 좋은 선택지가 될 수 있습니다.</p>\n<ul>\n<li>이미 Kubernetes 기반의 인프라를 사용하고 있으며, ML 인프라를 구축하려는 경우</li>\n<li>서비스를 On-premise, Multi-cloud 환경에 배포해야 하는 경우</li>\n<li>Scalable ML이 필수적이며, 기존의 여러 ML 서비스를 쉽게 배포하고 리소스 관리 비용을 줄이려는 경우</li>\n<li>Research Engineer, Data Scientist 를 위한 인프라 관리의 복잡성을 최소화하고 일관된 인터페이스를 제공하여 몇 번의 클릭만으로 설정을 쉽게 하고 싶은 경우</li>\n</ul>\n<br>\n<h2 id=\"consistency-in-infrastructure\" style=\"position:relative;\"><a href=\"#consistency-in-infrastructure\" aria-label=\"consistency in infrastructure permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Consistency in Infrastructure</h2>\n<p>Kubeflow는 Kubernetes 기반의 인프라가 가지는 장점을 그대로 가지고 있습니다. 각 서비스에 대한 Monitoring, Health Check, Replication 등의 기본 요구사항을 갖추고 있으며 쉬운 배포 환경을 제공합니다. 이외에도 아래와 같은 usecase에서 활용될 수 있습니다.</p>\n<ul>\n<li>Research Engineer들이 인프라가 아닌 모델링에만 집중할 수 있는 환경을 제공할 수 있습니다. 모두가 Docker 기반의 추상화된 환경에서 연구를 할 수 있으며, 동일한 데이터, 연구 결과를 공유할 수 있습니다. 가상화된 GPU 환경에서 모델을 분산 학습시킬 수 있으며, TensorFlow, PyTorch, MXNet 등 다양한 프레임워크 환경을 지원할 수 있습니다.</li>\n<li>Kubeflow는 end-to-end를 제공하기 때문에 ML 프로젝트를 production에 반영하는 과정이 단순해집니다. 지속적인 데이터 파이프라인을 구축하여 <strong>argo</strong>를 통해 모델을 업데이트 하고, <strong>seldon</strong>을 통해 production 환경을 테스트해 볼 수 있습니다.</li>\n<li><strong>Katib</strong>을 통해 Hyper parameter tuning 과정을 쉽게 자동화 할 수 있습니다. <strong>Katib</strong>에서 제공하는 인터페이스를 통해 여러 어플리케이션으로 확장시킬 수 있으며, 튜닝 결과를 지속적으로 기록하고 공유할 수 있습니다.</li>\n</ul>\n<br>\n<h2 id=\"resource-utilization-by-the-training--serving-modules\" style=\"position:relative;\"><a href=\"#resource-utilization-by-the-training--serving-modules\" aria-label=\"resource utilization by the training  serving modules permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Resource utilization by the Training / Serving modules</h2>\n<p>테스트 환경을 쉽게 구축할 수 있으며, 클라우드 비용을 최적화시킬 수 있습니다. K8S 클러스터는 동일한 인스턴스에 여러 Pod을 실행시킬 수 있습니다. 따라서, 사용하는 리소스를 팀 또는 프로젝트 단위로 namespace를 분리시켜 리소스 사용량을 모니터링 할 수 있습니다.</p>\n<p>일반적인 클라우드 인프라 환경을 서비스 라이프사이클과 연계되어 있지 않기 때문에 training job이 끝난 이후에도 인스턴스가 켜져 있기 때문에 그에 대한 비용을 지불해야 합니다. 하지만 Kubeflow를 사용하는 경우, 사용량에 따라 클러스터를 auto scaling 한다거나 spot instance로 training job을 실행시킬 수 있습니다.</p>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<ul>\n<li><a href=\"https://medium.com/kubeflow/why-kubeflow-in-your-infrastructure-56b8fabf1f3e\">https://medium.com/kubeflow/why-kubeflow-in-your-infrastructure-56b8fabf1f3e</a></li>\n</ul>","excerpt":"Hidden Technical Dept in Machine Learning Systems 실제 ML…"}}}},{"node":{"title":"KOPS로 AWS에 Kubernetes 클러스터 구축하기","id":"22782f34-788f-5197-a6f7-35b71f4da0c9","slug":"aws-kops","publishDate":"February 10, 2019","heroImage":{"id":"f36c235f-3e3e-517d-bd80-697bc6183072","title":"cover-devops","fluid":{"aspectRatio":1.5,"src":"//images.ctfassets.net/tushy4jlcik7/7KaSTt3mdmrYq2ZK1RiJku/dafd981ff3686217ac151b562e8b1412/cover_devops.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7KaSTt3mdmrYq2ZK1RiJku/dafd981ff3686217ac151b562e8b1412/cover_devops.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7KaSTt3mdmrYq2ZK1RiJku/dafd981ff3686217ac151b562e8b1412/cover_devops.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7KaSTt3mdmrYq2ZK1RiJku/dafd981ff3686217ac151b562e8b1412/cover_devops.jpg?w=1080&h=720&q=50 1080w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7KaSTt3mdmrYq2ZK1RiJku/dafd981ff3686217ac151b562e8b1412/cover_devops.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7KaSTt3mdmrYq2ZK1RiJku/dafd981ff3686217ac151b562e8b1412/cover_devops.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7KaSTt3mdmrYq2ZK1RiJku/dafd981ff3686217ac151b562e8b1412/cover_devops.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7KaSTt3mdmrYq2ZK1RiJku/dafd981ff3686217ac151b562e8b1412/cover_devops.jpg?w=1080&h=720&q=50&fm=webp 1080w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7KaSTt3mdmrYq2ZK1RiJku/dafd981ff3686217ac151b562e8b1412/cover_devops.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"39b3b781-063c-5008-81ca-6b2620548d99","childMarkdownRemark":{"id":"861450a3-c3ca-512b-9d61-4eb1dfeea051","timeToRead":4,"html":"<p>Kubernetes 클러스터를 구성하는 방법은 여러 가지가 있습니다.\n그 중에서 kubeadam은 온프레미스 환경에서 많이 사용하고 kops는 클라우드 환경에서 많이 사용하고 있습니다. 이번 글에서는 kops로 AWS EC2에 Kubernetes 클러스터 구축하는 방법에 대해 정리해보겠습니다.</p>\n<br>\n<h2 id=\"kops-kubectl-awscli-설치-linux\" style=\"position:relative;\"><a href=\"#kops-kubectl-awscli-%EC%84%A4%EC%B9%98-linux\" aria-label=\"kops kubectl awscli 설치 linux permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>kops, kubectl, awscli 설치 (Linux)</h2>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token comment\"># kops 설치</span>\n<span class=\"token function\">wget</span> -O kops https://github.com/kubernetes/kops/releases/download/<span class=\"token variable\"><span class=\"token variable\">$(</span><span class=\"token function\">curl</span> -s https://api.github.com/repos/kubernetes/kops/releases/latest <span class=\"token operator\">|</span> <span class=\"token function\">grep</span> tag_name <span class=\"token operator\">|</span> <span class=\"token function\">cut</span> -d <span class=\"token string\">'\"'</span> -f <span class=\"token number\">4</span><span class=\"token variable\">)</span></span>/kops-linux-amd64\n<span class=\"token function\">chmod</span> +x ./kops\n<span class=\"token function\">sudo</span> <span class=\"token function\">mv</span> ./kops /usr/local/bin/\n\n<span class=\"token comment\"># kubectl 설치</span>\n<span class=\"token function\">wget</span> -O kubectl https://storage.googleapis.com/kubernetes-release/release/<span class=\"token variable\"><span class=\"token variable\">$(</span><span class=\"token function\">curl</span> -s https://storage.googleapis.com/kubernetes-release/release/stable.txt<span class=\"token variable\">)</span></span>/bin/linux/amd64/kubectl\n<span class=\"token function\">chmod</span> +x ./kubectl\n<span class=\"token function\">sudo</span> <span class=\"token function\">mv</span> ./kubectl /usr/local/bin/kubectl\n\n<span class=\"token comment\"># aws-cli 설치 (amazon linux라면 불필요)</span>\npip <span class=\"token function\">install</span> awscli</code></pre></div>\n<br>\n<h2 id=\"iam-user-설정\" style=\"position:relative;\"><a href=\"#iam-user-%EC%84%A4%EC%A0%95\" aria-label=\"iam user 설정 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>IAM User 설정</h2>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token comment\"># 아래의 권한이 필요</span>\nAmazonEC2FullAccess\nAmazonRoute53FullAccess\nAmazonS3FullAccess\nIAMFullAccess\nAmazonVPCFullAccess</code></pre></div>\n<br>\n<h2 id=\"aws-cli로-iam-계정-생성\" style=\"position:relative;\"><a href=\"#aws-cli%EB%A1%9C-iam-%EA%B3%84%EC%A0%95-%EC%83%9D%EC%84%B1\" aria-label=\"aws cli로 iam 계정 생성 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>aws-cli로 IAM 계정 생성</h2>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">aws iam create-group --group-name kops\n\naws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonEC2FullAccess --group-name kops\naws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonRoute53FullAccess --group-name kops\naws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonS3FullAccess --group-name kops\naws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/IAMFullAccess --group-name kops\naws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonVPCFullAccess --group-name kops\n\naws iam create-user --user-name kops\naws iam add-user-to-group --user-name kops --group-name kops\naws iam create-access-key --user-name kops\n\naws configure   <span class=\"token comment\"># AccessKeyID와 SecretAccessKey 등록</span></code></pre></div>\n<br>\n<h2 id=\"dns-cluster-state-storage-설정\" style=\"position:relative;\"><a href=\"#dns-cluster-state-storage-%EC%84%A4%EC%A0%95\" aria-label=\"dns cluster state storage 설정 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>DNS, Cluster State storage 설정</h2>\n<ul>\n<li>kops 1.6.2 버전 이상이라면 DNS 설정은 옵션 (gossip-based cluster)</li>\n<li>Cluster Configuration Storage로 S3를 사용 (Bucket 미리 생성해야 함)</li>\n<li>S3 default bucket encryption을 사용할 수 있음</li>\n<li>default encryption 설정이 안되어 있다면 kops에서 AES256 encryption</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token comment\"># Create Bucket</span>\naws s3api create-bucket <span class=\"token punctuation\">\\</span>\n    --bucket prefix-example-com-state-store <span class=\"token punctuation\">\\</span>\n    --region ap-northeast-2\n\n<span class=\"token comment\"># S3 versioning</span>\naws s3api put-bucket-versioning <span class=\"token punctuation\">\\</span>\n    --bucket prefix-example-com-state-store <span class=\"token punctuation\">\\</span>\n    --versioning-configuration <span class=\"token assign-left variable\">Status</span><span class=\"token operator\">=</span>Enabled</code></pre></div>\n<br>\n<h2 id=\"kubernetes-cluster-생성\" style=\"position:relative;\"><a href=\"#kubernetes-cluster-%EC%83%9D%EC%84%B1\" aria-label=\"kubernetes cluster 생성 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Kubernetes Cluster 생성</h2>\n<ul>\n<li>kops를 통해 생성된 인스턴스는 자동으로 Auto Scaling 그룹에 들어감</li>\n<li><code class=\"language-text\">kops create</code>: cluster configuration을 생성, SSH-Key가 필요</li>\n<li><code class=\"language-text\">kops edit</code>: cluster configuation을 수정</li>\n<li><code class=\"language-text\">kops update</code>: Build 단계, kubernetes component를 모두 설치하고 나면 ready 상태로 전환</li>\n<li><code class=\"language-text\">kops delete</code>: cluster 제거, --yes (구성요소까지 전부 삭제)</li>\n<li><code class=\"language-text\">kops rolling-update</code>: downtime이 없는 rolling-update 실행</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token comment\"># Environment</span>\n<span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">NAME</span><span class=\"token operator\">=</span>myfirstcluster.example.com  <span class=\"token comment\"># DNS가 설정되어 있는 경우</span>\n<span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">NAME</span><span class=\"token operator\">=</span>myfirstcluster.k8s.local    <span class=\"token comment\"># DNS가 설정되어 있지 않은 경우</span>\n<span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">KOPS_STATE_STORE</span><span class=\"token operator\">=</span>s3://prefix-example-com-state-store\n\n<span class=\"token comment\"># Seoul region</span>\naws ec2 describe-availability-zones --region ap-northeast-2\nkops create cluster --zones ap-northeast-2 <span class=\"token variable\">${NAME}</span>\nkops edit cluster <span class=\"token variable\">${NAME}</span>\nkops update cluster <span class=\"token variable\">${NAME}</span> --yes\nkops validate cluster\n\n<span class=\"token comment\"># Kubectl</span>\nkubectl get nodes\nkubectl cluster-info\nkubectl -n kube-system get po   <span class=\"token comment\"># system pod</span>\n\n<span class=\"token comment\"># Dashboard</span>\nkops get secrets admin -oplaintext\nkubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml\n\n<span class=\"token comment\"># Access https://&lt;kubernetes-master-hostname>/ui</span>\nkops get secrets admin --type secret -oplaintext\n\n<span class=\"token comment\"># Stop cluster</span>\n<span class=\"token comment\"># Change minSize, MaxSize to 0</span>\nkops get ig\nkops edit ig nodes\nkops edit ig master</code></pre></div>\n<br>\n<h2 id=\"advanced\" style=\"position:relative;\"><a href=\"#advanced\" aria-label=\"advanced permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Advanced</h2>\n<ul>\n<li>Network topology를 설정할 수 있음 (public, private)</li>\n<li>Private: VPC내의 private subnet으로 생성</li>\n<li>Public: VPC내의 public subnet으로 생성 (routed to Internet Gateway)</li>\n<li>Multiple zone, HA Master를 구성할 수 있음 (--master-zones=us-east-1b,us-east-1c,us-east-1d)</li>\n<li>Instance Group을 지정 가능 (<a href=\"https://github.com/kubernetes/kops/blob/master/docs/instance_groups.md\">https://github.com/kubernetes/kops/blob/master/docs/instance_groups.md</a>)</li>\n<li>AMI를 지정가능, CoreOS AMI</li>\n<li>Container Network Interface (CNI) 지정 가능 (<a href=\"https://kubernetes.io/docs/concepts/cluster-administration/networking/\">https://kubernetes.io/docs/concepts/cluster-administration/networking/</a>)</li>\n<li>Authorization (<a href=\"https://kubernetes.io/docs/reference/access-authn-authz/authorization/\">https://kubernetes.io/docs/reference/access-authn-authz/authorization/</a>)</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token comment\"># SSH Key</span>\nssh-keygen -t rsa -f <span class=\"token variable\">$NAME</span>.key -N <span class=\"token string\">''</span>\n<span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">PUBKEY</span><span class=\"token operator\">=</span><span class=\"token string\">\"<span class=\"token variable\">$NAME</span>.key.pub\"</span>\n\n<span class=\"token comment\"># CoreOS Image</span>\n<span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">IMAGE</span><span class=\"token operator\">=</span><span class=\"token variable\"><span class=\"token variable\">$(</span><span class=\"token function\">curl</span> -s https://coreos.com/dist/aws/aws-stable.json<span class=\"token operator\">|</span><span class=\"token function\">sed</span> <span class=\"token string\">'s/-/_/g'</span><span class=\"token operator\">|</span>jq <span class=\"token string\">'.'</span>$REGION<span class=\"token string\">'.hvm'</span><span class=\"token operator\">|</span><span class=\"token function\">sed</span> <span class=\"token string\">'s/_/-/g'</span> <span class=\"token operator\">|</span> <span class=\"token function\">sed</span> <span class=\"token string\">'s/<span class=\"token entity\" title=\"\\&quot;\">\\\"</span>//g'</span><span class=\"token variable\">)</span></span>\n\n<span class=\"token comment\"># Create Cluster</span>\nkops create cluster --kubernetes-version<span class=\"token operator\">=</span><span class=\"token number\">1.12</span>.1 <span class=\"token punctuation\">\\</span>\n    --ssh-public-key <span class=\"token variable\">$PUBKEY</span> <span class=\"token punctuation\">\\</span>\n    --networking flannel <span class=\"token punctuation\">\\</span>\n    --api-loadbalancer-type public <span class=\"token punctuation\">\\</span>\n    --admin-access <span class=\"token number\">0.0</span>.0.0/0 <span class=\"token punctuation\">\\</span>\n    --authorization RBAC <span class=\"token punctuation\">\\</span>\n    --zones ap-northeast-2 <span class=\"token punctuation\">\\</span>\n    --master-zones ap-northeast-2 <span class=\"token punctuation\">\\</span>\n    --master-size t2.medium <span class=\"token punctuation\">\\</span>\n    --node-size t2.medium <span class=\"token punctuation\">\\</span>\n    --image <span class=\"token variable\">$IMAGE</span> <span class=\"token punctuation\">\\</span>\n    --node-count <span class=\"token number\">3</span> <span class=\"token punctuation\">\\</span>\n    --cloud aws <span class=\"token punctuation\">\\</span>\n    --bastion <span class=\"token punctuation\">\\</span>\n    --name <span class=\"token variable\">$NAME</span> <span class=\"token punctuation\">\\</span>\n    --yes</code></pre></div>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<ul>\n<li><a href=\"https://github.com/kubernetes/kops\">https://github.com/kubernetes/kops</a></li>\n<li><a href=\"https://kubernetes.io/ko/docs/setup/custom-cloud/kops/\">https://kubernetes.io/ko/docs/setup/custom-cloud/kops/</a></li>\n</ul>\n<br>","excerpt":"Kubernetes 클러스터를 구성하는 방법은 여러 가지가 있습니다.\n그 중에서 kubeadam은 온프레미스 환경에서 많이 사용하고 kops…"}}}}]}},"pageContext":{"basePath":"","paginationPath":"","pageNumber":4,"humanPageNumber":5,"skip":25,"limit":6,"numberOfPages":16,"previousPagePath":"/4","nextPagePath":"/6"}}}