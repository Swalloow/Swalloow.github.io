{"componentChunkName":"component---src-templates-posts-js","path":"/4","result":{"data":{"allContentfulPost":{"edges":[{"node":{"title":"분산 컨테이너 환경에서의 디자인 패턴 (1)","id":"9307407d-64a7-50d7-a261-07a48ec192cb","slug":"container-patterns","publishDate":"January 26, 2019","heroImage":{"id":"1563c3af-a4e8-5db4-acb2-9bfd9fdb294d","title":"cover-develop","fluid":{"aspectRatio":1.5,"src":"//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=1800&h=1200&q=50 1800w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=1800&h=1200&q=50&fm=webp 1800w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/4W9SzEIJpHuwsUBnxSSypH/3a18765095ea5756c742b7adb83a0518/cover_develop.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"3a9720a9-32ed-51fb-9835-f2d0e7f319d0","childMarkdownRemark":{"id":"5240b6d3-d24e-55e9-be93-71350bb375bb","timeToRead":3,"html":"<p>구글 클라우드 팀이 Kubernetes와 같은 Container Orchestration 기술을 개발하면서 겪은\n분산 컨테이너 환경에서의 디자인 패턴에 대해 정리한 내용입니다.\n분산 어플리케이션을 컨테이너 환경으로 옮기려는 분들에게 많은 도움이 될 듯 합니다.</p>\n<ul>\n<li><a href=\"http://swalloow.github.io/container-patterns\">분산 컨테이너 환경에서의 디자인 패턴 1. Single-Node Patterns</a></li>\n<li><a href=\"http://swalloow.github.io/container-patterns2\">분산 컨테이너 환경에서의 디자인 패턴 2. Multi-Node Serving Patterns</a></li>\n<li><a href=\"http://swalloow.github.io/container-patterns3\">분산 컨테이너 환경에서의 디자인 패턴 3. Batch Computational Patterns</a></li>\n</ul>\n<br>\n<h2 id=\"modular-container-design\" style=\"position:relative;\"><a href=\"#modular-container-design\" aria-label=\"modular container design permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Modular Container Design</h2>\n<p>최근 많은 개발 환경이 Docker 기반의 컨테이너 환경으로 옮겨가고 있습니다.\n그 중에서는 복잡한 의존성에서 벗어나 독립적으로 운영하고 싶어서 옮기는 경우가 많습니다.</p>\n<p>하지만 분산 컨테이너 환경은 아주 복잡하게 연결되어 있어서 운영하기 힘듭니다.\n복잡한 연결을 쉽게 이해하려면 이 문제가 어디에 해당하는지 경계를 잘 정의하는 것이 중요합니다.\n이렇게 <strong>경계를 정의하고 분류하는 것을 모듈화</strong>라고 부릅니다.</p>\n<p>우리는 과거부터 효율적인 코드를 작성하기 위해 절차지향 프로그래밍에서 객체지향 프로그래밍으로 변화해왔습니다.\n객체지향 프로그래밍의 클래스는 경계를 정의한다는 측면에서 컨테이너 환경과 유사한 면이 있습니다.</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1KTN3XFpFugvI6OXqnJdvc0LBUjW0HfbV\" alt=\"modular\"></p>\n<p>과거 모놀리틱 아키텍쳐에서는 왼쪽 그림과 같은 구조로 설계되어 왔습니다.\n우리가 기여하거나 자주 수정하는 코드가 있는 반면, 코어 모듈이나 공통에 해당하는 부분은 잘 변하지 않습니다.</p>\n<p>컨테이너 환경은 이와 조금 다릅니다.\n우선 <strong>컨테이너 환경에서 컨테이너는 하나의 어플리케이션이 아니라는 점</strong>을 이해하고 있어야 합니다.\n하나의 컨테이너는 객체지향 언어의 클래스 또는 함수와 유사합니다.\n오른쪽 그림처럼 작은 모듈 조각을 모으고 조립해서 다음 어플리케이션을 설계하는 형태가 되어야 합니다.</p>\n<br>\n<h2 id=\"benefit\" style=\"position:relative;\"><a href=\"#benefit\" aria-label=\"benefit permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Benefit</h2>\n<p>위와 같은 컨테이너 환경을 구성했을 때 가지는 장점은 아래와 같습니다.</p>\n<ul>\n<li>이미 만들어 놓은 컨테이너를 재사용할 수 있고 사용하기 쉬움</li>\n<li>컨테이너 경계에 따라 팀의 역할을 분리시킬 수 있음</li>\n<li>분리되어 있기 때문에 각 모듈에 대해 더 깊게 이해할 수 있음</li>\n<li>각 모듈에 대해 작은 수정사항을 빠르게 업데이트할 수 있음</li>\n<li>흔히 얘기하는 관심사의 분리를 만족시킬 수 있음 (Seperate concerns)</li>\n</ul>\n<br>\n<h2 id=\"requirements\" style=\"position:relative;\"><a href=\"#requirements\" aria-label=\"requirements permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Requirements</h2>\n<p>위와 같은 컨테이너 환경을 구성하기 위해 필요한 요소는 아래와 같습니다.</p>\n<ul>\n<li>공통된 네임스페이스 (PID, IPC, 네트워크 등), 마치 localhost 처럼 사용할 수 있도록 하나의 컨테이너가 다른 컨테이너의 프로세스를 컨트롤 할 수 있어야 합니다.</li>\n<li>공유할 수 있는 파일 시스템, Kubernetes의 PV, PVC에 내한 내용을 떠올리면 이해하기 쉽습니다.</li>\n<li>어플리케이션을 구성할 때 노드의 분리도 고려되어야 합니다. 예시로 WordPress-MySQL 어플리케이션을 배포한다고 가정했을 때, WordPress가 배포된 노드와 MySQL 노드의 위치가 달라야 합니다. 그리고 WordPress, MySQL에 각각에 대한 Scale-out도 고려되어야 합니다.</li>\n<li>컨테이너가 런타임 시점에 파라메터로 설정 값을 받을 수 있도록 설계되어야 합니다. 그리고 각 이미지에 대한 문서화도 필요합니다.\n특히 여러 컨테이너에서 공통으로 사용하는 라이브러리의 경우 필요</li>\n</ul>\n<br>\n<h2 id=\"sidecar-pattern\" style=\"position:relative;\"><a href=\"#sidecar-pattern\" aria-label=\"sidecar pattern permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Sidecar Pattern</h2>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1zkTfbZgsYUlylN6kGVXDjCqfZGVTo5jF\"></p>\n<p>이제부터 자주 사용되는 세 가지 디자인 패턴을 소개드리려고 합니다.\n먼저 첫 번째는 사이드 카 패턴입니다.\n<strong>사이드 카 패턴은 이전에 사용되던 컨테이너의 기능을 확장시키고 싶을 때</strong> 유용하게 사용됩니다.\n여기서 이전에 사용되던 컨테이너란 잘 변하지 않으며 같은 작업을 반복하는 어플리케이션을 말합니다.</p>\n<p>위 그림의 예시에서 이전에 사용되던 컨테이너는 왼쪽의 node.js 어플리케이션 입니다.\nnode.js 어플리케이션은 단순히 파일 시스템에 접근하여 어떤 작업을 수행하는 일만 합니다.\n만일 파일 시스템에 대해 git 동기화 기능을 추가하고 싶다면, 오른쪽 컨테이너처럼 확장시킬 수 있습니다.\nnode.js 어플리케이션은 사이드 카 컨테이너가 어떤 작업을 수행하는지 고려할 필요가 없습니다.\n사이드 카 컨테이너 역시 어떤 어플리케이션이 이 파일을 서빙하는지 고려할 필요가 없습니다.\n앞서 말한 것처럼 관심사의 분리를 만족시키며, 컨테이너를 관리하는 팀을 분리시킬 수 있습니다.\n또한 사이드 카 컨테이너를 다른 어플리케이션에서 재사용할 수 있고, 더 다양한 기능으로 확장시킬 수 있습니다.</p>\n<br>\n<h2 id=\"ambassador-pattern\" style=\"position:relative;\"><a href=\"#ambassador-pattern\" aria-label=\"ambassador pattern permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Ambassador Pattern</h2>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1pzXLY74nqBfNti5cPd-zSw0kGPEh2CUK\"></p>\n<p>다음은 엠베서더 패턴입니다.\n<strong>엠베서더 패턴은 어플리케이션을 대신하여 외부의 네트워크 또는 요청을 처리해야할 때</strong> 유용하게 사용됩니다.</p>\n<p>위 그림의 예시에서 어플리케이션은 PHP 앱이고 Memcache를 사용한 지속적인 해싱이 필요하다고 가정해보겠습니다.\n그리고 Memcache 사용을 위해 <a href=\"https://github.com/twitter/twemproxy\">twemproxy</a>라는 라이브러리를 가져와야 합니다.\n위 그림처럼 어플리케이션과 twemproxy 컨테이너를 분리시킨다면,\ntwemproxy 컨테이너는 외부에 있는 Memcache 샤드를 관리하고 통신하는 역할을 수행할 수 있습니다.\n기존에 있던 어플리케이션 컨테이너는 twemproxy 컨테이너와 같은 네임스페이스에 존재하지만, 외부의 통신에 대해서는 관여할 필요가 없습니다.\n역시 마찬가지로 관심사의 분리를 만족시키며, 재사용될 수 있고, 다양한 기능으로 확장시킬 수 있습니다.</p>\n<br>\n<h2 id=\"adapter-pattern\" style=\"position:relative;\"><a href=\"#adapter-pattern\" aria-label=\"adapter pattern permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Adapter Pattern</h2>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1Vpp_gVNarlAql_eGKkBJ2ojntRkAYzQL\"></p>\n<p>다음은 어댑터 패턴입니다.\n<strong>어댑터 패턴은 추상화된 레이어가 필요할 때</strong> 유용하게 사용됩니다.</p>\n<p>대표적인 예시로 위 그림과 같은 모니터링 에이전트가 있습니다.\n일반적으로 Redis, Memcache, MySQL 등 다양한 컴포넌트에 모니터링이 필요합니다.\n모놀리틱 구조로 설계되었다면, 새로운 컴포넌트에 대한 지원이 필요할때마다 변경이 필요합니다.\n하지만 분리되어 있는 공통 인터페이스가 존재한다면, 새로운 컴포넌트를 쉽게 추가할 수 있습니다.\n특히 오픈소스 진영에서는 많은 사람들이 다양한 컴포넌트를 사용하기 때문에 많이 활용됩니다.</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1doLkvd4eNSQvCtw0KT1ipw2EVA0uTXJP\"></p>\n<p>많이 사용하는 prometheus exporter도 이와 같은 패턴으로 설계되어 있습니다.\nexporter는 모니터링 시스템과 쉽게 결합할 수 있습니다.\n그리고 exporter와 memcache, redis는 결합해서 하나의 컨테이너로 배포하는 형태입니다.\nredis-exporter에 코드 변경이 이루어지더라도 memcache-exporter는 변경될 필요가 없습니다.</p>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<p>이외에도 Replication, Micro service Load Balancer에 사용되는 다양한 패턴이 존재합니다.\n분산 컨테이너 환경에서 어플리케이션을 개발하는 일은 레고 블럭을 조립하는 것과 비슷합니다.\n더 자세한 내용이 궁금하신 분은 아래 링크를 확인하시면 됩니다.</p>\n<ul>\n<li><a href=\"https://www.youtube.com/watch?v=Ph3t8jIt894\">DockerCon - Container patterns for modular distributed system design</a></li>\n<li><a href=\"https://static.googleusercontent.com/media/research.google.com/ko//pubs/archive/45406.pdf\">GooglePaper - Design patterns for container-based distributed systems</a></li>\n</ul>\n<br>","excerpt":"구글 클라우드 팀이 Kubernetes와 같은 Container Orchestration…"}}}},{"node":{"title":"Apache Airflow에 기여하면서 배운 점들","id":"50a917d3-58d2-56fb-b3c1-101b359f2f8a","slug":"airflow-contrib","publishDate":"December 08, 2018","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"a216f939-c13e-5c9e-bf73-f38e51932651","childMarkdownRemark":{"id":"188eab1d-542f-5ef1-b928-da67dfe8eee5","timeToRead":4,"html":"<p>Apache Airflow는 코드를 통해 워크플로우를 관리하고 모니터링 할 수 있도록 도와주는 플랫폼이다.\nAirflow 프로젝트에 대한 설명은 다른 글에서도 많이 다루기 때문에 생략하고\n이 글에서는 처음으로 아파치 프로젝트에 기여해본 경험을 정리해보려 한다.</p>\n<br>\n<h2 id=\"기여하게-된-배경\" style=\"position:relative;\"><a href=\"#%EA%B8%B0%EC%97%AC%ED%95%98%EA%B2%8C-%EB%90%9C-%EB%B0%B0%EA%B2%BD\" aria-label=\"기여하게 된 배경 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>기여하게 된 배경</h2>\n<p>당시에 관리하던 데이터 인프라에는 의존성이 얽혀있는 배치 작업이 상당히 많았다.\n여기에서 의존성이 얽혀있다는 말은 A 작업과 B 작업이 성공적으로 끝나고 난 뒤 C 작업을 해야하는 경우를 말한다.\n또한 각 작업들은 서로 다른 시간에 스케줄링 되어야 했고, 작업이 실패하는 경우 재시도 또는 특정 로직을 실행시킬 수 있어야 했다.</p>\n<p>처음에는 단순한 구조이다 보니 스크립트로 관리했지만 점차 늘어나는 운영 이슈에 대응하기 위해 Airflow를 활용하기로 결정했다.\n하지만 운영하다 보니 AWS 관련 컴포넌트들의 여러 버그를 발견하게 되었고 이를 수정하기 위해 PR을 추가했었다.</p>\n<br>\n<h2 id=\"아파치-프로젝트-pr-프로세스\" style=\"position:relative;\"><a href=\"#%EC%95%84%ED%8C%8C%EC%B9%98-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-pr-%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4\" aria-label=\"아파치 프로젝트 pr 프로세스 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>아파치 프로젝트 PR 프로세스</h2>\n<p>아파치 프로젝트는 이슈 관리 도구로 JIRA를 사용한다. CI 도구는 프로젝트마다 다른 편인데 Airflow의 경우 TravisCI를 사용한다.\n모든 프로젝트에는 처음 프로젝트에 기여하려는 개발자를 위해 <strong>CONTRIBUTING.md</strong> 라는 문서를 제공한다.\n문서에는 개발 및 테스트 환경을 어떻게 구축해야하는지, 지켜야할 규칙, PR 가이드라인 등에 대해 설명되어 있다.\n그리고 PR template를 준수해야 하는데 잘 모르겠다면, 이전 PR들을 확인하고 비슷한 양식으로 작성하면 된다.</p>\n<p>내가 처음 접했던 Airflow 문서에는 AWS 관련 Hook, Operator도 반영되어 있지 않았다.\n그래서 첫 PR로 AWS, GCP 관련 컴포넌트를 업데이트하는 문서 기여를 하게 되었다.\n문서 관리에는 <a href=\"https://readthedocs.org/\">readthedocs</a>를 사용하고 있었고 Sphinx 빌드를 통해 문서를 확인할 수 있었다.</p>\n<p>사용하다보니 특히 EMR 관련 Hook과 Operator에 버그가 많았다.\n만일 JIRA에 이미 등록되어 있는 이슈가 아니라면 이슈를 새로 생성한 다음 PR을 추가해주어야 한다.</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1d0SNiE9qJza0CtmU8S2k8h4Q3iRPE8vN\"></p>\n<p>비슷한 이슈를 겪고 있는 사람들이 있어서 좀 신기했다.\n그리고 <strong>아주 작은 수정이라도 테스트 케이스를 추가</strong>해야 한다는 사실을 알게 되었다.</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1Re-gmGnEOlB8hxPhAkbjYQpQ-6kOzm6j\"></p>\n<p>양식만 잘 지키면 커미터들은 정말 친절하다. 내가 파악하지 못한 부분까지 알려주고, 코드 리뷰도 받을 수 있다.\n다른 PR을 참고하면서 많이 배울 수 있었다.</p>\n<br>\n<h2 id=\"클라우드-인프라-테스트-방법\" style=\"position:relative;\"><a href=\"#%ED%81%B4%EB%9D%BC%EC%9A%B0%EB%93%9C-%EC%9D%B8%ED%94%84%EB%9D%BC-%ED%85%8C%EC%8A%A4%ED%8A%B8-%EB%B0%A9%EB%B2%95\" aria-label=\"클라우드 인프라 테스트 방법 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>클라우드 인프라 테스트 방법</h2>\n<p>AWS는 기본적으로 클라우드 환경이다.\n따라서 과금문제로 인해 실제로 추가, 변경한 오퍼레이터가 잘 동작하는지 매번 확인해보기가 힘들다.\nAirflow에서는 AWS 서비스를 Mocking 하기 위해 <a href=\"https://github.com/spulec/moto\">moto</a> 라는 라이브러를 활용해서 테스트를 작성한다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token decorator annotation punctuation\">@mock_s3</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">test_my_model_save</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\"># Create Bucket so that test can run</span>\n    conn <span class=\"token operator\">=</span> boto3<span class=\"token punctuation\">.</span>resource<span class=\"token punctuation\">(</span><span class=\"token string\">'s3'</span><span class=\"token punctuation\">,</span> region_name<span class=\"token operator\">=</span><span class=\"token string\">'us-east-1'</span><span class=\"token punctuation\">)</span>\n    conn<span class=\"token punctuation\">.</span>create_bucket<span class=\"token punctuation\">(</span>Bucket<span class=\"token operator\">=</span><span class=\"token string\">'mybucket'</span><span class=\"token punctuation\">)</span>\n    model_instance <span class=\"token operator\">=</span> MyModel<span class=\"token punctuation\">(</span><span class=\"token string\">'steve'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'is awesome'</span><span class=\"token punctuation\">)</span>\n    model_instance<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    body <span class=\"token operator\">=</span> conn<span class=\"token punctuation\">.</span>Object<span class=\"token punctuation\">(</span><span class=\"token string\">'mybucket'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'steve'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token string\">'Body'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>decode<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">assert</span> body <span class=\"token operator\">==</span> <span class=\"token string\">'is awesome'</span></code></pre></div>\n<p>위와 같이 moto에서 미리 정의한 mock object를 decorator를 사용하여 쉽게 활용할 수 있다.\n하지만 AWS에서 공식으로 지원하는 라이브러리가 아니다보니 업데이트가 늦어지기도 한다.\n이런 이유로 인해 unittest의 mock으로 작성된 테스트 코드도 많이 있다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">TestEmrAddStepsOperator</span><span class=\"token punctuation\">(</span>unittest<span class=\"token punctuation\">.</span>TestCase<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\"># When</span>\n    _config <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">{</span>\n        <span class=\"token string\">'Name'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'test_step'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'ActionOnFailure'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'CONTINUE'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'HadoopJarStep'</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n            <span class=\"token string\">'Jar'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'command-runner.jar'</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">'Args'</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span>\n                <span class=\"token string\">'/usr/lib/spark/bin/run-example'</span>\n            <span class=\"token punctuation\">]</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">]</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">setUp</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        configuration<span class=\"token punctuation\">.</span>load_test_config<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\"># Mock out the emr_client (moto has incorrect response)</span>\n        self<span class=\"token punctuation\">.</span>emr_client_mock <span class=\"token operator\">=</span> MagicMock<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>operator <span class=\"token operator\">=</span> EmrAddStepsOperator<span class=\"token punctuation\">(</span>\n            task_id<span class=\"token operator\">=</span><span class=\"token string\">'test_task'</span><span class=\"token punctuation\">,</span>\n            job_flow_id<span class=\"token operator\">=</span><span class=\"token string\">'j-8989898989'</span><span class=\"token punctuation\">,</span>\n            aws_conn_id<span class=\"token operator\">=</span><span class=\"token string\">'aws_default'</span><span class=\"token punctuation\">,</span>\n            steps<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>_config\n        <span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">test_init</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>assertEqual<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>operator<span class=\"token punctuation\">.</span>aws_conn_id<span class=\"token punctuation\">,</span> <span class=\"token string\">'aws_default'</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>assertEqual<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>operator<span class=\"token punctuation\">.</span>emr_conn_id<span class=\"token punctuation\">,</span> <span class=\"token string\">'emr_default'</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">test_render_template</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        ti <span class=\"token operator\">=</span> TaskInstance<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>operator<span class=\"token punctuation\">,</span> DEFAULT_DATE<span class=\"token punctuation\">)</span>\n        ti<span class=\"token punctuation\">.</span>render_templates<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n        expected_args <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">{</span>\n            <span class=\"token string\">'Name'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'test_step'</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">'ActionOnFailure'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'CONTINUE'</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">'HadoopJarStep'</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n                <span class=\"token string\">'Jar'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'command-runner.jar'</span><span class=\"token punctuation\">,</span>\n                <span class=\"token string\">'Args'</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span>\n                    <span class=\"token string\">'/usr/lib/spark/bin/run-example'</span>\n                <span class=\"token punctuation\">]</span>\n            <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">}</span><span class=\"token punctuation\">]</span>\n\n        self<span class=\"token punctuation\">.</span>assertListEqual<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>operator<span class=\"token punctuation\">.</span>steps<span class=\"token punctuation\">,</span> expected_args<span class=\"token punctuation\">)</span>\n\n\n<span class=\"token keyword\">if</span> __name__ <span class=\"token operator\">==</span> <span class=\"token string\">'__main__'</span><span class=\"token punctuation\">:</span>\n    unittest<span class=\"token punctuation\">.</span>main<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>unittest로 작성된 테스트 케이스는 API로 주고 받는 json을 직접 정의해줘야 하는 번거로움이 있다.\n테스트 케이스를 작성하고 난 다음 바로 PR을 추가하는 것보다 로컬 CI를 미리 돌려보는게 좋다.</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1MEOqsKocQTV8y5y_y2xrpIppkw2ndOvT\"></p>\n<p>TravisCI는 오픈소스인 경우 무료로 사용할 수 있으며, yml 파일에 미리 정의되어 있으니 참고하면 된다. 로컬에서 CI가 통과되고 나면 PR을 추가해도 좋다.\n작업이 길어지면서 커밋이 여러 개로 늘어나는 경우, <strong>commit을 squash</strong> 해주는 것이 좋다.\n(나중에 문제가 생겼을 때 쉽게 rebase 하기 위함)</p>\n<br>\n<h2 id=\"잡다한-정리\" style=\"position:relative;\"><a href=\"#%EC%9E%A1%EB%8B%A4%ED%95%9C-%EC%A0%95%EB%A6%AC\" aria-label=\"잡다한 정리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>잡다한 정리</h2>\n<ul>\n<li><a href=\"https://issues.apache.org/jira/browse/AIRFLOW-713\">[AIRFLOW-713] EmrCreateJobFlowOperator and EmrAddStepsOperator attributes are not jinjafied</a></li>\n<li><a href=\"https://issues.apache.org/jira/browse/AIRFLOW-950\">[AIRFLOW-950] Missing AWS integrations on documentation::integrations</a></li>\n<li><a href=\"https://issues.apache.org/jira/browse/AIRFLOW-1453\">[AIRFLOW-1453] Add 'steps' into template_fields in EmrAddSteps</a></li>\n<li><a href=\"https://issues.apache.org/jira/browse/AIRFLOW-1436\">[AIRFLOW-1436, AIRFLOW-1475] EmrJobFlowSensor consideres Cancelled step as Successful</a></li>\n</ul>\n<p>그 동안 5개 정도의 버그를 해결했고 수정했던 AWS EMR 관련 버그들은 1.9 - 10 버전에 모두 반영 되었다.\n이외에도 Airflow에는 여전히 자잘한 버그가 많이 남아있다.\n(Docker로 운영했을 때 로그가 이상하게 나타난다거나, SubDag Deadlock 문제 등)\n당시에 블로그를 열심히 했다면 운영 관련해서 글을 남겼을텐데 하는 아쉬움이 남아있다.</p>\n<p>어쨋든 Airflow를 적용하고 난 뒤, 편히 새벽에 잠들 수 있게 되었다.\n지금은 머신러닝 파이프라인 관련 도구가 많이 나왔지만, Airflow도 충분히 해당 영역을 커버할 수 있다.</p>\n<p>그리고 오픈소스에 대해 다시 한번 생각해보게 되었다.\n많은 사람들이 참여하는 오픈소스이다 보니 당연히 버그나 이슈가 생길 수 있고,\n문제가 생겼을 때 고쳐달라고 강요하거나 기다리는 것보다 스스로 수정해서 기여하는 것이 올바른 태도가 아닌가 싶다.</p>","excerpt":"Apache Airflow는 코드를 통해 워크플로우를 관리하고 모니터링 할 수 있도록 도와주는 플랫폼이다.\nAirflow…"}}}},{"node":{"title":"Kafka Connect로 S3에 데이터를 저장해보자","id":"c548511f-3e1d-5c2e-a96f-b0e297f133e2","slug":"kafka-connect","publishDate":"November 16, 2018","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"e81fb246-b516-57b8-bf98-7771d7cfb4fc","childMarkdownRemark":{"id":"26d0807b-21d9-5de5-864e-e44c27cc2883","timeToRead":4,"html":"<p>Kafka에는 정말 유용한 컴포넌트들이 존재합니다.\n오늘은 그 중 하나인 Kafka-Connect에 대해 알아보고,\nConfluent에서 제공하는 Kafka-Connect-S3를 활용하여\nS3로 데이터를 저장하는 방법에 대해 정리해보려고 합니다.</p>\n<br>\n<h2 id=\"kafka-connect\" style=\"position:relative;\"><a href=\"#kafka-connect\" aria-label=\"kafka connect permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Kafka Connect</h2>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=172qcC4a0mgYnkeZHlH7HH4lar1dAebA3\" alt=\"kafka-connect\"></p>\n<p>우리는 서버로부터 생성되는 데이터를 실시간으로 Kafka에 보내기도 하고,\nKafka Topic에 쌓여있는 데이터를 실시간으로 RDBMS, Object Storage와 같은 시스템에 보내기도 합니다.\nKafka Connect는 위의 그림과 같이 다양한 시스템과 Kafka 사이의 연결을 도와주는 역할을 하는 컴포넌트입니다.\nSource System에서 Kafka로 들어가는 Connector를 Source Connect라 부르고,\nKafka에서 Target System으로 보내는 Connector를 Sink Connect라 부릅니다.</p>\n<p>Kafka Connect는 JSON, Avro, Protobuf 등의 다양한 직렬화 포멧을 지원하며\nKafka Schema Registry와 연동시켜 공통된 스키마 지정을 할 수도 있습니다.</p>\n<p>사실 Fluentd와 ELK Stack에서 사용하는 Logstash 등 서로 다른 시스템 간의 브릿지 역할을 하는 프레임워크들은 다양하게 존재합니다.\n하지만 Kafka Connect가 갖는 강점은 Kafka와 긴밀히 연동되어 있다는 점 입니다.</p>\n<p>Kafka Connect를 사용하지 않고 데이터를 실시간으로 전달하기 위해서는 Producer, Consumer API를 사용해야 합니다.\n이 과정에서 이미 처리되거나 실패한 데이터를 추적한다거나, 데이터 분산처리, 작업을 배포하는 등의 작업을 수행해야만 합니다.</p>\n<p>Kafka Connect는 앞의 모든 작업을 수행할 뿐만 아니라 connector task를 클러스터 전체에 자동으로 배포합니다.\n또한, Connect Worker 중에 하나가 실패하거나 Network partition이 발생하더라도 실행하던 작업을 나머지 Worker들에게 자동으로 재조정합니다.\nOffset을 자동으로 관리, 유지하기 때문에 재시작하더라도 중단 시점부터 다시 시작할 수 있고 (Exactly Once Delivery),\nHigh performance Kafka library로 작성되어 빠르며 불필요한 polling 작업을 수행하지 않습니다.\n무엇보다 코드 한 줄 없이 사용하기 편하다는 것도 큰 강점입니다.\n혹시 Kafka를 이미 중앙 집중형 로그 저장소로 사용하고 있다면 Kafka Connect를 고려해볼만 하다고 생각합니다.</p>\n<br>\n<h2 id=\"kafka-connect-s3\" style=\"position:relative;\"><a href=\"#kafka-connect-s3\" aria-label=\"kafka connect s3 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Kafka-Connect-S3</h2>\n<p>이 글에서는 Confluent로 Kafka를 설치하지 않은 경우를 예시로 들겠습니다.\n이미 confluent-hub를 설치하셨거나 Confluent로 Kafka를 설치하셨다면 공식문서를 따라가시면 됩니다.</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1R80lOarW9k1RGv2kYAYxNz_-q6wUsm28\" alt=\"aws-kafka-s3\"></p>\n<p>데이터 인프라가 AWS 환경에 구축되어 있다면 S3를 Cold Storage로 많이 사용하게 됩니다.\n최대한 단순하게 그림을 그려보면 위의 그림과 같은 아키텍쳐가 나오게 됩니다.\n여기에서는 Kafka에서 S3로 실시간 데이터를 저장하기 위해 Kafka-Connect-S3를 사용하게 됩니다.</p>\n<p>먼저 confluent에서 kafka-connect-s3를 다운받아 plugins 경로에 추가합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token function\">wget</span> https://api.hub.confluent.io/api/plugins/confluentinc/kafka-connect-s3/versions/4.1.1/archive\n$ <span class=\"token function\">unzip</span> archive\n$ <span class=\"token function\">mkdir</span> -p plugins/kafka-connect-s3\n$ <span class=\"token function\">cp</span> confluentinc-kafka-connect-s3-4.1.1/lib/* plugins/kafka-connect-s3/</code></pre></div>\n<p>이제 kafka config 경로에 <code class=\"language-text\">connect.properties</code>라는 이름으로 설정 파일을 추가합니다.\n<code class=\"language-text\">bootstrap.servers</code>와 <code class=\"language-text\">plugin.path</code> 경로는 상황에 맞게 수정하시면 됩니다.\n추가로 kafka 클러스터를 private network로 연결하고 싶다면 9093 포트를 사용해주시면 됩니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\"># Kafka broker IP addresses to connect to\nbootstrap.servers=localhost:9092\n\n# Path to directory containing the connector jar and dependencies\nplugin.path=/home/ec2-user/kafka/plugins\n\n# Converters to use to convert keys and values\nkey.converter=org.apache.kafka.connect.storage.StringConverter\nvalue.converter=org.apache.kafka.connect.storage.StringConverter\n\n# The internal converters Kafka Connect uses for storing offset and configuration data\ninternal.key.converter=org.apache.kafka.connect.json.JsonConverter\ninternal.value.converter=org.apache.kafka.connect.json.JsonConverter\ninternal.key.converter.schemas.enable=false\ninternal.value.converter.schemas.enable=false\noffset.storage.file.filename=/tmp/connect.offsets</code></pre></div>\n<br>\n<p>기존 클러스터에 Authentication credentials, encryption이 설정되어 있다면,\nconnect.properties에 관련 설정을 추가해주셔야 합니다.</p>\n<p>다음 S3에 데이터가 저장될 Bucket을 생성하고, AWS Credentials를 설정합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ pip <span class=\"token function\">install</span> awscli\n$ aws configure</code></pre></div>\n<p>sink connector 관련 설정 파일을 <code class=\"language-text\">s3-sink.properties</code>라는 이름으로 config 경로에 추가합니다.\ntopics와 s3.bucket.name의 이름은 맞게 수정해주셔야 합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">name=s3-sink\nconnector.class=io.confluent.connect.s3.S3SinkConnector\ntasks.max=1\ntopics=my-topic-name\ns3.region=ap-northeast-2\ns3.bucket.name=my-bucket-name\ns3.compression.type=gzip\ns3.part.size=5242880\nflush.size=3\nstorage.class=io.confluent.connect.s3.storage.S3Storage\nformat.class=io.confluent.connect.s3.format.json.JsonFormat\nschema.generator.class=io.confluent.connect.storage.hive.schema.DefaultSchemaGenerator\npartitioner.class=io.confluent.connect.storage.partitioner.TimeBasedPartitioner\npartition.duration.ms=3600000\npath.format=YYYY-MM-dd\nlocale=KR\ntimezone=UTC\nschema.compatibility=NONE</code></pre></div>\n<br>\n<p>이제 Kafka 설치 경로로 이동하고 Kafka-Connect를 실행시킵니다.\n여기에서는 standalone mode로 실행시켰지만, 경우에 따라 cluster mode로 실행하거나\ndocker container로 실행시켜도 됩니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">./bin/connect-standalone.sh connect.properties s3-sink.properties</code></pre></div>\n<p>이제 지정한 S3 Bucket의 topic/my-topic-name/2018-11-16 경로에 가시면\n지정한 설정 값에 따라 파일이 저장되는 것을 확인하실 수 있습니다.</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1bepmpAHi7kwUnqvGOwyq0i8jSMIhhMeU\"></p>\n<p>이미 Yahoo의 kafka-manager를 사용하고 계신 분들은 consumers 메뉴로 가시면\ntopic 마다 lag도 모니터링할 수 있습니다.</p>\n<br>\n<h2 id=\"kafka-connect-s3-configuration\" style=\"position:relative;\"><a href=\"#kafka-connect-s3-configuration\" aria-label=\"kafka connect s3 configuration permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Kafka-Connect-S3 Configuration</h2>\n<p>데이터 인프라에 맞게 수정해야할 옵션은 아래와 같습니다.</p>\n<ul>\n<li><strong>s3.part.size</strong>: S3의 multi part upload 사이즈를 지정</li>\n<li><strong>flush.size</strong>: file commit 시 저장할 record의 수 (파일 사이즈와 연관)</li>\n<li><strong>partitioner.class</strong>: partition 기준을 지정 (TimeBasedPartitioner는 시간을 기준으로 파티셔닝)</li>\n</ul>\n<p>이외에도 Avro Format과 Schema Registry를 사용하신다면 <code class=\"language-text\">format.class</code>, <code class=\"language-text\">schema.generator.class</code>를 수정해야 합니다.\n더 자세한 내용은 <a href=\"https://docs.confluent.io/5.0.0/connect/kafka-connect-s3/configuration_options.html#s3-configuration-options\">공식문서</a>에서 확인하시면 됩니다.</p>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<p>사실 Kafka는 이미 대부분의 데이터 파이프라인에서 활용하고 있다는 것이 강점이라고 생각합니다.\nETL 과정이 다양하고 복잡할 수록 새로운 프레임워크가 추가되고 아키텍쳐가 복잡해지기 마련인데,\nKafka의 다양한 컴포넌트들을 잘 활용하면 아키텍쳐를 단순화시킬 수도 있습니다.</p>\n<ul>\n<li><a href=\"https://www.confluent.io/blog/kafka-connect-deep-dive-converters-serialization-explained\">https://www.confluent.io/blog/kafka-connect-deep-dive-converters-serialization-explained</a></li>\n<li><a href=\"https://docs.confluent.io/5.0.0/connect/kafka-connect-s3/index.html\">https://docs.confluent.io/5.0.0/connect/kafka-connect-s3/index.html</a></li>\n</ul>","excerpt":"Kafka에는 정말 유용한 컴포넌트들이 존재합니다.\n오늘은 그 중 하나인 Kafka-Connect에 대해 알아보고,\nConfluent…"}}}},{"node":{"title":"17-18년 블로그 회고 및 다짐","id":"43937b5a-56f0-5266-8196-0e18788d00a5","slug":"start","publishDate":"November 09, 2018","heroImage":{"id":"1faaada3-e12b-5548-8532-08b7c04dc7eb","title":"cover-personal","fluid":{"aspectRatio":1.694915254237288,"src":"//images.ctfassets.net/tushy4jlcik7/3ltdJp06NzCExAWz9OF8Ak/d8ca530c80e7c79a7bd7e4c396c0ae00/cover_personal.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/3ltdJp06NzCExAWz9OF8Ak/d8ca530c80e7c79a7bd7e4c396c0ae00/cover_personal.jpg?w=450&h=266&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/3ltdJp06NzCExAWz9OF8Ak/d8ca530c80e7c79a7bd7e4c396c0ae00/cover_personal.jpg?w=900&h=531&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/3ltdJp06NzCExAWz9OF8Ak/d8ca530c80e7c79a7bd7e4c396c0ae00/cover_personal.jpg?w=1400&h=826&q=50 1400w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/3ltdJp06NzCExAWz9OF8Ak/d8ca530c80e7c79a7bd7e4c396c0ae00/cover_personal.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/3ltdJp06NzCExAWz9OF8Ak/d8ca530c80e7c79a7bd7e4c396c0ae00/cover_personal.jpg?w=450&h=266&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/3ltdJp06NzCExAWz9OF8Ak/d8ca530c80e7c79a7bd7e4c396c0ae00/cover_personal.jpg?w=900&h=531&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/3ltdJp06NzCExAWz9OF8Ak/d8ca530c80e7c79a7bd7e4c396c0ae00/cover_personal.jpg?w=1400&h=826&q=50&fm=webp 1400w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/3ltdJp06NzCExAWz9OF8Ak/d8ca530c80e7c79a7bd7e4c396c0ae00/cover_personal.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"6dfe0082-032b-5184-84bb-2a7aa9f18288","childMarkdownRemark":{"id":"093ebd36-2cb8-5f63-85b2-79f4c334a568","timeToRead":1,"html":"<p>지킬 블로그로 이사한지도 벌써 2년이 다 되어 간다.\n항상 이 맘때쯤이면 글쓰는 횟수가 줄어들고 블로그를 또 이사하고 싶은 욕구가 생긴다.\n하지만 지금 운영하고 있는 블로그도 전혀 문제가 없기 때문에 올해까지는 참기로 결정했다.</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1BC2DMbBuEZCL8oBNSNPTD6PM4rOs8y5B\"></p>\n<p>18년 들어서 글을 정말 안쓰기 시작했는데 이상하게도 방문자 수는 계속 증가했다.\n특히 최근 몇달 간 방문자 수가 6천 - 8천 사이에만 있는 걸 보니 다시 글을 써야겠다는 생각이 들었다.\n가장 많이 방문한 페이지 리스트를 보면 어려운 주제에 대한 글보다\n간단한 주제이면서 잊지 않기 위해 기록해 둔 글들이 더 인기가 많았다.</p>\n<p>다시 2주에 1번 정도 글을 써보려 한다.\n주로 백엔드, 데이터 엔지니어링에 대한 내용이겠지만, 가끔씩 금융 도메인에 대한 내용도 올릴 예정이다.</p>\n<br>","excerpt":"지킬 블로그로 이사한지도 벌써…"}}}},{"node":{"title":"Raft consensus algorithm","id":"6e05249f-6d11-5fe8-9c0f-2ad22a78c83c","slug":"raft-consensus","publishDate":"September 01, 2018","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"c603432b-0bfc-5d13-92ef-bb9f6b0614d0","childMarkdownRemark":{"id":"0ec7ec4f-c7ec-5944-902c-ba22c2a35bf8","timeToRead":2,"html":"<p>Consensus란 분산 시스템에서 노드 간의 상태를 공유하는 알고리즘을 말합니다.\n가장 유명한 알고리즘으로 Paxos가 있고, Zookeeper에서 사용하는 Zab이 있습니다.\nRaft는 이해하기 어려운 기존의 알고리즘과 달리 쉽게 이해하고 구현하기 위해 설계되었습니다.\n(PS. 이 글은 블록체인에서의 Consensus 알고리즘을 말하는 것이 아닙니다)</p>\n<br>\n<h2 id=\"what-is-consensus-problem\" style=\"position:relative;\"><a href=\"#what-is-consensus-problem\" aria-label=\"what is consensus problem permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>What is consensus problem</h2>\n<p>하나의 클라이언트와 서버가 있고 클라이언트가 서버에게 데이터를 전달한다고 가정해보겠습니다.\n서버는 하나의 노드로 이루어져있기 때문에 합의가 이루어지는건 아주 쉬운 문제입니다.\n(여기에서 말하는 합의는 공유된 상태라고 이해하시면 됩니다)</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1-KZIAy8UAFgLlUCHESjbOO7pgCVHByGS\" alt=\"con1\"></p>\n<p>만일 위 그림처럼 여러 노드로 이루어진 분산 서버에서 합의를 이루어내야한다면 어떻게 해야할까요?\n이러한 문제를 <strong>distributed consensus problem</strong> 이라고 합니다.</p>\n<br>\n<h2 id=\"raft-algorithm\" style=\"position:relative;\"><a href=\"#raft-algorithm\" aria-label=\"raft algorithm permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Raft Algorithm</h2>\n<p>Raft의 node는 <strong>Follower, Candidate, Leader</strong>라는 3가지 state를 가집니다.\n모든 노드는 처음에 Follower state를 가지고 시작합니다.\n만일 Follower가 Leader의 응답을 받지 못하면 Candidate 상태로 전환될 수 있습니다.</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1CiOwa7f7dv50HgqvF3Rm4MrWVQlQMRF4\" alt=\"election\"></p>\n<p>Candidate는 다른 노드들에게 투표를 요청하고 노드들은 투표 결과를 응답으로 전달합니다.\n노드 중 가장 많은 표를 얻은 노드는 Leader가 될 수 있습니다.\n이러한 프로세스를 <strong>Leader Election</strong> 이라고 부릅니다.</p>\n<br>\n<h2 id=\"leader-election\" style=\"position:relative;\"><a href=\"#leader-election\" aria-label=\"leader election permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Leader Election</h2>\n<p>Raft는 투표를 관리하기 위해 두 가지 timeout 설정을 가지고 있습니다.\n첫 번째는 <strong>Election timeout</strong> 입니다.\nElection timeout 이란, Follower에서 Candidate로 전환되기 위해 기다리는 시간을 의미합니다.\n일반적으로 Election timeout은 150ms에서 300ms 사이의 값으로 랜덤하게 설정됩니다.</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=18EJCDHGadTVHAtFEoXIms6OnB8hn8DTY\" alt=\"timeout\"></p>\n<ol>\n<li>Election timeout이 끝나면 Follower는 Candidate가 되고 Election term을 시작합니다.</li>\n<li>Candidate는 본인에게 투표를 하고 다른 노드들에게 투표 요청 메세지를 전달합니다.</li>\n<li>만일 메세지를 받는 노드가 해당 Election term에서 아직 투표를 하지 않았다면, 먼저 메세지를 전달해준 Candidate에게 투표합니다.</li>\n<li>투표를 마친 해당 노드는 Election timeout이 초기화 됩니다.</li>\n<li>가장 많은 표를 받은 노드가 Leader로 선정됩니다.</li>\n</ol>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=14gQt-B4NYslCtwca8xcATt9a2IVH7qqH\" alt=\"reelection\"></p>\n<ol>\n<li>선정 이후 Leader는 Append Entries 메세지를 Follower들에게 전송합니다.\n(이 메세지는 <strong>Heartbeat timeout</strong> 에 설정된 간격마다 보내게 됩니다)</li>\n<li>Follower들은 Append Entries 메세지를 받으면 Election timeout이 초기화되고 메세지에 대한 응답을 Leader에게 보냅니다.</li>\n<li>만일 Follower에게 Heartbeat가 도달하지 않으면 다시 Election term이 시작되고, Follower는 Candidate 상태로 전환됩니다.\n(위 그림은 노드A가 죽고 난 이후 노드B가 Leader로 선정되고 Heartbeat 메세지를 전달하는 예시입니다)</li>\n</ol>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1OtRVbaqBh-QmGg5JjDF4hxt4LFxK4oTP\" alt=\"same1\"></p>\n<ol>\n<li>만일 두 개의 노드가 동시에 Election term을 시작하고 메세지가 동시에 Follower에게 도달한다고 가정해보겠습니다.</li>\n<li>이러한 경우 노드A, 노드B는 2표씩 얻게 되고, 표가 동일하므로 해당 Election term에는 Leader가 선정되지 않습니다.</li>\n<li>Leader가 선정되지 않았으므로 Election timeout에 따라 새로운 Election term을 시작하게 됩니다.</li>\n</ol>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1o-llsn2rZop8u0jxzam8_K2hu-3n-nvD\" alt=\"same2\"></p>\n<br>\n<h2 id=\"log-replication\" style=\"position:relative;\"><a href=\"#log-replication\" aria-label=\"log replication permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Log Replication</h2>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=13PUDuWgR3bl8frAbiHhpkRieWuKrygVI\" alt=\"message\"></p>\n<p>Leader가 선정되고 난 이후, 시스템의 모든 변화는 Leader를 통해 이루어집니다.\n클라이언트는 Leader에게 데이터를 전달하고, Leader는 데이터의 복제하여 Follower에게 전달합니다.\n이 과정은 앞서 언급했던 <strong>Append Entries</strong> 메세지를 통해 이루어집니다.</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1RQVmzrOGOg0HZnZ8fO5dpZwoW7XVMd79\" alt=\"res\"></p>\n<p>Follower는 받은 데이터를 commit 하고 결과를 Leader에게 전달합니다.\nLeader는 Follow로부터 받은 결과를 Client에게 전달합니다.</p>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<p>정리하자면 분산 시스템은 fault-tolerence를 보장하기 위해 consensus algorithm을 사용하고 있고,\n분산 시스템을 다루는 프레임워크마다 Consensus 구현이 조금씩 다를 수 있습니다.\n그리고 원활한 Leader Election을 위해 클러스터 노드의 개수는 홀수로 구성하는 것이 좋습니다.</p>\n<p>Raft의 경우 Redis cluster에서 응용하여 사용하고 있고,\nElasticsearch cluster 또한 quorum-based consensus algorithm을 사용하고 있습니다.\n아래의 Raft 논문과 시각화 자료 링크를 보시면 더 쉽게 이해할 수 있습니다.</p>\n<ul>\n<li><a href=\"https://raft.github.io/raft.pdf\">https://raft.github.io/raft.pdf</a></li>\n<li><a href=\"http://thesecretlivesofdata.com/raft/\">http://thesecretlivesofdata.com/raft/</a></li>\n<li><a href=\"https://raft.github.io/\">https://raft.github.io/</a></li>\n</ul>\n<br>","excerpt":"Consensus란 분산 시스템에서 노드 간의 상태를 공유하는 알고리즘을 말합니다.\n가장 유명한 알고리즘으로 Paxos…"}}}},{"node":{"title":"AWS에 Hadoop MR 어플리케이션 환경 구축하기","id":"314dca06-efff-5b51-a3f2-609f2e02b3bb","slug":"aws-hadoop","publishDate":"June 13, 2018","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"85e2c430-57ba-5039-afc3-8ba29e23441f","childMarkdownRemark":{"id":"fa2082b2-a22e-59b9-a803-553e8dc09e59","timeToRead":4,"html":"<p>이번 학기에 하둡 프로그래밍 강의를 들으면서 정말 실습 환경의 개선이 필요하다는 생각이 들었습니다...\n나약한 실습 환경속에서 과제와 기말 프로젝트를 제출해야하는 후배들을 위해 AWS를 추천합니다!</p>\n<br>\n<h2 id=\"ec2-amazon-linux2에-기본-환경-구축\" style=\"position:relative;\"><a href=\"#ec2-amazon-linux2%EC%97%90-%EA%B8%B0%EB%B3%B8-%ED%99%98%EA%B2%BD-%EA%B5%AC%EC%B6%95\" aria-label=\"ec2 amazon linux2에 기본 환경 구축 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>EC2 Amazon Linux2에 기본 환경 구축</h2>\n<p>AWS에는 EMR이라는 클러스터 서비스가 있지만, 스터디 목적이라면 비용을 생각해서 사용하지 않겠습니다.\nAmazon Linux AMI는 EC2에서 편하게 사용할 수 있도록 지원하고 관리하는 리눅스 이미지입니다.\n만일 학생용 크레딧이 있다면 <strong>t2.medium</strong> 인스턴스를 추천합니다.</p>\n<p>먼저, JAVA JDK와 Hadoop 파일을 받겠습니다. 실습 환경은 자바 7, 하둡 1.2 버전입니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token function\">sudo</span> yum update -y\n$ <span class=\"token function\">sudo</span> yum <span class=\"token function\">install</span> -y java-1.7.0-openjdk-devel\n$ <span class=\"token function\">wget</span> https://archive.apache.org/dist/hadoop/core/hadoop-1.2.1/hadoop-1.2.1.tar.gz\n$ <span class=\"token function\">tar</span> xvfz hadoop-1.2.1</code></pre></div>\n<p>그리고 자바 프로젝트를 위해 Maven도 설치해줍니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token function\">wget</span> http://mirror.navercorp.com/apache/maven/maven-3/3.5.3/binaries/apache-maven-3.5.3-bin.tar.gz\n$ <span class=\"token function\">tar</span> xvfs apache-maven-3.5.3-bin.tar.gz\n$ <span class=\"token function\">mv</span> apache-maven-3.5.3/ apache-maven\n$ <span class=\"token function\">sudo</span> <span class=\"token function\">vi</span> /etc/profile.d/maven.sh\n\n<span class=\"token comment\"># Apache Maven Environment Variables</span>\n<span class=\"token comment\"># MAVEN_HOME for Maven 1 - M2_HOME for Maven 2</span>\n$ <span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">M2_HOME</span><span class=\"token operator\">=</span>/home/ec2-user/apache-maven\n$ <span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\"><span class=\"token environment constant\">PATH</span></span><span class=\"token operator\">=</span><span class=\"token variable\">${M2_HOME}</span>/bin:<span class=\"token variable\">${<span class=\"token environment constant\">PATH</span>}</span>\n\n$ <span class=\"token function\">chmod</span> +x maven.sh\n$ <span class=\"token builtin class-name\">source</span> /etc/profile.d/maven.sh</code></pre></div>\n<p>정상적으로 설치가 되었다면 아래의 명령어에 대한 결과가 나옵니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ java --version\n$ mvn --version</code></pre></div>\n<br>\n<h2 id=\"hadoop-환경-구축\" style=\"position:relative;\"><a href=\"#hadoop-%ED%99%98%EA%B2%BD-%EA%B5%AC%EC%B6%95\" aria-label=\"hadoop 환경 구축 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Hadoop 환경 구축</h2>\n<p>실습환경은 <strong>Pseudo-Distibuted</strong> 모드로 진행합니다.\n먼저 Password less SSH Login을 설정해주어야 합니다.\n그리고 편의를 위해 hadoop-1.2.1 폴더에 Symbolic link를 생성하겠습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token comment\"># ssh login setting</span>\n$ ssh-keygen -t rsa -P <span class=\"token string\">\"\"</span>\n$ <span class=\"token function\">cat</span> /home/ec2-user/.ssh/id_rsa.pub <span class=\"token operator\">>></span> /home/ec2-user/.ssh/authorized_keys\n\n<span class=\"token comment\"># symbolic link</span>\n$ <span class=\"token function\">ln</span> -s hadoop-1.2.1 hadoop</code></pre></div>\n<p>이제 HDFS와 MR 실행을 위해 설정파일을 수정해줍니다.\n먼저 <code class=\"language-text\">hadoop-env.sh</code>을 열어 <code class=\"language-text\">JAVA_HOME</code> 환경변수를 지정해줍니다.\n가상분산모드에서는 masters, slaves 파일을 수정할 필요가 없습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token builtin class-name\">cd</span> hadoop\n$ <span class=\"token function\">vi</span> conf/hadoop-env.sh\n\n<span class=\"token comment\"># set JAVA_HOME in this file, so that it is correctly defined on</span>\n<span class=\"token comment\"># remote nodes.</span>\n\n<span class=\"token comment\"># The java implementation to use. Required.</span>\n<span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">JAVA_HOME</span><span class=\"token operator\">=</span>/usr/lib/jvm/java-1.7.0\n\n<span class=\"token comment\"># Extra Java CLASSPATH elements.  Optional.</span>\n<span class=\"token comment\"># export HADOOP_CLASSPATH=</span></code></pre></div>\n<p>이제 <code class=\"language-text\">core-site.xml</code> 파일을 아래와 같이 수정해줍니다.\nHDFS 데이터 파일들은 홈 디렉토리의 hadoop-data 폴더에 저장하겠습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token function\">vi</span> conf/core-site.xml\n\n<span class=\"token operator\">&lt;</span>configuration<span class=\"token operator\">></span>\n    <span class=\"token operator\">&lt;</span>property<span class=\"token operator\">></span>\n        <span class=\"token operator\">&lt;</span>name<span class=\"token operator\">></span>fs.default.name<span class=\"token operator\">&lt;</span>/name<span class=\"token operator\">></span>\n        <span class=\"token operator\">&lt;</span>value<span class=\"token operator\">></span>hdfs://localhost:900<span class=\"token operator\"><span class=\"token file-descriptor important\">0</span>&lt;</span>/value<span class=\"token operator\">></span>\n    <span class=\"token operator\">&lt;</span>/property<span class=\"token operator\">></span>\n    <span class=\"token operator\">&lt;</span>property<span class=\"token operator\">></span>\n        <span class=\"token operator\">&lt;</span>name<span class=\"token operator\">></span>hadoop.tmp.dir<span class=\"token operator\">&lt;</span>/name<span class=\"token operator\">></span>\n        <span class=\"token operator\">&lt;</span>value<span class=\"token operator\">></span>/home/ec2-user/hadoop-data/<span class=\"token operator\">&lt;</span>/value<span class=\"token operator\">></span>\n    <span class=\"token operator\">&lt;</span>/property<span class=\"token operator\">></span>\n<span class=\"token operator\">&lt;</span>/configuration<span class=\"token operator\">></span></code></pre></div>\n<p><code class=\"language-text\">hdfs-site.xml</code> 파일도 수정해줍니다.\ndfs.replication 프로퍼티는 복제 개수를 의미합니다.\n일반적으로 복제 개수를 3으로 두는 것을 권장하지만,\n실습에서는 Fully-Distributed 모드가 아니기 때문에 1로 설정하겠습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token function\">vi</span> conf/hdfs-site.xml\n\n<span class=\"token operator\">&lt;</span>configuration<span class=\"token operator\">></span>\n    <span class=\"token operator\">&lt;</span>property<span class=\"token operator\">></span>\n        <span class=\"token operator\">&lt;</span>name<span class=\"token operator\">></span>dfs.replication<span class=\"token operator\">&lt;</span>/name<span class=\"token operator\">></span>\n        <span class=\"token operator\">&lt;</span>value<span class=\"token operator\">></span><span class=\"token operator\"><span class=\"token file-descriptor important\">1</span>&lt;</span>/value<span class=\"token operator\">></span>\n    <span class=\"token operator\">&lt;</span>/property<span class=\"token operator\">></span>\n<span class=\"token operator\">&lt;</span>/configuration<span class=\"token operator\">></span></code></pre></div>\n<p><code class=\"language-text\">mapred-site.xml</code> 파일도 수정해줍니다.\nmapred.job.tracker 프로퍼티는 job tracker가 동작하는 서버를 말합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token function\">vi</span> conf/mapred-site.xml\n\n<span class=\"token operator\">&lt;</span>configuration<span class=\"token operator\">></span>\n    <span class=\"token operator\">&lt;</span>property<span class=\"token operator\">></span>\n        <span class=\"token operator\">&lt;</span>name<span class=\"token operator\">></span>mapred.job.tracker<span class=\"token operator\">&lt;</span>/name<span class=\"token operator\">></span>\n        <span class=\"token operator\">&lt;</span>value<span class=\"token operator\">></span>localhost:900<span class=\"token operator\"><span class=\"token file-descriptor important\">1</span>&lt;</span>/value<span class=\"token operator\">></span>\n    <span class=\"token operator\">&lt;</span>/property<span class=\"token operator\">></span>\n<span class=\"token operator\">&lt;</span>/configuration<span class=\"token operator\">></span></code></pre></div>\n<br>\n<h2 id=\"hadoop-mr\" style=\"position:relative;\"><a href=\"#hadoop-mr\" aria-label=\"hadoop mr permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Hadoop MR</h2>\n<p>이제 NameNode를 초기화하고 하둡과 관련된 모든 데몬을 실행합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">./bin/hadoop namenode-format\n./bin/start-all.sh</code></pre></div>\n<p>jps를 통해 자바 프로세스가 제대로 실행되었는지 확인할 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ jps\n3368 TaskTracker\n2991 DataNode\n3241 JobTracker\n3480 Jps\n2872 NameNode\n3139 SecondaryNameNode</code></pre></div>\n<p>HDFS 웹 인터페이스 주소는 <a href=\"http://localhost:50070\">http://localhost:50070</a> 이며,\nMapReduce 웹 인터페이스 주소는 <a href=\"http://localhost:50030\">http://localhost:50030</a> 입니다.\n들어가시면 아래와 같은 화면이 나타납니다.</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=15OIYCbnc1cy93jJgqX1y8a5vfpCBkpqM\"></p>\n<p>이제 기본으로 설치되어 있는 WordCount 예제를 실행시켜보겠습니다.\n먼저 WordCount 예제의 input 데이터를 HDFS에 업로드하고 jar 파일과 output 경로를 지정해줍니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ ./bin/hadoop fs -put conf/hadoop-env.sh ./hadoop-env.sh\n$ ./bin/hadoop jar hadoop-examples-1.2.1.jar wordcount hadoop-env.sh output</code></pre></div>\n<p>HDFS에 write한 결과는 HDFS의 output 경로에서 확인하실 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ ./bin/hadoop fs -ls output\n$ ./bin/hadoop fs -cat output/part-r-00000</code></pre></div>\n<br>\n<h2 id=\"intellij\" style=\"position:relative;\"><a href=\"#intellij\" aria-label=\"intellij permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>IntelliJ</h2>\n<p>이번엔 예제가 아니라 Hadoop MR 어플리케이션 프로젝트를 새로 생성해보겠습니다.\nIntelliJ에서 JAVA, maven 프로젝트를 생성하시면 됩니다.</p>\n<p>그리고 pom.xml은 아래와 같이 수정해줍니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"xml\"><pre class=\"language-xml\"><code class=\"language-xml\"><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>groupId</span><span class=\"token punctuation\">></span></span>org.swalloow.hadoop<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>groupId</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>artifactId</span><span class=\"token punctuation\">></span></span>hadoop<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>artifactId</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>version</span><span class=\"token punctuation\">></span></span>1.0-SNAPSHOT<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>version</span><span class=\"token punctuation\">></span></span>\n\n<span class=\"token comment\">&lt;!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-core --></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>dependencies</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>dependency</span><span class=\"token punctuation\">></span></span>\n        <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>groupId</span><span class=\"token punctuation\">></span></span>org.apache.hadoop<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>groupId</span><span class=\"token punctuation\">></span></span>\n        <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>artifactId</span><span class=\"token punctuation\">></span></span>hadoop-core<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>artifactId</span><span class=\"token punctuation\">></span></span>\n        <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>version</span><span class=\"token punctuation\">></span></span>1.2.1<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>version</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>dependency</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>dependencies</span><span class=\"token punctuation\">></span></span></code></pre></div>\n<p>Mapper와 Reducer 클래스를 수정한 다음, <code class=\"language-text\">mvn packages</code> 명령어를 통해 jar 파일을 생성합니다.\n그리고 input 파일을 이전과 동일하게 HDFS에 추가하고 생성한 jar 파일을 통해 MR job을 실행시키시면 됩니다.</p>\n<p>아래 링크는 코인 거래 데이터를 입력받아 이동평균선(SMA) 추세를 계산해주는 간단한 예시 프로젝트입니다. 템플릿은 자유롭게 참고하셔도 됩니다!</p>\n<p><a href=\"https://github.com/Swalloow/hadoop-mr-project\">https://github.com/Swalloow/hadoop-mr-project</a></p>\n<br>","excerpt":"…"}}}}]}},"pageContext":{"basePath":"","paginationPath":"","pageNumber":3,"humanPageNumber":4,"skip":19,"limit":6,"numberOfPages":14,"previousPagePath":"/3","nextPagePath":"/5"}}}