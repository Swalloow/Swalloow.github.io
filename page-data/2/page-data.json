{"componentChunkName":"component---src-templates-posts-js","path":"/2","result":{"data":{"allContentfulPost":{"edges":[{"node":{"title":"JupyterHub에 Tensorboard 연동하기","id":"8f863c41-ab16-5084-9ee1-f00bba67af7f","slug":"jupyterhub-tensorboard","publishDate":"October 23, 2021","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"eba6ee8a-eb29-50ba-97f2-89eece6cf63a","childMarkdownRemark":{"id":"20b1d52e-ca00-582b-a661-02275bf14cb9","timeToRead":1,"html":"<p>이 글에서는 JupyterHub 사용자 환경에 tensorboard를 proxy 형태로 연동하는 방법에 대해 정리해보려고 합니다. 연동 과정으로 jupyter-server-proxy 라는 extension을 사용합니다.</p>\n<br>\n<h2 id=\"기존-연동-방식\" style=\"position:relative;\"><a href=\"#%EA%B8%B0%EC%A1%B4-%EC%97%B0%EB%8F%99-%EB%B0%A9%EC%8B%9D\" aria-label=\"기존 연동 방식 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>기존 연동 방식</h2>\n<p>Jupyter Notebook에 Tensorboard를 연동하는 가장 쉬운 방법은 공식문서에 나와있는 <strong>%tensorboard</strong> 를 사용하는 방법입니다. </p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">%load_ext tensorboard\n%tensorboard --logdir logs</code></pre></div>\n<p>이 방법은 간단하지만 노트북 내에서 접근하거나 IP주소:포트번호를 통해 접근하게 됩니다.</p>\n<p>따라서 JupyterHub와 같이 여러 사용자가 쓰는 환경이라면 나의 Tensorboard 프로세스에 어떤 주소를 통해 접근해야 하는지 매번 찾아야 합니다.\n또한 JupyterHub는 인증 과정을 거치는 반면 프로세스로 직접 띄우는 텐서보드는 인증 없이 접근이 가능해집니다.</p>\n<br>\n<h2 id=\"jupyter-server-proxy\" style=\"position:relative;\"><a href=\"#jupyter-server-proxy\" aria-label=\"jupyter server proxy permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>jupyter-server-proxy</h2>\n<p>jupyter-server-proxy는 외부 웹 서비스의 프록시를 지원하는 extension 입니다.\njupyter-server-proxy를 통해 연동하면 다음과 같은 이점을 가질 수 있습니다.</p>\n<ul>\n<li>tensorboard 프로세스는 JupyterLab Launcher를 통해 생성됩니다</li>\n<li>프록시를 통해 /hub/proxy/ 하위의 주소로 연결되므로 인증이 그대로 사용됩니다</li>\n</ul>\n<br>\n<h2 id=\"jupyter-tensorboard-proxy-설치\" style=\"position:relative;\"><a href=\"#jupyter-tensorboard-proxy-%EC%84%A4%EC%B9%98\" aria-label=\"jupyter tensorboard proxy 설치 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>jupyter-tensorboard-proxy 설치</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># pip install jupyter-tensorboard-proxy</span>\n\n<span class=\"token comment\"># log path</span>\nlog_dir <span class=\"token operator\">=</span> <span class=\"token string\">\"/home/jovyan/logs/\"</span> <span class=\"token operator\">+</span> datetime<span class=\"token punctuation\">.</span>datetime<span class=\"token punctuation\">.</span>now<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>strftime<span class=\"token punctuation\">(</span><span class=\"token string\">\"%Y%m%d-%H%M\"</span><span class=\"token punctuation\">)</span>\ntensorboard_callback <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>callbacks<span class=\"token punctuation\">.</span>TensorBoard<span class=\"token punctuation\">(</span>log_dir<span class=\"token operator\">=</span>log_dir<span class=\"token punctuation\">,</span> histogram_freq<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>설치 방법은 아주 간단합니다. singleuser profile 이미지에 위의 패키지만 설치해주면 됩니다. 기본으로 바라보는 로그 경로는 $HOME/logs 입니다. 따라서 tensorflow 코드에서 로그 경로를 연결해주어야 합니다.</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=161QSE21LbDPZzQzG6Szq3-IiER1dqbgT\" alt=\"extension\"></p>\n<br>\n<h2 id=\"정리\" style=\"position:relative;\"><a href=\"#%EC%A0%95%EB%A6%AC\" aria-label=\"정리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>정리</h2>\n<p>tensorboard가 아니더라도 jupyter-server-proxy를 사용하면 Spark UI, R Studio Session 등 다양한 외부 웹 서비스들과 연동할 수 있습니다.</p>\n<ul>\n<li><a href=\"https://github.com/jupyterhub/jupyter-server-proxy\">https://github.com/jupyterhub/jupyter-server-proxy</a></li>\n<li><a href=\"https://github.com/kopwei/jupyter-tensorboard-proxy\">https://github.com/kopwei/jupyter-tensorboard-proxy</a></li>\n</ul>","excerpt":"이 글에서는 JupyterHub 사용자 환경에 tensorboard를 proxy…"}}}},{"node":{"title":"Data Mesh 아키텍쳐의 네 가지 원칙","id":"f4493d83-09a7-5393-83bc-85f0047f4b7a","slug":"data-mesh-principle","publishDate":"September 25, 2021","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"1f16465f-7355-5975-a52c-8fd36c5a3819","childMarkdownRemark":{"id":"fc0295d1-3d94-50ed-be82-a4cd9f724dc7","timeToRead":5,"html":"<p>이 글은 martinfowler.com의 <a href=\"https://martinfowler.com/articles/data-mesh-principles.html\">Data Mesh Principles and Logical Architecture</a> 원문을 정리한 내용입니다. Data Mesh 아키텍쳐의 네 가지 원칙에 대한 내용은 <a href=\"https://martinfowler.com/articles/data-monolith-to-mesh.html\">How to Move Beyond a Monolithic Data Lake to a Distributed Data Mesh</a>의 후속글 입니다.</p>\n<br>\n<h2 id=\"the-great-divide-of-data\" style=\"position:relative;\"><a href=\"#the-great-divide-of-data\" aria-label=\"the great divide of data permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>The great divide of data</h2>\n<p>오늘 날의 데이터 환경은 <strong>운영 데이터 영역</strong>과 <strong>분석 데이터 영역</strong>으로 나누어 볼 수 있습니다. 운영 데이터는 주로 마이크로서비스에서 사용하는 데이터베이스에 해당하며 트랜잭션과 비즈니스 요구사항을 담고 있습니다. 분석 데이터는 특정 시간 경과에 따라 집계된 비즈니스 데이터이며 주로 BI / 분석 리포트나 ML 모델링에 사용됩니다.</p>\n<p><img src=\"https://martinfowler.com/articles/data-mesh-principles/data-planes.png\" alt=\"data-planes\"></p>\n<p>데이터 아키텍쳐와 조직 구조 또한 두 가지 데이터 영역을 반영합니다.\n운영 환경으로부터 데이터를 가져오고 ETL 프로세스를 거쳐 분석 데이터를 생성합니다.\n그리고 분석 데이터를 또 다시 운영 환경에 활용하는 경우가 많습니다.\n이러한 데이터 흐름은 빈번한 ETL 프로세스의 실패와 복잡한 파이프라인으로 이어졌습니다.</p>\n<p><img src=\"https://martinfowler.com/articles/data-mesh-principles/data-warehouse.png\" alt=\"dw\"></p>\n<p>분석 데이터 영역은 <strong>데이터 레이크와 데이터 웨어하우스</strong>라는 아키텍쳐로 나누어집니다.\n데이터 레이크는 데이터 사이언스 환경을 지원하며 데이터 웨어하우스는 분석 리포트 및 BI 도구를 지원합니다.</p>\n<p><img src=\"https://martinfowler.com/articles/data-mesh-principles/data-lake.png\" alt=\"datalake\"></p>\n<p>Data Mesh에서는 분석 데이터 영역에 중점을 두고 두 가지 데이터 영역을 연결하고 합니다.\n두 가지 영역의 데이터를 관리하기 위해 기술 스택을 나누고 조직과 팀을 분리하면 안 됩니다.\n마이크로서비스 아키텍쳐로 인해 운영 데이터도 과거에 비해 많이 성숙해졌으며 데이터는 각 마이크로서비스의 API를 통해 제어됩니다. 하지만 분석 데이터에 대한 관리 및 접근 제어는 여전히 어려운 과제로 남아있습니다. Data Mesh는 이 부분을 중점적으로 해결하고 합니다.</p>\n<p>Data Mesh의 목표는 분석 데이터와 히스토리로부터 가치를 얻기 위한 기반을 만드는 것 입니다.\n데이터 환경의 지속적인 변화에도 대응하고 데이터의 품질과 무결성을 제공하면서 데이터 사용에 대한 다양한 요구사항을 지원할 수 있어야 합니다. 이 글에서는 이를 달성하기 위한 네 가지 원칙을 제안합니다.</p>\n<br>\n<h2 id=\"domain-ownership\" style=\"position:relative;\"><a href=\"#domain-ownership\" aria-label=\"domain ownership permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Domain Ownership</h2>\n<p>Data Mesh는 지속적인 변화와 확장성을 지원하기 위해 데이터를 가장 잘 이해하는 사람들에게 <strong>책임을 분산하고 탈중앙화</strong>하는데 기반을 두고 있습니다. 여기서 분석 데이터, 메타 데이터에 대한 소유권을 어떻게 나누어야 하는지에 대한 의문이 생기게 됩니다.</p>\n<p>요즘 조직 구조는 비즈니스 도메인을 기준으로 나누어집니다. 이러한 구조를 통해 도메인 경계에 따라 지속적인 발전을 할 수 있게 만듭니다. 따라서 비즈니스 도메인의 경계(Bounded Context)를 기준으로 나누는 것이 적절하다고 볼 수 있습니다.</p>\n<p>이러한 기준을 가지고 분리하려면 분석 데이터를 도메인 별로 나누는 아키텍쳐를 모델링해야 합니다. 이 아키텍처에서 도메인의 인터페이스에는 운영 데이터 뿐만 아니라 도메인이 제공하는 분석 데이터도 포함됩니다.</p>\n<p><img src=\"https://martinfowler.com/articles/data-mesh-principles/domain-notation.png\" alt=\"domain-not\"></p>\n<p>각 도메인은 하나 이상의 운영 API와 하나 이상의 분석 데이터를 제공합니다.\n또한 각 도메인은 다른 도메인의 운영 및 분석 데이터와 의존 관계를 가질 수도 있습니다.</p>\n<p><img src=\"https://martinfowler.com/articles/data-mesh-principles/domains.png\" alt=\"domains\"></p>\n<p>위의 예시와 같이 Podcasts 도메인은 Users 도메인의 데이터를 통해 Podcast 청취자들의 정보를 데이터화 할 수 있습니다.</p>\n<br>\n<h2 id=\"data-as-a-product\" style=\"position:relative;\"><a href=\"#data-as-a-product\" aria-label=\"data as a product permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Data as a product</h2>\n<p>기존 데이터 분석 아키텍쳐에서 어떤 데이터가 있는지 탐색하고 이해하고 데이터 품질을 유지하는 것이 큰 과제로 남아있었습니다. 이를 해결하지 않으면 Data Mesh 아키텍쳐에서 더 큰 문제로 다가올 수 있습니다. 탈중앙화 원칙에 따라 데이터를 제공하는 곳과 팀의 수가 늘어나기 때문입니다.</p>\n<p><strong>Data as a product 원칙은 데이터 사일로와 데이터 품질 문제를 해결하기 위한 방법</strong>입니다.\n도메인에서 제공하는 분석 데이터는 product로 취급되어야 하며 데이터의 소비자는 고객으로 받아들여야 합니다.</p>\n<p>조직에서는 도메인 데이터에 대한 PO(Product Owner)를 지정해야 하며 PO는 데이터가 프로덕트로써 전달되기 위한 여러 역할을 담당합니다. PO는 데이터 사용자가 누구인지, 어떻게 사용하는지 정의하고 데이터에 대해 깊이 이해하고 있어야 합니다. 데이터 품질, 데이터 사용 만족도를 측정하고 데이터에는 이를 지원하기 위한 표준 인터페이스가 개발되어야 합니다. 데이터 사용자와 PO는 꾸준히 커뮤니케이션을 통해 data product를 발전시킬 수 있습니다.</p>\n<p>각 도메인에는 도메인의 data product를 구축하고 운영 및 제공하는 데이터 개발자 역할도 있어야 합니다. 각 도메인 팀은 하나 이상의 data product를 제공할 수 있습니다.</p>\n<p><img src=\"https://martinfowler.com/articles/data-mesh-principles/data-product-components.png\" alt=\"dataproduct\"></p>\n<p>data product는 위와 같이 세 가지 구성 요소로 이루어져 있습니다.</p>\n<h3 id=\"1-code\" style=\"position:relative;\"><a href=\"#1-code\" aria-label=\"1 code permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. Code</h3>\n<ul>\n<li>업스트림 데이터에 대한 ETL 프로세스를 제공하는 데이터 파이프라인 코드</li>\n<li>데이터 스키마, 데이터 품질에 대한 지표, 메타데이터 적용을 위한 API</li>\n<li>접근 제어 정책, 데이터 정책을 적용하기 위한 코드 (비식별화 등)</li>\n</ul>\n<br>\n<h3 id=\"2-data-and-metadata\" style=\"position:relative;\"><a href=\"#2-data-and-metadata\" aria-label=\"2 data and metadata permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. Data and Metadata</h3>\n<ul>\n<li>이벤트, 배치, 관계형 테이블, 그래프 등 다양하게 소비되는 데이터</li>\n<li>각 데이터에 대한 메타데이터 정의</li>\n<li>생성 로직과 접근 제어 정책</li>\n</ul>\n<br>\n<h3 id=\"3-infrastructure\" style=\"position:relative;\"><a href=\"#3-infrastructure\" aria-label=\"3 infrastructure permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. Infrastructure</h3>\n<ul>\n<li>data product 코드를 구축, 배포 및 실행할 수 있는 인프라</li>\n<li>데이터 및 메타데이터에 대한 저장 및 접근을 가능하게 하는 플랫폼</li>\n</ul>\n<br>\n<p><img src=\"https://martinfowler.com/articles/data-mesh-principles/data-product-notation.png\" alt=\"notation\"></p>\n<p>이를 다이어그램으로 표현하면 위와 같습니다.</p>\n<br>\n<h2 id=\"self-serve-data-platform\" style=\"position:relative;\"><a href=\"#self-serve-data-platform\" aria-label=\"self serve data platform permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Self-serve data platform</h2>\n<p>위와 같이 data product를 구축, 배포, 실행 및 모니터링하려면 이를 위해 많은 인프라가 필요합니다. 이를 구성하는데 필요한 기술은 전문적인 영역이라 각 도메인에서 운영하기 어렵습니다. 각 팀이 data product를 자율적으로 개발하고 운영하기 위해 제품의 수명 주기를 프로비저닝하고 관리할 수 있는 추상화된 인프라가 필요합니다. <strong>Self-serve data platform 원칙은 도메인 자율성을 가능하도록 지원하는 플랫폼을 말합니다.</strong></p>\n<p>셀프 서비스 데이터 플랫폼은 데이터 개발자의 워크플로우를 지원할 수 있어야 합니다.\n데이터 제품을 생성하기 위해 필요한 비용과 진입장벽을 낮추고 스키마, 파이프라인 개발, 데이터 리니지, 컴퓨팅 클러스터 등을 지원해야 합니다.</p>\n<p><img src=\"https://martinfowler.com/articles/data-mesh-principles/platform.png\" alt=\"platform\"></p>\n<br>\n<p>셀프 서비스 플랫폼에는 위와 같이 여러 기능을 제공하는 영역이 존재합니다.\n위 그림에서는 아래와 같이 세 가지 영역으로 나누고 있습니다.</p>\n<h3 id=\"1-data-infrastructure-provisioning-plane\" style=\"position:relative;\"><a href=\"#1-data-infrastructure-provisioning-plane\" aria-label=\"1 data infrastructure provisioning plane permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. Data infrastructure provisioning plane</h3>\n<ul>\n<li>경험이 많은 데이터 개발자만 직접 사용</li>\n<li>data product를 실행하는데 필요한 기본 인프라 프로비저닝을 지원</li>\n<li>분산 스토리지, 스토리지 계정과 접근 제어 시스템</li>\n<li>데이터에 대한 분산 쿼리 엔진 프로비저닝</li>\n</ul>\n<h3 id=\"2-data-product-developer-experience-plane\" style=\"position:relative;\"><a href=\"#2-data-product-developer-experience-plane\" aria-label=\"2 data product developer experience plane permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. Data product developer experience plane</h3>\n<ul>\n<li>일반적인 데이터 개발자가 사용하는 기본 인터페이스</li>\n<li>워크플로우 정의를 위해 필요한 복잡성을 추상화해서 제공</li>\n<li>data product에 대한 빌드, 배포, 모니터링 지원</li>\n<li>미리 정의된 표준 규칙을 통해 자동으로 구현</li>\n</ul>\n<h3 id=\"3-data-mesh-supervision-plane\" style=\"position:relative;\"><a href=\"#3-data-mesh-supervision-plane\" aria-label=\"3 data mesh supervision plane permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. Data mesh supervision plane</h3>\n<ul>\n<li>Data Mesh 수준에서 한눈에 볼 수 있는 인터페이스</li>\n<li>data product를 검색할 수 있는 기능</li>\n<li>여러 data product에 걸쳐 필요한 기능</li>\n</ul>\n<br>\n<h2 id=\"federated-computational-governance\" style=\"position:relative;\"><a href=\"#federated-computational-governance\" aria-label=\"federated computational governance permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Federated computational governance</h2>\n<p>지금까지 정의한 내용과 같이 Data Mesh 모델은 분산 아키텍쳐 형태를 가지고 있습니다.\n독립적인 data product를 가지며 각 팀이 구축하고 배포합니다.\n그러나 ML 영역과 같은 곳에서 가치를 얻으려면 각 data product가 상호적으로 운용되어야 합니다. 이러한 상호 운용을 위해 <strong>플랫폼에 의한 의사 결정을 자동화하기 위한 거버넌스 모델</strong>이 필요합니다. 이를 Federated computational governance 원칙이라고 합니다.\n데이터 PO와 데이터 플랫폼 PO가 함께 주도하는 의사 결정 모델은 도메인 의사 결정 권한을 가지며 여러 규칙을 만들고 준수합니다. 이러한 거버넌스를 통해 중앙 집중화와 분산화 사이의 균형을 유지할 수 있습니다.</p>\n<p><img src=\"https://martinfowler.com/articles/data-mesh-principles/governance.png\" alt=\"governance\"></p>\n<p>거버넌스 모델을 구현하기 위해 참여해야 하는 조직과 인센티브 모델을 정의해야 합니다.\n데이터 플랫폼은 거버넌스로부터 정의된 정책을 자동으로 적용하기 위한 기능을 제공해야 합니다.</p>\n<br>\n<h2 id=\"principles-summary\" style=\"position:relative;\"><a href=\"#principles-summary\" aria-label=\"principles summary permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Principles Summary</h2>\n<p><strong>Domain Ownership</strong>을 통해 데이터 생성과 사용자 수의 증가, 데이터 접근 정책의 다양성과 데이터의 확장에 대응할 수 있습니다.</p>\n<p><strong>Data as a product</strong>를 통해 데이터 사용자가 데이터를 쉽게 검색이 가능하고 품질이 보장된 데이터를 사용하며 데이터에 대한 이해도가 올라가고 안전하게 사용할 수 있습니다.</p>\n<p><strong>Self-serve data platform</strong>을 통해 각 도메인 팀이 자율적으로 제품을 만들고 사용할 수 있도록 하며 data product를 쉽게 구축, 실행 및 운영할 수 있습니다.</p>\n<p><strong>Federated computational governance</strong>를 통해 데이터 사용자가 상호 운용을 위한 표준을 따르는 생태계로 운영할 수 있습니다. 이러한 표준 정책은 플랫폼에 반영됩니다.</p>\n<br>","excerpt":"이 글은 martinfowler.com의 Data Mesh Principles and Logical Architecture…"}}}},{"node":{"title":"Spark on Kubernetes: 성능 최적화 방법들","id":"026096e5-5d5d-5809-a3c9-1481f1909414","slug":"spark-on-kubernetes-perf","publishDate":"September 11, 2021","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"66c09a28-a712-595b-b711-4741ad2681b1","childMarkdownRemark":{"id":"048a4410-1e86-5140-9739-04bd0e8c5793","timeToRead":3,"html":"<p>Spark 3.1 버전부터 Spark on Kubernetes가 GA로 변경되었습니다.\n이 글에서는 Spark on YARN 만큼의 성능을 내기 위해서 필요한 설정들에 대해 알아보겠습니다.</p>\n<br>\n<h2 id=\"교차-az-전송-지연-개선\" style=\"position:relative;\"><a href=\"#%EA%B5%90%EC%B0%A8-az-%EC%A0%84%EC%86%A1-%EC%A7%80%EC%97%B0-%EA%B0%9C%EC%84%A0\" aria-label=\"교차 az 전송 지연 개선 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>교차 AZ 전송 지연 개선</h2>\n<p>대부분 사용자들은 가용성을 우려하여 Multi-AZ 사용을 선호합니다.\n하지만 driver, executor pod가 여러 AZ에 분산되어 있는 어플리케이션은 AZ 간 <strong>추가 데이터 전송 비용</strong>이 발생할 수 있습니다. 특히 spark shuffle은 disk IO, network IO에 대한 비용이 많이 드는 연산이므로 latency가 낮은 단일 AZ가 좋은 성능을 보일 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">--conf spark.kubernetes.node.selector.zone=&#39;&lt;availability zone&gt;&#39;</code></pre></div>\n<p>Spark on Kubernetes에서는 Pod Template 또는 node selector 설정을 통해 단일 AZ 노드 그룹에서 실행되도록 설정할 수 있습니다.</p>\n<br>\n<h2 id=\"클러스터-노드-가용성-계산하기\" style=\"position:relative;\"><a href=\"#%ED%81%B4%EB%9F%AC%EC%8A%A4%ED%84%B0-%EB%85%B8%EB%93%9C-%EA%B0%80%EC%9A%A9%EC%84%B1-%EA%B3%84%EC%82%B0%ED%95%98%EA%B8%B0\" aria-label=\"클러스터 노드 가용성 계산하기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>클러스터 노드 가용성 계산하기</h2>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1GLAMXGewFey6ymOrL5ZZDo_oaAW1uE5C\" alt=\"k8s-resource\"></p>\n<p>노드 전체의 리소스를 최대로 사용하기 위해 어느 정도의 리소스를 할당할 수 있는지 계산할 수 있어야 합니다. 모든 Kubernetes 노드는 클러스터 운영을 위해 <strong>OS 시스템과 Kubelet에서 일정량의 리소스를 점유</strong>하고 있습니다. 따라서 Pod에 할당 가능한 리소스를 계산할 때 이 부분은 제외하고 계산해야 합니다. 만약 노드마다 뜨는 daemonset이나 agent와 같은 어플리케이션을 띄웠다면 해당 리소스도 제외되어야 합니다.</p>\n<p>클라우드 인스턴스 유형에 따라 빠르게 보고 싶을 때 <a href=\"https://learnk8s.io/kubernetes-instance-calculator\">Kubernetes Instance Calculator</a>를 사용하면 쉽게 계산할 수 있습니다.</p>\n<br>\n<h2 id=\"셔플-단계에서의-scratch-space-개선\" style=\"position:relative;\"><a href=\"#%EC%85%94%ED%94%8C-%EB%8B%A8%EA%B3%84%EC%97%90%EC%84%9C%EC%9D%98-scratch-space-%EA%B0%9C%EC%84%A0\" aria-label=\"셔플 단계에서의 scratch space 개선 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>셔플 단계에서의 scratch space 개선</h2>\n<p>Spark Shuffle 발생 시 중간 파일들이 생기게 되는데, 보통 driver나 executor의 로컬 디렉토리를 사용합니다. 하지만 Kubernetes의 경우, 기본 값으로 Pod 내부의 볼륨(emptyDir)을 사용하고 있습니다.</p>\n<p>emptyDir 유형의 볼륨은 Docker Storage Driver의 CoW(Copy-On-Write) 오버헤드로 인해 작은 파일 쓰기를 반복하는 경우 속도가 느려질 수 있습니다. 이를 개선하기 위해 Spark on Kubernetes GA 버전에서는 2가지의 설정이 추가되었습니다.</p>\n<br>\n<h3 id=\"1-spark-25262-support-tmpfs-for-local-dirs-in-k8s\" style=\"position:relative;\"><a href=\"#1-spark-25262-support-tmpfs-for-local-dirs-in-k8s\" aria-label=\"1 spark 25262 support tmpfs for local dirs in k8s permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. [SPARK-25262] Support tmpfs for local dirs in k8s</h3>\n<p>먼저 tmpfs를 local dir로 활용하는 방법입니다.\ntmpfs는 RAM 기반 파일 시스템으로 노드 재부팅 시 지워지고, 파일이 컨테이너 메모리 제한에 포함됩니다. 설정 방법은 아래와 같이 간단하지만 tmpfs 사이즈가 커질 수록 Pod OOM이 발생할 가능성이 크다보니 운영할 때는 번거로울 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">&quot;spark.kubernetes.local.dirs.tmpfs&quot;: &quot;true&quot;</code></pre></div>\n<br>\n<h3 id=\"2-spark-27499-support-mapping-sparklocaldir-to-hostpath-volume\" style=\"position:relative;\"><a href=\"#2-spark-27499-support-mapping-sparklocaldir-to-hostpath-volume\" aria-label=\"2 spark 27499 support mapping sparklocaldir to hostpath volume permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. [SPARK-27499] Support mapping spark.local.dir to hostPath volume</h3>\n<p>다음은 host에 마운트된 볼륨을 직접 사용하는 방법입니다. hostPath 볼륨을 spark.local.dir에 할당해서 셔플 과정에서의 디스크 성능을 향상시킬 수 있습니다. 다만 인스턴스에 SSD 또는 NVMe와 같은 볼륨을 추가로 마운트하는 경우에 더 좋은 효과를 볼 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">spec</span><span class=\"token punctuation\">:</span>\n  <span class=\"token punctuation\">...</span>\n  <span class=\"token key atrule\">volumes</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"spark-local-dir-1\"</span>\n      <span class=\"token key atrule\">hostPath</span><span class=\"token punctuation\">:</span>\n        <span class=\"token key atrule\">path</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"/tmp/spark-local-dir\"</span>\n  <span class=\"token key atrule\">executor</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">instances</span><span class=\"token punctuation\">:</span> <span class=\"token number\">10</span>\n    <span class=\"token key atrule\">cores</span><span class=\"token punctuation\">:</span> <span class=\"token number\">2</span>\n    <span class=\"token punctuation\">...</span>.\n    <span class=\"token key atrule\">volumeMounts</span><span class=\"token punctuation\">:</span>\n      <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"spark-local-dir-1\"</span></code></pre></div>\n<br>\n<h2 id=\"executor-pod-batch-관련-설정\" style=\"position:relative;\"><a href=\"#executor-pod-batch-%EA%B4%80%EB%A0%A8-%EC%84%A4%EC%A0%95\" aria-label=\"executor pod batch 관련 설정 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Executor Pod Batch 관련 설정</h2>\n<p>보통 무거운 작업은 executor 여러 개가 떠서 처리하는 경우가 많습니다.\nSpark on Kubernetes에는 executor pod을 생성할 때 <strong>batch size와 delay</strong>가 존재합니다.</p>\n<p>예를 들어 executor 10개를 띄울 때 기본 설정 값이 <code class=\"language-text\">batch size = 5, delay = 1</code>로 되어 있다면, executor pod 5개가 동시에 뜨고 1초 지연 이후에 5개가 추가로 생성됩니다.\n이 설정 값은 Kubernetes Scheduler와 driver pod의 부하를 고려해서 설정해주어야 합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">&quot;spark.kubernetes.allocation.batch.size&quot;: &quot;5&quot;\n&quot;spark.kubernetes.allocation.batch.delay&quot;: &quot;1s&quot;</code></pre></div>\n<br>\n<p>반면 아직 3.1 버전 기준으로 지원하지 않는 설정들은 아래와 같습니다.</p>\n<ul>\n<li>External Shuffle Service는 지원하지 않음</li>\n<li>Job Queue 없음 (Future Work)</li>\n</ul>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<ul>\n<li><a href=\"https://aws.amazon.com/ko/blogs/containers/optimizing-spark-performance-on-kubernetes\">https://aws.amazon.com/ko/blogs/containers/optimizing-spark-performance-on-kubernetes</a></li>\n<li><a href=\"https://aws.github.io/aws-emr-containers-best-practices\">https://aws.github.io/aws-emr-containers-best-practices</a></li>\n<li><a href=\"https://spark.apache.org/docs/latest/running-on-kubernetes.html\">https://spark.apache.org/docs/latest/running-on-kubernetes.html</a></li>\n</ul>","excerpt":"Spark 3.1 버전부터 Spark on Kubernetes가 GA로 변경되었습니다.\n이 글에서는 Spark on YARN…"}}}},{"node":{"title":"여러 조직이 함께 사용하는 Airflow 만들기","id":"1287610b-f42e-5418-85fd-7b80bac6222f","slug":"airflow-multi-tenent-1","publishDate":"August 15, 2021","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"5a118100-3719-5895-9fd0-bf3c690e91e8","childMarkdownRemark":{"id":"070cdd72-3f88-5a52-b46d-48a515c1b70a","timeToRead":6,"html":"<p>사내 데이터가 다양해지고 사용자가 많아지면 접근 제어와 권한 등 다양한 고민이 생기게 됩니다.\n이 글에서는 여러 조직이 함께 사용하는 Airflow를 만들 때 알아두면 좋은 내용들에 대해 정리해보려고 합니다.</p>\n<ul>\n<li><a href=\"https://swalloow.github.io/airflow-multi-tenent-1/#airflow-rbac\">Airflow RBAC</a></li>\n<li><a href=\"https://swalloow.github.io/airflow-multi-tenent-1/#dag-level-permissions\">DAG-Level Permissions</a></li>\n<li><a href=\"https://swalloow.github.io/airflow-multi-tenent-1/#connection-variable-access-control\">Connection, Variable Permissions</a></li>\n<li><a href=\"https://swalloow.github.io/airflow-multi-tenent-1/#cluster-policy\">Cluster Policy</a></li>\n</ul>\n<br>\n<h2 id=\"접근-제어가-필요한-경우\" style=\"position:relative;\"><a href=\"#%EC%A0%91%EA%B7%BC-%EC%A0%9C%EC%96%B4%EA%B0%80-%ED%95%84%EC%9A%94%ED%95%9C-%EA%B2%BD%EC%9A%B0\" aria-label=\"접근 제어가 필요한 경우 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>접근 제어가 필요한 경우</h2>\n<p>먼저 접근 제어는 모든 조직에 필요한 내용은 아닙니다. 다만 아래와 같은 경우에는 필요할 수 있습니다.</p>\n<ul>\n<li>다른 사람이 실행, 중지 권한을 가져서는 안될 만큼 중요한 DAG이 존재하는 경우</li>\n<li>민감한 데이터를 다루는 DAG이 존재하는 경우 (HR, 매출 데이터 등)</li>\n<li>팀에서 운영하는 DAG, Connection, Variable을 우리 팀만 보고 싶은 경우</li>\n</ul>\n<p>특히 Airflow Connections, Variable에는 DB 또는 클러스터 접속 정보, API키 등 민감한 정보가 많이 저장됩니다. 물론 마스킹 기능을 통해 UI에서 볼 수 없게 만들 수 있지만 id는 볼 수 있기 때문에 쉽게 값을 가져올 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> airflow<span class=\"token punctuation\">.</span>models <span class=\"token keyword\">import</span> Variable\n<span class=\"token keyword\">from</span> airflow<span class=\"token punctuation\">.</span>hooks<span class=\"token punctuation\">.</span>base_hook <span class=\"token keyword\">import</span> BaseHook\n\nvariable <span class=\"token operator\">=</span> Variable<span class=\"token punctuation\">.</span>get<span class=\"token punctuation\">(</span><span class=\"token string\">\"myvar\"</span><span class=\"token punctuation\">)</span>\nconnection <span class=\"token operator\">=</span> BaseHook<span class=\"token punctuation\">.</span>get_connection<span class=\"token punctuation\">(</span><span class=\"token string\">\"myconn\"</span><span class=\"token punctuation\">)</span></code></pre></div>\n<br>\n<p>이 문제를 해결하기 위한 방법으로 조직마다 Airflow 환경을 분리하는 방법이 있습니다.\n하지만 이 방법은 운영과 모니터링이 힘들 수 있어 프라이빗 클라우드를 운영해야하는 상황이 아니라면 추천하지 않습니다. 두 번째 방법은 <strong>Airflow의 RBAC 기능</strong>을 활용하는 방법 입니다.</p>\n<br>\n<h2 id=\"airflow-rbac\" style=\"position:relative;\"><a href=\"#airflow-rbac\" aria-label=\"airflow rbac permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Airflow RBAC</h2>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=1tfr6zzzwrDkMIsTMJFOsNVzDwCchvzjo\" alt=\"security-model\"></p>\n<p>Airflow RBAC은 1.10 버전부터 추가되었고 2.0 버전부터 기본 설정으로 제공됩니다.\nAirflow의 Security Model은 위의 그림과 같은 구조를 따르고 있습니다.\n사용자는 User, Role로 구성되어 있습니다. 여기서 User는 하나 이상의 Role을 가질 수 있습니다.</p>\n<p>접근 권한은 <strong>Permission, ViewMenu</strong> 그리고 이를 조합한 <strong>PermissionView</strong>로 구성되어 있습니다.\nRole은 여러 개의 Permission을 가질 수 있습니다. PermissionView에 대한 예시는 아래와 같습니다.</p>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=1CsfVPlTQL_hqtY4a3_dXxz2kTAFjFqVo\" alt=\"permission-view\"></p>\n<p>Connections <strong>ViewMenu</strong> 와 can_edit <strong>Permission</strong> 을 조합하면 <code class=\"language-text\">can edit on Connections</code>라는 <strong>PermissionView</strong> 가 생성됩니다. 이 권한을 가진 사용자만 Connections UI에서 편집을 할 수 있습니다. 이러한 방식을 Airflow에서는 <strong>Resource-Based permissions</strong>라고 정의하고 있습니다.</p>\n<p>Airflow에는 다양한 리소스에 대해 권한이 이미 정의되어 있고, 기본적으로 Admin을 포함한 5개의 Role을 제공합니다. 조직마다 다른 Role을 가지고 싶은 경우, BaseRole을 정의하고 Copy Role을 통해 새로 만들면 편하게 운영할 수 있습니다.</p>\n<p>리소스 기반의 권한 제어도 필요하지만 이 기능에서는 DAGs 라는 단일 리소스로 보고 있기 때문에 DAG 단위로 접근 제어를 할 수 없습니다. 이를 지원하기 위해 2.0+ 버전부터 <strong>DAG-level Permission</strong>이 추가되었습니다.</p>\n<br>\n<h2 id=\"dag-level-permissions\" style=\"position:relative;\"><a href=\"#dag-level-permissions\" aria-label=\"dag level permissions permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>DAG-level Permissions</h2>\n<p>DAG-level Permission을 사용하면 다음과 같은 접근 제어를 할 수 있습니다.</p>\n<ul>\n<li>A 사용자는 A 사용자의 DAG만 볼 수 있음</li>\n<li>A 사용자는 B 사용자의 DAG을 볼 수 없음</li>\n<li>B 사용자가 A 사용자에게 권한을 부여하면 볼 수 있음</li>\n</ul>\n<p>DAG-level Permission은 앞서 얘기했던 리소스 기반 접근 제어에 <code class=\"language-text\">DAG:dag_id</code>라는 리소스를 추가하는 방식으로 구현되었습니다. 예를 들어 A 사용자와 B 사용자에게 example DAG에 대한 읽기 권한을 부여하고 싶은 경우, <code class=\"language-text\">DAG:example.can_read</code>라는 권한을 추가해주어야 합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">with</span> DAG<span class=\"token punctuation\">(</span>\n    <span class=\"token string\">\"example_dag\"</span><span class=\"token punctuation\">,</span>\n    default_args<span class=\"token operator\">=</span>default_args<span class=\"token punctuation\">,</span>\n    description<span class=\"token operator\">=</span><span class=\"token string\">\"example dags\"</span><span class=\"token punctuation\">,</span>\n    schedule_interval<span class=\"token operator\">=</span><span class=\"token string\">\"@once\"</span><span class=\"token punctuation\">,</span>\n    access_control<span class=\"token operator\">=</span><span class=\"token punctuation\">{</span><span class=\"token string\">\"myrole\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span><span class=\"token string\">\"can_dag_read\"</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    start_date<span class=\"token operator\">=</span>days_ago<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> dag<span class=\"token punctuation\">:</span></code></pre></div>\n<p>위와 같이 DAG을 정의하는 단계에서도 <code class=\"language-text\">access_control</code> 파라메터를 통해 DAG의 접근 권한을 정의해주어야 합니다. 이후 BaseRole에 DAGs 리소스 접근 권한을 제거하면 사용자는 오직 허용된 DAG에 대해서만 접근할 수 있게 됩니다.</p>\n<p>DAG access_control이 변경될 때마다 Role에 권한을 추가하는 일은 보통 번거로운 일이 아닙니다. 이를 위해 Airflow에서는 <code class=\"language-text\">airflow sync-perm</code> 이라는 명령어를 제공합니다. 해당 명령어를 실행하면 모든 DAG에 정의된 권한이 연관된 Role에 반영됩니다. Permission Sync 사이드카 컨테이너를 webserver에 배포하면 이 과정을 자동화할 수 있습니다. 관련 내용은 <a href=\"https://swalloow.github.io/airflow-sidecar/#2-permission-sync-container\">사이드카 컨테이너로 Airflow 기능 확장하기</a> 글을 참고해주시면 됩니다.</p>\n<br>\n<h2 id=\"connection-variable-access-control\" style=\"position:relative;\"><a href=\"#connection-variable-access-control\" aria-label=\"connection variable access control permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Connection, Variable Access Control</h2>\n<p>앞서 DAG-level Permission을 보셨다면 느끼셨겠지만 Connection, Variable 또한 각 변수에 대해 접근 제어를 할 수 없고 관련 기능도 없습니다. 하지만 <strong>Alternative Secrets Backend</strong> 라는 기능을 통해 Custom Backend 클래스를 만들면 접근 제어를 구현할 수 있습니다.</p>\n<br>\n<h3 id=\"alternative-secrets-backend\" style=\"position:relative;\"><a href=\"#alternative-secrets-backend\" aria-label=\"alternative secrets backend permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Alternative Secrets Backend</h3>\n<p>원래 Connection, Variable은 Meta DB에 저장됩니다. 하지만 이 기능을 사용하면 AWS Parameter Store, Vault 등 외부 자원을 저장소로 사용할 수 있습니다. airflow에 구현된 코드는 아래와 같습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token decorator annotation punctuation\">@classmethod</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">get_connection_from_secrets</span><span class=\"token punctuation\">(</span>cls<span class=\"token punctuation\">,</span> conn_id<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span><span class=\"token operator\">></span> <span class=\"token string\">'Connection'</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    Get connection by conn_id.\n    :param conn_id: connection id\n    :return: connection\n    \"\"\"</span>\n    <span class=\"token keyword\">for</span> secrets_backend <span class=\"token keyword\">in</span> ensure_secrets_loaded<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        conn <span class=\"token operator\">=</span> secrets_backend<span class=\"token punctuation\">.</span>get_connection<span class=\"token punctuation\">(</span>conn_id<span class=\"token operator\">=</span>conn_id<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> conn<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">return</span> conn\n    <span class=\"token keyword\">raise</span> AirflowNotFoundException<span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"The conn_id `</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>conn_id<span class=\"token punctuation\">}</span></span><span class=\"token string\">` not defined\"</span></span><span class=\"token punctuation\">)</span></code></pre></div>\n<br>\n<p><code class=\"language-text\">BaseHook</code>에서 호출하는 <code class=\"language-text\">get_connection_from_secrets</code> 메서드는 여러 backend로부터 conn_id에 대한 값을 받아오고 리턴합니다. 즉 기존 Meta DB를 사용하고 있더라도 유지하면서 새로운 backend와 호환 가능합니다.</p>\n<p>AWS Parameter Store는 Path 단위로 키를 다르게 값을 저장할 수 있습니다.\n이 점을 활용해서 id 상위 경로로 role을 지정한다면 role 단위로 접근 제어가 가능해집니다.\n접근 제어를 위한 AWS Parameter Store에 저장되는 규칙은 아래와 같습니다.\nAirflow 환경, 역할 별로 구분해서 저장합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">secrets</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">backend</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"airflow...SystemsManagerParameterStoreBackend\"</span>\n    <span class=\"token key atrule\">backend_kwargs</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token key atrule\">\"connections_prefix\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"/airflow/prod/connections\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token key atrule\">\"variables_prefix\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"/airflow/prod/variables\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token key atrule\">\"profile_name\"</span><span class=\"token punctuation\">:</span> <span class=\"token null important\">null</span>\n    <span class=\"token punctuation\">}</span></code></pre></div>\n<ul>\n<li>/airflow/prod/connections/myrole/connection_id</li>\n<li>/airflow/prod/variables/myrole/variable_id</li>\n</ul>\n<p>기본으로 제공하는 Connections, Variables UI는 세부 경로로 값을 가져오는게 아니기 때문에 secrets backend 설정과 함께 Custom UI Plugin이 필요합니다.</p>\n<br>\n<h2 id=\"access-control-ui-plugin\" style=\"position:relative;\"><a href=\"#access-control-ui-plugin\" aria-label=\"access control ui plugin permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Access Control UI Plugin</h2>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=1QhjXiETQQLqnLo3iJbmcPMtfGcTXRSgV\" alt=\"acl-plugin\"></p>\n<p>플러그인의 역할은 다음과 같습니다. myrole이라는 Airflow Role을 가진 사용자가 Connections UI 페이지에 접근하면 Custom Backend를 통해 Paramter Store의 <code class=\"language-text\">/airflow/prod/connections/myrole</code> 경로 하위의 값들을 받아오도록 요청해야 합니다. list 뿐만 아니라 create, edit, delete에 대한 기능도 추가해주어야 합니다.</p>\n<p>이를 위해 UI 플러그인에서 현재 접속한 사용자의 Role 이름을 받아올 수 있어야 합니다. 이 때 flask의 global session을 활용하면 쉽게 받아올 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> flask <span class=\"token keyword\">import</span> g\n\nrole_name <span class=\"token operator\">=</span> g<span class=\"token punctuation\">.</span>user<span class=\"token punctuation\">.</span>roles<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>name</code></pre></div>\n<p>이제 UI에서 추가, 편집, 삭제 시 Secrets Backend를 통해 AWS Parameter Store에 반영됩니다. 오직 권한을 가진 사용자만이 DAG, Connection, Variable에 접근할 수 있습니다.</p>\n<br>\n<h2 id=\"cluster-policy\" style=\"position:relative;\"><a href=\"#cluster-policy\" aria-label=\"cluster policy permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Cluster Policy</h2>\n<p>DAG 작성에 대한 가이드가 있더라도 모두 만족하는지 체크하는건 상당히 번거로운 일 입니다.\nAirflow 2.0+에서는 Cluster Policy를 통해 클러스터 전체에서 DAG 또는 task에 대한 정책을 정의하고 강제하도록 설정할 수 있습니다. 예를 들면 다음과 같은 정책을 정의할 수 있습니다.</p>\n<ul>\n<li>모든 DAG에는 적어도 하나의 태그를 달아야 한다</li>\n<li>특정 task의 timeout은 48시간을 넘을 수 없다</li>\n</ul>\n<p><code class=\"language-text\">airflow_local_settings.py</code> 파일을 만들고 정의하면 적용할 수 있습니다.\n태그를 강제하는 정책 예시는 아래와 같습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">dag_policy</span><span class=\"token punctuation\">(</span>dag<span class=\"token punctuation\">:</span> DAG<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"Ensure that DAG has at least one tag\"\"\"</span>\n    <span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> dag<span class=\"token punctuation\">.</span>tags<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">raise</span> AirflowClusterPolicyViolation<span class=\"token punctuation\">(</span>\n            <span class=\"token string-interpolation\"><span class=\"token string\">f\"DAG </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>dag<span class=\"token punctuation\">.</span>dag_id<span class=\"token punctuation\">}</span></span><span class=\"token string\"> has no tags. At least one tag required. File path: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>dag<span class=\"token punctuation\">.</span>filepath<span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span>\n        <span class=\"token punctuation\">)</span></code></pre></div>\n<p>위 정책이 적용된 클러스터에 태그가 없는 DAG을 배포하는 경우, <code class=\"language-text\">AirflowClusterPolicyViolation</code> 오류가 발생하기 때문에 DAG을 등록할 수 없습니다.\n자세한 내용은 <a href=\"https://airflow.apache.org/docs/apache-airflow/stable/concepts/cluster-policies.html\">공식문서</a>를 참고하시면 됩니다.</p>\n<br>\n<h2 id=\"정리\" style=\"position:relative;\"><a href=\"#%EC%A0%95%EB%A6%AC\" aria-label=\"정리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>정리</h2>\n<p>최근 Airflow Summit에서 Multi-Tenent와 관련된 영상들이 많이 올라와서 함께 참고하면 도움이 될 것 같습니다.</p>\n<ul>\n<li><a href=\"https://airflow.apache.org/docs/apache-airflow/stable/security/access-control.html\">https://airflow.apache.org/docs/apache-airflow/stable/security/access-control.html</a></li>\n<li><a href=\"https://eng.lyft.com/securing-apache-airflow-ui-with-dag-level-access-a7bc649a2821\">https://eng.lyft.com/securing-apache-airflow-ui-with-dag-level-access-a7bc649a2821</a></li>\n<li><a href=\"https://airflow.apache.org/docs/apache-airflow/stable/security/secrets/secrets-backend/index.html\">https://airflow.apache.org/docs/apache-airflow/stable/security/secrets/secrets-backend/index.html</a></li>\n</ul>","excerpt":"…"}}}},{"node":{"title":"사이드카 컨테이너로 Airflow 기능 확장하기","id":"c97edb01-df3d-53e4-bc7a-47e2e5d6feb2","slug":"airflow-sidecar","publishDate":"August 01, 2021","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"943e8b84-7c33-5c3d-9d5a-ac780a6c7746","childMarkdownRemark":{"id":"9370d60d-b64f-5b01-9e00-d82e32fe4218","timeToRead":4,"html":"<p>Airflow 2.1 버전부터 공식 Helm Chart가 정식 릴리즈 되었습니다.\n오늘은 공식 차트에서 사용할 수 있는 기능 중 <code class=\"language-text\">extraContainers</code> 옵션을 활용하는 방법을 3가지 예시를 통해 소개해보려 합니다.</p>\n<ul>\n<li><a href=\"https://swalloow.github.io/airflow-sidecar/#1-s3-sync-container\">S3 Sync Container</a></li>\n<li><a href=\"https://swalloow.github.io/airflow-sidecar/#2-permission-sync-container\">Permission Sync Container</a></li>\n<li><a href=\"https://swalloow.github.io/airflow-sidecar/#3-kerberos-container\">Kerberos Container</a></li>\n</ul>\n<br>\n<h2 id=\"sidecar-container\" style=\"position:relative;\"><a href=\"#sidecar-container\" aria-label=\"sidecar container permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Sidecar Container</h2>\n<p>분산 컨테이너 환경에서 사이드카 패턴이란 Pod 안에서 두 개 이상의 컨테이너로 구성되어 있는 형태를 말합니다. 컨테이너들은 서로 네트워크 또는 볼륨을 공유할 수 있습니다. 사이드카 컨테이너를 활용하면 다음과 장점을 가져갈 수 있습니다.</p>\n<p><strong>기존 로직의 변경 없이 새로운 기능 추가</strong>:\n가끔 일부 기능 추가를 위해 Airflow 저장소 코드를 수정하는 경우가 생길 수 있습니다.\n하지만 이렇게 한번 수정하고 나면 이후에 버전 업데이트할 때마다 새로운 버전 브랜치와 병합해야 하는 번거로움이 생깁니다. 만약 원하는 기능이 사이드카 컨테이너를 활용할 수 있다면 기존 저장소의 변경 없이 새로운 기능을 추가할 수 있습니다.</p>\n<p><strong>컨테이너 재사용</strong>:\n사내에서 개발 환경에 따라 또는 접근 권한에 따라 Airflow 인스턴스를 여러 개 구성하고 운영하는 경우가 많습니다. 사이드카 컨테이너로 구성한 기능은 재사용이 가능하기 때문에 새로 배포한 Airflow 인스턴스에 쉽게 적용할 수 있습니다.</p>\n<br>\n<h2 id=\"airflow-extracontainers\" style=\"position:relative;\"><a href=\"#airflow-extracontainers\" aria-label=\"airflow extracontainers permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Airflow extraContainers</h2>\n<p>Airflow Helm Chart에서는 <code class=\"language-text\">extraContainers</code> 옵션을 통해 사이드카 컨테이너를 scheduler, webserver, worker에 정의할 수 있습니다. <del>제가 기여한 옵션입니다!</del> (<a href=\"https://github.com/apache/airflow/pull/13735\">https://github.com/apache/airflow/pull/13735</a>)</p>\n<p>이제 몇 가지 예시를 통해 어떻게 활용할 수 있는지 알아보겠습니다.</p>\n<br>\n<h2 id=\"1-s3-sync-container\" style=\"position:relative;\"><a href=\"#1-s3-sync-container\" aria-label=\"1 s3 sync container permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. S3 Sync Container</h2>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=1Hh0f6l9jDLHHEaH5OyGU7Nhe5nUnnJU1\"></p>\n<p>AWS MWAA 처럼 <strong>S3를 DAG 저장소로 활용하고 싶은 경우</strong>에 S3 Sync 사이드카 컨테이너를 통해 구현할 수 있습니다. S3 Sync 사이드카 컨테이너는 S3 버킷에 올라간 파일을 DAG 경로에 주기적으로 동기화하는 컨테이너입니다. 만약 DAG Serialiaztion 옵션이 활성화되어 있다면 scheduler에만 정의하면 됩니다.</p>\n<p>예시는 아래와 같습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">scheduler</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">extraContainers</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> s3<span class=\"token punctuation\">-</span>sync\n      <span class=\"token key atrule\">image</span><span class=\"token punctuation\">:</span> myrepository/s3<span class=\"token punctuation\">-</span>sync<span class=\"token punctuation\">:</span>latest\n      <span class=\"token key atrule\">imagePullPolicy</span><span class=\"token punctuation\">:</span> Always\n      <span class=\"token key atrule\">volumeMounts</span><span class=\"token punctuation\">:</span>\n        <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> dags\n          <span class=\"token key atrule\">mountPath</span><span class=\"token punctuation\">:</span> /opt/airflow/dags\n      <span class=\"token key atrule\">env</span><span class=\"token punctuation\">:</span>\n        <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> AWS_BUCKET\n          <span class=\"token key atrule\">value</span><span class=\"token punctuation\">:</span> airflow<span class=\"token punctuation\">-</span>src\n        <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> KEY_PATH\n          <span class=\"token key atrule\">value</span><span class=\"token punctuation\">:</span> dags\n        <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> DEST_PATH\n          <span class=\"token key atrule\">value</span><span class=\"token punctuation\">:</span> /opt/airflow/dags\n        <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> INTERVAL\n          <span class=\"token key atrule\">value</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"10\"</span></code></pre></div>\n<br>\n<p>위와 같이 인스턴스마다 서로 다른 설정이 필요한 값들은 환경변수로 구성할 수 있도록 이미지를 정의합니다. S3 접근 권한은 직접 credential을 사용하는 것보다 EKS의 IRSA를 활용해서 Role 기반으로 제어하는 편이 좋습니다. Dockerfile은 <a href=\"https://github.com/Swalloow/s3-sync\">s3sync</a> 저장소를 참고하시면 됩니다.</p>\n<br>\n<h2 id=\"2-permission-sync-container\" style=\"position:relative;\"><a href=\"#2-permission-sync-container\" aria-label=\"2 permission sync container permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. Permission Sync Container</h2>\n<p>2.0 부터 추가된 <strong>DAG level Permission을 사용하는 경우</strong>, airflow sync-perm 명령어를 통해 DAG 권한을 갱신해주어야 Role에 권한제어가 정상적으로 반영됩니다. Permission Sync 컨테이너는 webserver에서 주기적으로 <code class=\"language-text\">sync-perm</code> 명령어를 수행하는 역할을 합니다.</p>\n<p>예시는 아래와 같습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">webserver</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">extraContainers</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> sync<span class=\"token punctuation\">-</span>perm\n      <span class=\"token key atrule\">image</span><span class=\"token punctuation\">:</span> apache/airflow<span class=\"token punctuation\">:</span>2.1.2<span class=\"token punctuation\">-</span>python3.7\n      <span class=\"token key atrule\">imagePullPolicy</span><span class=\"token punctuation\">:</span> Always\n      <span class=\"token key atrule\">command</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"/bin/sh\"</span><span class=\"token punctuation\">]</span>\n      <span class=\"token key atrule\">args</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span><span class=\"token string\">\"-c\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"while true; do airflow sync-perm; sleep 60; done\"</span><span class=\"token punctuation\">]</span>\n      <span class=\"token key atrule\">volumeMounts</span><span class=\"token punctuation\">:</span>\n        <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> dags\n          <span class=\"token key atrule\">mountPath</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"/opt/airflow/dags\"</span>\n      <span class=\"token key atrule\">env</span><span class=\"token punctuation\">:</span>\n        <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> AIRFLOW__CORE__SQL_ALCHEMY_CONN\n          <span class=\"token key atrule\">valueFrom</span><span class=\"token punctuation\">:</span>\n            <span class=\"token key atrule\">secretKeyRef</span><span class=\"token punctuation\">:</span>\n              <span class=\"token key atrule\">key</span><span class=\"token punctuation\">:</span> connection\n              <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> airflow<span class=\"token punctuation\">-</span>dev<span class=\"token punctuation\">-</span>airflow<span class=\"token punctuation\">-</span>metadata</code></pre></div>\n<br>\n<p>보시면 Airflow 이미지와 정의된 connection을 재활용 합니다. 컴포넌트 컨테이너와 분리되어 있으니 사이드카에서 발생하는 로그만 따로 확인할 수도 있습니다.</p>\n<br>\n<h2 id=\"3-kerberos-container\" style=\"position:relative;\"><a href=\"#3-kerberos-container\" aria-label=\"3 kerberos container permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. Kerberos Container</h2>\n<p>클러스터에 접근하기 위해 Kerberos 인증이 필요한 경우, Kerberos 컨테이너를 활용하면 인증 토큰 갱신을 자동화할 수 있습니다. <a href=\"https://airflow.apache.org/docs/apache-airflow/stable/production-deployment.html#kerberos-authenticated-workers\">Airflow 공식 문서</a>의 production-deployment 부분을 보면 아래와 같은 내용이 있습니다.</p>\n<blockquote>\n<p>In the Kubernetes environment, this can be realized by the\nconcept of side‐car, where both Kerberos token refresher and\nworker are part of the same Pod. Only the Kerberos side‐car has\naccess to Keytab secret and both containers in the same Pod\nshare the volume, where temporary token is written by the side‐\ncare container and read by the worker container.</p>\n</blockquote>\n<p>대략 K8S 환경에서 사이드카 형태로 구성하는 방법에 대한 내용입니다.\n이를 그림으로 그려보면 아래와 같습니다.</p>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=14rfnQmDROdWpqN4TNQJr02_sIT9E_K0i\" alt=\"krb\"></p>\n<p>kerberos 컨테이너는 keytab이 존재하는 볼륨에 접근하고 kinit 명령어를 통해 ccache를 갱신합니다. airflow 인스턴스들의 worker는 해당 볼륨의 갱신된 토큰을 통해 인증을 달성할 수 있습니다. prod, dev와 같이 여러 airflow를 사용하더라도 kerberos의 컨테이너에서 한번만 캐시 업데이트를 수행하면 됩니다. </p>\n<p>예시는 아래와 같습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">worker</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">extraContainers</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> worker<span class=\"token punctuation\">-</span>kerberos\n      <span class=\"token key atrule\">image</span><span class=\"token punctuation\">:</span> myrepository/kerberos<span class=\"token punctuation\">:</span>latest\n      <span class=\"token key atrule\">imagePullPolicy</span><span class=\"token punctuation\">:</span> Always\n      <span class=\"token key atrule\">volumeMounts</span><span class=\"token punctuation\">:</span>\n        <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> keytab\n          <span class=\"token key atrule\">mountPath</span><span class=\"token punctuation\">:</span> /etc/keytab\n      <span class=\"token key atrule\">env</span><span class=\"token punctuation\">:</span>\n        <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> INTERVAL\n          <span class=\"token key atrule\">value</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"3600\"</span>\n        <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> KRB5_CONFIG\n          <span class=\"token key atrule\">value</span><span class=\"token punctuation\">:</span> /etc/keytab/krb5.conf\n\n<span class=\"token punctuation\">...</span>\n\n<span class=\"token key atrule\">extraVolumes</span><span class=\"token punctuation\">:</span>\n  <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> keytab\n    <span class=\"token key atrule\">persistentVolumeClaim</span><span class=\"token punctuation\">:</span>\n      <span class=\"token key atrule\">claimName</span><span class=\"token punctuation\">:</span> airflow<span class=\"token punctuation\">-</span>keytab\n<span class=\"token key atrule\">extraVolumeMounts</span><span class=\"token punctuation\">:</span>\n  <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> keytab\n    <span class=\"token key atrule\">mountPath</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"/etc/keytab\"</span></code></pre></div>\n<br>\n<p>위와 같이 keytab이 존재하는 볼륨을 마운트해주어야 합니다.</p>\n<br>\n<h2 id=\"정리\" style=\"position:relative;\"><a href=\"#%EC%A0%95%EB%A6%AC\" aria-label=\"정리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>정리</h2>\n<p>이외에도 사이드카 컨테이너를 잘 활용한다면 다양한 기능으로 확장할 수 있습니다.\n<code class=\"language-text\">extraInitContainers</code> 옵션도 있으니 함께 활용해보면 좋을 것 같습니다.</p>\n<ul>\n<li><a href=\"https://airflow.apache.org/docs/helm-chart/stable/using-additional-containers.html\">https://airflow.apache.org/docs/helm-chart/stable/using-additional-containers.html</a></li>\n</ul>","excerpt":"Airflow 2.1 버전부터 공식 Helm Chart…"}}}},{"node":{"title":"Airflow on Kubernetes (3)","id":"d2deb481-7412-52bb-8ec1-07246c2aea6d","slug":"airflow-on-kubernetes-3","publishDate":"February 05, 2021","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"785a541c-cdc7-5256-911b-4e9c1d0e2b40","childMarkdownRemark":{"id":"2d5e8de2-19ad-5003-bef6-aa09dbdc0f32","timeToRead":2,"html":"<p>최근 Airflow에는 Kubernetes 지원을 위해 다양한 컴포넌트들이 추가되고 있습니다. 이러한 변화의 흐름에 따라 Airflow를 Kubernetes 위에 배포하고 운영하는 방법에 대해 글을 작성해보고자 합니다. 이 글은 시리즈로 연재됩니다.</p>\n<ul>\n<li><a href=\"https://swalloow.github.io/airflow-on-kubernetes-1\">Airflow on Kubernetes (1): CeleryExecutor</a></li>\n<li><a href=\"https://swalloow.github.io/airflow-on-kubernetes-2\">Airflow on Kubernetes (2): KubernetesExecutor</a></li>\n<li><a href=\"https://swalloow.github.io/airflow-on-kubernetes-3\">Airflow on Kubernetes (3): Airflow Logging, Monitoring</a></li>\n</ul>\n<br>\n<h2 id=\"airflow-logging\" style=\"position:relative;\"><a href=\"#airflow-logging\" aria-label=\"airflow logging permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Airflow Logging</h2>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=1qGMB1yIsT06y3y9knBQ2T2G2O3xQs-8b\" alt=\"airflow-log\"></p>\n<p>Airflow의 Task 로그는 PV를 통해 영구 볼륨에 저장하거나 <strong>Remote Logging</strong> 설정을 통해 외부 저장소로 수집할 수 있습니다. S3, ES, GCS 등 다양한 저장소를 지원합니다.\n예를 들어 S3로 설정하면 Task 로그의 수명주기를 S3 Lifecycle에 의해 관리할 수 있게 됩니다.\n참고로 2.0 버전부터 로그 관련 설정은 <code class=\"language-text\">core</code>에서 <code class=\"language-text\">logging</code> 섹션으로 이동했습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">logging:\n  remote_logging: &quot;True&quot;\n  remote_base_log_folder: &quot;s3://mybucketname/airflow&quot;\n  remote_log_conn_id: &quot;aws_default&quot;\n  logging_level: INFO</code></pre></div>\n<br>\n<h2 id=\"airflow-metrics\" style=\"position:relative;\"><a href=\"#airflow-metrics\" aria-label=\"airflow metrics permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Airflow Metrics</h2>\n<p>Airflow는 <a href=\"https://airflow.apache.org/docs/apache-airflow/stable/logging-monitoring/metrics.html\">StatsD를 통한 메트릭 전송 방법</a>을 공식 지원합니다.\nK8S 환경에서 많이 사용하는 Prometheus을 통해 메트릭을 수집하는 방법은 아래와 같이 2가지가 있습니다.\nOfficial Helm Chart의 경우 statsd-export를 통해 전송하는 방법을 지원하고 있습니다.\n<code class=\"language-text\">Values.statsd.enabled</code> 옵션을 통해 쉽게 설정하실 수 있습니다.</p>\n<br>\n<p><strong>1. airflow-prometheus-exporter</strong>:\nairflow model 객체를 활용하여 prometheus metrics collector를 구현한 모듈입니다.\nstable/airflow chart에서 옵션을 통해 설정할 수 있으며 airflow plugin 형태로 구현되어 있어 UI의 /metrics 경로에서 로그를 확인할 수 있습니다.</p>\n<p><strong>2. airflow-statsd-exporter</strong>:\nstatsd는 UDP, TCP를 통해 메트릭을 수집에서 전송하는 프록시입니다.\nairflow에서는 공식적으로 statsd를 통해 메트릭을 지원하고 있습니다.\nofficial helm chart에서는 statsd를 통해 메트릭을 수집하고 exporter를 통해 prometheus에 저장할 수 있습니다.</p>\n<br>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=1T5teIwjMzfvxJGE37oFMOyGFtC9zqfJq\"></p>\n<p>수집하는 과정은 위의 그림과 같습니다. statsd-exporter는 Deployment 형태로 배포되며 수집 어노테이션이 정의되어 있습니다.</p>\n<br>\n<h2 id=\"monitoring\" style=\"position:relative;\"><a href=\"#monitoring\" aria-label=\"monitoring permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Monitoring</h2>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=1V3YNecz4_GRBV_5fgOFSu13ScbImFmjU\"></p>\n<p>Prometheus에 저장된 메트릭은 Grafana를 통해 데이터 소스로 지정하고 원하는 지표를 시각화할 수 있습니다. 위의 대시보드에 활용한 지표는 다음과 같습니다.</p>\n<ul>\n<li>Airflow Scheduler Health</li>\n<li>Number of Queued Tasks</li>\n<li>Number of Running Tasks</li>\n<li>Scheduling Delay by DAG</li>\n<li>DAG Import Time</li>\n<li>DAG Running Duration</li>\n</ul>\n<br>\n<p>사용자가 작성한 DAG은 Parser를 통해 객체로 변환되고 메타데이터 DB에 저장되는데 <code class=\"language-text\">DAG Import Time</code>은 이 과정을 수행하는데 있어 걸리는 시간을 의미합니다. 위에 언급된 지표 외에도 다양한 지표를 지원합니다. 자세한 리스트는 <a href=\"https://airflow.apache.org/docs/apache-airflow/stable/logging-monitoring/metrics.html#counters\">Airflow Metrics 공식 문서</a>를 통해 확인하실 수 있습니다.</p>\n<br>","excerpt":"최근 Airflow에는 Kubernetes 지원을 위해 다양한 컴포넌트들이 추가되고 있습니다. 이러한 변화의 흐름에 따라 Airflow…"}}}}]}},"pageContext":{"basePath":"","paginationPath":"","pageNumber":1,"humanPageNumber":2,"skip":7,"limit":6,"numberOfPages":16,"previousPagePath":"/","nextPagePath":"/3"}}}