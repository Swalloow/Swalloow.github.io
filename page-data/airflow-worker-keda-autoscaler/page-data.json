{"componentChunkName":"component---src-templates-post-js","path":"/airflow-worker-keda-autoscaler/","result":{"data":{"contentfulPost":{"id":"b10d61e7-5adc-53e4-b2da-9142ae8bffb5","title":"Airflow worker에 KEDA autoscaler 적용한 후기","slug":"airflow-worker-keda-autoscaler","metaDescription":null,"publishDate":"June 24, 2022","publishDateISO":"2022-06-24","tags":[{"title":"DataEngineering","id":"6d3fb203-7cdf-53d7-be6f-12ba3e82d74d","slug":"dataengineering"}],"heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"ea004cc8-b136-57cb-b9c0-22e9a7a65cf3","childMarkdownRemark":{"id":"2a2780a6-435b-5112-9cc3-94f01693acb8","timeToRead":4,"html":"<p>Airflow에서 실행되는 배치 작업들은 특정 시간 또는 야간에 많이 수행되고 이외의 시간은 상대적으로 여유로운 경우가 많습니다. 이러한 상황에서 오토스케일링을 적용한다면 효율적으로 리소스를 최적화하여 사용할 수 있습니다.</p>\n<p>만약 쿠버네티스 위에서 Celery Executor를 사용한다면 worker의 오토스케일링을 위해 KEDA를 고려해볼 수 있습니다. 이 글에서는 Airflow worker에 KEDA autoscaler를 적용하면서 겪었던 여러 문제들과 해결 과정에 대해 정리해보려 합니다.</p>\n<p><br><br></p>\n<h2 id=\"keda-autoscaler\" style=\"position:relative;\"><a href=\"#keda-autoscaler\" aria-label=\"keda autoscaler permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>KEDA autoscaler</h2>\n<p>KEDA는 쿠버네티스에서 이벤트 기반 오토스케일링을 쉽게 구현할 수 있도록 지원하는 컴포넌트입니다. 쿠버네티스의 HPA와 함께 동작하며 다양한 built-in scaler를 통해 유연하게 오토스케일링 조건을 설정할 수 있습니다.</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1ASRyxTdtpbFqt6qGdRhD98OBSbTa-i8k\" alt=\"keda\"></p>\n<p>만약 Airflow에 적용한다면 위의 그림과 같은 형태로 구성됩니다.\n사용자는 KEDA의 <code class=\"language-text\">ScaledObject</code> CRD를 생성하여 클러스터에 배포합니다.\nKEDA는 쿠버네티스의 API Server와 통신하며 Operator와 같은 형태로써 컨트롤 루프에 따라 동작합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">apiVersion</span><span class=\"token punctuation\">:</span> keda.sh/v1alpha1\n<span class=\"token key atrule\">kind</span><span class=\"token punctuation\">:</span> ScaledObject\n<span class=\"token key atrule\">metadata</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> airflow<span class=\"token punctuation\">-</span>worker\n<span class=\"token key atrule\">spec</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">scaleTargetRef</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">name</span><span class=\"token punctuation\">:</span> airflow<span class=\"token punctuation\">-</span>worker\n  <span class=\"token key atrule\">pollingInterval</span><span class=\"token punctuation\">:</span> <span class=\"token number\">10</span>\n  <span class=\"token key atrule\">cooldownPeriod</span><span class=\"token punctuation\">:</span> <span class=\"token number\">30</span>\n  <span class=\"token key atrule\">minReplicaCount</span><span class=\"token punctuation\">:</span> <span class=\"token number\">3</span>\n  <span class=\"token key atrule\">maxReplicaCount</span><span class=\"token punctuation\">:</span> <span class=\"token number\">10</span>\n  <span class=\"token key atrule\">triggers</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">type</span><span class=\"token punctuation\">:</span> postgresql\n      <span class=\"token key atrule\">metadata</span><span class=\"token punctuation\">:</span>\n        <span class=\"token key atrule\">connectionFromEnv</span><span class=\"token punctuation\">:</span> AIRFLOW_CONN_AIRFLOW_DB\n        <span class=\"token key atrule\">query</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"\"</span></code></pre></div>\n<p><code class=\"language-text\">ScaledObject</code>는 위와 같이 무엇을 기준으로 트리거할지, 스케일링 정책 등을 정의할 수 있습니다. KEDA는 <code class=\"language-text\">minReplicaCount</code>에 따라 다르게 동작하는데 <code class=\"language-text\">minReplicaCount</code>가 0인 경우, KEDA가 trigger 지표를 통해 직접 처리하지만 1 이상인 경우에는 KEDA가 Metrics Server에 전달만하고 HPA를 통해 처리됩니다. 각 옵션에 대한 자세한 설명은 <a href=\"https://keda.sh/docs/2.7/concepts/scaling-deployments/\">공식 문서</a>에서 확인할 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"sql\"><pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">SELECT</span> ceil<span class=\"token punctuation\">(</span><span class=\"token function\">COUNT</span><span class=\"token punctuation\">(</span><span class=\"token operator\">*</span><span class=\"token punctuation\">)</span>::<span class=\"token keyword\">decimal</span> <span class=\"token operator\">/</span> {{ celery<span class=\"token punctuation\">.</span>worker_concurrency }}<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">FROM</span> task_instance\n<span class=\"token keyword\">WHERE</span> state<span class=\"token operator\">=</span><span class=\"token string\">'running'</span> <span class=\"token operator\">OR</span> state<span class=\"token operator\">=</span><span class=\"token string\">'queued'</span></code></pre></div>\n<p>Airflow에서 사용하는 <code class=\"language-text\">ScaledObject</code>의 트리거 쿼리는 위와 같이<code class=\"language-text\">celery.worker_concurrency</code> 설정을 기준으로 하고 있습니다. 예를 들어 concurrency 설정이 12이며 running 또는 queued 상태의 task instance가 10에서 23으로 증가한 상황이라고 가정해보겠습니다. desired state가 1에서 2로 변경되었기 때문에 deployment의 replica 수는 2로 확장 됩니다. 스케줄이 모두 종료된 이후 다시 task instance가 10으로 줄어들면 replica 수는 1으로 축소 됩니다.</p>\n<p>Airflow 공식 차트에서는 KEDA 관련 옵션을 지원하고 있기 때문에 <a href=\"https://airflow.apache.org/docs/helm-chart/stable/keda.html\">공식 문서</a>를 통해 쉽게 적용할 수 있습니다.<br>\n하지만 문제는 적용한 이후에 발생했습니다.</p>\n<br>\n<h2 id=\"적용-후에-발생한-문제\" style=\"position:relative;\"><a href=\"#%EC%A0%81%EC%9A%A9-%ED%9B%84%EC%97%90-%EB%B0%9C%EC%83%9D%ED%95%9C-%EB%AC%B8%EC%A0%9C\" aria-label=\"적용 후에 발생한 문제 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>적용 후에 발생한 문제</h2>\n<p>적용 후에 실행 중인 task의 로그가 갑자기 끊기면서 강제로 실패 처리되는 문제가 있었습니다.<br>\n시간을 보니 worker가 Scale-In 되는 시점에 발생했고 크게 두 가지 문제를 확인할 수 있었습니다.</p>\n<br>\n<h3 id=\"1-hpa의-replica-flapping-문제\" style=\"position:relative;\"><a href=\"#1-hpa%EC%9D%98-replica-flapping-%EB%AC%B8%EC%A0%9C\" aria-label=\"1 hpa의 replica flapping 문제 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. HPA의 replica flapping 문제</h3>\n<p>먼저 의도한 것보다 Scale-In/Out이 너무 빈번하게 발생했습니다.\n새로 노드가 뜨는데 시간이 소요되므로 배치가 많은 시간 대에도 잦은 스케일 조정이 발생하는 것은 비효율적입니다. 이러한 문제를 HPA에서는 <strong>replica flapping</strong> 이라고 말합니다.\nHPA는 이를 제어하기 위해 <strong>안정화 윈도우와 스케일링 정책</strong>을 지원하고 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">behavior</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">scaleDown</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">stabilizationWindowSeconds</span><span class=\"token punctuation\">:</span> <span class=\"token number\">600</span></code></pre></div>\n<p>위와 같이 <code class=\"language-text\">stabilizationWindowSeconds</code> 설정을 600으로 설정하면 이전 10분 동안의 모든 목표 상태를 고려해서 가장 높은 값으로 설정합니다. 현재 시점에 scaleDown 조건을 만족하더라도 즉시 수행되는게 아니라 10분이 지난 시점에 scaleDown이 수행됩니다. 이를 통해 잦은 스케일 조정을 제한할 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"yaml\"><pre class=\"language-yaml\"><code class=\"language-yaml\"><span class=\"token key atrule\">behavior</span><span class=\"token punctuation\">:</span>\n  <span class=\"token key atrule\">scaleDown</span><span class=\"token punctuation\">:</span>\n    <span class=\"token key atrule\">policies</span><span class=\"token punctuation\">:</span>\n    <span class=\"token punctuation\">-</span> <span class=\"token key atrule\">type</span><span class=\"token punctuation\">:</span> Pods\n      <span class=\"token key atrule\">value</span><span class=\"token punctuation\">:</span> <span class=\"token number\">1</span>\n      <span class=\"token key atrule\">periodSeconds</span><span class=\"token punctuation\">:</span> <span class=\"token number\">300</span></code></pre></div>\n<p><code class=\"language-text\">scaleDown.polices</code>를 통해 Scale-In 발생 시 replica 변경 허용에 대한 정책을 지정할 수 있습니다. 위의 예시는 5분 내에 최대 1개의 replica를 scaleDown 하도록 허용하는 정책입니다. 이를 통해 계단식으로 천천히 pod를 축소할 수 있습니다.</p>\n<p>현재 Airflow 공식 차트에서는 KEDA의 advanced 옵션을 지원하지 않아 <a href=\"https://github.com/apache/airflow/pull/24220\">PR</a>을 추가했습니다.<br>\n신규 버전에 추가되기 전까지는 별도의 scaledobject를 추가하여 옵션을 적용할 수 있습니다.</p>\n<br>\n<h3 id=\"2-worker-warm-shutdown-문제\" style=\"position:relative;\"><a href=\"#2-worker-warm-shutdown-%EB%AC%B8%EC%A0%9C\" aria-label=\"2 worker warm shutdown 문제 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. Worker Warm Shutdown 문제</h3>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=10C7umomf0yxDRGav3STo5-uX3i5JUmdA\" alt=\"celery\"></p>\n<p>celery worker의 warm shutdown이 제대로 이루어지지 않았기 때문에 task의 로그가 갑자기 끊기면서 강제로 실패 했습니다. Airflow의 CeleryExecutor는 위와 같이 여러 프로세스를 통해 수행됩니다. 이 때 실제로 task를 실행하는 프로세스는 main 프로세스가 아니라 subprocess 입니다. celery에서는 실행 중인 task가 처리된 이후에 종료할 수 있도록 <strong>warm shutdown</strong>을 지원하고 있습니다. worker의 main process가 <code class=\"language-text\">SIGTERM</code>을 받으면 task가 종료될때까지 기다리게 됩니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\"># warm shutdown log\nworker: Warm shutdown (MainProcess)\n\n -------------- celery@fcd56490a11f v4.4.7 (cliffs)\n--- ***** -----\n-- ******* ---- Linux-5.4.0-1045-aws-x86_64-with-debian-10.8\n- *** --- * ---\n- ** ---------- [config]\n- ** ---------- .&gt; app:         airflow.executors.celery_executor:0x7f95\n- ** ---------- .&gt; transport:   redis://redis:6379/0\n- ** ---------- .&gt; results:     postgresql://airflow:**@postgres/airflow\n- *** --- * --- .&gt; concurrency: 16 (prefork)\n-- ******* ---- .&gt; task events: OFF (enable -E to monitor tasks in this worker)\n--- ***** -----\n -------------- [queues]\n                .&gt; default          exchange=default(direct) key=default\n\n[tasks]\n  . airflow.executors.celery_executor.execute_command</code></pre></div>\n<p><a href=\"https://swalloow.github.io/container-tini-dumb-init/\">이전 글</a>에서 설명한 것처럼 Airflow 공식 차트에서 worker pod은 <code class=\"language-text\">DUMB_INIT_SETSID=0</code>으로 이미 설정되어 있기 때문에 메인 프로세스에만 SIGNAL이 전파되고 task process는 계속 실행됩니다. 하지만\n<strong>scaleDown이 발생한다면, 실행 중이던 worker pod이 종료되기 때문에 pod 내에 있던 task process도 함께 강제 종료되면서 task가 실패</strong>하게 됩니다. 장시간 수행되는 task 일수록 이러한 문제를 마주칠 가능성이 높습니다.</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1MO0UQlSLa2mJvYyNZBajcfzKN14dhufr\" alt=\"learnk8s\"></p>\n<p>이를 해결하기 위해 task의 execution_timeout 시간까지 pod가 종료되지 않도록 <code class=\"language-text\">terminationGracePeriodSeconds</code>를 지정해주었습니다. 이제 각 컨테이너 내부의 프로세스 1에 <code class=\"language-text\">SIGTERM</code>이 전달되더라도 pod의 graceful shutdown 시간 동안 대기하므로 task process는 계속 실행됩니다. 시간이 모두 지나면 <code class=\"language-text\">SIGKILL</code>을 통해 모든 프로세스가 종료되고 pod도 삭제됩니다.</p>\n<br>\n<h2 id=\"적용-후기\" style=\"position:relative;\"><a href=\"#%EC%A0%81%EC%9A%A9-%ED%9B%84%EA%B8%B0\" aria-label=\"적용 후기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>적용 후기</h2>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=16q46FTUBbbJRrccrGFLihodJKODGDW1v\" alt=\"test\"></p>\n<p>위의 문제들을 모두 수정한 이후부터 안정적으로 worker의 확장, 축소가 이루어졌습니다.<br>\n위 그림과 같이 개발 환경에 동시성 테스트를 위한 DAG을 먼저 만들어서 slot 지표에 따라 replica count가 어떻게 변화하는지 확인해본다면 안정적으로 적용할 수 있습니다.</p>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<ul>\n<li><a href=\"https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#flapping\">https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#flapping</a></li>\n<li><a href=\"https://learnk8s.io/graceful-shutdown\">https://learnk8s.io/graceful-shutdown</a></li>\n</ul>","excerpt":"Airflow에서 실행되는 배치 작업들은 특정 시간 또는 야간에 많이 수행되고 이외의 시간은 상대적으로 여유로운 경우가 많습니다. 이러한 상황에서 오토스케일링을 적용한다면 효율적으로 리소스를 최적화하여 사용할 수 있습니다. 만약 쿠버네티스 위에서 Celery Executor를 사용한다면 worker의 오토스케일링을 위해 KEDA를 고려해볼 수 있습니다. 이 글에서는 Airflow worker에 KEDA autoscaler를 적용하면서 겪었던 여러 문제들과 해결 과정에 대해 정리해보려 합니다.  KEDA autoscaler KEDA…"}}}},"pageContext":{"slug":"airflow-worker-keda-autoscaler","basePath":"","prev":null,"next":{"slug":"container-tini-dumb-init","publishDate":"2022-05-27"}}}}