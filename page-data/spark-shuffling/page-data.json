{"componentChunkName":"component---src-templates-post-js","path":"/spark-shuffling/","result":{"data":{"contentfulPost":{"title":"Spark의 Shuffling 이해하기","slug":"spark-shuffling","metaDescription":null,"publishDate":"August 25, 2017","publishDateISO":"2017-08-25","tags":[{"title":"DataEngineering","id":"25d7d0d6-3cf7-5e19-a5cb-9c3fa926046f","slug":"dataengineering"}],"heroImage":{"title":"cover-dataengineering","gatsbyImageData":{"images":{"sources":[{"srcSet":"https://images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=400&h=267&q=50&fm=webp 400w,\nhttps://images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=800&h=533&q=50&fm=webp 800w,\nhttps://images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(min-width: 1600px) 1600px, 100vw","type":"image/webp"}],"fallback":{"src":"https://images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&fl=progressive&q=50&fm=jpg","srcSet":"https://images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=400&h=267&fl=progressive&q=50&fm=jpg 400w,\nhttps://images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=800&h=533&fl=progressive&q=50&fm=jpg 800w,\nhttps://images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&fl=progressive&q=50&fm=jpg 1600w","sizes":"(min-width: 1600px) 1600px, 100vw"}},"layout":"constrained","width":1800,"height":1200,"placeholder":{"fallback":"data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAlgCWAAD/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wAARCAANABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAMBAgb/xAAcEAACAgMBAQAAAAAAAAAAAAAAAQIREiExYeH/xAAWAQEBAQAAAAAAAAAAAAAAAAABAgP/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwDK1DF0vgtxW9EylQu8nTotmo+gHfAEP//Z"}},"ogimg":{"src":"https://images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50"}},"body":{"childMarkdownRemark":{"timeToRead":2,"html":"<p>효율적인 Spark Application을 개발하기 위해 <strong>Shuffling</strong> 은 상당히 중요한 개념입니다.\n이에 대해 간단히 정리해보았습니다.</p>\n<br>\n<h2 id=\"spark-architecture-shuffle\" style=\"position:relative;\"><a href=\"#spark-architecture-shuffle\" aria-label=\"spark architecture shuffle permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Spark Architecture: Shuffle</h2>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=1jH6eFX_nkb9vzPFlIiFOV9z-afkUOELQ\" alt=\"\"></p>\n<p>Shuffle을 설명하기 전에 한 가지 예시를 들어보겠습니다.\n테이블에 전화 통화 기록 목록이 있고 매일 발생한 통화량을 계산한다고 가정 해보겠습니다.\n“날짜”를 키로 설정하고 각 레코드에 대해 값으로 “1”을 지정한 다음, 각 키의 값을 합산하여 결과 값을 계산할 수 있을 것 입니다.</p>\n<p>만일 데이터가 여러 클러스터에 저장되어 있다면 어떻게 해야 동일한 키의 값을 합산할 수 있을까요?\n이를 위한 유일한 방법은 같은 키의 모든 값을 동일한 시스템에 두는 것입니다. 그런 다음 이 값들을 합치면 됩니다.</p>\n<br>\n<h2 id=\"narrow-and-wide-transformation\" style=\"position:relative;\"><a href=\"#narrow-and-wide-transformation\" aria-label=\"narrow and wide transformation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Narrow and Wide Transformation</h2>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=1TrPHpsimWez75krgjIQHYr49Wr8WwEdA\" alt=\"\"></p>\n<p>몇 가지 사례를 통해 더 자세히 알아보겠습니다.\n만일 데이터가 이미 키 값으로 파티셔닝 되어 있고 키 값에 대해 변화를 주고 싶다면, 좌측의 그림처럼 수행하게 됩니다.\n<code class=\"language-text\">filter(), sample(), map(), flatMap()</code> 등의 transformation이 이에 해당하며, 이 경우 Shuffle이 필요 없습니다.\n이를 <strong>Narrow Transformation</strong> 이라고 합니다.</p>\n<p>반면, 서로 다른 파티션으로부터 특정한 값을 기준으로 추출하고 싶은 경우, 그 값을 기준으로 Shuffle이 발생하게 됩니다.\n<code class=\"language-text\">groupByKey(), reduceByKey()</code> 등이 이에 해당하며, 이를 <strong>Wide Transformation</strong> 이라고 합니다.</p>\n<br>\n<h2 id=\"shuffled-hashjoin\" style=\"position:relative;\"><a href=\"#shuffled-hashjoin\" aria-label=\"shuffled hashjoin permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Shuffled HashJoin</h2>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=1BlOjTPvvIknPOyZvSZ0SUG6dDvPewvn-\" alt=\"\"></p>\n<p>두 개의 테이블을 <code class=\"language-text\">Join</code> 할 때에도 Shuffle 이 발생할 수 있습니다.\n위의 예시 처럼 두 테이블에서 키 값을 기준으로 Join 하게 되면, 동일한 키를 가진 데이터가 동일한 파티션으로 이동합니다.</p>\n<p>하지만 이 때, 셔플 되는 데이터의 양이 성능에 영향을 미칠 수 있습니다.\n만일 C의 데이터의 크기가 A보다 훨씬 크다면, C에 대한 작업으로 인해 전체의 수행시간이 오래 걸리게 될 것 입니다.</p>\n<br>\n<h2 id=\"broadcast-hashjoin\" style=\"position:relative;\"><a href=\"#broadcast-hashjoin\" aria-label=\"broadcast hashjoin permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Broadcast HashJoin</h2>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=1v4QkFLzoEGFhahqnfaXiYlOFuE4XioUL\" alt=\"\"></p>\n<p>이를 개선하기 위해 Spark에서는 <strong>Broadcast Join</strong> 을 제공합니다.\n이 경우 RDD 중 하나가 모든 파티션으로 브로드 캐스팅되며 복사됩니다.\n만일 RDD 중 하나가 다른 것에 비해 상당히 작다면 큰 RDD가 전혀 셔플 할 필요가 없습니다.\n작은 RDD 만 모든 작업자 서버에 복사해야 하므로 Broadcast Join은 전체적으로 네트워크 트래픽을 줄여주는 효과가 있습니다.</p>\n<p>Spark 1.2에서는 <code class=\"language-text\">spark.sql.autoBroadcastJoinThreshold</code> 값을 설정해주어야 했지만,\n2.0 이후 버전의 경우 Spark SQL이 알아서 최적화 잘 해줍니다.</p>\n<br>\n<h2 id=\"spark-shuffle-properties\" style=\"position:relative;\"><a href=\"#spark-shuffle-properties\" aria-label=\"spark shuffle properties permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Spark Shuffle Properties</h2>\n<ul>\n<li><code class=\"language-text\">spark.shuffle.compress</code>: 엔진이 shuffle 출력을 압축할지 여부를 지정</li>\n<li><code class=\"language-text\">spark.shuffle.spill.compress</code>: 중간 shuffle spill 파일을 압축할지 여부를 지정</li>\n</ul>\n<p>Shuffle에는 위의 두 가지 중요한 Spark Property 가 있습니다.</p>\n<p>둘 다 기본적으로 값이 “true”이며, <code class=\"language-text\">spark.io.compression.codec</code> 압축 코덱을 기본으로합니다.\n그리고 위에서 설명한 것처럼 Spark에는 여러 가지 셔플 구현이 있습니다.\n특정 구현에서 사용되는 Shuffle은 <code class=\"language-text\">spark.shuffle.manager</code> 값에 의해 결정됩니다.\n가능한 옵션은 <strong>hash, sort, tungsten-sort</strong> 이며, “sort” 옵션은 기본적으로 Spark 1.2.0부터 시작합니다.</p>\n<p>이외에도 Spark Shuffle 관련된 Property는 아래의 공식문서에서 확인하실 수 있습니다.\n<a href=\"https://spark.apache.org/docs/latest/configuration.html#shuffle-behavior\">https://spark.apache.org/docs/latest/configuration.html#shuffle-behavior</a></p>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<ul>\n<li><a href=\"https://0x0fff.com/spark-architecture-shuffle\">https://0x0fff.com/spark-architecture-shuffle</a></li>\n<li><a href=\"https://www.slideshare.net/databricks/strata-sj-everyday-im-shuffling-tips-for-writing-better-spark-programs\">https://www.slideshare.net/databricks/strata-sj-everyday-im-shuffling-tips-for-writing-better-spark-programs</a></li>\n</ul>\n<br>","excerpt":"효율적인 Spark Application을 개발하기 위해 Shuffling 은 상당히 중요한 개념입니다.\n이에 대해 간단히 정리해보았습니다. Spark Architecture: Shuffle  Shuffle을 설명하기 전에 한 가지 예시를 들어보겠습니다.\n테이블에 전화 통화 기록 목록이 있고 매일 발생한 통화량을 계산한다고 가정 해보겠습니다.\n“날짜”를 키로 설정하고 각 레코드에 대해 값으로 “…"}}}},"pageContext":{"slug":"spark-shuffling","basePath":"","prev":{"slug":"aws-emr-s3-spark","publishDate":"2017-09-09"},"next":{"slug":"spark-reduceByKey-groupByKey","publishDate":"2017-08-22"}}},"staticQueryHashes":["1946181227","2744905544","3732430097"]}