{"componentChunkName":"component---src-templates-posts-js","path":"/7","result":{"data":{"allContentfulPost":{"edges":[{"node":{"title":"제플린 노트북 자동 실행 스크립트 만들기","id":"ae1bd687-b1b2-535f-a826-8e600505d3df","slug":"zeppelin-bootstrap","publishDate":"September 13, 2017","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"a29a76e7-6151-5f0f-8eb3-1c75a8fb8f5a","childMarkdownRemark":{"id":"1107c2c0-8dc1-5eca-a038-7c07e481d047","timeToRead":1,"html":"<p>제플린 노트북을 사용하다보면 가끔 제플린 어플리케이션을 재시작해야 하는 경우가 있습니다.\n이 때, view 또는 udf 등록을 위해 처음 실행시켜야 하는 노트북이 있다면 참 번거롭습니다.\n하지만 <strong>Zeppelin Notebook API</strong> 사용한다면 이를 쉽게 자동화 할 수 있습니다.</p>\n<br>\n<h2 id=\"zeppelin-notebook-api\" style=\"position:relative;\"><a href=\"#zeppelin-notebook-api\" aria-label=\"zeppelin notebook api permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Zeppelin Notebook API</h2>\n<p>제플린은 노트북 자동실행을 위한 REST API를 제공합니다.\n하지만 제플린에 인증이 걸려있다면, 인증을 거쳐야만 API를 사용할 수 있습니다.\n따라서, 먼저 curl로 세션 값을 받고 해당 노트북 아이디를 호출하시면 됩니다.</p>\n<p>노트북 아이디는 해당 노트 URL의 가장 마지막 값 입니다. (ex 2AZPHY918)\n아래의 스크립트는 아이디가 user, 패스워드가 1234인 경우를 예시로 들었습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">#!/bin/sh\nsudo /usr/lib/zeppelin/bin/zeppelin-daemon.sh stop\nsleep 3\nsudo /usr/lib/zeppelin/bin/zeppelin-daemon.sh start\n\nsleep 15\n\nSESSION=&quot;`curl -i --data &#39;userName=user&amp;password=1234)&#39; -X POST http://zeppelin-url.com:8890/api/login | grep &#39;Set-Cookie: JSESSIONID=&#39; | cut -d &#39;:&#39; -f2 |  tail -1 | cut -d &#39;;&#39; -f1`&quot;\necho $SESSION\ncurl -i -b ${SESSION} -X POST http://zeppelin-url.com:8890/api/notebook/job/NOTEBOOK_ID</code></pre></div>\n<p>Notebook API를 활용하면 노트북 실행 뿐만 아니라, Cron이나 노트북 권한 설정도 자동화할 수 있습니다.\n자세한 내용은 아래의 공식문서에서 확인하실 수 있습니다.</p>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<ul>\n<li><a href=\"https://zeppelin.apache.org/docs/0.7.3/rest-api/rest-notebook.html\">https://zeppelin.apache.org/docs/0.7.3/rest-api/rest-notebook.html</a></li>\n</ul>\n<br>","excerpt":"제플린 노트북을 사용하다보면 가끔 제플린 어플리케이션을 재시작해야 하는 경우가 있습니다.\n이 때, view 또는 udf…"}}}},{"node":{"title":"AWS EMR에서 S3 사용 시 주의사항","id":"5a25926b-645a-574b-ba52-5085574c8619","slug":"aws-emr-s3-spark","publishDate":"September 09, 2017","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"0b9a2387-1599-568e-a5c4-5841d21e528b","childMarkdownRemark":{"id":"2f4a55d7-9be9-53d7-a09a-4da4630a4cde","timeToRead":3,"html":"<p>AWS EMR에서 Spark을 사용하는 경우, S3를 저장소로 사용하는 경우가 많습니다.\n이때 주의해야 할 사항들을 정리해보았습니다.</p>\n<ul>\n<li><strong>최근 수정사항</strong> : 해당 이슈는 EMR 최신 버전에서 대부분 해결되었습니다.</li>\n<li>자세한 내용은 <a href=\"https://aws.amazon.com/ko/blogs/korea/improve-apache-spark-write-performance-on-apache-parquet-formats-with-the-emrfs-s3-optimized-committer/\">Parquet 형식의 EMRFS S3 최적화 커미터를 통한 Apache Spark 쓰기 성능 개선하기</a> 에서 확인하시기 바랍니다.</li>\n</ul>\n<br>\n<h2 id=\"aws-emr-spark-그리고-s3\" style=\"position:relative;\"><a href=\"#aws-emr-spark-%EA%B7%B8%EB%A6%AC%EA%B3%A0-s3\" aria-label=\"aws emr spark 그리고 s3 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>AWS EMR, Spark 그리고 S3</h2>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1FWjProAZAa51cBO6nkLEq1kRhpeG8uhQ\"></p>\n<br>\n<p>Daily로 돌려야 하는 ETL 작업의 경우 위와 같이 간단한 아키텍쳐로 구성하는 경우가 많습니다.\n대부분의 경우 저장소로 S3를 적극 활용하게 됩니다.\n최초 입수되는 로그를 저장하기도 하고, Transformation 작업 이후 중간 또는 최종 데이터로 저장하기도 합니다.</p>\n<br>\n<h2 id=\"문제-상황\" style=\"position:relative;\"><a href=\"#%EB%AC%B8%EC%A0%9C-%EC%83%81%ED%99%A9\" aria-label=\"문제 상황 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>문제 상황</h2>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">java.io.IOException: Connection reset by peer\nERROR ContextCleaner: Error cleaning broadcast 5</code></pre></div>\n<p>최근 Spark RDD 코드를 DataFrame으로 리팩토링 하던 중에 위와 같은 오류를 겪었습니다.\n일별 로그를 불러와서 전처리하고 다시 저장하는데 s3 write 부분에서 갑자기 Executor의 Connection이 끊기는 문제였습니다.</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=1jKeOxJk_fjDCXfmkLr_GVxTiMAY5IKAQ\"></p>\n<br>\n<p>Ganglia 모니터링 결과를 보면 중간에 약 15분의 공백이 있는데,\n이 부분이 Connection이 중간에 끊기고 다시 뜰 때까지 걸리는 시간입니다.</p>\n<br>\n<h2 id=\"s3n-s3a-s3\" style=\"position:relative;\"><a href=\"#s3n-s3a-s3\" aria-label=\"s3n s3a s3 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>S3N, S3A, S3</h2>\n<p>먼저 S3는 File System이 아닌 <strong>Object Storage</strong> 라는 점을 알고 계셔야 합니다.\n따라서, S3에 분산저장하는 경우, 우리는 Hadoop 클라이언트를 거쳐 저장하게 됩니다.\nHadoop은 <code class=\"language-text\">S3N, S3A, S3</code> 이렇게 세 가지 시스템 클라이언트를 제공합니다. 각 클라이언트는 URI 스키마를 통해 접근할 수 있습니다.</p>\n<ul>\n<li><strong>S3N (s3n://)</strong> : S3N은 S3에 일반 파일을 읽고 쓰는 기본 파일 시스템입니다. S3N은 안정적이며 널리 사용되고 있지만 현재는 업데이트가 중단되었습니다. S3N의 단점은 파일 엑세스가 한번에 5GB로 제한되어 있다는 점입니다.</li>\n<li><strong>S3A (s3a://)</strong> : S3A는 S3N을 개선한 다음 버전의 파일 시스템입니다. S3A는 Amazon의 라이브러리를 사용하여 S3와 상호 작용합니다. S3A는 5GB 이상의 파일 액세스를 지원하며 성능이 많이 향상되었습니다.</li>\n<li><strong>S3 (s3://)</strong> : S3는 Hadoop 0.10 버전부터 나온 블록 기반의 S3 파일 시스템 입니다. 따라서 파일이 HDFS에 있는 것과 같이 블록으로 저장됩니다.</li>\n</ul>\n<p>EMR은 EMRFS 라는 파일 시스템이 별도로 존재합니다.\nEMR의 S3 파일 시스템과 Hadoop에서의 S3 파일 시스템은 서로 다르기 때문에 항상 주의하셔야 합니다.\nEMR의 경우 <strong>s3</strong> 로 사용하는 것을 권장하고 있습니다. 반면에 s3a의 경우 EMRFS와 호환되지 않는다고 합니다.\n물론 실행 될 때도 있지만 위와 같은 오류가 발생할 수도 있습니다.</p>\n<br>\n<h2 id=\"parquet-저장-성능-개선하기\" style=\"position:relative;\"><a href=\"#parquet-%EC%A0%80%EC%9E%A5-%EC%84%B1%EB%8A%A5-%EA%B0%9C%EC%84%A0%ED%95%98%EA%B8%B0\" aria-label=\"parquet 저장 성능 개선하기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Parquet 저장 성능 개선하기</h2>\n<p>위의 오류는 URI를 s3로 수정해서 해결할 수 있었습니다.\n하지만 S3에 parquet로 저장하는 속도가 너무 느려 이 부분을 개선해보기로 했습니다.</p>\n<p>먼저 Spark에는 Parquet 빌드 속도를 개선하기 위해 <code class=\"language-text\">DirectParquetOutputCommitter</code>라는 기능이 있었습니다.\n하지만, S3에 저장할 때 이 기능을 사용하는 경우 데이터 유실이 발생할 수 있었습니다.\n<a href=\"https://issues.apache.org/jira/browse/SPARK-10063\">SPARK-10063 JIRA 티켓 참고</a></p>\n<p>이러한 이유로 Spark 2.0 버전부터 이 옵션은 사라졌습니다. 그러나, 성능 개선이 필요했기 때문에 Spark 사용자들은 대안을 요구했습니다.\n본래의 FileCommiter가 느린 이유는 rename 연산 때문이었습니다.\n실제 파일 시스템(HDFS)에서 rename 연산은 대상 파일 시스템의 임시 디렉토리로 출력 한 다음, 디렉토리의 이름을 커밋하는 방식으로 O(1)이 소요됩니다.\n하지만 Object Storage에 저장하는 경우, 데이터 사이즈만큼 O(N)이 소요됩니다.</p>\n<p>이 문제는 s3guard와 s3a의 도움으로 해결되었습니다.\ngetFileStatus()에서의 S3 HTTP 콜을 생략하고 dynamo metadata 저장 등을 통해 해결했다는데 자세한 내용은 <a href=\"https://issues.apache.org/jira/browse/MAPREDUCE-4815\">MAPREDUCE-4815 JIRA 티켓</a>을 보시는게 나을 듯 합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version 2\nspark.speculation False</code></pre></div>\n<p>적용하는 방법은 위의 Spark property 옵션을 추가해주시면 됩니다. Spark 2.1, Hadoop 2.7.2 버전 이상부터 사용가능 합니다.\n하지만 Spark 문서에도 나와있듯이 아직 failure에 대한 보장이 떨어집니다.\n따라서 먼저 로컬 HDFS에 임시저장 후 distcp 명령어를 사용하여 S3로 저장해주시면 됩니다.\nHadoop 2.8 버전부터는 s3guard가 기본으로 들어가기 때문에 안정화 될 것 이라고 합니다.</p>\n<p>결과는 로그 1억 건 기준 <strong>약 10배</strong> 의 성능 개선을 확인할 수 있었습니다.\n두서없이 정리하다보니 좀 글이 복잡해졌네요. 결론은 '옵션을 추가하자' 입니다.</p>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<ul>\n<li><a href=\"https://github.com/steveloughran/hadoop/blob/s3guard/HADOOP-13786-committer/hadoop-tools/hadoop-aws/src/site/markdown/tools/hadoop-aws/s3a_committer_architecture.md\">S3A Commiter가 아키텍쳐 및 구현 세부사항에 대하여 정리한 글</a></li>\n<li><a href=\"https://aws.amazon.com/ko/premiumsupport/knowledge-center/emr-file-system-s3/\">AWS 공식 문서에서 정리한 글 : S3N, S3A, S3</a></li>\n</ul>\n<br>","excerpt":"AWS EMR에서 Spark을 사용하는 경우, S…"}}}},{"node":{"title":"Spark의 Shuffling 이해하기","id":"ca419fc7-c4a8-5527-8671-c1e508769568","slug":"spark-shuffling","publishDate":"August 25, 2017","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"2a8f6e13-331a-57ae-9646-63d4ef59b0a6","childMarkdownRemark":{"id":"232124a0-9bf3-5161-8345-9ff38e52cee0","timeToRead":2,"html":"<p>효율적인 Spark Application을 개발하기 위해 <strong>Shuffling</strong> 은 상당히 중요한 개념입니다.\n이에 대해 간단히 정리해보았습니다.</p>\n<br>\n<h2 id=\"spark-architecture-shuffle\" style=\"position:relative;\"><a href=\"#spark-architecture-shuffle\" aria-label=\"spark architecture shuffle permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Spark Architecture: Shuffle</h2>\n<p><img src=\"/assets/images/shuffle.png\"></p>\n<p>Shuffle을 설명하기 전에 한 가지 예시를 들어보겠습니다.\n테이블에 전화 통화 기록 목록이 있고 매일 발생한 통화량을 계산한다고 가정 해보겠습니다.\n“날짜”를 키로 설정하고 각 레코드에 대해 값으로 “1”을 지정한 다음, 각 키의 값을 합산하여 결과 값을 계산할 수 있을 것 입니다.</p>\n<p>만일 데이터가 여러 클러스터에 저장되어 있다면 어떻게 해야 동일한 키의 값을 합산할 수 있을까요?\n이를 위한 유일한 방법은 같은 키의 모든 값을 동일한 시스템에 두는 것입니다. 그런 다음 이 값들을 합치면 됩니다.</p>\n<br>\n<h2 id=\"narrow-and-wide-transformation\" style=\"position:relative;\"><a href=\"#narrow-and-wide-transformation\" aria-label=\"narrow and wide transformation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Narrow and Wide Transformation</h2>\n<p><img src=\"/assets/images/narrow_and_wide.png\"></p>\n<p>몇 가지 사례를 통해 더 자세히 알아보겠습니다.\n만일 데이터가 이미 키 값으로 파티셔닝 되어 있고 키 값에 대해 변화를 주고 싶다면, 좌측의 그림처럼 수행하게 됩니다.\n<code class=\"language-text\">filter(), sample(), map(), flatMap()</code> 등의 transformation이 이에 해당하며, 이 경우 Shuffle이 필요 없습니다.\n이를 <strong>Narrow Transformation</strong> 이라고 합니다.</p>\n<p>반면, 서로 다른 파티션으로부터 특정한 값을 기준으로 추출하고 싶은 경우, 그 값을 기준으로 Shuffle이 발생하게 됩니다.\n<code class=\"language-text\">groupByKey(), reduceByKey()</code> 등이 이에 해당하며, 이를 <strong>Wide Transformation</strong> 이라고 합니다.</p>\n<br>\n<h2 id=\"shuffled-hashjoin\" style=\"position:relative;\"><a href=\"#shuffled-hashjoin\" aria-label=\"shuffled hashjoin permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Shuffled HashJoin</h2>\n<p><img src=\"/assets/images/shuffle_join.png\"></p>\n<p>두 개의 테이블을 <code class=\"language-text\">Join</code> 할 때에도 Shuffle 이 발생할 수 있습니다.\n위의 예시 처럼 두 테이블에서 키 값을 기준으로 Join 하게 되면, 동일한 키를 가진 데이터가 동일한 파티션으로 이동합니다.</p>\n<p>하지만 이 때, 셔플 되는 데이터의 양이 성능에 영향을 미칠 수 있습니다.\n만일 C의 데이터의 크기가 A보다 훨씬 크다면, C에 대한 작업으로 인해 전체의 수행시간이 오래 걸리게 될 것 입니다.</p>\n<br>\n<h2 id=\"broadcast-hashjoin\" style=\"position:relative;\"><a href=\"#broadcast-hashjoin\" aria-label=\"broadcast hashjoin permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Broadcast HashJoin</h2>\n<p><img src=\"/assets/images/broadcast_join.png\"></p>\n<p>이를 개선하기 위해 Spark에서는 <strong>Broadcast Join</strong> 을 제공합니다.\n이 경우 RDD 중 하나가 모든 파티션으로 브로드 캐스팅되며 복사됩니다.\n만일 RDD 중 하나가 다른 것에 비해 상당히 작다면 큰 RDD가 전혀 셔플 할 필요가 없습니다.\n작은 RDD 만 모든 작업자 서버에 복사해야 하므로 Broadcast Join은 전체적으로 네트워크 트래픽을 줄여주는 효과가 있습니다.</p>\n<p>Spark 1.2에서는 <code class=\"language-text\">spark.sql.autoBroadcastJoinThreshold</code> 값을 설정해주어야 했지만,\n2.0 이후 버전의 경우 Spark SQL이 알아서 최적화 잘 해줍니다.</p>\n<br>\n<h2 id=\"spark-shuffle-properties\" style=\"position:relative;\"><a href=\"#spark-shuffle-properties\" aria-label=\"spark shuffle properties permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Spark Shuffle Properties</h2>\n<ul>\n<li><code class=\"language-text\">spark.shuffle.compress</code>: 엔진이 shuffle 출력을 압축할지 여부를 지정</li>\n<li><code class=\"language-text\">spark.shuffle.spill.compress</code>: 중간 shuffle spill 파일을 압축할지 여부를 지정</li>\n</ul>\n<p>Shuffle에는 위의 두 가지 중요한 Spark Property 가 있습니다.</p>\n<p>둘 다 기본적으로 값이 “true”이며, <code class=\"language-text\">spark.io.compression.codec</code> 압축 코덱을 기본으로합니다.\n그리고 위에서 설명한 것처럼 Spark에는 여러 가지 셔플 구현이 있습니다.\n특정 구현에서 사용되는 Shuffle은 <code class=\"language-text\">spark.shuffle.manager</code> 값에 의해 결정됩니다.\n가능한 옵션은 <strong>hash, sort, tungsten-sort</strong> 이며, “sort” 옵션은 기본적으로 Spark 1.2.0부터 시작합니다.</p>\n<p>이외에도 Spark Shuffle 관련된 Property는 아래의 공식문서에서 확인하실 수 있습니다.\n<a href=\"https://spark.apache.org/docs/latest/configuration.html#shuffle-behavior\">https://spark.apache.org/docs/latest/configuration.html#shuffle-behavior</a></p>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<ul>\n<li><a href=\"https://0x0fff.com/spark-architecture-shuffle\">https://0x0fff.com/spark-architecture-shuffle</a></li>\n<li><a href=\"https://www.slideshare.net/databricks/strata-sj-everyday-im-shuffling-tips-for-writing-better-spark-programs\">https://www.slideshare.net/databricks/strata-sj-everyday-im-shuffling-tips-for-writing-better-spark-programs</a></li>\n</ul>\n<br>","excerpt":"효율적인 Spark Application을 개발하기 위해 Shuffling…"}}}},{"node":{"title":"Spark groupByKey vs reduceByKey","id":"346030b5-8193-5161-9bea-951b3f0146ac","slug":"spark-reduceByKey-groupByKey","publishDate":"August 22, 2017","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"037fcf8d-17a3-5fd2-8b52-271bc7f8836f","childMarkdownRemark":{"id":"5103dbd1-1b3c-5d75-8c16-3f900b1d0d8f","timeToRead":1,"html":"<p>Spark Application 성능 개선을 위한 <code class=\"language-text\">groupByKey, reduceBykey</code>에 대해 알아보겠습니다.</p>\n<br>\n<h2 id=\"groupbykey-vs-reducebykey\" style=\"position:relative;\"><a href=\"#groupbykey-vs-reducebykey\" aria-label=\"groupbykey vs reducebykey permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>groupByKey vs reduceBykey</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># reduceByKey</span>\nspark<span class=\"token punctuation\">.</span>textFile<span class=\"token punctuation\">(</span><span class=\"token string\">\"hdfs://...\"</span><span class=\"token punctuation\">)</span>\n <span class=\"token punctuation\">.</span>flatMap<span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> line<span class=\"token punctuation\">:</span> line<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n <span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> word<span class=\"token punctuation\">:</span> <span class=\"token punctuation\">(</span>word<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n <span class=\"token punctuation\">.</span>reduceByKey<span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> a<span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">:</span> a <span class=\"token operator\">+</span> b<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># groupByKey</span>\nspark<span class=\"token punctuation\">.</span>textFile<span class=\"token punctuation\">(</span><span class=\"token string\">\"hdfs://...\"</span><span class=\"token punctuation\">)</span>\n <span class=\"token punctuation\">.</span>flatMap<span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> line<span class=\"token punctuation\">:</span> line<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n <span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> word<span class=\"token punctuation\">:</span> <span class=\"token punctuation\">(</span>word<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n <span class=\"token punctuation\">.</span>groupByKey<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n <span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> <span class=\"token punctuation\">(</span>w<span class=\"token punctuation\">,</span> counts<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">(</span>w<span class=\"token punctuation\">,</span> <span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>counts<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>가장 흔히 알고 있는 word count 예제를 예로 들어보겠습니다.\n위의 예시는 reduceByKey를 사용했으며, 아래의 예시는 groupByKey를 사용했습니다.\n둘의 결과는 같지만 성능은 확인히 차이가 납니다.</p>\n<p>먼저 위의 코드에서 <code class=\"language-text\">flatMap, map</code> 까지는 동일한 노드에서 실행이 됩니다.\n하지만 reducer 부분에서는 모든 동일한 단어 쌍을 같은 노드로 이동시켜야 하기 때문에 <strong>Shuffle</strong> 이 발생합니다.</p>\n<p><img src=\"/assets/images/reduceByKey.png\"></p>\n<p>우선 reduceByKey의 경우, 먼저 각 노드에서 중간 집계를 진행하고 이에 대한 결과를 동일한 키 값으로 전송합니다.</p>\n<p><img src=\"/assets/images/groupByKey.png\"></p>\n<p>반면, groupByKey는 각 노드에 있는 데이터에 대해 바로 Shuffle 과정을 거치게 되고 결과를 내보냅니다.\n따라서 groupByKey는 네트워크를 통해 전송되는 데이터의 양이 많아질 뿐만 아니라, <strong>Out of disk</strong> 문제가 발생할 수도 있습니다.</p>\n<p>Shuffle은 기본적으로 비용이 큰 연산입니다.\ngroupByKey는 reduceByKey로 대체될 수 있기 때문에 많은 문서에서 이를 권장하고 있습니다.</p>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<ul>\n<li><a href=\"https://www.slideshare.net/databricks/strata-sj-everyday-im-shuffling-tips-for-writing-better-spark-programs\">https://www.slideshare.net/databricks/strata-sj-everyday-im-shuffling-tips-for-writing-better-spark-programs</a></li>\n</ul>\n<br>","excerpt":"Spark Application 성능 개선을 위한 에 대해 알아보겠습니다. groupByKey vs reduceBykey…"}}}},{"node":{"title":"Hive Metastore 구축 관련 문제와 해결과정","id":"ae3d06e8-e30e-5942-b118-b3e930d67172","slug":"hive-metastore-issue","publishDate":"August 11, 2017","heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"8ff6b231-b785-52d0-8bed-8d7b851c2c78","childMarkdownRemark":{"id":"ce6997a5-dcfe-5d66-ad3b-4c121fa5b2f8","timeToRead":2,"html":"<p>최근 Hive Metastore를 구축하면서 겪은 이슈와 해결과정을 기록해두려고 합니다.\n사용 환경은 Spark 2.1.1, Hive 2.1.1 입니다.</p>\n<br>\n<h2 id=\"hive-partition\" style=\"position:relative;\"><a href=\"#hive-partition\" aria-label=\"hive partition permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Hive Partition</h2>\n<div class=\"gatsby-highlight\" data-language=\"sql\"><pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">CREATE</span> EXTERNAL <span class=\"token keyword\">TABLE</span> table_name <span class=\"token punctuation\">(</span>\ncol1 STRING<span class=\"token punctuation\">,</span>\ncol2 STRING\n<span class=\"token punctuation\">)</span>\nPARTITIONED <span class=\"token keyword\">BY</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">key</span> STRING<span class=\"token punctuation\">)</span>\nSTORED <span class=\"token keyword\">AS</span> PARQUET\nLOCATION <span class=\"token string\">'location'</span><span class=\"token punctuation\">;</span></code></pre></div>\n<p>Hive에서 보통 위와 같은 쿼리로 테이블을 생성합니다.\nMetastore는 말 그대로 외부에 있는 테이블의 정보(스키마, 파티션 등)를 저장하는 개념입니다.\n따라서 <strong>EXTERNAL TABLE</strong> 로 생성하지 않은 상태에서 테이블을 DROP 시키면 다 날아가게 됩니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"sql\"><pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">ALTER</span> <span class=\"token keyword\">TABLE</span> table_name\n<span class=\"token keyword\">ADD</span> <span class=\"token keyword\">PARTITION</span> <span class=\"token punctuation\">(</span><span class=\"token keyword\">key</span><span class=\"token operator\">=</span><span class=\"token string\">'2017-08-11'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code></pre></div>\n<p>도중에 Partition key를 추가하고 싶을 때는 위와 같은 쿼리를 통해 추가할 수 있습니다.\n그러나, 추가한 정보가 바로 반영이 안될 때가 있습니다.</p>\n<p>이 경우에는 <code class=\"language-text\">MSCK REPAIR TABLE table_name;</code> 쿼리로 해결할 수 있습니다.\nMSCK는 Metastore Check의 약자라고 합니다.</p>\n<br>\n<h2 id=\"hive-metastore-parquet\" style=\"position:relative;\"><a href=\"#hive-metastore-parquet\" aria-label=\"hive metastore parquet permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Hive Metastore, Parquet</h2>\n<p>먼저 겪었던 문제에 대해 설명드리자면 Hive Metastore에 분명히 테이블이 들어가있고,\nHue에서는 잘 보이는데 Zeppelin에서는 모든 데이터에 null 값이 찍혀있었습니다.</p>\n<p>우선 Spark으로 Hive를 사용하는 방식이 2.0 버전 이후 부터 조금 변경되었습니다.\n이전에는 HiveContext를 사용했다면, 이제 SparkSession에서 <code class=\"language-text\">.enableHiveSupport()</code> 추가만 하면 됩니다.\n제플린에서는 SparkSession이 spark이라는 변수로 제공되는데,\n이 경우 interpreter에 <code class=\"language-text\">zeppelin.spark.useHiveContext=true</code>를 추가해서 사용할 수 있습니다.</p>\n<p>다시 문제로 돌아와서 좀 더 확인해보니 컬럼명에 대문자가 들어가면 모든 값이 null로 출력되고 있었습니다.\nSpark 공식문서에 이와 관련된 내용이 잘 나와있습니다.</p>\n<p>Spark SQL에서 Hive metastore로 데이터를 불러오는 경우, 성능 상의 이슈로 SerDe 대신 Spark SQL의 <strong>MetastoreParquet</strong> 를 사용합니다.\n이때 주의사항으로 Hive는 대소문자를 구분하지 않지만, Parquet는 구분합니다. (Hive is case insensitive, while Parquet is not)</p>\n<p>이를 위해 Spark 2.1.1 버전부터 새로운 Spark Properties가 추가되었습니다.</p>\n<p>따라서, Zeppelin interpreter에 아래의 설정 값을 추가해주시면 해결됩니다.\n<code class=\"language-text\">spark.sql.hive.caseSensitiveInferenceMode = INFER_AND_SAVE</code></p>\n<br>\n<h2 id=\"hive-tblproperties\" style=\"position:relative;\"><a href=\"#hive-tblproperties\" aria-label=\"hive tblproperties permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Hive TBLPROPERTIES</h2>\n<p>위에서 말한대로 Spark Properties를 추가하면,\nHive metastore의 parameter에 <code class=\"language-text\">spark.sql.sources.schema.part</code>가 생기게 됩니다.</p>\n<p>여기에서 \"field: name\"에 대소문자가 잘 구분되는 경우, 문제가 없지만 간혹 소문자로 들어오는 경우가 있습니다.\n이 경우에는 아래의 쿼리를 통해 Hive parameter를 수정해주시면 됩니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"sql\"><pre class=\"language-sql\"><code class=\"language-sql\"><span class=\"token keyword\">ALTER</span> <span class=\"token keyword\">TABLE</span> table_name <span class=\"token keyword\">SET</span> TBLPROPERTIES <span class=\"token punctuation\">(</span><span class=\"token string\">\"spark.sql.sources.schema.part.0\"</span> <span class=\"token operator\">=</span> <span class=\"token string\">\"fix this line\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code></pre></div>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<ul>\n<li><a href=\"https://spark.apache.org/docs/latest/sql-programming-guide.html#hive-metastore-parquet-table-conversion\">https://spark.apache.org/docs/latest/sql-programming-guide.html#hive-metastore-parquet-table-conversion</a></li>\n<li><a href=\"http://spark.apache.org/docs/latest/sql-programming-guide.html#upgrading-from-spark-sql-21-to-22\">http://spark.apache.org/docs/latest/sql-programming-guide.html#upgrading-from-spark-sql-21-to-22</a></li>\n</ul>\n<br>","excerpt":"최근 Hive Metastore를 구축하면서 겪은 이슈와 해결과정을 기록해두려고 합니다.\n사용 환경은 Spark 2.1.1, Hive 2.1.…"}}}},{"node":{"title":"Bagging과 Boosting 그리고 Stacking","id":"2a1f51a0-65ac-59d9-bb86-370d6b8ac4a8","slug":"bagging-boosting","publishDate":"July 19, 2017","heroImage":{"id":"434fa86e-ac5b-52f4-8bd1-6ac1432526e2","title":"cover-datascience","fluid":{"aspectRatio":1.5,"src":"//images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&h=1200&q=50 1800w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&h=1200&q=50&fm=webp 1800w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"ac8ad07c-6470-59fe-a551-b037f7ed51c7","childMarkdownRemark":{"id":"5f6e217c-527c-531d-bcd0-66f2d122662e","timeToRead":2,"html":"<p>오늘은 머신러닝 성능을 최대로 끌어올릴 수 있는 앙상블 기법에 대해 정리해보았습니다.</p>\n<br>\n<h2 id=\"ensemble-hybrid-method\" style=\"position:relative;\"><a href=\"#ensemble-hybrid-method\" aria-label=\"ensemble hybrid method permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Ensemble, Hybrid Method</h2>\n<p>앙상블 기법은 동일한 학습 알고리즘을 사용해서 여러 모델을 학습하는 개념입니다.\nWeak learner를 결합한다면, Single learner보다 더 나은 성능을 얻을 수 있다는 아이디어입니다.\n<strong>Bagging</strong> 과 <strong>Boosting</strong> 이 이에 해당합니다.</p>\n<p>동일한 학습 알고리즘을 사용하는 방법을 앙상블이라고 한다면,\n서로 다른 모델을 결합하여 새로운 모델을 만들어내는 방법도 있습니다.\n대표적으로 <strong>Stacking</strong> 이 있으며, 최근 Kaggle 에서 많이 소개된 바 있습니다.</p>\n<br>\n<h2 id=\"bagging\" style=\"position:relative;\"><a href=\"#bagging\" aria-label=\"bagging permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Bagging</h2>\n<p>Bagging은 샘플을 여러 번 뽑아 각 모델을 학습시켜 결과를 <strong>집계(Aggregating)</strong> 하는 방법입니다. 아래의 그림을 통해 자세히 알아보겠습니다.</p>\n<p><img src=\"/assets/images/boosting.png\"></p>\n<p>먼저 대상 데이터로부터 복원 랜덤 샘플링을 합니다.\n이렇게 추출한 데이터가 일종의 표본 집단이 됩니다.\n이제 여기에 동일한 모델을 학습시킵니다.\n그리고 학습된 모델의 예측변수들을 집계하여 그 결과로 모델을 생성해냅니다.</p>\n<p>이러한 방식을 <strong>Bootstrap Aggregating</strong> 이라고 부릅니다.</p>\n<p>이렇게 하는 이유는 \"알고리즘의 안정성과 정확성을 향상시키기 위해서\" 입니다.\n대부분 학습에서 나타나는 오류는 다음과 같습니다.</p>\n<ol>\n<li>높은 bias로 인한 Underfitting</li>\n<li>높은 Variance로 인한 Overfitting</li>\n</ol>\n<p>앙상블 기법은 이러한 오류를 최소화하는데 도움이 됩니다.\n특히 Bagging은 각 샘플에서 나타난 결과를 일종의 중간값으로 맞추어 주기 때문에,\nOverfitting을 피할 수 있습니다.</p>\n<p>일반적으로 Categorical Data인 경우, 투표 방식 (Voting)으로 집계하며\nContinuous Data인 경우, 평균 (Average)으로 집계합니다.</p>\n<p>대표적인 Bagging 알고리즘으로 <code class=\"language-text\">RandomForest</code> 모델이 있습니다.\n원래 단일 DecisionTree 모델은 boundary가 discrete 한 모양일 수 밖에 없지만,\nRandomForest는 여러 트리 모델을 결합하여 이를 넘어설 수 있게 되었습니다.</p>\n<p>결과는 아래와 같습니다.</p>\n<p><img src=\"/assets/images/agg_result.png\"></p>\n<br>\n<h2 id=\"boosting\" style=\"position:relative;\"><a href=\"#boosting\" aria-label=\"boosting permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Boosting</h2>\n<p>Bagging이 일반적인 모델을 만드는데 집중되어있다면,\nBoosting은 맞추기 어려운 문제를 맞추는데 초점이 맞춰져 있습니다.</p>\n<p>수학 문제를 푸는데 9번 문제가 엄청 어려워서 계속 틀렸다고 가정해보겠습니다.\nBoosting 방식은 9번 문제에 가중치를 부여해서 9번 문제를 잘 맞춘 모델을 최종 모델로 선정합니다.\n아래 그림을 통해 자세히 알아보겠습니다.</p>\n<p><img src=\"https://quantdare.com/wp-content/uploads/2016/04/bb3.png\"></p>\n<p>Boosting도 Bagging과 동일하게 복원 랜덤 샘플링을 하지만, 가중치를 부여한다는 차이점이 있습니다.\nBagging이 병렬로 학습하는 반면, Boosting은 순차적으로 학습시킵니다.\n학습이 끝나면 나온 결과에 따라 가중치가 재분배됩니다.</p>\n<p>오답에 대해 높은 가중치를 부여하고, 정답에 대해 낮은 가중치를 부여하기 때문에\n오답에 더욱 집중할 수 있게 되는 것 입니다.\nBoosting 기법의 경우, 정확도가 높게 나타납니다.\n하지만, 그만큼 Outlier에 취약하기도 합니다.</p>\n<p>AdaBoost, XGBoost, GradientBoost 등 다양한 모델이 있습니다.\n그 중에서도 XGBoost 모델은 강력한 성능을 보여줍니다. 최근 대부분의 Kaggle 대회 우승 알고리즘이기도 합니다.</p>\n<br>\n<h2 id=\"stacking\" style=\"position:relative;\"><a href=\"#stacking\" aria-label=\"stacking permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Stacking</h2>\n<p><strong>Meta Modeling</strong> 이라고 불리기도 하는 이 방법은 위의 2가지 방식과는 조금 다릅니다.\n“Two heads are better than one” 이라는 아이디어에서 출발합니다.</p>\n<p>Stacking은 서로 다른 모델들을 조합해서 최고의 성능을 내는 모델을 생성합니다.\n여기에서 사용되는 모델은 SVM, RandomForest, KNN 등 다양한 알고리즘을 사용할 수 있습니다.\n이러한 조합을 통해 서로의 장점은 취하고 약점을 보완할 수 있게 되는 것 입니다.</p>\n<p>Stacking은 이미 느끼셨겠지만 필요한 연산량이 어마어마합니다.\n적용해보고 싶다면 아래의 StackNet을 사용하는 방법을 추천합니다.</p>\n<p><a href=\"https://github.com/kaz-Anova/StackNet\">https://github.com/kaz-Anova/StackNet</a></p>\n<p>문제에 따라 정확도를 요구하기도 하지만, 안정성을 요구하기도 합니다.\n따라서, 주어진 문제에 적절한 모델을 선택하는 것이 중요합니다.</p>\n<br>","excerpt":"오늘은 머신러닝 성능을 최대로 끌어올릴 수 있는 앙상블 기법에 대해 정리해보았습니다. Ensemble, Hybrid Method…"}}}}]}},"pageContext":{"basePath":"","paginationPath":"","pageNumber":6,"humanPageNumber":7,"skip":37,"limit":6,"numberOfPages":15,"previousPagePath":"/6","nextPagePath":"/8"}}}