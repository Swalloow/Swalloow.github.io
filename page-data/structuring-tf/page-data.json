{"componentChunkName":"component---src-templates-post-js","path":"/structuring-tf/","result":{"data":{"contentfulPost":{"title":"Structuring Your TensorFlow Models","slug":"structuring-tf","metaDescription":null,"publishDate":"April 20, 2018","publishDateISO":"2018-04-20","tags":[{"title":"DataScience","id":"82931dd3-d22b-528e-8a9b-ddbb200bb401","slug":"datascience"}],"heroImage":{"title":"cover-datascience","gatsbyImageData":{"images":{"sources":[{"srcSet":"https://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=450&h=300&q=50&fm=webp 450w,\nhttps://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=900&h=600&q=50&fm=webp 900w,\nhttps://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&h=1200&q=50&fm=webp 1800w","sizes":"(min-width: 1800px) 1800px, 100vw","type":"image/webp"}],"fallback":{"src":"https://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&h=1200&fl=progressive&q=50&fm=jpg","srcSet":"https://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=450&h=300&fl=progressive&q=50&fm=jpg 450w,\nhttps://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=900&h=600&fl=progressive&q=50&fm=jpg 900w,\nhttps://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&h=1200&fl=progressive&q=50&fm=jpg 1800w","sizes":"(min-width: 1800px) 1800px, 100vw"}},"layout":"constrained","width":1800,"height":1200,"placeholder":{"fallback":"data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wAARCAANABQDASIAAhEBAxEB/8QAGQAAAgMBAAAAAAAAAAAAAAAAAAQCAwUG/8QAIBAAAgEEAQUAAAAAAAAAAAAAAQIAAwQRIRIFEzFCkf/EABQBAQAAAAAAAAAAAAAAAAAAAAH/xAAWEQEBAQAAAAAAAAAAAAAAAAABABH/2gAMAwEAAhEDEQA/AK2EUrvxZQfJOplUeoXt4xHeWkMeqSS8jcKtSrUqHOcs2vggpIN0JGSdQiZvnXRUGENJxv/Z"}},"ogimg":{"src":"https://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&q=50"}},"body":{"childMarkdownRemark":{"timeToRead":4,"html":"<p>이 글은 저자의 허락을 받아 번역한 글 입니다. <a href=\"https://danijar.com/structuring-your-tensorflow-models/\">원문 링크</a></p>\n<p>TensorFlow에서 모델을 정의하다보면 어느새 많은 양의 코드가 생성된 경험이 있을 것 입니다. 어떻게 하면 가독성과 재사용성이 높은 코드로 구성할 수 있을까요? 여기에서 실제 동작하는 예시 코드를 확인하실 수 있습니다. <a href=\"https://gist.github.com/danijar/8663d3bbfd586bffecf6a0094cd116f2\">Gist Link</a></p>\n<br>\n<h2 id=\"defining-the-compute-graph\" style=\"position:relative;\"><a href=\"#defining-the-compute-graph\" aria-label=\"defining the compute graph permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Defining the Compute Graph</h2>\n<p>모델 당 하나의 클래스부터 시작하는 것이 좋습니다. 그 클래스의 인터페이스는 무엇인가요? 일반적으로 모델은 input data와 target placeholder를 연결하며 training, evaluation 그리고 inference 관련 함수를 제공합니다.</p>\n<script src=\"https://gist.github.com/Swalloow/c90dea8bce9ceee147851656f48fac9f.js\"></script>\n<p>위의 코드가 기본적으로 TensorFlow codebase에서 모델이 정의되는 방식입니다. 그러나 여기에도 몇 가지 문제가 있습니다. 가장 중요한 문제는 전체 그래프가 단일 함수 생성자로 정의된다는 점 입니다. 이렇게 되면 가독성이 떨어지며 재사용이 어렵습니다.</p>\n<br>\n<h2 id=\"using-properties\" style=\"position:relative;\"><a href=\"#using-properties\" aria-label=\"using properties permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Using Properties</h2>\n<p>함수가 호출 될 때마다 그래프는 확장되기 때문에 함수로 분할하는 것만으로는 부족합니다. 따라서 함수를 처음 호출하는 시점에 operation들이 그래프에 추가되도록 해야합니다. 이러한 방식을 기본적으로 <strong>lazy-loading</strong>이라고 합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">Model</span><span class=\"token punctuation\">:</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> data<span class=\"token punctuation\">,</span> target<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        data_size <span class=\"token operator\">=</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">.</span>get_shape<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n        target_size <span class=\"token operator\">=</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>target<span class=\"token punctuation\">.</span>get_shape<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n        weight <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>Variable<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>truncated_normal<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>data_size<span class=\"token punctuation\">,</span> target_size<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        bias <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>Variable<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>constant<span class=\"token punctuation\">(</span><span class=\"token number\">0.1</span><span class=\"token punctuation\">,</span> shape<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span>target_size<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        incoming <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>matmul<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">,</span> weight<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> bias\n        self<span class=\"token punctuation\">.</span>_prediction <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>softmax<span class=\"token punctuation\">(</span>incoming<span class=\"token punctuation\">)</span>\n        cross_entropy <span class=\"token operator\">=</span> <span class=\"token operator\">-</span>tf<span class=\"token punctuation\">.</span>reduce_sum<span class=\"token punctuation\">(</span>target<span class=\"token punctuation\">,</span> tf<span class=\"token punctuation\">.</span>log<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>_prediction<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>_optimize <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">.</span>RMSPropOptimizer<span class=\"token punctuation\">(</span><span class=\"token number\">0.03</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>minimize<span class=\"token punctuation\">(</span>cross_entropy<span class=\"token punctuation\">)</span>\n        mistakes <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>not_equal<span class=\"token punctuation\">(</span>\n            tf<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>target<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> tf<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>_prediction<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>_error <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>reduce_mean<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>cast<span class=\"token punctuation\">(</span>mistakes<span class=\"token punctuation\">,</span> tf<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token decorator annotation punctuation\">@property</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">prediction</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>_prediction\n\n    <span class=\"token decorator annotation punctuation\">@property</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">optimize</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>_optimize\n\n    <span class=\"token decorator annotation punctuation\">@property</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">error</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>_error</code></pre></div>\n<p>위의 방식이 첫 번째 예제보다 훨씬 좋습니다. 이제 코드는 독립적인 함수로 구성되어 있습니다. 그러나 아직 코드는 lazy-loading으로 인해 약간 복잡해보입니다. 이를 어떻게 개선 할 수 있는지 보도록 하겠습니다.</p>\n<br>\n<h2 id=\"lazy-property-decorator\" style=\"position:relative;\"><a href=\"#lazy-property-decorator\" aria-label=\"lazy property decorator permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Lazy Property Decorator</h2>\n<p>파이썬은 아주 유연한 언어입니다. 이제 마지막 예제에서 중복 코드를 제거하는 방법을 보여드리겠습니다. 우리는 <code class=\"language-text\">@property</code>처럼 동작하지만 한번만 함수를 평가하는 decorator를 사용할 것입니다. decorator는 함수(접두사를 앞에 붙임)의 이름을 따서 멤버에 결과를 저장하고 나중에 호출되는 시점에 해당 값을 반환합니다. custom decorator를 아직 사용해본적이 없다면, <a href=\"http://blog.apcelent.com/python-decorator-tutorial-with-example.html\">이 가이드</a>를 참고하시면 됩니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">Model</span><span class=\"token punctuation\">:</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> data<span class=\"token punctuation\">,</span> target<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>data <span class=\"token operator\">=</span> data\n        self<span class=\"token punctuation\">.</span>target <span class=\"token operator\">=</span> target\n        self<span class=\"token punctuation\">.</span>_prediction <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span>\n        self<span class=\"token punctuation\">.</span>_optimize <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span>\n        self<span class=\"token punctuation\">.</span>_error <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span>\n\n    <span class=\"token decorator annotation punctuation\">@property</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">prediction</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> self<span class=\"token punctuation\">.</span>_prediction<span class=\"token punctuation\">:</span>\n            data_size <span class=\"token operator\">=</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">.</span>get_shape<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n            target_size <span class=\"token operator\">=</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>target<span class=\"token punctuation\">.</span>get_shape<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n            weight <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>Variable<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>truncated_normal<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>data_size<span class=\"token punctuation\">,</span> target_size<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n            bias <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>Variable<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>constant<span class=\"token punctuation\">(</span><span class=\"token number\">0.1</span><span class=\"token punctuation\">,</span> shape<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span>target_size<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n            incoming <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>matmul<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">,</span> weight<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> bias\n            self<span class=\"token punctuation\">.</span>_prediction <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>softmax<span class=\"token punctuation\">(</span>incoming<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>_prediction\n\n    <span class=\"token decorator annotation punctuation\">@property</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">optimize</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> self<span class=\"token punctuation\">.</span>_optimize<span class=\"token punctuation\">:</span>\n            cross_entropy <span class=\"token operator\">=</span> <span class=\"token operator\">-</span>tf<span class=\"token punctuation\">.</span>reduce_sum<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>target<span class=\"token punctuation\">,</span> tf<span class=\"token punctuation\">.</span>log<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>prediction<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n            optimizer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">.</span>RMSPropOptimizer<span class=\"token punctuation\">(</span><span class=\"token number\">0.03</span><span class=\"token punctuation\">)</span>\n            self<span class=\"token punctuation\">.</span>_optimize <span class=\"token operator\">=</span> optimizer<span class=\"token punctuation\">.</span>minimize<span class=\"token punctuation\">(</span>cross_entropy<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>_optimize\n\n    <span class=\"token decorator annotation punctuation\">@property</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">error</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> self<span class=\"token punctuation\">.</span>_error<span class=\"token punctuation\">:</span>\n            mistakes <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>not_equal<span class=\"token punctuation\">(</span>\n                tf<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>target<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> tf<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>prediction<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n            self<span class=\"token punctuation\">.</span>_error <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>reduce_mean<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>cast<span class=\"token punctuation\">(</span>mistakes<span class=\"token punctuation\">,</span> tf<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> self<span class=\"token punctuation\">.</span>_error</code></pre></div>\n<p>위의 decorator를 사용해서 예시 코드는 아래와 같이 간결해졌습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> functools\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">lazy_property</span><span class=\"token punctuation\">(</span>function<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    attribute <span class=\"token operator\">=</span> <span class=\"token string\">'_cache_'</span> <span class=\"token operator\">+</span> function<span class=\"token punctuation\">.</span>__name__\n\n    <span class=\"token decorator annotation punctuation\">@property</span>\n    <span class=\"token decorator annotation punctuation\">@functools<span class=\"token punctuation\">.</span>wraps</span><span class=\"token punctuation\">(</span>function<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">decorator</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">if</span> <span class=\"token keyword\">not</span> <span class=\"token builtin\">hasattr</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> attribute<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            <span class=\"token builtin\">setattr</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> attribute<span class=\"token punctuation\">,</span> function<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> <span class=\"token builtin\">getattr</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> attribute<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">return</span> decorator</code></pre></div>\n<p>생성자에서 property를 언급했다는 부분이 중요합니다. 이렇게 구성한다면 <code class=\"language-text\">tf.initialize_variables()</code>를 실행할 때 전체 그래프가 정의됩니다.</p>\n<br>\n<h2 id=\"organizing-the-graph-with-scopes\" style=\"position:relative;\"><a href=\"#organizing-the-graph-with-scopes\" aria-label=\"organizing the graph with scopes permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Organizing the Graph with Scopes</h2>\n<p>이제 코드에서 모델을 정의하는 부분은 깔끔해졌지만, 그래프의 연산 부분은 여전히 복잡합니다. 만일 <a href=\"https://www.tensorflow.org/programmers_guide/graph_viz\">그래프를 시각화</a>한다면, 서로 연결되어 있는 노드가 많이 나타날 것 입니다. 이를 해결하기 위한 방법은 <code class=\"language-text\">tf.name_scope('name')</code> 또는 <code class=\"language-text\">tf.variable_scope('name')</code>을 사용하여 각 함수의 내용을 래핑하는 것 입니다. 이렇게 하면 노드들은 그래프 상에서 그룹화되어 있을 것 입니다. 우리는 이전에 만들었던 decorator를 이용하여 이를 자동으로 적용시켜보겠습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">Model</span><span class=\"token punctuation\">:</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> data<span class=\"token punctuation\">,</span> target<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>data <span class=\"token operator\">=</span> data\n        self<span class=\"token punctuation\">.</span>target <span class=\"token operator\">=</span> target\n        self<span class=\"token punctuation\">.</span>prediction\n        self<span class=\"token punctuation\">.</span>optimize\n        self<span class=\"token punctuation\">.</span>error\n\n    <span class=\"token decorator annotation punctuation\">@lazy_property</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">prediction</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        data_size <span class=\"token operator\">=</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">.</span>get_shape<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n        target_size <span class=\"token operator\">=</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>target<span class=\"token punctuation\">.</span>get_shape<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n        weight <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>Variable<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>truncated_normal<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>data_size<span class=\"token punctuation\">,</span> target_size<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        bias <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>Variable<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>constant<span class=\"token punctuation\">(</span><span class=\"token number\">0.1</span><span class=\"token punctuation\">,</span> shape<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span>target_size<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        incoming <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>matmul<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">,</span> weight<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> bias\n        <span class=\"token keyword\">return</span> tf<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>softmax<span class=\"token punctuation\">(</span>incoming<span class=\"token punctuation\">)</span>\n\n    <span class=\"token decorator annotation punctuation\">@lazy_property</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">optimize</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        cross_entropy <span class=\"token operator\">=</span> <span class=\"token operator\">-</span>tf<span class=\"token punctuation\">.</span>reduce_sum<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>target<span class=\"token punctuation\">,</span> tf<span class=\"token punctuation\">.</span>log<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>prediction<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        optimizer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">.</span>RMSPropOptimizer<span class=\"token punctuation\">(</span><span class=\"token number\">0.03</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> optimizer<span class=\"token punctuation\">.</span>minimize<span class=\"token punctuation\">(</span>cross_entropy<span class=\"token punctuation\">)</span>\n\n    <span class=\"token decorator annotation punctuation\">@lazy_property</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">error</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        mistakes <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>not_equal<span class=\"token punctuation\">(</span>\n            tf<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>target<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> tf<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>prediction<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> tf<span class=\"token punctuation\">.</span>reduce_mean<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>cast<span class=\"token punctuation\">(</span>mistakes<span class=\"token punctuation\">,</span> tf<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>lazy caching 이외에도 TensorFlow의 기능을 포함시키므로 decorator에 새로운 이름을 지정했습니다. 그 외의 나머지 부분은 이전과 동일합니다.</p>\n<p>이제 <code class=\"language-text\">@define_scope</code> decorator를 통해 <code class=\"language-text\">tf.variable_scope()</code>에 인자를 전달할 수 있습니다. 예를 들어 해당 scope에 default initializer를 정의할 수 있습니다. 이 부분이 더 궁금하다면 <a href=\"https://gist.github.com/danijar/8663d3bbfd586bffecf6a0094cd116f2\">전체 예제 코드</a>를 확인해보시면 됩니다.</p>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<p><a href=\"https://danijar.com/structuring-your-tensorflow-models/\">https://danijar.com/structuring-your-tensorflow-models/</a></p>\n<br>","excerpt":"이 글은 저자의 허락을 받아 번역한 글 입니다. 원문 링크 TensorFlow에서 모델을 정의하다보면 어느새 많은 양의 코드가 생성된 경험이 있을 것 입니다. 어떻게 하면 가독성과 재사용성이 높은 코드로 구성할 수 있을까요? 여기에서 실제 동작하는 예시 코드를 확인하실 수 있습니다. Gist Link Defining the Compute Graph 모델 당 하나의 클래스부터 시작하는 것이 좋습니다. 그 클래스의 인터페이스는 무엇인가요? 일반적으로 모델은 input data와 target placeholder를 연결하며 training, evaluation…"}}}},"pageContext":{"slug":"structuring-tf","basePath":"","prev":{"slug":"portfolio-basic","publishDate":"2018-04-25"},"next":{"slug":"data-science-inconvenient-truth","publishDate":"2018-04-01"}}},"staticQueryHashes":["1946181227","2744905544","3732430097"]}