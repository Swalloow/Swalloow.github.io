{"componentChunkName":"component---src-templates-post-js","path":"/bagging-boosting/","result":{"data":{"contentfulPost":{"title":"Bagging과 Boosting 그리고 Stacking","slug":"bagging-boosting","metaDescription":null,"publishDate":"July 19, 2017","publishDateISO":"2017-07-19","tags":[{"title":"DataScience","id":"82931dd3-d22b-528e-8a9b-ddbb200bb401","slug":"datascience"}],"heroImage":{"title":"cover-datascience","gatsbyImageData":{"images":{"sources":[{"srcSet":"https://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=450&h=300&q=50&fm=webp 450w,\nhttps://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=900&h=600&q=50&fm=webp 900w,\nhttps://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&h=1200&q=50&fm=webp 1800w","sizes":"(min-width: 1800px) 1800px, 100vw","type":"image/webp"}],"fallback":{"src":"https://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&h=1200&fl=progressive&q=50&fm=jpg","srcSet":"https://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=450&h=300&fl=progressive&q=50&fm=jpg 450w,\nhttps://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=900&h=600&fl=progressive&q=50&fm=jpg 900w,\nhttps://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&h=1200&fl=progressive&q=50&fm=jpg 1800w","sizes":"(min-width: 1800px) 1800px, 100vw"}},"layout":"constrained","width":1800,"height":1200,"placeholder":{"fallback":"data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wAARCAANABQDASIAAhEBAxEB/8QAGQAAAgMBAAAAAAAAAAAAAAAAAAQCAwUG/8QAIBAAAgEEAQUAAAAAAAAAAAAAAQIAAwQRIRIFEzFCkf/EABQBAQAAAAAAAAAAAAAAAAAAAAH/xAAWEQEBAQAAAAAAAAAAAAAAAAABABH/2gAMAwEAAhEDEQA/AK2EUrvxZQfJOplUeoXt4xHeWkMeqSS8jcKtSrUqHOcs2vggpIN0JGSdQiZvnXRUGENJxv/Z"}},"ogimg":{"src":"https://images.ctfassets.net/tushy4jlcik7/5l0PQJpz5C5IDFjHYigWJI/389fe4852b9cb39e9ada4938db33e6ca/cover_datascience.jpg?w=1800&q=50"}},"body":{"childMarkdownRemark":{"timeToRead":2,"html":"<p>오늘은 머신러닝 성능을 최대로 끌어올릴 수 있는 앙상블 기법에 대해 정리해보았습니다.</p>\n<br>\n<h2 id=\"ensemble-hybrid-method\" style=\"position:relative;\"><a href=\"#ensemble-hybrid-method\" aria-label=\"ensemble hybrid method permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Ensemble, Hybrid Method</h2>\n<p>앙상블 기법은 동일한 학습 알고리즘을 사용해서 여러 모델을 학습하는 개념입니다.\nWeak learner를 결합한다면, Single learner보다 더 나은 성능을 얻을 수 있다는 아이디어입니다.\n<strong>Bagging</strong> 과 <strong>Boosting</strong> 이 이에 해당합니다.</p>\n<p>동일한 학습 알고리즘을 사용하는 방법을 앙상블이라고 한다면,\n서로 다른 모델을 결합하여 새로운 모델을 만들어내는 방법도 있습니다.\n대표적으로 <strong>Stacking</strong> 이 있으며, 최근 Kaggle 에서 많이 소개된 바 있습니다.</p>\n<br>\n<h2 id=\"bagging\" style=\"position:relative;\"><a href=\"#bagging\" aria-label=\"bagging permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Bagging</h2>\n<p>Bagging은 샘플을 여러 번 뽑아 각 모델을 학습시켜 결과를 <strong>집계(Aggregating)</strong> 하는 방법입니다. 아래의 그림을 통해 자세히 알아보겠습니다.</p>\n<p><span\n        class=\"gatsby-resp-image-wrapper\"\n        style=\"position: relative; display: block; ; max-width: 650px; margin-left: auto; margin-right: auto;\"\n      >\n        <span\n          class=\"gatsby-resp-image-background-image\"\n          style=\"padding-bottom: 67.3768308921438%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACgAAAAbCAIAAACBclo5AAAE9ElEQVRIx71WS4tc1Rb+1tr7nFOvLrsTbbua1pCrQntRMlAIRogDNQ4E8UIG93c4E/wPDq8DQSd3dJEMLkhsCHcQBTWCxJEvtH2QpB9Jd6qqT+1z9uNzUJV0VaKhW8lds71Ye3/rtde3hCQOLINRuDGorcr4SJLA8tGmuaU5uNhDWX/14+5bF64eydWIJNIndHN9++zfHnyguL/AKvLcw425wpCwBgLpu0j8GTkccEwc1MmIuJCamQowrBP+D8CtwrStGkE7UwCJeKht7OELDEAO1VwEYqQKfKRREQEIY+QvRUwiTjkhQLrLJQFEQAhAAAKhMCZy7NRts1lPVEXuEXFMEIEISEAggA80KhMUuTP28WMhIrMTv8d3Y0JmJukZXyVxdzUsgLquSVY+5VZVkee5956JzqciUxHJ87yua5BjeIHYLHPOjW8VmapqkefOuUTUPjUyVWOyLBs5lwgfJjaNRmMfOMZ47ty569evE6IiKcUzZ85cunTp5s2biVCBqrz00ssXL150zo2HRlEUp0+fXltbCyEkAkzz8/OnTp06f/78uOOYYq/XO3HixNramjEmETH4lZWVs2fPyq2sWxHp9/siYo0RkZ2dvvd+MBioqhEBMBgMxpq8KMaXhsNhCKGqqk6nAyClVFVVCMF73+12AYQQnHPee+99q9USkaqSsixnUk2yruuyLJvNlqvczX6fpHMuxFgUxagsy7IkWZajEGKW58PhQICxxtjMGjMY9FutFsnhcJjnhRqzu7uzaC3Jfn+Q54Wq7uzcaDabJG9HLCTX19ddVem4CQS9Xm97e7uuvSARqqq93tLGxkYIQaKjaVhrl5aWtrav05fQjKJ5li0sLGxuboEJsaJtNIqi2+1ubm0JACZCG41ieXl5qj1vy+anjHuclo2PyXpG88uHZNw/XrtItzljEPf460czmtDn1ue8S3SKetZRDaeqkND/AfVUYVINv4dY72vCCN7N/JJQI5Qzn7oaYPDTPSdXKqENYMqVWMI0Z79wBMwfH39XmRArmOadwDHxv9+4KsGoJGCvSi88kn+54SMgIiRd4OmV/NMr3piJPRNPLucXfq6bmQDwkZng5HJ24Wc/lwuBKrCbydMP2f/9WndzJaT06Wgh/3iyIVNdjY+uhV88j1hRwbejtHrEfHg17CTOWSFxtebqgvnPFa+CthVPVIGPzZsPNsK8RcuKi+gIHp83/77mV3JtWfQDj+ey1Nb3robHG9o02PL8e0Nf5/40tQAi8YXjkzkSURICePKy4/EMNSdZGyX8EHgsYRjxsAWAK4HfeDyR44rns00h8KXHZkqPWlkPfCQTAp97lky9TL6quVrMjH6rihcXzVNz2s3FRYJY7JhXl7KTLnUyKQMzlcW2+eeyHXq2M9nz7FhZ6pg3j+U+sZnJXs2FhizPmX8dzwAURvY8e21d6Zr3j+eZIjey69JKR6cntpBM5OQL494UKbhFGbibNaaGw5giiH1NTLxjL5t0dToAKcuEIUCgSmjoPkkfhNPvIKjDLQK733+//dlnYm0ijApJtXbllTNZZ+7+rj7D9fXNd981R4+yLKXdRghpNFp8/tR9B4ZqsbrafeaZ0O8zRsY4+u47Eb3vyx6977/zjr7xBusaIn5jo758GfwzC66kdND9VERufP315iefiLWTTktJrD322mtFt8tDwv8GnTAxXRy6lLMAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n        >\n          <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;\"\n        alt=\"boosting\"\n        title=\"\"\n        src=\"https://images.ctfassets.net/tushy4jlcik7/2Qi9V8VS1XzgWdLT3UiSpk/fe2d857d275ee85b2122f350bc18c718/boosting.png\"\n        srcset=\"https://images.ctfassets.net/tushy4jlcik7/2Qi9V8VS1XzgWdLT3UiSpk/fe2d857d275ee85b2122f350bc18c718/boosting.png?w=188 188w,\nhttps://images.ctfassets.net/tushy4jlcik7/2Qi9V8VS1XzgWdLT3UiSpk/fe2d857d275ee85b2122f350bc18c718/boosting.png?w=376 376w,\nhttps://images.ctfassets.net/tushy4jlcik7/2Qi9V8VS1XzgWdLT3UiSpk/fe2d857d275ee85b2122f350bc18c718/boosting.png?w=751 751w\"\n        sizes=\"(max-width: 650px) 100vw, 650px\"\n        loading=\"lazy\"\n      />\n        </span>\n      </span></p>\n<p>먼저 대상 데이터로부터 복원 랜덤 샘플링을 합니다.\n이렇게 추출한 데이터가 일종의 표본 집단이 됩니다.\n이제 여기에 동일한 모델을 학습시킵니다.\n그리고 학습된 모델의 예측변수들을 집계하여 그 결과로 모델을 생성해냅니다.</p>\n<p>이러한 방식을 <strong>Bootstrap Aggregating</strong> 이라고 부릅니다.</p>\n<p>이렇게 하는 이유는 \"알고리즘의 안정성과 정확성을 향상시키기 위해서\" 입니다.\n대부분 학습에서 나타나는 오류는 다음과 같습니다.</p>\n<ol>\n<li>높은 bias로 인한 Underfitting</li>\n<li>높은 Variance로 인한 Overfitting</li>\n</ol>\n<p>앙상블 기법은 이러한 오류를 최소화하는데 도움이 됩니다.\n특히 Bagging은 각 샘플에서 나타난 결과를 일종의 중간값으로 맞추어 주기 때문에,\nOverfitting을 피할 수 있습니다.</p>\n<p>일반적으로 Categorical Data인 경우, 투표 방식 (Voting)으로 집계하며\nContinuous Data인 경우, 평균 (Average)으로 집계합니다.</p>\n<p>대표적인 Bagging 알고리즘으로 <code class=\"language-text\">RandomForest</code> 모델이 있습니다.\n원래 단일 DecisionTree 모델은 boundary가 discrete 한 모양일 수 밖에 없지만,\nRandomForest는 여러 트리 모델을 결합하여 이를 넘어설 수 있게 되었습니다.</p>\n<p>결과는 아래와 같습니다.</p>\n<p><span\n        class=\"gatsby-resp-image-wrapper\"\n        style=\"position: relative; display: block; ; max-width: 650px; margin-left: auto; margin-right: auto;\"\n      >\n        <span\n          class=\"gatsby-resp-image-background-image\"\n          style=\"padding-bottom: 110.00000000000001%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wAARCAAsACgDAREAAhEBAxEB/8QAGgAAAgMBAQAAAAAAAAAAAAAABAUAAgMGCf/EAC0QAAIBAwMCAwgDAQAAAAAAAAECAwAEEQUSITFRBhSREyIjQWFxgaEVMkLh/8QAGAEBAQEBAQAAAAAAAAAAAAAAAAMBAgT/xAAfEQEBAAICAgMBAAAAAAAAAAABAAIxESEDEiJBUWH/2gAMAwEAAhEDEQA/APSyS8uYXuTOjCMGQlhJzw52gD7YrSlkHdS2u7qdGKfFj9oqho5CcpjnJ7k4o24dPJZTau0TR+4FdlKhDKcBsgDP4INSd3txFFjJ7ieO4XbC0kRWPZ8QgDIJY8nn89qqXnd91NLvvM3ywMNyBmy6yE9OB8/pVEQuZjfeHbXUJGeQvuPY4x3H5qfNjiPdhY+HjYidRLiOQ5CwqFwc9ec1m7QMXkhLrQLU3KwRPJHM6E5ePeABgcdPp6VFzxMzx/bV9st8zGXQ0ubaOGV5HCKFycDOM49M1cfXVwvPdhaeGfJX8NxDclVQYKFAS2Tk5P8Azit9nVk9rmQmqSSxadcPACZQh2460kqutZeK8h3bY2DsmGPVcZ57cgUk5s5mnt0dwAx6gdKS3pKUljdNGsDCV9iuCufuKxQ3aC6uXvrNP5C0t4FEtpMkpuLtnX4TADZlf9ZyfSpPk+QGq54hwyyXhOODjf73/J7osQtrcw+c82ynOdoXaO2KoZDqiibmNdXNKSE1WOSXTrhYm2OUOCf3+qSS3OqyxyqTKWIkYYRSQBg+vNJPNPkaWzjZm3kj+3ekiaSlJVdA6MrDKkYIpIAaDa4bPtGJXaCZDlfsflSRNjYxadbiGIuUBz77lj+6SIpL/9k='); background-size: cover; display: block;\"\n        >\n          <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;\"\n        alt=\"agg result\"\n        title=\"\"\n        src=\"https://images.ctfassets.net/tushy4jlcik7/24IAgyNrQgeMlBCt81CroN/3d82eca18a1289219478efdbd24fbe2f/agg_result.png\"\n        srcset=\"https://images.ctfassets.net/tushy4jlcik7/24IAgyNrQgeMlBCt81CroN/3d82eca18a1289219478efdbd24fbe2f/agg_result.png?w=240 240w,\nhttps://images.ctfassets.net/tushy4jlcik7/24IAgyNrQgeMlBCt81CroN/3d82eca18a1289219478efdbd24fbe2f/agg_result.png?w=480 480w,\nhttps://images.ctfassets.net/tushy4jlcik7/24IAgyNrQgeMlBCt81CroN/3d82eca18a1289219478efdbd24fbe2f/agg_result.png?w=960 960w\"\n        sizes=\"(max-width: 650px) 100vw, 650px\"\n        loading=\"lazy\"\n      />\n        </span>\n      </span></p>\n<br>\n<h2 id=\"boosting\" style=\"position:relative;\"><a href=\"#boosting\" aria-label=\"boosting permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Boosting</h2>\n<p>Bagging이 일반적인 모델을 만드는데 집중되어있다면,\nBoosting은 맞추기 어려운 문제를 맞추는데 초점이 맞춰져 있습니다.</p>\n<p>수학 문제를 푸는데 9번 문제가 엄청 어려워서 계속 틀렸다고 가정해보겠습니다.\nBoosting 방식은 9번 문제에 가중치를 부여해서 9번 문제를 잘 맞춘 모델을 최종 모델로 선정합니다.\n아래 그림을 통해 자세히 알아보겠습니다.</p>\n<p><img src=\"https://quantdare.com/wp-content/uploads/2016/04/bb3.png\" alt=\"\"></p>\n<p>Boosting도 Bagging과 동일하게 복원 랜덤 샘플링을 하지만, 가중치를 부여한다는 차이점이 있습니다.\nBagging이 병렬로 학습하는 반면, Boosting은 순차적으로 학습시킵니다.\n학습이 끝나면 나온 결과에 따라 가중치가 재분배됩니다.</p>\n<p>오답에 대해 높은 가중치를 부여하고, 정답에 대해 낮은 가중치를 부여하기 때문에\n오답에 더욱 집중할 수 있게 되는 것 입니다.\nBoosting 기법의 경우, 정확도가 높게 나타납니다.\n하지만, 그만큼 Outlier에 취약하기도 합니다.</p>\n<p>AdaBoost, XGBoost, GradientBoost 등 다양한 모델이 있습니다.\n그 중에서도 XGBoost 모델은 강력한 성능을 보여줍니다. 최근 대부분의 Kaggle 대회 우승 알고리즘이기도 합니다.</p>\n<br>\n<h2 id=\"stacking\" style=\"position:relative;\"><a href=\"#stacking\" aria-label=\"stacking permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Stacking</h2>\n<p><strong>Meta Modeling</strong> 이라고 불리기도 하는 이 방법은 위의 2가지 방식과는 조금 다릅니다.\n“Two heads are better than one” 이라는 아이디어에서 출발합니다.</p>\n<p>Stacking은 서로 다른 모델들을 조합해서 최고의 성능을 내는 모델을 생성합니다.\n여기에서 사용되는 모델은 SVM, RandomForest, KNN 등 다양한 알고리즘을 사용할 수 있습니다.\n이러한 조합을 통해 서로의 장점은 취하고 약점을 보완할 수 있게 되는 것 입니다.</p>\n<p>Stacking은 이미 느끼셨겠지만 필요한 연산량이 어마어마합니다.\n적용해보고 싶다면 아래의 StackNet을 사용하는 방법을 추천합니다.</p>\n<p><a href=\"https://github.com/kaz-Anova/StackNet\">https://github.com/kaz-Anova/StackNet</a></p>\n<p>문제에 따라 정확도를 요구하기도 하지만, 안정성을 요구하기도 합니다.\n따라서, 주어진 문제에 적절한 모델을 선택하는 것이 중요합니다.</p>\n<br>","excerpt":"오늘은 머신러닝 성능을 최대로 끌어올릴 수 있는 앙상블 기법에 대해 정리해보았습니다. Ensemble, Hybrid Method 앙상블 기법은 동일한 학습 알고리즘을 사용해서 여러 모델을 학습하는 개념입니다.\nWeak learner를 결합한다면, Single learner보다 더 나은 성능을 얻을 수 있다는 아이디어입니다.\nBagging 과 Boosting 이 이에 해당합니다. 동일한 학습 알고리즘을 사용하는 방법을 앙상블이라고 한다면,\n서로 다른 모델을 결합하여 새로운 모델을 만들어내는 방법도 있습니다.\n대표적으로 Stacking 이 있으며, 최근 Kaggle…"}}}},"pageContext":{"slug":"bagging-boosting","basePath":"","prev":{"slug":"hive-metastore-issue","publishDate":"2017-08-11"},"next":{"slug":"spark-df-mysql","publishDate":"2017-07-17"}}},"staticQueryHashes":["1946181227","2744905544","3732430097"]}