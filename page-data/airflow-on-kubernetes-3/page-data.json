{"componentChunkName":"component---src-templates-post-js","path":"/airflow-on-kubernetes-3/","result":{"data":{"contentfulPost":{"title":"Airflow on Kubernetes (3)","slug":"airflow-on-kubernetes-3","metaDescription":null,"publishDate":"February 05, 2021","publishDateISO":"2021-02-05","tags":[{"title":"DataEngineering","id":"25d7d0d6-3cf7-5e19-a5cb-9c3fa926046f","slug":"dataengineering"}],"heroImage":{"title":"cover-dataengineering","gatsbyImageData":{"images":{"sources":[{"srcSet":"https://images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=400&h=267&q=50&fm=webp 400w,\nhttps://images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=800&h=533&q=50&fm=webp 800w,\nhttps://images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(min-width: 1600px) 1600px, 100vw","type":"image/webp"}],"fallback":{"src":"https://images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&fl=progressive&q=50&fm=jpg","srcSet":"https://images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=400&h=267&fl=progressive&q=50&fm=jpg 400w,\nhttps://images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=800&h=533&fl=progressive&q=50&fm=jpg 800w,\nhttps://images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&fl=progressive&q=50&fm=jpg 1600w","sizes":"(min-width: 1600px) 1600px, 100vw"}},"layout":"constrained","width":1800,"height":1200,"placeholder":{"fallback":"data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAlgCWAAD/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wAARCAANABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAMBAgb/xAAcEAACAgMBAQAAAAAAAAAAAAAAAQIREiExYeH/xAAWAQEBAQAAAAAAAAAAAAAAAAABAgP/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwDK1DF0vgtxW9EylQu8nTotmo+gHfAEP//Z"}},"ogimg":{"src":"https://images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50"}},"body":{"childMarkdownRemark":{"timeToRead":2,"html":"<p>최근 Airflow에는 Kubernetes 지원을 위해 다양한 컴포넌트들이 추가되고 있습니다. 이러한 변화의 흐름에 따라 Airflow를 Kubernetes 위에 배포하고 운영하는 방법에 대해 글을 작성해보고자 합니다. 이 글은 시리즈로 연재됩니다.</p>\n<ul>\n<li><a href=\"https://swalloow.github.io/airflow-on-kubernetes-1\">Airflow on Kubernetes (1): CeleryExecutor</a></li>\n<li><a href=\"https://swalloow.github.io/airflow-on-kubernetes-2\">Airflow on Kubernetes (2): KubernetesExecutor</a></li>\n<li><a href=\"https://swalloow.github.io/airflow-on-kubernetes-3\">Airflow on Kubernetes (3): Airflow Logging, Monitoring</a></li>\n</ul>\n<br>\n<h2 id=\"airflow-logging\" style=\"position:relative;\"><a href=\"#airflow-logging\" aria-label=\"airflow logging permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Airflow Logging</h2>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=1qGMB1yIsT06y3y9knBQ2T2G2O3xQs-8b\" alt=\"airflow-log\"></p>\n<p>Airflow의 Task 로그는 PV를 통해 영구 볼륨에 저장하거나 <strong>Remote Logging</strong> 설정을 통해 외부 저장소로 수집할 수 있습니다. S3, ES, GCS 등 다양한 저장소를 지원합니다.\n예를 들어 S3로 설정하면 Task 로그의 수명주기를 S3 Lifecycle에 의해 관리할 수 있게 됩니다.\n참고로 2.0 버전부터 로그 관련 설정은 <code class=\"language-text\">core</code>에서 <code class=\"language-text\">logging</code> 섹션으로 이동했습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">logging:\n  remote_logging: \"True\"\n  remote_base_log_folder: \"s3://mybucketname/airflow\"\n  remote_log_conn_id: \"aws_default\"\n  logging_level: INFO</code></pre></div>\n<br>\n<h2 id=\"airflow-metrics\" style=\"position:relative;\"><a href=\"#airflow-metrics\" aria-label=\"airflow metrics permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Airflow Metrics</h2>\n<p>Airflow는 <a href=\"https://airflow.apache.org/docs/apache-airflow/stable/logging-monitoring/metrics.html\">StatsD를 통한 메트릭 전송 방법</a>을 공식 지원합니다.\nK8S 환경에서 많이 사용하는 Prometheus을 통해 메트릭을 수집하는 방법은 아래와 같이 2가지가 있습니다.\nOfficial Helm Chart의 경우 statsd-export를 통해 전송하는 방법을 지원하고 있습니다.\n<code class=\"language-text\">Values.statsd.enabled</code> 옵션을 통해 쉽게 설정하실 수 있습니다.</p>\n<br>\n<p><strong>1. airflow-prometheus-exporter</strong>:\nairflow model 객체를 활용하여 prometheus metrics collector를 구현한 모듈입니다.\nstable/airflow chart에서 옵션을 통해 설정할 수 있으며 airflow plugin 형태로 구현되어 있어 UI의 /metrics 경로에서 로그를 확인할 수 있습니다.</p>\n<p><strong>2. airflow-statsd-exporter</strong>:\nstatsd는 UDP, TCP를 통해 메트릭을 수집에서 전송하는 프록시입니다.\nairflow에서는 공식적으로 statsd를 통해 메트릭을 지원하고 있습니다.\nofficial helm chart에서는 statsd를 통해 메트릭을 수집하고 exporter를 통해 prometheus에 저장할 수 있습니다.</p>\n<br>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=1T5teIwjMzfvxJGE37oFMOyGFtC9zqfJq\" alt=\"\"></p>\n<p>수집하는 과정은 위의 그림과 같습니다. statsd-exporter는 Deployment 형태로 배포되며 수집 어노테이션이 정의되어 있습니다.</p>\n<br>\n<h2 id=\"monitoring\" style=\"position:relative;\"><a href=\"#monitoring\" aria-label=\"monitoring permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Monitoring</h2>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=1V3YNecz4_GRBV_5fgOFSu13ScbImFmjU\" alt=\"\"></p>\n<p>Prometheus에 저장된 메트릭은 Grafana를 통해 데이터 소스로 지정하고 원하는 지표를 시각화할 수 있습니다. 위의 대시보드에 활용한 지표는 다음과 같습니다.</p>\n<ul>\n<li>Airflow Scheduler Health</li>\n<li>Number of Queued Tasks</li>\n<li>Number of Running Tasks</li>\n<li>Scheduling Delay by DAG</li>\n<li>DAG Import Time</li>\n<li>DAG Running Duration</li>\n</ul>\n<br>\n<p>사용자가 작성한 DAG은 Parser를 통해 객체로 변환되고 메타데이터 DB에 저장되는데 <code class=\"language-text\">DAG Import Time</code>은 이 과정을 수행하는데 있어 걸리는 시간을 의미합니다. 위에 언급된 지표 외에도 다양한 지표를 지원합니다. 자세한 리스트는 <a href=\"https://airflow.apache.org/docs/apache-airflow/stable/logging-monitoring/metrics.html#counters\">Airflow Metrics 공식 문서</a>를 통해 확인하실 수 있습니다.</p>\n<br>","excerpt":"최근 Airflow에는 Kubernetes 지원을 위해 다양한 컴포넌트들이 추가되고 있습니다. 이러한 변화의 흐름에 따라 Airflow를 Kubernetes 위에 배포하고 운영하는 방법에 대해 글을 작성해보고자 합니다. 이 글은 시리즈로 연재됩니다. Airflow on Kubernetes (1): CeleryExecutor Airflow on Kubernetes (2): KubernetesExecutor Airflow on Kubernetes (3): Airflow Logging, Monitoring Airflow Logging airflow-log Airflow…"}}}},"pageContext":{"slug":"airflow-on-kubernetes-3","basePath":"","prev":{"slug":"airflow-sidecar","publishDate":"2021-08-01"},"next":{"slug":"airflow-on-kubernetes-2","publishDate":"2020-07-12"}}},"staticQueryHashes":["1946181227","2744905544","3732430097"]}