{"componentChunkName":"component---src-templates-post-js","path":"/spark-reduceByKey-groupByKey/","result":{"data":{"contentfulPost":{"id":"346030b5-8193-5161-9bea-951b3f0146ac","title":"Spark groupByKey vs reduceByKey","slug":"spark-reduceByKey-groupByKey","metaDescription":null,"publishDate":"August 22, 2017","publishDateISO":"2017-08-22","tags":[{"title":"DataEngineering","id":"6d3fb203-7cdf-53d7-be6f-12ba3e82d74d","slug":"dataengineering"}],"heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"037fcf8d-17a3-5fd2-8b52-271bc7f8836f","childMarkdownRemark":{"id":"5103dbd1-1b3c-5d75-8c16-3f900b1d0d8f","timeToRead":1,"html":"<p>Spark Application 성능 개선을 위한 <code class=\"language-text\">groupByKey, reduceBykey</code>에 대해 알아보겠습니다.</p>\n<br>\n<h2 id=\"groupbykey-vs-reducebykey\" style=\"position:relative;\"><a href=\"#groupbykey-vs-reducebykey\" aria-label=\"groupbykey vs reducebykey permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>groupByKey vs reduceBykey</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># reduceByKey</span>\nspark<span class=\"token punctuation\">.</span>textFile<span class=\"token punctuation\">(</span><span class=\"token string\">\"hdfs://...\"</span><span class=\"token punctuation\">)</span>\n <span class=\"token punctuation\">.</span>flatMap<span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> line<span class=\"token punctuation\">:</span> line<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n <span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> word<span class=\"token punctuation\">:</span> <span class=\"token punctuation\">(</span>word<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n <span class=\"token punctuation\">.</span>reduceByKey<span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> a<span class=\"token punctuation\">,</span> b<span class=\"token punctuation\">:</span> a <span class=\"token operator\">+</span> b<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># groupByKey</span>\nspark<span class=\"token punctuation\">.</span>textFile<span class=\"token punctuation\">(</span><span class=\"token string\">\"hdfs://...\"</span><span class=\"token punctuation\">)</span>\n <span class=\"token punctuation\">.</span>flatMap<span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> line<span class=\"token punctuation\">:</span> line<span class=\"token punctuation\">.</span>split<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n <span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> word<span class=\"token punctuation\">:</span> <span class=\"token punctuation\">(</span>word<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n <span class=\"token punctuation\">.</span>groupByKey<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n <span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> <span class=\"token punctuation\">(</span>w<span class=\"token punctuation\">,</span> counts<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">(</span>w<span class=\"token punctuation\">,</span> <span class=\"token builtin\">sum</span><span class=\"token punctuation\">(</span>counts<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>가장 흔히 알고 있는 word count 예제를 예로 들어보겠습니다.\n위의 예시는 reduceByKey를 사용했으며, 아래의 예시는 groupByKey를 사용했습니다.\n둘의 결과는 같지만 성능은 확인히 차이가 납니다.</p>\n<p>먼저 위의 코드에서 <code class=\"language-text\">flatMap, map</code> 까지는 동일한 노드에서 실행이 됩니다.\n하지만 reducer 부분에서는 모든 동일한 단어 쌍을 같은 노드로 이동시켜야 하기 때문에 <strong>Shuffle</strong> 이 발생합니다.</p>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=1ogSb1p0MRbvEsrXKsvP-9ItWxkMMK6eb\"></p>\n<p>우선 reduceByKey의 경우, 먼저 각 노드에서 중간 집계를 진행하고 이에 대한 결과를 동일한 키 값으로 전송합니다.</p>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=1PvGTtQ9wpGA0ZLveZ8zF1FZUj9VhVpkf\"></p>\n<p>반면, groupByKey는 각 노드에 있는 데이터에 대해 바로 Shuffle 과정을 거치게 되고 결과를 내보냅니다.\n따라서 groupByKey는 네트워크를 통해 전송되는 데이터의 양이 많아질 뿐만 아니라, <strong>Out of disk</strong> 문제가 발생할 수도 있습니다.</p>\n<p>Shuffle은 기본적으로 비용이 큰 연산입니다.\ngroupByKey는 reduceByKey로 대체될 수 있기 때문에 많은 문서에서 이를 권장하고 있습니다.</p>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<ul>\n<li><a href=\"https://www.slideshare.net/databricks/strata-sj-everyday-im-shuffling-tips-for-writing-better-spark-programs\">https://www.slideshare.net/databricks/strata-sj-everyday-im-shuffling-tips-for-writing-better-spark-programs</a></li>\n</ul>\n<br>","excerpt":"Spark Application 성능 개선을 위한 에 대해 알아보겠습니다. groupByKey vs reduceBykey 가장 흔히 알고 있는 word count 예제를 예로 들어보겠습니다.\n위의 예시는 reduceByKey를 사용했으며, 아래의 예시는 groupByKey를 사용했습니다.\n둘의 결과는 같지만 성능은 확인히 차이가 납니다. 먼저 위의 코드에서  까지는 동일한 노드에서 실행이 됩니다.\n하지만 reducer 부분에서는 모든 동일한 단어 쌍을 같은 노드로 이동시켜야 하기 때문에 Shuffle 이 발생합니다.  우선 reduceByKey…"}}}},"pageContext":{"slug":"spark-reduceByKey-groupByKey","basePath":"","prev":{"slug":"spark-shuffling","publishDate":"2017-08-25"},"next":{"slug":"hive-metastore-issue","publishDate":"2017-08-11"}}}}