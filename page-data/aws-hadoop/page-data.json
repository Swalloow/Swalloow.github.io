{"componentChunkName":"component---src-templates-post-js","path":"/aws-hadoop/","result":{"data":{"contentfulPost":{"title":"AWS에 Hadoop MR 어플리케이션 환경 구축하기","slug":"aws-hadoop","metaDescription":null,"publishDate":"June 13, 2018","publishDateISO":"2018-06-13","tags":[{"title":"DataEngineering","id":"25d7d0d6-3cf7-5e19-a5cb-9c3fa926046f","slug":"dataengineering"}],"heroImage":{"title":"cover-dataengineering","gatsbyImageData":{"images":{"sources":[{"srcSet":"https://images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=400&h=267&q=50&fm=webp 400w,\nhttps://images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=800&h=533&q=50&fm=webp 800w,\nhttps://images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(min-width: 1600px) 1600px, 100vw","type":"image/webp"}],"fallback":{"src":"https://images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&fl=progressive&q=50&fm=jpg","srcSet":"https://images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=400&h=267&fl=progressive&q=50&fm=jpg 400w,\nhttps://images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=800&h=533&fl=progressive&q=50&fm=jpg 800w,\nhttps://images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&fl=progressive&q=50&fm=jpg 1600w","sizes":"(min-width: 1600px) 1600px, 100vw"}},"layout":"constrained","width":1800,"height":1200,"placeholder":{"fallback":"data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAlgCWAAD/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wAARCAANABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAMBAgb/xAAcEAACAgMBAQAAAAAAAAAAAAAAAQIREiExYeH/xAAWAQEBAQAAAAAAAAAAAAAAAAABAgP/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwDK1DF0vgtxW9EylQu8nTotmo+gHfAEP//Z"}},"ogimg":{"src":"https://images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50"}},"body":{"childMarkdownRemark":{"timeToRead":4,"html":"<p>이번 학기에 하둡 프로그래밍 강의를 들으면서 정말 실습 환경의 개선이 필요하다는 생각이 들었습니다...\n나약한 실습 환경속에서 과제와 기말 프로젝트를 제출해야하는 후배들을 위해 AWS를 추천합니다!</p>\n<br>\n<h2 id=\"ec2-amazon-linux2에-기본-환경-구축\" style=\"position:relative;\"><a href=\"#ec2-amazon-linux2%EC%97%90-%EA%B8%B0%EB%B3%B8-%ED%99%98%EA%B2%BD-%EA%B5%AC%EC%B6%95\" aria-label=\"ec2 amazon linux2에 기본 환경 구축 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>EC2 Amazon Linux2에 기본 환경 구축</h2>\n<p>AWS에는 EMR이라는 클러스터 서비스가 있지만, 스터디 목적이라면 비용을 생각해서 사용하지 않겠습니다.\nAmazon Linux AMI는 EC2에서 편하게 사용할 수 있도록 지원하고 관리하는 리눅스 이미지입니다.\n만일 학생용 크레딧이 있다면 <strong>t2.medium</strong> 인스턴스를 추천합니다.</p>\n<p>먼저, JAVA JDK와 Hadoop 파일을 받겠습니다. 실습 환경은 자바 7, 하둡 1.2 버전입니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token function\">sudo</span> yum update <span class=\"token parameter variable\">-y</span>\n$ <span class=\"token function\">sudo</span> yum <span class=\"token function\">install</span> <span class=\"token parameter variable\">-y</span> java-1.7.0-openjdk-devel\n$ <span class=\"token function\">wget</span> https://archive.apache.org/dist/hadoop/core/hadoop-1.2.1/hadoop-1.2.1.tar.gz\n$ <span class=\"token function\">tar</span> xvfz hadoop-1.2.1</code></pre></div>\n<p>그리고 자바 프로젝트를 위해 Maven도 설치해줍니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token function\">wget</span> http://mirror.navercorp.com/apache/maven/maven-3/3.5.3/binaries/apache-maven-3.5.3-bin.tar.gz\n$ <span class=\"token function\">tar</span> xvfs apache-maven-3.5.3-bin.tar.gz\n$ <span class=\"token function\">mv</span> apache-maven-3.5.3/ apache-maven\n$ <span class=\"token function\">sudo</span> <span class=\"token function\">vi</span> /etc/profile.d/maven.sh\n\n<span class=\"token comment\"># Apache Maven Environment Variables</span>\n<span class=\"token comment\"># MAVEN_HOME for Maven 1 - M2_HOME for Maven 2</span>\n$ <span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">M2_HOME</span><span class=\"token operator\">=</span>/home/ec2-user/apache-maven\n$ <span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\"><span class=\"token environment constant\">PATH</span></span><span class=\"token operator\">=</span><span class=\"token variable\">${M2_HOME}</span>/bin:<span class=\"token variable\">${<span class=\"token environment constant\">PATH</span>}</span>\n\n$ <span class=\"token function\">chmod</span> +x maven.sh\n$ <span class=\"token builtin class-name\">source</span> /etc/profile.d/maven.sh</code></pre></div>\n<p>정상적으로 설치가 되었다면 아래의 명령어에 대한 결과가 나옵니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token function\">java</span> <span class=\"token parameter variable\">--version</span>\n$ mvn <span class=\"token parameter variable\">--version</span></code></pre></div>\n<br>\n<h2 id=\"hadoop-환경-구축\" style=\"position:relative;\"><a href=\"#hadoop-%ED%99%98%EA%B2%BD-%EA%B5%AC%EC%B6%95\" aria-label=\"hadoop 환경 구축 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Hadoop 환경 구축</h2>\n<p>실습환경은 <strong>Pseudo-Distibuted</strong> 모드로 진행합니다.\n먼저 Password less SSH Login을 설정해주어야 합니다.\n그리고 편의를 위해 hadoop-1.2.1 폴더에 Symbolic link를 생성하겠습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token comment\"># ssh login setting</span>\n$ ssh-keygen <span class=\"token parameter variable\">-t</span> rsa <span class=\"token parameter variable\">-P</span> <span class=\"token string\">\"\"</span>\n$ <span class=\"token function\">cat</span> /home/ec2-user/.ssh/id_rsa.pub <span class=\"token operator\">>></span> /home/ec2-user/.ssh/authorized_keys\n\n<span class=\"token comment\"># symbolic link</span>\n$ <span class=\"token function\">ln</span> <span class=\"token parameter variable\">-s</span> hadoop-1.2.1 hadoop</code></pre></div>\n<p>이제 HDFS와 MR 실행을 위해 설정파일을 수정해줍니다.\n먼저 <code class=\"language-text\">hadoop-env.sh</code>을 열어 <code class=\"language-text\">JAVA_HOME</code> 환경변수를 지정해줍니다.\n가상분산모드에서는 masters, slaves 파일을 수정할 필요가 없습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token builtin class-name\">cd</span> hadoop\n$ <span class=\"token function\">vi</span> conf/hadoop-env.sh\n\n<span class=\"token comment\"># set JAVA_HOME in this file, so that it is correctly defined on</span>\n<span class=\"token comment\"># remote nodes.</span>\n\n<span class=\"token comment\"># The java implementation to use. Required.</span>\n<span class=\"token builtin class-name\">export</span> <span class=\"token assign-left variable\">JAVA_HOME</span><span class=\"token operator\">=</span>/usr/lib/jvm/java-1.7.0\n\n<span class=\"token comment\"># Extra Java CLASSPATH elements.  Optional.</span>\n<span class=\"token comment\"># export HADOOP_CLASSPATH=</span></code></pre></div>\n<p>이제 <code class=\"language-text\">core-site.xml</code> 파일을 아래와 같이 수정해줍니다.\nHDFS 데이터 파일들은 홈 디렉토리의 hadoop-data 폴더에 저장하겠습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token function\">vi</span> conf/core-site.xml\n\n<span class=\"token operator\">&lt;</span>configuration<span class=\"token operator\">></span>\n    <span class=\"token operator\">&lt;</span>property<span class=\"token operator\">></span>\n        <span class=\"token operator\">&lt;</span>name<span class=\"token operator\">></span>fs.default.name<span class=\"token operator\">&lt;</span>/name<span class=\"token operator\">></span>\n        <span class=\"token operator\">&lt;</span>value<span class=\"token operator\">></span>hdfs://localhost:900<span class=\"token operator\"><span class=\"token file-descriptor important\">0</span>&lt;</span>/value<span class=\"token operator\">></span>\n    <span class=\"token operator\">&lt;</span>/property<span class=\"token operator\">></span>\n    <span class=\"token operator\">&lt;</span>property<span class=\"token operator\">></span>\n        <span class=\"token operator\">&lt;</span>name<span class=\"token operator\">></span>hadoop.tmp.dir<span class=\"token operator\">&lt;</span>/name<span class=\"token operator\">></span>\n        <span class=\"token operator\">&lt;</span>value<span class=\"token operator\">></span>/home/ec2-user/hadoop-data/<span class=\"token operator\">&lt;</span>/value<span class=\"token operator\">></span>\n    <span class=\"token operator\">&lt;</span>/property<span class=\"token operator\">></span>\n<span class=\"token operator\">&lt;</span>/configuration<span class=\"token operator\">></span></code></pre></div>\n<p><code class=\"language-text\">hdfs-site.xml</code> 파일도 수정해줍니다.\ndfs.replication 프로퍼티는 복제 개수를 의미합니다.\n일반적으로 복제 개수를 3으로 두는 것을 권장하지만,\n실습에서는 Fully-Distributed 모드가 아니기 때문에 1로 설정하겠습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token function\">vi</span> conf/hdfs-site.xml\n\n<span class=\"token operator\">&lt;</span>configuration<span class=\"token operator\">></span>\n    <span class=\"token operator\">&lt;</span>property<span class=\"token operator\">></span>\n        <span class=\"token operator\">&lt;</span>name<span class=\"token operator\">></span>dfs.replication<span class=\"token operator\">&lt;</span>/name<span class=\"token operator\">></span>\n        <span class=\"token operator\">&lt;</span>value<span class=\"token operator\">></span><span class=\"token operator\"><span class=\"token file-descriptor important\">1</span>&lt;</span>/value<span class=\"token operator\">></span>\n    <span class=\"token operator\">&lt;</span>/property<span class=\"token operator\">></span>\n<span class=\"token operator\">&lt;</span>/configuration<span class=\"token operator\">></span></code></pre></div>\n<p><code class=\"language-text\">mapred-site.xml</code> 파일도 수정해줍니다.\nmapred.job.tracker 프로퍼티는 job tracker가 동작하는 서버를 말합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ <span class=\"token function\">vi</span> conf/mapred-site.xml\n\n<span class=\"token operator\">&lt;</span>configuration<span class=\"token operator\">></span>\n    <span class=\"token operator\">&lt;</span>property<span class=\"token operator\">></span>\n        <span class=\"token operator\">&lt;</span>name<span class=\"token operator\">></span>mapred.job.tracker<span class=\"token operator\">&lt;</span>/name<span class=\"token operator\">></span>\n        <span class=\"token operator\">&lt;</span>value<span class=\"token operator\">></span>localhost:900<span class=\"token operator\"><span class=\"token file-descriptor important\">1</span>&lt;</span>/value<span class=\"token operator\">></span>\n    <span class=\"token operator\">&lt;</span>/property<span class=\"token operator\">></span>\n<span class=\"token operator\">&lt;</span>/configuration<span class=\"token operator\">></span></code></pre></div>\n<br>\n<h2 id=\"hadoop-mr\" style=\"position:relative;\"><a href=\"#hadoop-mr\" aria-label=\"hadoop mr permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Hadoop MR</h2>\n<p>이제 NameNode를 초기화하고 하둡과 관련된 모든 데몬을 실행합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">./bin/hadoop namenode-format\n./bin/start-all.sh</code></pre></div>\n<p>jps를 통해 자바 프로세스가 제대로 실행되었는지 확인할 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">$ jps\n3368 TaskTracker\n2991 DataNode\n3241 JobTracker\n3480 Jps\n2872 NameNode\n3139 SecondaryNameNode</code></pre></div>\n<p>HDFS 웹 인터페이스 주소는 <a href=\"http://localhost:50070\">http://localhost:50070</a> 이며,\nMapReduce 웹 인터페이스 주소는 <a href=\"http://localhost:50030\">http://localhost:50030</a> 입니다.\n들어가시면 아래와 같은 화면이 나타납니다.</p>\n<p><img src=\"http://drive.google.com/uc?export=view&#x26;id=15OIYCbnc1cy93jJgqX1y8a5vfpCBkpqM\" alt=\"\"></p>\n<p>이제 기본으로 설치되어 있는 WordCount 예제를 실행시켜보겠습니다.\n먼저 WordCount 예제의 input 데이터를 HDFS에 업로드하고 jar 파일과 output 경로를 지정해줍니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ ./bin/hadoop fs <span class=\"token parameter variable\">-put</span> conf/hadoop-env.sh ./hadoop-env.sh\n$ ./bin/hadoop jar hadoop-examples-1.2.1.jar wordcount hadoop-env.sh output</code></pre></div>\n<p>HDFS에 write한 결과는 HDFS의 output 경로에서 확인하실 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ ./bin/hadoop fs <span class=\"token parameter variable\">-ls</span> output\n$ ./bin/hadoop fs <span class=\"token parameter variable\">-cat</span> output/part-r-00000</code></pre></div>\n<br>\n<h2 id=\"intellij\" style=\"position:relative;\"><a href=\"#intellij\" aria-label=\"intellij permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>IntelliJ</h2>\n<p>이번엔 예제가 아니라 Hadoop MR 어플리케이션 프로젝트를 새로 생성해보겠습니다.\nIntelliJ에서 JAVA, maven 프로젝트를 생성하시면 됩니다.</p>\n<p>그리고 pom.xml은 아래와 같이 수정해줍니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"xml\"><pre class=\"language-xml\"><code class=\"language-xml\"><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>groupId</span><span class=\"token punctuation\">></span></span>org.swalloow.hadoop<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>groupId</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>artifactId</span><span class=\"token punctuation\">></span></span>hadoop<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>artifactId</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>version</span><span class=\"token punctuation\">></span></span>1.0-SNAPSHOT<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>version</span><span class=\"token punctuation\">></span></span>\n\n<span class=\"token comment\">&lt;!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-core --></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>dependencies</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>dependency</span><span class=\"token punctuation\">></span></span>\n        <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>groupId</span><span class=\"token punctuation\">></span></span>org.apache.hadoop<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>groupId</span><span class=\"token punctuation\">></span></span>\n        <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>artifactId</span><span class=\"token punctuation\">></span></span>hadoop-core<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>artifactId</span><span class=\"token punctuation\">></span></span>\n        <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>version</span><span class=\"token punctuation\">></span></span>1.2.1<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>version</span><span class=\"token punctuation\">></span></span>\n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>dependency</span><span class=\"token punctuation\">></span></span>\n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>dependencies</span><span class=\"token punctuation\">></span></span></code></pre></div>\n<p>Mapper와 Reducer 클래스를 수정한 다음, <code class=\"language-text\">mvn packages</code> 명령어를 통해 jar 파일을 생성합니다.\n그리고 input 파일을 이전과 동일하게 HDFS에 추가하고 생성한 jar 파일을 통해 MR job을 실행시키시면 됩니다.</p>\n<p>아래 링크는 코인 거래 데이터를 입력받아 이동평균선(SMA) 추세를 계산해주는 간단한 예시 프로젝트입니다. 템플릿은 자유롭게 참고하셔도 됩니다!</p>\n<p><a href=\"https://github.com/Swalloow/hadoop-mr-project\">https://github.com/Swalloow/hadoop-mr-project</a></p>\n<br>","excerpt":"이번 학기에 하둡 프로그래밍 강의를 들으면서 정말 실습 환경의 개선이 필요하다는 생각이 들었습니다...\n나약한 실습 환경속에서 과제와 기말 프로젝트를 제출해야하는 후배들을 위해 AWS를 추천합니다! EC2 Amazon Linux2에 기본 환경 구축 AWS에는 EMR이라는 클러스터 서비스가 있지만, 스터디 목적이라면 비용을 생각해서 사용하지 않겠습니다.\nAmazon Linux AMI는 EC2에서 편하게 사용할 수 있도록 지원하고 관리하는 리눅스 이미지입니다.\n만일 학생용 크레딧이 있다면 t2.medium 인스턴스를 추천합니다. 먼저, JAVA JDK와 Hadoop…"}}}},"pageContext":{"slug":"aws-hadoop","basePath":"","prev":{"slug":"raft-consensus","publishDate":"2018-09-01"},"next":{"slug":"portfolio-basic","publishDate":"2018-04-25"}}},"staticQueryHashes":["1946181227","2744905544","3732430097"]}