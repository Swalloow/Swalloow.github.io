{"componentChunkName":"component---src-templates-post-js","path":"/spark-on-kubernetes-spot-instance/","result":{"data":{"contentfulPost":{"id":"1e8b83c6-ab58-5682-b4e9-2c995faf6103","title":"Spark on Kubernetes: 스팟 인스턴스 사용을 위한 기능들","slug":"spark-on-kubernetes-spot-instance","metaDescription":null,"publishDate":"July 23, 2022","publishDateISO":"2022-07-23","tags":[{"title":"DataEngineering","id":"6d3fb203-7cdf-53d7-be6f-12ba3e82d74d","slug":"dataengineering"}],"heroImage":{"id":"dab22ea8-d54d-52a6-852a-278ba3b19a2b","title":"cover-dataengineering","fluid":{"aspectRatio":1.499531396438613,"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50","srcSet":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50 1600w","srcWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&q=50&fm=webp","srcSetWebp":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=450&h=300&q=50&fm=webp 450w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=900&h=600&q=50&fm=webp 900w,\n//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1600&h=1067&q=50&fm=webp 1600w","sizes":"(max-width: 1800px) 100vw, 1800px"},"ogimg":{"src":"//images.ctfassets.net/tushy4jlcik7/7uo9TsqFN9EBsDBqDJ5vXl/4c58a9f94babb15d8fd996c247737656/cover_dataengineering.jpg?w=1800&fl=progressive&q=50"}},"body":{"id":"456f045e-0520-51cd-b056-4f330449b7a5","childMarkdownRemark":{"id":"dbcbd6f9-ba42-5df6-8d65-cab1263fa8e9","timeToRead":3,"html":"<p>스팟 인스턴스 유형을 사용하면 온디맨드에 비해 70~90%의 비용을 절감할 수 있습니다.\n하지만 스팟 인스턴스는 가격 입찰, 가용성 등 여러 이유로 중단될 수 있습니다.\n따라서 스팟 인스턴스를 사용한다면 노드가 중단되는 상황에 대비할 수 있어야 합니다.\n이 글에서는 Spark on Kubernetes를 스팟 인스턴스 위에서 안정적으로 운영하기 위해 필요한 설정들을 정리해보려 합니다.</p>\n<p><br><br></p>\n<h2 id=\"driver는-on-demand에-할당하기\" style=\"position:relative;\"><a href=\"#driver%EB%8A%94-on-demand%EC%97%90-%ED%95%A0%EB%8B%B9%ED%95%98%EA%B8%B0\" aria-label=\"driver는 on demand에 할당하기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>driver는 on-demand에 할당하기</h2>\n<p>중단된 노드에 있던 <code class=\"language-text\">driver pod</code>가 종료되는 경우, Spark 작업은 실패하게 됩니다. <code class=\"language-text\">executor pod</code>가 종료되는 경우, 캐시된 데이터 또는 셔플 파일을 잃게 되지만 새로운 executor를 통해 이를 다시 계산하기 때문에 전체 작업이 실패하지는 않습니다.</p>\n<p>위와 같은 이유로 <strong>driver는 온디맨드 인스턴스에 할당</strong>하는 것이 안전합니다.\n노드 그룹을 분리하고 <code class=\"language-text\">nodeSelector</code>를 활용한다면 driver는 온디맨드에서, executor는 스팟에서 실행하도록 설정할 수 있습니다.</p>\n<p><br><br></p>\n<h2 id=\"적절한-인스턴스-유형-선택하기\" style=\"position:relative;\"><a href=\"#%EC%A0%81%EC%A0%88%ED%95%9C-%EC%9D%B8%EC%8A%A4%ED%84%B4%EC%8A%A4-%EC%9C%A0%ED%98%95-%EC%84%A0%ED%83%9D%ED%95%98%EA%B8%B0\" aria-label=\"적절한 인스턴스 유형 선택하기 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>적절한 인스턴스 유형 선택하기</h2>\n<p>일부 인스턴스 유형은 해당 시점의 spot market 상황에 따라 안정적으로 확보하지 못할 수도 있습니다. 확보를 못하게 되면 executor는 계속 pending 상태에 머무르게 되고 전체 수행시간도 지연됩니다.</p>\n<p>사용량에 비해 크기가 큰 인스턴스 유형을 선택했다면, 여러 <code class=\"language-text\">executor pod</code>가 하나의 노드에 할당됩니다. 이 때 해당 노드가 중단된다면 여러 executor가 종료되므로 재계산에 더 많은 시간이 소요됩니다.</p>\n<p>위와 같은 이유로 적절한 인스턴스 유형을 선택하는 것이 spot kill을 줄이는데 도움이 됩니다.\nKarpenter를 사용한다면, 여러 인스턴스 유형을 지정하여 Pod의 리소스 요청량에 가장 적합한 노드를 프로비저닝 할 수 있습니다. 또한 <code class=\"language-text\">Instance Fleet</code>의 <code class=\"language-text\">Allocation Strategy</code>에 따라 가장 안정적으로 확보 가능한 인스턴스 유형을 선택할 수 있습니다.</p>\n<p><br><br></p>\n<h2 id=\"spark-31-graceful-executor-decommissioning\" style=\"position:relative;\"><a href=\"#spark-31-graceful-executor-decommissioning\" aria-label=\"spark 31 graceful executor decommissioning permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Spark 3.1: Graceful Executor Decommissioning</h2>\n<p><code class=\"language-text\">Graceful Executor Decommissioning</code>은 Spark 3.1 버전에 추가된 기능입니다.\n이 기능을 통해 <strong>노드가 중단되더라도 최소한의 손실로 Spark 작업이 지속되도록 설정</strong>할 수 있습니다. 이를 사용하려면 먼저 클러스터에 <code class=\"language-text\">Node Termination Handler</code>가 설치되어 있어야 합니다. <code class=\"language-text\">Node Termination Handler</code>는 클라우드에 따라 다르게 설치할 수 있도록 지원하고 있습니다.</p>\n<p>이제 노드가 중단되었을 때 과정을 아래 그림을 통해 확인해보겠습니다.</p>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=13uYTCOGv5FG9RY4I_mkFMjpWubX9XVv_\" alt=\"spark-decom\"></p>\n<ol>\n<li>스팟 인스턴스가 중단되기 약 120초 전에 <code class=\"language-text\">Termination Handler</code>의 notice 발생</li>\n<li>driver가 해당 executor를 blacklist에 추가하고 신규 task의 스케줄링을 차단</li>\n<li>중단되는 노드에 있던 캐시된 데이터, 셔플 파일을 다른 노드로 복제</li>\n<li>실패 처리된 task를 이어서 수행 (복제한 파일을 그대로 활용)</li>\n</ol>\n<br>\n<p>위의 과정을 통해 노드가 중단되었을 때 재계산을 최소화 할 수 있습니다.<br>\n이 기능에는 다음과 같이 일부 제한 사항도 존재합니다.</p>\n<p>120초의 시간 제한이 있기 때문에 <strong>옮겨야할 파일이 아주 큰 경우, 일부 파일 손실이 발생</strong>할 수 있습니다. 일반적으로 non-SSD 볼륨은 분당 최대 15GB, SSD 볼륨은 35~40GB 까지 가능합니다. 동시에 많은 executor가 spot kill 당하는 경우, 동일한 이유로 파일 손실이 발생할 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">spark.decommission.enabled\nspark.storage.decommission.enabled\nspark.storage.decommission.rddBlocks.enabled\nspark.storage.decommission.shuffleBlocks.enabled</code></pre></div>\n<p><code class=\"language-text\">Graceful Executor Decommissioning</code>은 위의 설정을 통해 활성화 할 수 있습니다.</p>\n<p><br><br></p>\n<h2 id=\"spark-32-executor-pvc-reuse\" style=\"position:relative;\"><a href=\"#spark-32-executor-pvc-reuse\" aria-label=\"spark 32 executor pvc reuse permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Spark 3.2: Executor PVC Reuse</h2>\n<p><img src=\"https://drive.google.com/uc?export=view&#x26;id=10K0rCJi2wCrEwZSU00GUV4JozCf15ivw\" alt=\"spark-reuse\"></p>\n<p><code class=\"language-text\">Executor PVC Reuse</code>는 Spark 3.2 버전에 추가된 기능입니다.\n이 기능을 통해 spot kill 이후에도 <strong>동일한 PVC 연결을 통해 셔플 파일을 재사용</strong>할 수 있습니다. 이를 사용하려면 먼저 클러스터에 <code class=\"language-text\">Dynamic PVC</code>에 대한 설정이 필요합니다.</p>\n<p>현재는 NVMe 기반의 SSD에서 사용이 어렵다는 제한 사항이 있습니다.<br>\n또한 PVC가 즉시 재사용 불가능한 상황이라면 race condition이 발생할 수도 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">spark.kubernetes.driver.reusePersistentVolumeClaim\nspark.kubernetes.driver.ownPersistentVolumeClaim\nspark.kubernetes.executor.volumes.persistentVolumeClaim.data.options.*\nspark.kubernetes.executor.volumes.persistentVolumeClaim.data.mount.*</code></pre></div>\n<p>Executor PVC Reuse는 위의 설정을 통해 활성화 할 수 있습니다.</p>\n<br>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<ul>\n<li><a href=\"https://databricks.com/it/dataaisummit/session/how-make-apache-spark-kubernetes-run-reliably-spot-instances/\">https://databricks.com/it/dataaisummit/session/how-make-apache-spark-kubernetes-run-reliably-spot-instances/</a></li>\n<li><a href=\"https://issues.apache.org/jira/browse/SPARK-20624\">https://issues.apache.org/jira/browse/SPARK-20624</a></li>\n<li><a href=\"https://issues.apache.org/jira/browse/SPARK-35593\">https://issues.apache.org/jira/browse/SPARK-35593</a></li>\n</ul>","excerpt":"스팟 인스턴스 유형을 사용하면 온디맨드에 비해 70~90%의 비용을 절감할 수 있습니다.\n하지만 스팟 인스턴스는 가격 입찰, 가용성 등 여러 이유로 중단될 수 있습니다.\n따라서 스팟 인스턴스를 사용한다면 노드가 중단되는 상황에 대비할 수 있어야 합니다.\n이 글에서는 Spark on Kubernetes를 스팟 인스턴스 위에서 안정적으로 운영하기 위해 필요한 설정들을 정리해보려 합니다.  driver는 on-demand에 할당하기 중단된 노드에 있던 가 종료되는 경우, Spark…"}}}},"pageContext":{"slug":"spark-on-kubernetes-spot-instance","basePath":"","prev":null,"next":{"slug":"gpu-utilization","publishDate":"2022-07-08"}}}}